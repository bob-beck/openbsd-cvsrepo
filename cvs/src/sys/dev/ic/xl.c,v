head	1.132;
access;
symbols
	OPENBSD_6_1:1.132.0.2
	OPENBSD_6_1_BASE:1.132
	OPENBSD_6_0:1.131.0.4
	OPENBSD_6_0_BASE:1.131
	OPENBSD_5_9:1.130.0.2
	OPENBSD_5_9_BASE:1.130
	OPENBSD_5_8:1.125.0.4
	OPENBSD_5_8_BASE:1.125
	OPENBSD_5_7:1.121.0.2
	OPENBSD_5_7_BASE:1.121
	OPENBSD_5_6:1.115.0.4
	OPENBSD_5_6_BASE:1.115
	OPENBSD_5_5:1.112.0.4
	OPENBSD_5_5_BASE:1.112
	OPENBSD_5_4:1.109.0.2
	OPENBSD_5_4_BASE:1.109
	OPENBSD_5_3:1.107.0.2
	OPENBSD_5_3_BASE:1.107
	OPENBSD_5_2:1.105.0.2
	OPENBSD_5_2_BASE:1.105
	OPENBSD_5_1_BASE:1.104
	OPENBSD_5_1:1.104.0.6
	OPENBSD_5_0:1.104.0.2
	OPENBSD_5_0_BASE:1.104
	OPENBSD_4_9:1.99.0.2
	OPENBSD_4_9_BASE:1.99
	OPENBSD_4_8:1.90.0.2
	OPENBSD_4_8_BASE:1.90
	OPENBSD_4_7:1.88.0.2
	OPENBSD_4_7_BASE:1.88
	OPENBSD_4_6:1.86.0.4
	OPENBSD_4_6_BASE:1.86
	OPENBSD_4_5:1.85.0.2
	OPENBSD_4_5_BASE:1.85
	OPENBSD_4_4:1.79.0.2
	OPENBSD_4_4_BASE:1.79
	OPENBSD_4_3:1.78.0.4
	OPENBSD_4_3_BASE:1.78
	OPENBSD_4_2:1.78.0.2
	OPENBSD_4_2_BASE:1.78
	OPENBSD_4_1:1.76.0.4
	OPENBSD_4_1_BASE:1.76
	OPENBSD_4_0:1.76.0.2
	OPENBSD_4_0_BASE:1.76
	OPENBSD_3_9:1.70.0.2
	OPENBSD_3_9_BASE:1.70
	OPENBSD_3_8:1.65.0.2
	OPENBSD_3_8_BASE:1.65
	OPENBSD_3_7:1.62.0.2
	OPENBSD_3_7_BASE:1.62
	OPENBSD_3_6:1.54.0.2
	OPENBSD_3_6_BASE:1.54
	SMP_SYNC_A:1.54
	SMP_SYNC_B:1.54
	OPENBSD_3_5:1.51.0.2
	OPENBSD_3_5_BASE:1.51
	OPENBSD_3_4:1.50.0.2
	OPENBSD_3_4_BASE:1.50
	UBC_SYNC_A:1.49
	OPENBSD_3_3:1.49.0.2
	OPENBSD_3_3_BASE:1.49
	OPENBSD_3_2:1.41.0.2
	OPENBSD_3_2_BASE:1.41
	OPENBSD_3_1:1.35.0.2
	OPENBSD_3_1_BASE:1.35
	UBC_SYNC_B:1.41
	UBC:1.32.0.2
	UBC_BASE:1.32
	OPENBSD_3_0:1.30.0.2
	OPENBSD_3_0_BASE:1.30
	SMP:1.23.0.4
	OPENBSD_2_9_BASE:1.23
	OPENBSD_2_9:1.23.0.2
	OPENBSD_2_8:1.17.0.2
	OPENBSD_2_8_BASE:1.17
	OPENBSD_2_7:1.2.0.2
	OPENBSD_2_7_BASE:1.2;
locks; strict;
comment	@ * @;


1.132
date	2017.01.22.10.17.38;	author dlg;	state Exp;
branches;
next	1.131;
commitid	VyLWTsbepAOk7VQM;

1.131
date	2016.04.13.10.49.26;	author mpi;	state Exp;
branches;
next	1.130;
commitid	QHiEhS9DHyE6oiIr;

1.130
date	2015.11.25.03.09.58;	author dlg;	state Exp;
branches;
next	1.129;
commitid	B0kwmVGiD5DVx4kv;

1.129
date	2015.11.24.17.11.39;	author mpi;	state Exp;
branches;
next	1.128;
commitid	5gdEnqVoJuTuwdTu;

1.128
date	2015.11.24.13.33.17;	author mpi;	state Exp;
branches;
next	1.127;
commitid	5DvsamK0GblTp8ww;

1.127
date	2015.10.25.12.48.46;	author mpi;	state Exp;
branches;
next	1.126;
commitid	p0v5tuE1Ch6fY0Nj;

1.126
date	2015.09.11.13.02.28;	author stsp;	state Exp;
branches;
next	1.125;
commitid	6vhYvh5CxZAHMnsN;

1.125
date	2015.06.24.09.40.54;	author mpi;	state Exp;
branches;
next	1.124;
commitid	MVWrtktB46JRxFWT;

1.124
date	2015.05.21.09.25.18;	author mpi;	state Exp;
branches;
next	1.123;
commitid	5znBuRM8DVpazbqf;

1.123
date	2015.03.24.11.23.02;	author mpi;	state Exp;
branches;
next	1.122;
commitid	avoArcjHOhqa0gil;

1.122
date	2015.03.14.03.38.47;	author jsg;	state Exp;
branches;
next	1.121;
commitid	p4LJxGKbi0BU2cG6;

1.121
date	2014.12.22.02.28.51;	author tedu;	state Exp;
branches;
next	1.120;
commitid	yM2VFFhpDTeFQlve;

1.120
date	2014.12.19.07.23.57;	author deraadt;	state Exp;
branches;
next	1.119;
commitid	cV4v1OA8Ccwr5fwb;

1.119
date	2014.12.08.10.58.45;	author brad;	state Exp;
branches;
next	1.118;
commitid	2lOR2VAGPukFfE5p;

1.118
date	2014.11.24.10.33.37;	author brad;	state Exp;
branches;
next	1.117;
commitid	n3mk3gi6o2NDYPpC;

1.117
date	2014.11.24.03.47.55;	author brad;	state Exp;
branches;
next	1.116;
commitid	e5pJ2UhHHklHiyKO;

1.116
date	2014.09.14.14.17.25;	author jsg;	state Exp;
branches;
next	1.115;
commitid	uzzBR7hz9ncd4O6G;

1.115
date	2014.07.22.13.12.12;	author mpi;	state Exp;
branches;
next	1.114;
commitid	TGHgrLxu6sxZoiFt;

1.114
date	2014.07.08.05.35.18;	author dlg;	state Exp;
branches;
next	1.113;
commitid	0QJleeeWqZmC5anF;

1.113
date	2014.05.30.19.51.22;	author chl;	state Exp;
branches;
next	1.112;

1.112
date	2013.12.28.03.35.01;	author deraadt;	state Exp;
branches;
next	1.111;

1.111
date	2013.12.06.21.03.03;	author deraadt;	state Exp;
branches;
next	1.110;

1.110
date	2013.08.07.01.06.31;	author bluhm;	state Exp;
branches;
next	1.109;

1.109
date	2013.03.14.01.42.45;	author brad;	state Exp;
branches;
next	1.108;

1.108
date	2013.03.07.05.55.30;	author brad;	state Exp;
branches;
next	1.107;

1.107
date	2012.10.19.02.49.55;	author brad;	state Exp;
branches;
next	1.106;

1.106
date	2012.10.13.17.24.46;	author deraadt;	state Exp;
branches;
next	1.105;

1.105
date	2012.02.24.06.19.00;	author guenther;	state Exp;
branches;
next	1.104;

1.104
date	2011.07.14.16.38.27;	author stsp;	state Exp;
branches;
next	1.103;

1.103
date	2011.07.08.18.56.47;	author stsp;	state Exp;
branches;
next	1.102;

1.102
date	2011.06.21.16.52.45;	author tedu;	state Exp;
branches;
next	1.101;

1.101
date	2011.04.17.20.52.43;	author stsp;	state Exp;
branches;
next	1.100;

1.100
date	2011.04.05.18.01.21;	author henning;	state Exp;
branches;
next	1.99;

1.99
date	2010.09.22.08.49.14;	author claudio;	state Exp;
branches;
next	1.98;

1.98
date	2010.09.21.01.05.12;	author claudio;	state Exp;
branches;
next	1.97;

1.97
date	2010.09.20.07.40.41;	author deraadt;	state Exp;
branches;
next	1.96;

1.96
date	2010.09.07.16.21.43;	author deraadt;	state Exp;
branches;
next	1.95;

1.95
date	2010.09.06.16.01.52;	author deraadt;	state Exp;
branches;
next	1.94;

1.94
date	2010.08.31.17.13.47;	author deraadt;	state Exp;
branches;
next	1.93;

1.93
date	2010.08.31.16.29.56;	author deraadt;	state Exp;
branches;
next	1.92;

1.92
date	2010.08.27.15.43.41;	author deraadt;	state Exp;
branches;
next	1.91;

1.91
date	2010.08.12.14.21.55;	author kettenis;	state Exp;
branches;
next	1.90;

1.90
date	2010.08.06.02.45.53;	author deraadt;	state Exp;
branches;
next	1.89;

1.89
date	2010.05.19.15.27.35;	author oga;	state Exp;
branches;
next	1.88;

1.88
date	2009.12.22.21.10.25;	author naddy;	state Exp;
branches;
next	1.87;

1.87
date	2009.10.15.17.54.54;	author deraadt;	state Exp;
branches;
next	1.86;

1.86
date	2009.06.02.07.55.10;	author deraadt;	state Exp;
branches;
next	1.85;

1.85
date	2008.11.28.02.44.17;	author brad;	state Exp;
branches;
next	1.84;

1.84
date	2008.11.19.08.20.01;	author brad;	state Exp;
branches;
next	1.83;

1.83
date	2008.11.19.08.17.37;	author brad;	state Exp;
branches;
next	1.82;

1.82
date	2008.10.02.20.21.13;	author brad;	state Exp;
branches;
next	1.81;

1.81
date	2008.09.18.15.16.30;	author naddy;	state Exp;
branches;
next	1.80;

1.80
date	2008.09.10.14.01.22;	author blambert;	state Exp;
branches;
next	1.79;

1.79
date	2008.05.11.03.01.29;	author brad;	state Exp;
branches;
next	1.78;

1.78
date	2007.05.19.16.51.57;	author kettenis;	state Exp;
branches;
next	1.77;

1.77
date	2007.05.05.13.24.04;	author deraadt;	state Exp;
branches;
next	1.76;

1.76
date	2006.08.10.20.10.18;	author brad;	state Exp;
branches;
next	1.75;

1.75
date	2006.08.10.18.40.54;	author brad;	state Exp;
branches;
next	1.74;

1.74
date	2006.05.27.20.40.34;	author brad;	state Exp;
branches;
next	1.73;

1.73
date	2006.05.22.20.35.12;	author krw;	state Exp;
branches;
next	1.72;

1.72
date	2006.03.25.22.41.43;	author djm;	state Exp;
branches;
next	1.71;

1.71
date	2006.03.04.23.31.20;	author brad;	state Exp;
branches;
next	1.70;

1.70
date	2006.01.20.05.49.32;	author brad;	state Exp;
branches;
next	1.69;

1.69
date	2006.01.11.04.19.42;	author brad;	state Exp;
branches;
next	1.68;

1.68
date	2006.01.11.04.15.20;	author brad;	state Exp;
branches;
next	1.67;

1.67
date	2006.01.11.03.57.50;	author brad;	state Exp;
branches;
next	1.66;

1.66
date	2005.11.07.03.20.00;	author brad;	state Exp;
branches;
next	1.65;

1.65
date	2005.07.02.23.10.16;	author brad;	state Exp;
branches;
next	1.64;

1.64
date	2005.04.25.17.55.51;	author brad;	state Exp;
branches;
next	1.63;

1.63
date	2005.04.23.22.51.28;	author brad;	state Exp;
branches;
next	1.62;

1.62
date	2005.01.15.05.24.11;	author brad;	state Exp;
branches;
next	1.61;

1.61
date	2004.11.01.02.03.45;	author brad;	state Exp;
branches;
next	1.60;

1.60
date	2004.10.31.17.41.01;	author brad;	state Exp;
branches;
next	1.59;

1.59
date	2004.10.23.05.14.33;	author brad;	state Exp;
branches;
next	1.58;

1.58
date	2004.10.23.05.12.55;	author brad;	state Exp;
branches;
next	1.57;

1.57
date	2004.10.02.16.44.23;	author brad;	state Exp;
branches;
next	1.56;

1.56
date	2004.09.28.05.14.44;	author brad;	state Exp;
branches;
next	1.55;

1.55
date	2004.09.23.17.45.16;	author brad;	state Exp;
branches;
next	1.54;

1.54
date	2004.06.04.21.49.02;	author brad;	state Exp;
branches
	1.54.2.1;
next	1.53;

1.53
date	2004.06.01.20.59.25;	author mickey;	state Exp;
branches;
next	1.52;

1.52
date	2004.05.30.23.49.39;	author brad;	state Exp;
branches;
next	1.51;

1.51
date	2003.10.21.18.58.50;	author jmc;	state Exp;
branches;
next	1.50;

1.50
date	2003.06.29.16.39.02;	author jason;	state Exp;
branches;
next	1.49;

1.49
date	2003.03.24.17.40.00;	author jason;	state Exp;
branches;
next	1.48;

1.48
date	2003.01.05.20.07.44;	author deraadt;	state Exp;
branches;
next	1.47;

1.47
date	2002.12.02.22.04.38;	author jason;	state Exp;
branches;
next	1.46;

1.46
date	2002.11.25.16.07.08;	author brad;	state Exp;
branches;
next	1.45;

1.45
date	2002.11.17.02.46.17;	author jason;	state Exp;
branches;
next	1.44;

1.44
date	2002.11.17.02.41.30;	author jason;	state Exp;
branches;
next	1.43;

1.43
date	2002.11.17.02.34.52;	author jason;	state Exp;
branches;
next	1.42;

1.42
date	2002.11.17.02.06.28;	author jason;	state Exp;
branches;
next	1.41;

1.41
date	2002.08.22.19.08.50;	author jason;	state Exp;
branches;
next	1.40;

1.40
date	2002.07.09.05.49.53;	author aaron;	state Exp;
branches;
next	1.39;

1.39
date	2002.06.15.19.35.29;	author aaron;	state Exp;
branches;
next	1.38;

1.38
date	2002.06.15.05.14.41;	author aaron;	state Exp;
branches;
next	1.37;

1.37
date	2002.06.09.03.14.18;	author todd;	state Exp;
branches;
next	1.36;

1.36
date	2002.06.08.23.38.51;	author aaron;	state Exp;
branches;
next	1.35;

1.35
date	2002.03.14.01.26.55;	author millert;	state Exp;
branches;
next	1.34;

1.34
date	2002.02.15.20.45.31;	author nordin;	state Exp;
branches;
next	1.33;

1.33
date	2002.01.25.05.44.06;	author nordin;	state Exp;
branches;
next	1.32;

1.32
date	2001.12.15.05.33.53;	author nordin;	state Exp;
branches
	1.32.2.1;
next	1.31;

1.31
date	2001.11.06.19.53.18;	author miod;	state Exp;
branches;
next	1.30;

1.30
date	2001.08.19.18.07.33;	author jason;	state Exp;
branches;
next	1.29;

1.29
date	2001.08.19.01.45.55;	author jason;	state Exp;
branches;
next	1.28;

1.28
date	2001.08.12.20.12.12;	author mickey;	state Exp;
branches;
next	1.27;

1.27
date	2001.08.03.23.31.52;	author chris;	state Exp;
branches;
next	1.26;

1.26
date	2001.07.02.01.28.21;	author jason;	state Exp;
branches;
next	1.25;

1.25
date	2001.06.27.06.34.43;	author kjc;	state Exp;
branches;
next	1.24;

1.24
date	2001.06.23.23.17.35;	author fgsch;	state Exp;
branches;
next	1.23;

1.23
date	2001.04.08.01.05.12;	author aaron;	state Exp;
branches
	1.23.4.1;
next	1.22;

1.22
date	2001.03.25.06.27.44;	author csapuntz;	state Exp;
branches;
next	1.21;

1.21
date	2001.02.20.19.39.38;	author mickey;	state Exp;
branches;
next	1.20;

1.20
date	2001.02.02.08.35.31;	author aaron;	state Exp;
branches;
next	1.19;

1.19
date	2001.01.12.21.48.25;	author todd;	state Exp;
branches;
next	1.18;

1.18
date	2000.11.09.17.39.06;	author mickey;	state Exp;
branches;
next	1.17;

1.17
date	2000.10.19.16.33.51;	author jason;	state Exp;
branches;
next	1.16;

1.16
date	2000.10.16.17.08.07;	author aaron;	state Exp;
branches;
next	1.15;

1.15
date	2000.10.15.18.46.02;	author aaron;	state Exp;
branches;
next	1.14;

1.14
date	2000.10.14.18.10.37;	author aaron;	state Exp;
branches;
next	1.13;

1.13
date	2000.10.13.15.02.02;	author aaron;	state Exp;
branches;
next	1.12;

1.12
date	2000.10.07.16.15.11;	author aaron;	state Exp;
branches;
next	1.11;

1.11
date	2000.09.30.14.07.10;	author aaron;	state Exp;
branches;
next	1.10;

1.10
date	2000.09.29.05.28.28;	author aaron;	state Exp;
branches;
next	1.9;

1.9
date	2000.09.16.21.50.56;	author aaron;	state Exp;
branches;
next	1.8;

1.8
date	2000.09.16.21.48.46;	author aaron;	state Exp;
branches;
next	1.7;

1.7
date	2000.09.16.21.42.16;	author aaron;	state Exp;
branches;
next	1.6;

1.6
date	2000.09.05.18.18.49;	author aaron;	state Exp;
branches;
next	1.5;

1.5
date	2000.07.01.03.19.14;	author aaron;	state Exp;
branches;
next	1.4;

1.4
date	2000.06.29.14.07.03;	author jason;	state Exp;
branches;
next	1.3;

1.3
date	2000.06.22.08.24.02;	author itojun;	state Exp;
branches;
next	1.2;

1.2
date	2000.04.18.14.32.49;	author aaron;	state Exp;
branches
	1.2.2.1;
next	1.1;

1.1
date	2000.04.08.05.50.50;	author aaron;	state Exp;
branches;
next	;

1.2.2.1
date	2000.06.28.17.42.04;	author jason;	state Exp;
branches;
next	1.2.2.2;

1.2.2.2
date	2000.07.01.05.10.34;	author jason;	state Exp;
branches;
next	;

1.23.4.1
date	2001.05.14.22.24.26;	author niklas;	state Exp;
branches;
next	1.23.4.2;

1.23.4.2
date	2001.07.04.10.41.21;	author niklas;	state Exp;
branches;
next	1.23.4.3;

1.23.4.3
date	2001.10.31.03.22.43;	author nate;	state Exp;
branches;
next	1.23.4.4;

1.23.4.4
date	2001.11.13.21.10.01;	author niklas;	state Exp;
branches;
next	1.23.4.5;

1.23.4.5
date	2002.03.06.02.11.43;	author niklas;	state Exp;
branches;
next	1.23.4.6;

1.23.4.6
date	2002.03.28.12.11.34;	author niklas;	state Exp;
branches;
next	1.23.4.7;

1.23.4.7
date	2003.03.28.00.38.15;	author niklas;	state Exp;
branches;
next	1.23.4.8;

1.23.4.8
date	2004.02.19.10.56.21;	author niklas;	state Exp;
branches;
next	1.23.4.9;

1.23.4.9
date	2004.06.05.23.12.44;	author niklas;	state Exp;
branches;
next	;

1.32.2.1
date	2002.01.31.22.55.32;	author niklas;	state Exp;
branches;
next	1.32.2.2;

1.32.2.2
date	2002.06.11.03.42.20;	author art;	state Exp;
branches;
next	1.32.2.3;

1.32.2.3
date	2002.10.29.00.33.26;	author art;	state Exp;
branches;
next	1.32.2.4;

1.32.2.4
date	2003.05.19.21.59.43;	author tedu;	state Exp;
branches;
next	;

1.54.2.1
date	2004.11.21.18.57.42;	author brad;	state Exp;
branches;
next	;


desc
@@


1.132
log
@move counting if_opackets next to counting if_obytes in if_enqueue.

this means packets are consistently counted in one place, unlike the
many and various ways that drivers thought they should do it.

ok mpi@@ deraadt@@
@
text
@/*	$OpenBSD: xl.c,v 1.131 2016/04/13 10:49:26 mpi Exp $	*/

/*
 * Copyright (c) 1997, 1998, 1999
 *	Bill Paul <wpaul@@ctr.columbia.edu>.  All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by Bill Paul.
 * 4. Neither the name of the author nor the names of any co-contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY Bill Paul AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL Bill Paul OR THE VOICES IN HIS HEAD
 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
 * THE POSSIBILITY OF SUCH DAMAGE.
 *
 * $FreeBSD: if_xl.c,v 1.77 2000/08/28 20:40:03 wpaul Exp $
 */

/*
 * 3Com 3c90x Etherlink XL PCI NIC driver
 *
 * Supports the 3Com "boomerang", "cyclone", and "hurricane" PCI
 * bus-master chips (3c90x cards and embedded controllers) including
 * the following:
 *
 * 3Com 3c900-TPO	10Mbps/RJ-45
 * 3Com 3c900-COMBO	10Mbps/RJ-45,AUI,BNC
 * 3Com 3c905-TX	10/100Mbps/RJ-45
 * 3Com 3c905-T4	10/100Mbps/RJ-45
 * 3Com 3c900B-TPO	10Mbps/RJ-45
 * 3Com 3c900B-COMBO	10Mbps/RJ-45,AUI,BNC
 * 3Com 3c900B-TPC	10Mbps/RJ-45,BNC
 * 3Com 3c900B-FL	10Mbps/Fiber-optic
 * 3Com 3c905B-COMBO	10/100Mbps/RJ-45,AUI,BNC
 * 3Com 3c905B-TX	10/100Mbps/RJ-45
 * 3Com 3c905B-FL/FX	10/100Mbps/Fiber-optic
 * 3Com 3c905C-TX	10/100Mbps/RJ-45 (Tornado ASIC)
 * 3Com 3c980-TX	10/100Mbps server adapter (Hurricane ASIC)
 * 3Com 3c980C-TX	10/100Mbps server adapter (Tornado ASIC)
 * 3Com 3cSOHO100-TX	10/100Mbps/RJ-45 (Hurricane ASIC)
 * 3Com 3c450-TX	10/100Mbps/RJ-45 (Tornado ASIC)
 * 3Com 3c555		10/100Mbps/RJ-45 (MiniPCI, Laptop Hurricane)
 * 3Com 3c556		10/100Mbps/RJ-45 (MiniPCI, Hurricane ASIC)
 * 3Com 3c556B		10/100Mbps/RJ-45 (MiniPCI, Hurricane ASIC)
 * 3Com 3c575TX		10/100Mbps/RJ-45 (Cardbus, Hurricane ASIC)
 * 3Com 3c575B		10/100Mbps/RJ-45 (Cardbus, Hurricane ASIC)
 * 3Com 3c575C		10/100Mbps/RJ-45 (Cardbus, Hurricane ASIC)
 * 3Com 3cxfem656	10/100Mbps/RJ-45 (Cardbus, Hurricane ASIC)
 * 3Com 3cxfem656b	10/100Mbps/RJ-45 (Cardbus, Hurricane ASIC)
 * 3Com 3cxfem656c	10/100Mbps/RJ-45 (Cardbus, Tornado ASIC)
 * Dell Optiplex GX1 on-board 3c918 10/100Mbps/RJ-45
 * Dell on-board 3c920 10/100Mbps/RJ-45
 * Dell Precision on-board 3c905B 10/100Mbps/RJ-45
 * Dell Latitude laptop docking station embedded 3c905-TX
 *
 * Written by Bill Paul <wpaul@@ctr.columbia.edu>
 * Electrical Engineering Department
 * Columbia University, New York City
 */

/*
 * The 3c90x series chips use a bus-master DMA interface for transferring
 * packets to and from the controller chip. Some of the "vortex" cards
 * (3c59x) also supported a bus master mode, however for those chips
 * you could only DMA packets to/from a contiguous memory buffer. For
 * transmission this would mean copying the contents of the queued mbuf
 * chain into an mbuf cluster and then DMAing the cluster. This extra
 * copy would sort of defeat the purpose of the bus master support for
 * any packet that doesn't fit into a single mbuf.
 *
 * By contrast, the 3c90x cards support a fragment-based bus master
 * mode where mbuf chains can be encapsulated using TX descriptors.
 * This is similar to other PCI chips such as the Texas Instruments
 * ThunderLAN and the Intel 82557/82558.
 *
 * The "vortex" driver (if_vx.c) happens to work for the "boomerang"
 * bus master chips because they maintain the old PIO interface for
 * backwards compatibility, but starting with the 3c905B and the
 * "cyclone" chips, the compatibility interface has been dropped.
 * Since using bus master DMA is a big win, we use this driver to
 * support the PCI "boomerang" chips even though they work with the
 * "vortex" driver in order to obtain better performance.
 */

#include "bpfilter.h"

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/mbuf.h>
#include <sys/protosw.h>
#include <sys/socket.h>
#include <sys/ioctl.h>
#include <sys/errno.h>
#include <sys/malloc.h>
#include <sys/kernel.h>
#include <sys/device.h>

#include <net/if.h>
#include <net/if_media.h>

#include <netinet/in.h>
#include <netinet/if_ether.h>

#include <dev/mii/miivar.h>

#include <machine/bus.h>

#if NBPFILTER > 0
#include <net/bpf.h>
#endif

#include <dev/ic/xlreg.h>

/* 
 * TX Checksumming is disabled by default for two reasons:
 * - TX Checksumming will occasionally produce corrupt packets
 * - TX Checksumming seems to reduce performance
 *
 * Only 905B/C cards were reported to have this problem, it is possible
 * that later chips _may_ be immune.
 */
#define	XL905B_TXCSUM_BROKEN	1

int xl_newbuf(struct xl_softc *, struct xl_chain_onefrag *);
void xl_stats_update(void *);
int xl_encap(struct xl_softc *, struct xl_chain *,
    struct mbuf * );
void xl_rxeof(struct xl_softc *);
void xl_txeof(struct xl_softc *);
void xl_txeof_90xB(struct xl_softc *);
void xl_txeoc(struct xl_softc *);
int xl_intr(void *);
void xl_start(struct ifnet *);
void xl_start_90xB(struct ifnet *);
int xl_ioctl(struct ifnet *, u_long, caddr_t);
void xl_freetxrx(struct xl_softc *);
void xl_watchdog(struct ifnet *);
int xl_ifmedia_upd(struct ifnet *);
void xl_ifmedia_sts(struct ifnet *, struct ifmediareq *);

int xl_eeprom_wait(struct xl_softc *);
int xl_read_eeprom(struct xl_softc *, caddr_t, int, int, int);
void xl_mii_sync(struct xl_softc *);
void xl_mii_send(struct xl_softc *, u_int32_t, int);
int xl_mii_readreg(struct xl_softc *, struct xl_mii_frame *);
int xl_mii_writereg(struct xl_softc *, struct xl_mii_frame *);

void xl_setcfg(struct xl_softc *);
void xl_setmode(struct xl_softc *, uint64_t);
void xl_iff(struct xl_softc *);
void xl_iff_90x(struct xl_softc *);
void xl_iff_905b(struct xl_softc *);
int xl_list_rx_init(struct xl_softc *);
void xl_fill_rx_ring(struct xl_softc *);
int xl_list_tx_init(struct xl_softc *);
int xl_list_tx_init_90xB(struct xl_softc *);
void xl_wait(struct xl_softc *);
void xl_mediacheck(struct xl_softc *);
void xl_choose_xcvr(struct xl_softc *, int);

int xl_miibus_readreg(struct device *, int, int);
void xl_miibus_writereg(struct device *, int, int, int);
void xl_miibus_statchg(struct device *);
#ifndef SMALL_KERNEL
int xl_wol(struct ifnet *, int);
void xl_wol_power(struct xl_softc *);
#endif

int
xl_activate(struct device *self, int act)
{
	struct xl_softc *sc = (struct xl_softc *)self;
	struct ifnet	*ifp = &sc->sc_arpcom.ac_if;
	int rv = 0;

	switch (act) {
	case DVACT_SUSPEND:
		if (ifp->if_flags & IFF_RUNNING)
			xl_stop(sc);
		rv = config_activate_children(self, act);
		break;
	case DVACT_RESUME:
		if (ifp->if_flags & IFF_UP)
			xl_init(sc);
		break;
	case DVACT_POWERDOWN:
		rv = config_activate_children(self, act);
#ifndef SMALL_KERNEL
		xl_wol_power(sc);
#endif
		break;
	default:
		rv = config_activate_children(self, act);
		break;
	}
	return (rv);
}

/*
 * Murphy's law says that it's possible the chip can wedge and
 * the 'command in progress' bit may never clear. Hence, we wait
 * only a finite amount of time to avoid getting caught in an
 * infinite loop. Normally this delay routine would be a macro,
 * but it isn't called during normal operation so we can afford
 * to make it a function.
 */
void
xl_wait(struct xl_softc *sc)
{
	int	i;

	for (i = 0; i < XL_TIMEOUT; i++) {
		if (!(CSR_READ_2(sc, XL_STATUS) & XL_STAT_CMDBUSY))
			break;
	}

	if (i == XL_TIMEOUT)
		printf("%s: command never completed!\n", sc->sc_dev.dv_xname);
}

/*
 * MII access routines are provided for adapters with external
 * PHYs (3c905-TX, 3c905-T4, 3c905B-T4) and those with built-in
 * autoneg logic that's faked up to look like a PHY (3c905B-TX).
 * Note: if you don't perform the MDIO operations just right,
 * it's possible to end up with code that works correctly with
 * some chips/CPUs/processor speeds/bus speeds/etc but not
 * with others.
 */
#define MII_SET(x)					\
	CSR_WRITE_2(sc, XL_W4_PHY_MGMT,			\
		CSR_READ_2(sc, XL_W4_PHY_MGMT) | (x))

#define MII_CLR(x)					\
	CSR_WRITE_2(sc, XL_W4_PHY_MGMT,			\
		CSR_READ_2(sc, XL_W4_PHY_MGMT) & ~(x))

/*
 * Sync the PHYs by setting data bit and strobing the clock 32 times.
 */
void
xl_mii_sync(struct xl_softc *sc)
{
	int	i;

	XL_SEL_WIN(4);
	MII_SET(XL_MII_DIR|XL_MII_DATA);

	for (i = 0; i < 32; i++) {
		MII_SET(XL_MII_CLK);
		MII_SET(XL_MII_DATA);
		MII_SET(XL_MII_DATA);
		MII_CLR(XL_MII_CLK);
		MII_SET(XL_MII_DATA);
		MII_SET(XL_MII_DATA);
	}
}

/*
 * Clock a series of bits through the MII.
 */
void
xl_mii_send(struct xl_softc *sc, u_int32_t bits, int cnt)
{
	int	i;

	XL_SEL_WIN(4);
	MII_CLR(XL_MII_CLK);

	for (i = (0x1 << (cnt - 1)); i; i >>= 1) {
                if (bits & i) {
			MII_SET(XL_MII_DATA);
                } else {
			MII_CLR(XL_MII_DATA);
                }
		MII_CLR(XL_MII_CLK);
		MII_SET(XL_MII_CLK);
	}
}

/*
 * Read an PHY register through the MII.
 */
int
xl_mii_readreg(struct xl_softc *sc, struct xl_mii_frame *frame)
{
	int	i, ack, s;

	s = splnet();

	/*
	 * Set up frame for RX.
	 */
	frame->mii_stdelim = XL_MII_STARTDELIM;
	frame->mii_opcode = XL_MII_READOP;
	frame->mii_turnaround = 0;
	frame->mii_data = 0;
	
	/*
	 * Select register window 4.
	 */

	XL_SEL_WIN(4);

	CSR_WRITE_2(sc, XL_W4_PHY_MGMT, 0);
	/*
 	 * Turn on data xmit.
	 */
	MII_SET(XL_MII_DIR);

	xl_mii_sync(sc);

	/*
	 * Send command/address info.
	 */
	xl_mii_send(sc, frame->mii_stdelim, 2);
	xl_mii_send(sc, frame->mii_opcode, 2);
	xl_mii_send(sc, frame->mii_phyaddr, 5);
	xl_mii_send(sc, frame->mii_regaddr, 5);

	/* Idle bit */
	MII_CLR((XL_MII_CLK|XL_MII_DATA));
	MII_SET(XL_MII_CLK);

	/* Turn off xmit. */
	MII_CLR(XL_MII_DIR);

	/* Check for ack */
	MII_CLR(XL_MII_CLK);
	ack = CSR_READ_2(sc, XL_W4_PHY_MGMT) & XL_MII_DATA;
	MII_SET(XL_MII_CLK);

	/*
	 * Now try reading data bits. If the ack failed, we still
	 * need to clock through 16 cycles to keep the PHY(s) in sync.
	 */
	if (ack) {
		for(i = 0; i < 16; i++) {
			MII_CLR(XL_MII_CLK);
			MII_SET(XL_MII_CLK);
		}
		goto fail;
	}

	for (i = 0x8000; i; i >>= 1) {
		MII_CLR(XL_MII_CLK);
		if (!ack) {
			if (CSR_READ_2(sc, XL_W4_PHY_MGMT) & XL_MII_DATA)
				frame->mii_data |= i;
		}
		MII_SET(XL_MII_CLK);
	}

fail:

	MII_CLR(XL_MII_CLK);
	MII_SET(XL_MII_CLK);

	splx(s);

	if (ack)
		return (1);
	return (0);
}

/*
 * Write to a PHY register through the MII.
 */
int
xl_mii_writereg(struct xl_softc *sc, struct xl_mii_frame *frame)
{
	int	s;

	s = splnet();

	/*
	 * Set up frame for TX.
	 */

	frame->mii_stdelim = XL_MII_STARTDELIM;
	frame->mii_opcode = XL_MII_WRITEOP;
	frame->mii_turnaround = XL_MII_TURNAROUND;
	
	/*
	 * Select the window 4.
	 */
	XL_SEL_WIN(4);

	/*
 	 * Turn on data output.
	 */
	MII_SET(XL_MII_DIR);

	xl_mii_sync(sc);

	xl_mii_send(sc, frame->mii_stdelim, 2);
	xl_mii_send(sc, frame->mii_opcode, 2);
	xl_mii_send(sc, frame->mii_phyaddr, 5);
	xl_mii_send(sc, frame->mii_regaddr, 5);
	xl_mii_send(sc, frame->mii_turnaround, 2);
	xl_mii_send(sc, frame->mii_data, 16);

	/* Idle bit. */
	MII_SET(XL_MII_CLK);
	MII_CLR(XL_MII_CLK);

	/*
	 * Turn off xmit.
	 */
	MII_CLR(XL_MII_DIR);

	splx(s);

	return (0);
}

int
xl_miibus_readreg(struct device *self, int phy, int reg)
{
	struct xl_softc *sc = (struct xl_softc *)self;
	struct xl_mii_frame	frame;

	if (!(sc->xl_flags & XL_FLAG_PHYOK) && phy != 24)
		return (0);

	bzero(&frame, sizeof(frame));

	frame.mii_phyaddr = phy;
	frame.mii_regaddr = reg;
	xl_mii_readreg(sc, &frame);

	return (frame.mii_data);
}

void
xl_miibus_writereg(struct device *self, int phy, int reg, int data)
{
	struct xl_softc *sc = (struct xl_softc *)self;
	struct xl_mii_frame	frame;

	if (!(sc->xl_flags & XL_FLAG_PHYOK) && phy != 24)
		return;

	bzero(&frame, sizeof(frame));

	frame.mii_phyaddr = phy;
	frame.mii_regaddr = reg;
	frame.mii_data = data;

	xl_mii_writereg(sc, &frame);
}

void
xl_miibus_statchg(struct device *self)
{
	struct xl_softc *sc = (struct xl_softc *)self;

	xl_setcfg(sc);

	/* Set ASIC's duplex mode to match the PHY. */
	XL_SEL_WIN(3);
	if ((sc->sc_mii.mii_media_active & IFM_GMASK) == IFM_FDX)
		CSR_WRITE_1(sc, XL_W3_MAC_CTRL, XL_MACCTRL_DUPLEX);
	else
		CSR_WRITE_1(sc, XL_W3_MAC_CTRL,
		    (CSR_READ_1(sc, XL_W3_MAC_CTRL) & ~XL_MACCTRL_DUPLEX));
}

/*
 * The EEPROM is slow: give it time to come ready after issuing
 * it a command.
 */
int
xl_eeprom_wait(struct xl_softc *sc)
{
	int	i;

	for (i = 0; i < 100; i++) {
		if (CSR_READ_2(sc, XL_W0_EE_CMD) & XL_EE_BUSY)
			DELAY(162);
		else
			break;
	}

	if (i == 100) {
		printf("%s: eeprom failed to come ready\n", sc->sc_dev.dv_xname);
		return (1);
	}

	return (0);
}

/*
 * Read a sequence of words from the EEPROM. Note that ethernet address
 * data is stored in the EEPROM in network byte order.
 */
int
xl_read_eeprom(struct xl_softc *sc, caddr_t dest, int off, int cnt, int swap)
{
	int		err = 0, i;
	u_int16_t	word = 0, *ptr;
#define EEPROM_5BIT_OFFSET(A) ((((A) << 2) & 0x7F00) | ((A) & 0x003F))
#define EEPROM_8BIT_OFFSET(A) ((A) & 0x003F)
	/* WARNING! DANGER!
	 * It's easy to accidentally overwrite the rom content!
	 * Note: the 3c575 uses 8bit EEPROM offsets.
	 */
	XL_SEL_WIN(0);

	if (xl_eeprom_wait(sc))
		return (1);

	if (sc->xl_flags & XL_FLAG_EEPROM_OFFSET_30)
		off += 0x30;

	for (i = 0; i < cnt; i++) {
		if (sc->xl_flags & XL_FLAG_8BITROM)
			CSR_WRITE_2(sc, XL_W0_EE_CMD,
			    XL_EE_8BIT_READ | EEPROM_8BIT_OFFSET(off + i));
		else
			CSR_WRITE_2(sc, XL_W0_EE_CMD,
			    XL_EE_READ | EEPROM_5BIT_OFFSET(off + i));
		err = xl_eeprom_wait(sc);
		if (err)
			break;
		word = CSR_READ_2(sc, XL_W0_EE_DATA);
		ptr = (u_int16_t *)(dest + (i * 2));
		if (swap)
			*ptr = ntohs(word);
		else
			*ptr = word;	
	}

	return (err ? 1 : 0);
}

void
xl_iff(struct xl_softc *sc)
{
	if (sc->xl_type == XL_TYPE_905B)
		xl_iff_905b(sc);
	else
		xl_iff_90x(sc);
}

/*
 * NICs older than the 3c905B have only one multicast option, which
 * is to enable reception of all multicast frames.
 */
void
xl_iff_90x(struct xl_softc *sc)
{
	struct ifnet	*ifp = &sc->sc_arpcom.ac_if;
	struct arpcom	*ac = &sc->sc_arpcom;
	u_int8_t	rxfilt;

	XL_SEL_WIN(5);

	rxfilt = CSR_READ_1(sc, XL_W5_RX_FILTER);
	rxfilt &= ~(XL_RXFILTER_ALLFRAMES | XL_RXFILTER_ALLMULTI |
	    XL_RXFILTER_BROADCAST | XL_RXFILTER_INDIVIDUAL);
	ifp->if_flags &= ~IFF_ALLMULTI;

	/*
	 * Always accept broadcast frames.
	 * Always accept frames destined to our station address.
	 */
	rxfilt |= XL_RXFILTER_BROADCAST | XL_RXFILTER_INDIVIDUAL;

	if (ifp->if_flags & IFF_PROMISC || ac->ac_multicnt > 0) {
		ifp->if_flags |= IFF_ALLMULTI;
		if (ifp->if_flags & IFF_PROMISC)
			rxfilt |= XL_RXFILTER_ALLFRAMES;
		else
			rxfilt |= XL_RXFILTER_ALLMULTI;
	}

	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_SET_FILT | rxfilt);

	XL_SEL_WIN(7);
}

/*
 * 3c905B adapters have a hash filter that we can program.
 */
void
xl_iff_905b(struct xl_softc *sc)
{
	struct ifnet	*ifp = &sc->sc_arpcom.ac_if;
	struct arpcom	*ac = &sc->sc_arpcom;
	int		h = 0, i;
	struct ether_multi *enm;
	struct ether_multistep step;
	u_int8_t	rxfilt;

	XL_SEL_WIN(5);

	rxfilt = CSR_READ_1(sc, XL_W5_RX_FILTER);
	rxfilt &= ~(XL_RXFILTER_ALLFRAMES | XL_RXFILTER_ALLMULTI |
	    XL_RXFILTER_BROADCAST | XL_RXFILTER_INDIVIDUAL |
	    XL_RXFILTER_MULTIHASH);
	ifp->if_flags &= ~IFF_ALLMULTI;

	/*
	 * Always accept broadcast frames.
	 * Always accept frames destined to our station address.
	 */
	rxfilt |= XL_RXFILTER_BROADCAST | XL_RXFILTER_INDIVIDUAL;

	if (ifp->if_flags & IFF_PROMISC || ac->ac_multirangecnt > 0) {
		ifp->if_flags |= IFF_ALLMULTI;
		if (ifp->if_flags & IFF_PROMISC)
			rxfilt |= XL_RXFILTER_ALLFRAMES;
		else
			rxfilt |= XL_RXFILTER_ALLMULTI;
	} else {
		rxfilt |= XL_RXFILTER_MULTIHASH;

		/* first, zot all the existing hash bits */
		for (i = 0; i < XL_HASHFILT_SIZE; i++)
			CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_SET_HASH|i);

		/* now program new ones */
		ETHER_FIRST_MULTI(step, ac, enm);
		while (enm != NULL) {
			h = ether_crc32_be(enm->enm_addrlo, ETHER_ADDR_LEN) &
			    0x000000FF;
			CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_SET_HASH |
			    XL_HASH_SET | h);

			ETHER_NEXT_MULTI(step, enm);
		}
	}

	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_SET_FILT | rxfilt);

	XL_SEL_WIN(7);
}

void
xl_setcfg(struct xl_softc *sc)
{
	u_int32_t icfg;

	XL_SEL_WIN(3);
	icfg = CSR_READ_4(sc, XL_W3_INTERNAL_CFG);
	icfg &= ~XL_ICFG_CONNECTOR_MASK;
	if (sc->xl_media & XL_MEDIAOPT_MII ||
		sc->xl_media & XL_MEDIAOPT_BT4)
		icfg |= (XL_XCVR_MII << XL_ICFG_CONNECTOR_BITS);
	if (sc->xl_media & XL_MEDIAOPT_BTX)
		icfg |= (XL_XCVR_AUTO << XL_ICFG_CONNECTOR_BITS);

	CSR_WRITE_4(sc, XL_W3_INTERNAL_CFG, icfg);
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_COAX_STOP);
}

void
xl_setmode(struct xl_softc *sc, uint64_t media)
{
	struct ifnet *ifp = &sc->sc_arpcom.ac_if;
	u_int32_t icfg;
	u_int16_t mediastat;

	XL_SEL_WIN(4);
	mediastat = CSR_READ_2(sc, XL_W4_MEDIA_STATUS);
	XL_SEL_WIN(3);
	icfg = CSR_READ_4(sc, XL_W3_INTERNAL_CFG);

	if (sc->xl_media & XL_MEDIAOPT_BT) {
		if (IFM_SUBTYPE(media) == IFM_10_T) {
			ifp->if_baudrate = IF_Mbps(10);
			sc->xl_xcvr = XL_XCVR_10BT;
			icfg &= ~XL_ICFG_CONNECTOR_MASK;
			icfg |= (XL_XCVR_10BT << XL_ICFG_CONNECTOR_BITS);
			mediastat |= XL_MEDIASTAT_LINKBEAT|
					XL_MEDIASTAT_JABGUARD;
			mediastat &= ~XL_MEDIASTAT_SQEENB;
		}
	}

	if (sc->xl_media & XL_MEDIAOPT_BFX) {
		if (IFM_SUBTYPE(media) == IFM_100_FX) {
			ifp->if_baudrate = IF_Mbps(100);
			sc->xl_xcvr = XL_XCVR_100BFX;
			icfg &= ~XL_ICFG_CONNECTOR_MASK;
			icfg |= (XL_XCVR_100BFX << XL_ICFG_CONNECTOR_BITS);
			mediastat |= XL_MEDIASTAT_LINKBEAT;
			mediastat &= ~XL_MEDIASTAT_SQEENB;
		}
	}

	if (sc->xl_media & (XL_MEDIAOPT_AUI|XL_MEDIAOPT_10FL)) {
		if (IFM_SUBTYPE(media) == IFM_10_5) {
			ifp->if_baudrate = IF_Mbps(10);
			sc->xl_xcvr = XL_XCVR_AUI;
			icfg &= ~XL_ICFG_CONNECTOR_MASK;
			icfg |= (XL_XCVR_AUI << XL_ICFG_CONNECTOR_BITS);
			mediastat &= ~(XL_MEDIASTAT_LINKBEAT|
					XL_MEDIASTAT_JABGUARD);
			mediastat |= ~XL_MEDIASTAT_SQEENB;
		}
		if (IFM_SUBTYPE(media) == IFM_10_FL) {
			ifp->if_baudrate = IF_Mbps(10);
			sc->xl_xcvr = XL_XCVR_AUI;
			icfg &= ~XL_ICFG_CONNECTOR_MASK;
			icfg |= (XL_XCVR_AUI << XL_ICFG_CONNECTOR_BITS);
			mediastat &= ~(XL_MEDIASTAT_LINKBEAT|
					XL_MEDIASTAT_JABGUARD);
			mediastat |= ~XL_MEDIASTAT_SQEENB;
		}
	}

	if (sc->xl_media & XL_MEDIAOPT_BNC) {
		if (IFM_SUBTYPE(media) == IFM_10_2) {
			ifp->if_baudrate = IF_Mbps(10);
			sc->xl_xcvr = XL_XCVR_COAX;
			icfg &= ~XL_ICFG_CONNECTOR_MASK;
			icfg |= (XL_XCVR_COAX << XL_ICFG_CONNECTOR_BITS);
			mediastat &= ~(XL_MEDIASTAT_LINKBEAT|
					XL_MEDIASTAT_JABGUARD|
					XL_MEDIASTAT_SQEENB);
		}
	}

	if ((media & IFM_GMASK) == IFM_FDX ||
			IFM_SUBTYPE(media) == IFM_100_FX) {
		XL_SEL_WIN(3);
		CSR_WRITE_1(sc, XL_W3_MAC_CTRL, XL_MACCTRL_DUPLEX);
	} else {
		XL_SEL_WIN(3);
		CSR_WRITE_1(sc, XL_W3_MAC_CTRL,
			(CSR_READ_1(sc, XL_W3_MAC_CTRL) & ~XL_MACCTRL_DUPLEX));
	}

	if (IFM_SUBTYPE(media) == IFM_10_2)
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_COAX_START);
	else
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_COAX_STOP);
	CSR_WRITE_4(sc, XL_W3_INTERNAL_CFG, icfg);
	XL_SEL_WIN(4);
	CSR_WRITE_2(sc, XL_W4_MEDIA_STATUS, mediastat);
	DELAY(800);
	XL_SEL_WIN(7);
}

void
xl_reset(struct xl_softc *sc)
{
	int	i;

	XL_SEL_WIN(0);
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RESET |
		    ((sc->xl_flags & XL_FLAG_WEIRDRESET) ?
		     XL_RESETOPT_DISADVFD:0));

	/*
	 * Pause briefly after issuing the reset command before trying
	 * to access any other registers. With my 3c575C cardbus card,
	 * failing to do this results in the system locking up while
	 * trying to poll the command busy bit in the status register.
	 */
	DELAY(100000);

	for (i = 0; i < XL_TIMEOUT; i++) {
		DELAY(10);
		if (!(CSR_READ_2(sc, XL_STATUS) & XL_STAT_CMDBUSY))
			break;
	}

	if (i == XL_TIMEOUT)
		printf("%s: reset didn't complete\n", sc->sc_dev.dv_xname);

	/* Note: the RX reset takes an absurd amount of time
	 * on newer versions of the Tornado chips such as those
	 * on the 3c905CX and newer 3c908C cards. We wait an
	 * extra amount of time so that xl_wait() doesn't complain
	 * and annoy the users.
	 */
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_RESET);
	DELAY(100000);
	xl_wait(sc);
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_TX_RESET);
	xl_wait(sc);

	if (sc->xl_flags & XL_FLAG_INVERT_LED_PWR || 
	    sc->xl_flags & XL_FLAG_INVERT_MII_PWR) {
		XL_SEL_WIN(2);
		CSR_WRITE_2(sc, XL_W2_RESET_OPTIONS, CSR_READ_2(sc,
		    XL_W2_RESET_OPTIONS) 
		    | ((sc->xl_flags & XL_FLAG_INVERT_LED_PWR)?XL_RESETOPT_INVERT_LED:0)
		    | ((sc->xl_flags & XL_FLAG_INVERT_MII_PWR)?XL_RESETOPT_INVERT_MII:0)
		    );
	}

	/* Wait a little while for the chip to get its brains in order. */
	DELAY(100000);
}

/*
 * This routine is a kludge to work around possible hardware faults
 * or manufacturing defects that can cause the media options register
 * (or reset options register, as it's called for the first generation
 * 3c90x adapters) to return an incorrect result. I have encountered
 * one Dell Latitude laptop docking station with an integrated 3c905-TX
 * which doesn't have any of the 'mediaopt' bits set. This screws up
 * the attach routine pretty badly because it doesn't know what media
 * to look for. If we find ourselves in this predicament, this routine
 * will try to guess the media options values and warn the user of a
 * possible manufacturing defect with his adapter/system/whatever.
 */
void
xl_mediacheck(struct xl_softc *sc)
{
	/*
	 * If some of the media options bits are set, assume they are
	 * correct. If not, try to figure it out down below.
	 * XXX I should check for 10baseFL, but I don't have an adapter
	 * to test with.
	 */
	if (sc->xl_media & (XL_MEDIAOPT_MASK & ~XL_MEDIAOPT_VCO)) {
		/*
	 	 * Check the XCVR value. If it's not in the normal range
	 	 * of values, we need to fake it up here.
	 	 */
		if (sc->xl_xcvr <= XL_XCVR_AUTO)
			return;
		else {
			printf("%s: bogus xcvr value "
			"in EEPROM (%x)\n", sc->sc_dev.dv_xname, sc->xl_xcvr);
			printf("%s: choosing new default based "
				"on card type\n", sc->sc_dev.dv_xname);
		}
	} else {
		if (sc->xl_type == XL_TYPE_905B &&
		    sc->xl_media & XL_MEDIAOPT_10FL)
			return;
		printf("%s: WARNING: no media options bits set in "
			"the media options register!!\n", sc->sc_dev.dv_xname);
		printf("%s: this could be a manufacturing defect in "
			"your adapter or system\n", sc->sc_dev.dv_xname);
		printf("%s: attempting to guess media type; you "
			"should probably consult your vendor\n", sc->sc_dev.dv_xname);
	}

	xl_choose_xcvr(sc, 1);
}

void
xl_choose_xcvr(struct xl_softc *sc, int verbose)
{
	u_int16_t devid;

	/*
	 * Read the device ID from the EEPROM.
	 * This is what's loaded into the PCI device ID register, so it has
	 * to be correct otherwise we wouldn't have gotten this far.
	 */
	xl_read_eeprom(sc, (caddr_t)&devid, XL_EE_PRODID, 1, 0);

	switch(devid) {
	case TC_DEVICEID_BOOMERANG_10BT:	/* 3c900-TPO */
	case TC_DEVICEID_KRAKATOA_10BT:		/* 3c900B-TPO */
		sc->xl_media = XL_MEDIAOPT_BT;
		sc->xl_xcvr = XL_XCVR_10BT;
		if (verbose)
			printf("%s: guessing 10BaseT transceiver\n",
			    sc->sc_dev.dv_xname);
		break;
	case TC_DEVICEID_BOOMERANG_10BT_COMBO:	/* 3c900-COMBO */
	case TC_DEVICEID_KRAKATOA_10BT_COMBO:	/* 3c900B-COMBO */
		sc->xl_media = XL_MEDIAOPT_BT|XL_MEDIAOPT_BNC|XL_MEDIAOPT_AUI;
		sc->xl_xcvr = XL_XCVR_10BT;
		if (verbose)
			printf("%s: guessing COMBO (AUI/BNC/TP)\n",
			    sc->sc_dev.dv_xname);
		break;
	case TC_DEVICEID_KRAKATOA_10BT_TPC:	/* 3c900B-TPC */
		sc->xl_media = XL_MEDIAOPT_BT|XL_MEDIAOPT_BNC;
		sc->xl_xcvr = XL_XCVR_10BT;
		if (verbose)
			printf("%s: guessing TPC (BNC/TP)\n", sc->sc_dev.dv_xname);
		break;
	case TC_DEVICEID_CYCLONE_10FL:		/* 3c900B-FL */
		sc->xl_media = XL_MEDIAOPT_10FL;
		sc->xl_xcvr = XL_XCVR_AUI;
		if (verbose)
			printf("%s: guessing 10baseFL\n", sc->sc_dev.dv_xname);
		break;
	case TC_DEVICEID_BOOMERANG_10_100BT:	/* 3c905-TX */
	case TC_DEVICEID_HURRICANE_555:		/* 3c555 */
	case TC_DEVICEID_HURRICANE_556:		/* 3c556 */
	case TC_DEVICEID_HURRICANE_556B:	/* 3c556B */
	case TC_DEVICEID_HURRICANE_575A:	/* 3c575TX */
	case TC_DEVICEID_HURRICANE_575B:	/* 3c575B */
	case TC_DEVICEID_HURRICANE_575C:	/* 3c575C */
	case TC_DEVICEID_HURRICANE_656:		/* 3c656 */
	case TC_DEVICEID_HURRICANE_656B:	/* 3c656B */
	case TC_DEVICEID_TORNADO_656C:		/* 3c656C */
	case TC_DEVICEID_TORNADO_10_100BT_920B: /* 3c920B-EMB */
		sc->xl_media = XL_MEDIAOPT_MII;
		sc->xl_xcvr = XL_XCVR_MII;
		if (verbose)
			printf("%s: guessing MII\n", sc->sc_dev.dv_xname);
		break;
	case TC_DEVICEID_BOOMERANG_100BT4:	/* 3c905-T4 */
	case TC_DEVICEID_CYCLONE_10_100BT4:	/* 3c905B-T4 */
		sc->xl_media = XL_MEDIAOPT_BT4;
		sc->xl_xcvr = XL_XCVR_MII;
		if (verbose)
			printf("%s: guessing 100BaseT4/MII\n", sc->sc_dev.dv_xname);
		break;
	case TC_DEVICEID_HURRICANE_10_100BT:	/* 3c905B-TX */
	case TC_DEVICEID_HURRICANE_10_100BT_SERV:/* 3c980-TX */
	case TC_DEVICEID_TORNADO_10_100BT_SERV:	/* 3c980C-TX */
	case TC_DEVICEID_HURRICANE_SOHO100TX:	/* 3cSOHO100-TX */
	case TC_DEVICEID_TORNADO_10_100BT:	/* 3c905C-TX */
	case TC_DEVICEID_TORNADO_HOMECONNECT:	/* 3c450-TX */
		sc->xl_media = XL_MEDIAOPT_BTX;
		sc->xl_xcvr = XL_XCVR_AUTO;
		if (verbose)
			printf("%s: guessing 10/100 internal\n",
			    sc->sc_dev.dv_xname);
		break;
	case TC_DEVICEID_CYCLONE_10_100_COMBO:	/* 3c905B-COMBO */
		sc->xl_media = XL_MEDIAOPT_BTX|XL_MEDIAOPT_BNC|XL_MEDIAOPT_AUI;
		sc->xl_xcvr = XL_XCVR_AUTO;
		if (verbose)
			printf("%s: guessing 10/100 plus BNC/AUI\n",
			    sc->sc_dev.dv_xname);
		break;
	default:
		printf("%s: unknown device ID: %x -- "
			"defaulting to 10baseT\n", sc->sc_dev.dv_xname, devid);
		sc->xl_media = XL_MEDIAOPT_BT;
		break;
	}
}

/*
 * Initialize the transmit descriptors.
 */
int
xl_list_tx_init(struct xl_softc *sc)
{
	struct xl_chain_data	*cd;
	struct xl_list_data	*ld;
	int			i;

	cd = &sc->xl_cdata;
	ld = sc->xl_ldata;
	for (i = 0; i < XL_TX_LIST_CNT; i++) {
		cd->xl_tx_chain[i].xl_ptr = &ld->xl_tx_list[i];
		if (i == (XL_TX_LIST_CNT - 1))
			cd->xl_tx_chain[i].xl_next = NULL;
		else
			cd->xl_tx_chain[i].xl_next = &cd->xl_tx_chain[i + 1];
	}

	cd->xl_tx_free = &cd->xl_tx_chain[0];
	cd->xl_tx_tail = cd->xl_tx_head = NULL;

	return (0);
}

/*
 * Initialize the transmit descriptors.
 */
int
xl_list_tx_init_90xB(struct xl_softc *sc)
{
	struct xl_chain_data	*cd;
	struct xl_list_data	*ld;
	int			i, next, prev;

	cd = &sc->xl_cdata;
	ld = sc->xl_ldata;
	for (i = 0; i < XL_TX_LIST_CNT; i++) {
		if (i == (XL_TX_LIST_CNT - 1))
			next = 0;
		else
			next = i + 1;
		if (i == 0)
			prev = XL_TX_LIST_CNT - 1;
		else
			prev = i - 1;
		cd->xl_tx_chain[i].xl_ptr = &ld->xl_tx_list[i];
		cd->xl_tx_chain[i].xl_phys =
		    sc->sc_listmap->dm_segs[0].ds_addr +   
		    offsetof(struct xl_list_data, xl_tx_list[i]);
		cd->xl_tx_chain[i].xl_next = &cd->xl_tx_chain[next];
		cd->xl_tx_chain[i].xl_prev = &cd->xl_tx_chain[prev];
	}

	bzero(ld->xl_tx_list, sizeof(struct xl_list) * XL_TX_LIST_CNT);
	ld->xl_tx_list[0].xl_status = htole32(XL_TXSTAT_EMPTY);

	cd->xl_tx_prod = 1;
	cd->xl_tx_cons = 1;
	cd->xl_tx_cnt = 0;

	return (0);
}

/*
 * Initialize the RX descriptors and allocate mbufs for them. Note that
 * we arrange the descriptors in a closed ring, so that the last descriptor
 * points back to the first.
 */
int
xl_list_rx_init(struct xl_softc *sc)
{
	struct xl_chain_data	*cd;
	struct xl_list_data	*ld;
	int			i, n;
	bus_addr_t		next;

	cd = &sc->xl_cdata;
	ld = sc->xl_ldata;

	for (i = 0; i < XL_RX_LIST_CNT; i++) {
		cd->xl_rx_chain[i].xl_ptr =
			(struct xl_list_onefrag *)&ld->xl_rx_list[i];
		if (i == (XL_RX_LIST_CNT - 1))
			n = 0;
		else
			n = i + 1;
		cd->xl_rx_chain[i].xl_next = &cd->xl_rx_chain[n];
		next = sc->sc_listmap->dm_segs[0].ds_addr +
		       offsetof(struct xl_list_data, xl_rx_list[n]);
		ld->xl_rx_list[i].xl_next = htole32(next);
	}

	cd->xl_rx_prod = cd->xl_rx_cons = &cd->xl_rx_chain[0];
	if_rxr_init(&cd->xl_rx_ring, 2, XL_RX_LIST_CNT - 1);
	xl_fill_rx_ring(sc);
	return (0);
}

void
xl_fill_rx_ring(struct xl_softc *sc)
{  
	struct xl_chain_data    *cd;
	u_int			slots;

	cd = &sc->xl_cdata;

	for (slots = if_rxr_get(&cd->xl_rx_ring, XL_RX_LIST_CNT);
	     slots > 0; slots--) {
		if (xl_newbuf(sc, cd->xl_rx_prod) == ENOBUFS)
			break;
		cd->xl_rx_prod = cd->xl_rx_prod->xl_next;
	}
	if_rxr_put(&cd->xl_rx_ring, slots);
}

/*
 * Initialize an RX descriptor and attach an MBUF cluster.
 */
int
xl_newbuf(struct xl_softc *sc, struct xl_chain_onefrag *c)
{
	struct mbuf	*m_new = NULL;
	bus_dmamap_t	map;

	m_new = MCLGETI(NULL, M_DONTWAIT, NULL, MCLBYTES);
	if (!m_new)
		return (ENOBUFS);

	m_new->m_len = m_new->m_pkthdr.len = MCLBYTES;
	if (bus_dmamap_load(sc->sc_dmat, sc->sc_rx_sparemap,
	    mtod(m_new, caddr_t), MCLBYTES, NULL, BUS_DMA_NOWAIT) != 0) {
		m_freem(m_new);
		return (ENOBUFS);
	}

	/* sync the old map, and unload it (if necessary) */
	if (c->map->dm_nsegs != 0) {
		bus_dmamap_sync(sc->sc_dmat, c->map,
		    0, c->map->dm_mapsize, BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->sc_dmat, c->map);
	}

	map = c->map;
	c->map = sc->sc_rx_sparemap;
	sc->sc_rx_sparemap = map;

	/* Force longword alignment for packet payload. */
	m_adj(m_new, ETHER_ALIGN);

	bus_dmamap_sync(sc->sc_dmat, c->map, 0, c->map->dm_mapsize,
	    BUS_DMASYNC_PREREAD);

	c->xl_mbuf = m_new;
	c->xl_ptr->xl_frag.xl_addr =
	    htole32(c->map->dm_segs[0].ds_addr + ETHER_ALIGN);
	c->xl_ptr->xl_frag.xl_len =
	    htole32(c->map->dm_segs[0].ds_len | XL_LAST_FRAG);
	c->xl_ptr->xl_status = htole32(0);

	bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,
	    ((caddr_t)c->xl_ptr - sc->sc_listkva), sizeof(struct xl_list),
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

	return (0);
}

/*
 * A frame has been uploaded: pass the resulting mbuf chain up to
 * the higher level protocols.
 */
void
xl_rxeof(struct xl_softc *sc)
{
	struct mbuf_list	ml = MBUF_LIST_INITIALIZER();
        struct mbuf		*m;
        struct ifnet		*ifp;
	struct xl_chain_onefrag	*cur_rx;
	int			total_len = 0;
	u_int32_t		rxstat;
	u_int16_t		sumflags = 0;

	ifp = &sc->sc_arpcom.ac_if;

again:

	while (if_rxr_inuse(&sc->xl_cdata.xl_rx_ring) > 0) {
		cur_rx = sc->xl_cdata.xl_rx_cons;
		bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,                    
		    ((caddr_t)cur_rx->xl_ptr - sc->sc_listkva),
		    sizeof(struct xl_list),
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
		if ((rxstat = letoh32(sc->xl_cdata.xl_rx_cons->xl_ptr->xl_status)) == 0)
			break;
		m = cur_rx->xl_mbuf;  
		cur_rx->xl_mbuf = NULL;
		sc->xl_cdata.xl_rx_cons = cur_rx->xl_next;
		if_rxr_put(&sc->xl_cdata.xl_rx_ring, 1);
		total_len = rxstat & XL_RXSTAT_LENMASK;

		/*
		 * Since we have told the chip to allow large frames,
		 * we need to trap giant frame errors in software. We allow
		 * a little more than the normal frame size to account for
		 * frames with VLAN tags.
		 */
		if (total_len > XL_MAX_FRAMELEN)
			rxstat |= (XL_RXSTAT_UP_ERROR|XL_RXSTAT_OVERSIZE);

		/*
		 * If an error occurs, update stats, clear the
		 * status word and leave the mbuf cluster in place:
		 * it should simply get re-used next time this descriptor
	 	 * comes up in the ring.
		 */
		if (rxstat & XL_RXSTAT_UP_ERROR) {
			ifp->if_ierrors++;
			cur_rx->xl_ptr->xl_status = htole32(0);
			m_freem(m);
			continue;
		}

		/*
		 * If the error bit was not set, the upload complete
		 * bit should be set which means we have a valid packet.
		 * If not, something truly strange has happened.
		 */
		if (!(rxstat & XL_RXSTAT_UP_CMPLT)) {
			printf("%s: bad receive status -- "
			    "packet dropped\n", sc->sc_dev.dv_xname);
			ifp->if_ierrors++;
			cur_rx->xl_ptr->xl_status = htole32(0);
			m_freem(m);
			continue;
		}

		m->m_pkthdr.len = m->m_len = total_len;

		if (sc->xl_type == XL_TYPE_905B) {
			if (!(rxstat & XL_RXSTAT_IPCKERR) &&
			    (rxstat & XL_RXSTAT_IPCKOK))
				sumflags |= M_IPV4_CSUM_IN_OK;

			if (!(rxstat & XL_RXSTAT_TCPCKERR) &&
			    (rxstat & XL_RXSTAT_TCPCKOK))
				sumflags |= M_TCP_CSUM_IN_OK;

			if (!(rxstat & XL_RXSTAT_UDPCKERR) &&
			    (rxstat & XL_RXSTAT_UDPCKOK))
				sumflags |= M_UDP_CSUM_IN_OK;

			m->m_pkthdr.csum_flags = sumflags;
		}

		ml_enqueue(&ml, m);
	}

	xl_fill_rx_ring(sc);

	/*
	 * Handle the 'end of channel' condition. When the upload
	 * engine hits the end of the RX ring, it will stall. This
	 * is our cue to flush the RX ring, reload the uplist pointer
	 * register and unstall the engine.
	 * XXX This is actually a little goofy. With the ThunderLAN
	 * chip, you get an interrupt when the receiver hits the end
	 * of the receive ring, which tells you exactly when you
	 * you need to reload the ring pointer. Here we have to
	 * fake it. I'm mad at myself for not being clever enough
	 * to avoid the use of a goto here.
	 */
	if (CSR_READ_4(sc, XL_UPLIST_PTR) == 0 ||
		CSR_READ_4(sc, XL_UPLIST_STATUS) & XL_PKTSTAT_UP_STALLED) {
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_UP_STALL);
		xl_wait(sc);
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_UP_UNSTALL);
		xl_fill_rx_ring(sc);
		goto again;
	}

	if_input(ifp, &ml);
}

/*
 * A frame was downloaded to the chip. It's safe for us to clean up
 * the list buffers.
 */
void
xl_txeof(struct xl_softc *sc)
{
	struct xl_chain		*cur_tx;
	struct ifnet		*ifp;

	ifp = &sc->sc_arpcom.ac_if;

	/*
	 * Go through our tx list and free mbufs for those
	 * frames that have been uploaded. Note: the 3c905B
	 * sets a special bit in the status word to let us
	 * know that a frame has been downloaded, but the
	 * original 3c900/3c905 adapters don't do that.
	 * Consequently, we have to use a different test if
	 * xl_type != XL_TYPE_905B.
	 */
	while (sc->xl_cdata.xl_tx_head != NULL) {
		cur_tx = sc->xl_cdata.xl_tx_head;

		bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,
		    ((caddr_t)cur_tx->xl_ptr - sc->sc_listkva),
		    sizeof(struct xl_list),
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

		if (CSR_READ_4(sc, XL_DOWNLIST_PTR))
			break;

		sc->xl_cdata.xl_tx_head = cur_tx->xl_next;
		if (cur_tx->map->dm_nsegs != 0) {
			bus_dmamap_t map = cur_tx->map;

			bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
			    BUS_DMASYNC_POSTWRITE);
			bus_dmamap_unload(sc->sc_dmat, map);
		}
		if (cur_tx->xl_mbuf != NULL) {
			m_freem(cur_tx->xl_mbuf);
			cur_tx->xl_mbuf = NULL;
		}
		cur_tx->xl_next = sc->xl_cdata.xl_tx_free;
		sc->xl_cdata.xl_tx_free = cur_tx;
	}

	if (sc->xl_cdata.xl_tx_head == NULL) {
		ifq_clr_oactive(&ifp->if_snd);
		/* Clear the timeout timer. */
		ifp->if_timer = 0;
		sc->xl_cdata.xl_tx_tail = NULL;
	} else {
		if (CSR_READ_4(sc, XL_DMACTL) & XL_DMACTL_DOWN_STALLED ||
			!CSR_READ_4(sc, XL_DOWNLIST_PTR)) {
			CSR_WRITE_4(sc, XL_DOWNLIST_PTR,
			    sc->sc_listmap->dm_segs[0].ds_addr +
			    ((caddr_t)sc->xl_cdata.xl_tx_head->xl_ptr -
			    sc->sc_listkva));
			CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_DOWN_UNSTALL);
		}
	}
}

void
xl_txeof_90xB(struct xl_softc *sc)
{
	struct xl_chain *cur_tx = NULL;
	struct ifnet *ifp;
	int idx;

	ifp = &sc->sc_arpcom.ac_if;

	idx = sc->xl_cdata.xl_tx_cons;
	while (idx != sc->xl_cdata.xl_tx_prod) {

		cur_tx = &sc->xl_cdata.xl_tx_chain[idx];

		if ((cur_tx->xl_ptr->xl_status &
		    htole32(XL_TXSTAT_DL_COMPLETE)) == 0)
			break;

		if (cur_tx->xl_mbuf != NULL) {
			m_freem(cur_tx->xl_mbuf);
			cur_tx->xl_mbuf = NULL;
		}

		if (cur_tx->map->dm_nsegs != 0) {
			bus_dmamap_sync(sc->sc_dmat, cur_tx->map,
			    0, cur_tx->map->dm_mapsize, BUS_DMASYNC_POSTWRITE);
			bus_dmamap_unload(sc->sc_dmat, cur_tx->map);
		}

		sc->xl_cdata.xl_tx_cnt--;
		XL_INC(idx, XL_TX_LIST_CNT);
	}

	sc->xl_cdata.xl_tx_cons = idx;

	if (cur_tx != NULL)
		ifq_clr_oactive(&ifp->if_snd);
	if (sc->xl_cdata.xl_tx_cnt == 0)
		ifp->if_timer = 0;
}

/*
 * TX 'end of channel' interrupt handler. Actually, we should
 * only get a 'TX complete' interrupt if there's a transmit error,
 * so this is really TX error handler.
 */
void
xl_txeoc(struct xl_softc *sc)
{
	u_int8_t	txstat;

	while ((txstat = CSR_READ_1(sc, XL_TX_STATUS))) {
		if (txstat & XL_TXSTATUS_UNDERRUN ||
			txstat & XL_TXSTATUS_JABBER ||
			txstat & XL_TXSTATUS_RECLAIM) {
			if (txstat != 0x90) {
				printf("%s: transmission error: %x\n",
				    sc->sc_dev.dv_xname, txstat);
			}
			CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_TX_RESET);
			xl_wait(sc);
			if (sc->xl_type == XL_TYPE_905B) {
				if (sc->xl_cdata.xl_tx_cnt) {
					int i;
					struct xl_chain *c;

					i = sc->xl_cdata.xl_tx_cons;
					c = &sc->xl_cdata.xl_tx_chain[i];
					CSR_WRITE_4(sc, XL_DOWNLIST_PTR,
					    c->xl_phys);
					CSR_WRITE_1(sc, XL_DOWN_POLL, 64);
				}
			} else {
				if (sc->xl_cdata.xl_tx_head != NULL)
					CSR_WRITE_4(sc, XL_DOWNLIST_PTR,
					    sc->sc_listmap->dm_segs[0].ds_addr +
					    ((caddr_t)sc->xl_cdata.xl_tx_head->xl_ptr -
					    sc->sc_listkva));
			}
			/*
			 * Remember to set this for the
			 * first generation 3c90X chips.
			 */
			CSR_WRITE_1(sc, XL_TX_FREETHRESH, XL_PACKET_SIZE >> 8);
			if (txstat & XL_TXSTATUS_UNDERRUN &&
			    sc->xl_tx_thresh < XL_PACKET_SIZE) {
				sc->xl_tx_thresh += XL_MIN_FRAMELEN;
#ifdef notdef
				printf("%s: tx underrun, increasing tx start"
				    " threshold to %d\n", sc->sc_dev.dv_xname,
				    sc->xl_tx_thresh);
#endif
			}
			CSR_WRITE_2(sc, XL_COMMAND,
			    XL_CMD_TX_SET_START|sc->xl_tx_thresh);
			if (sc->xl_type == XL_TYPE_905B) {
				CSR_WRITE_2(sc, XL_COMMAND,
				XL_CMD_SET_TX_RECLAIM|(XL_PACKET_SIZE >> 4));
			}
			CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_TX_ENABLE);
			CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_DOWN_UNSTALL);
		} else {
			CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_TX_ENABLE);
			CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_DOWN_UNSTALL);
		}
		/*
		 * Write an arbitrary byte to the TX_STATUS register
	 	 * to clear this interrupt/error and advance to the next.
		 */
		CSR_WRITE_1(sc, XL_TX_STATUS, 0x01);
	}
}

int
xl_intr(void *arg)
{
	struct xl_softc		*sc;
	struct ifnet		*ifp;
	u_int16_t		status;
	int			claimed = 0;

	sc = arg;
	ifp = &sc->sc_arpcom.ac_if;

	while ((status = CSR_READ_2(sc, XL_STATUS)) & XL_INTRS && status != 0xFFFF) {

		claimed = 1;

		CSR_WRITE_2(sc, XL_COMMAND,
		    XL_CMD_INTR_ACK|(status & XL_INTRS));

		if (sc->intr_ack)
			(*sc->intr_ack)(sc);

		if (!(ifp->if_flags & IFF_RUNNING))
			return (claimed);

		if (status & XL_STAT_UP_COMPLETE)
			xl_rxeof(sc);

		if (status & XL_STAT_DOWN_COMPLETE) {
			if (sc->xl_type == XL_TYPE_905B)
				xl_txeof_90xB(sc);
			else
				xl_txeof(sc);
		}

		if (status & XL_STAT_TX_COMPLETE) {
			ifp->if_oerrors++;
			xl_txeoc(sc);
		}

		if (status & XL_STAT_ADFAIL)
			xl_init(sc);

		if (status & XL_STAT_STATSOFLOW) {
			sc->xl_stats_no_timeout = 1;
			xl_stats_update(sc);
			sc->xl_stats_no_timeout = 0;
		}
	}

	if (!IFQ_IS_EMPTY(&ifp->if_snd))
		(*ifp->if_start)(ifp);

	return (claimed);
}

void
xl_stats_update(void *xsc)
{
	struct xl_softc		*sc;
	struct ifnet		*ifp;
	struct xl_stats		xl_stats;
	u_int8_t		*p;
	int			i;
	struct mii_data		*mii = NULL;

	bzero(&xl_stats, sizeof(struct xl_stats));

	sc = xsc;
	ifp = &sc->sc_arpcom.ac_if;
	if (sc->xl_hasmii)
		mii = &sc->sc_mii;

	p = (u_int8_t *)&xl_stats;

	/* Read all the stats registers. */
	XL_SEL_WIN(6);

	for (i = 0; i < 16; i++)
		*p++ = CSR_READ_1(sc, XL_W6_CARRIER_LOST + i);

	ifp->if_ierrors += xl_stats.xl_rx_overrun;

	ifp->if_collisions += xl_stats.xl_tx_multi_collision +
				xl_stats.xl_tx_single_collision +
				xl_stats.xl_tx_late_collision;

	/*
	 * Boomerang and cyclone chips have an extra stats counter
	 * in window 4 (BadSSD). We have to read this too in order
	 * to clear out all the stats registers and avoid a statsoflow
	 * interrupt.
	 */
	XL_SEL_WIN(4);
	CSR_READ_1(sc, XL_W4_BADSSD);

	if (mii != NULL && (!sc->xl_stats_no_timeout))
		mii_tick(mii);

	XL_SEL_WIN(7);

	if (!sc->xl_stats_no_timeout)
		timeout_add_sec(&sc->xl_stsup_tmo, 1);
}

/*
 * Encapsulate an mbuf chain in a descriptor by coupling the mbuf data
 * pointers to the fragment pointers.
 */
int
xl_encap(struct xl_softc *sc, struct xl_chain *c, struct mbuf *m_head)
{
	int		error, frag, total_len;
	u_int32_t	status;
	bus_dmamap_t	map;

	map = sc->sc_tx_sparemap;

reload:
	error = bus_dmamap_load_mbuf(sc->sc_dmat, map,
	    m_head, BUS_DMA_NOWAIT);

	if (error && error != EFBIG) {
		m_freem(m_head);
		return (1);
	}

	/*
 	 * Start packing the mbufs in this chain into
	 * the fragment pointers. Stop when we run out
 	 * of fragments or hit the end of the mbuf chain.
	 */
	for (frag = 0, total_len = 0; frag < map->dm_nsegs; frag++) {
		if (frag == XL_MAXFRAGS)
			break;
		total_len += map->dm_segs[frag].ds_len;
		c->xl_ptr->xl_frag[frag].xl_addr =
		    htole32(map->dm_segs[frag].ds_addr);
		c->xl_ptr->xl_frag[frag].xl_len =
		    htole32(map->dm_segs[frag].ds_len);
	}

	/*
	 * Handle special case: we used up all 63 fragments,
	 * but we have more mbufs left in the chain. Copy the
	 * data into an mbuf cluster. Note that we don't
	 * bother clearing the values in the other fragment
	 * pointers/counters; it wouldn't gain us anything,
	 * and would waste cycles.
	 */
	if (error) {
		struct mbuf	*m_new = NULL;

		MGETHDR(m_new, M_DONTWAIT, MT_DATA);
		if (m_new == NULL) {
			m_freem(m_head);
			return (1);
		}
		if (m_head->m_pkthdr.len > MHLEN) {
			MCLGET(m_new, M_DONTWAIT);
			if (!(m_new->m_flags & M_EXT)) {
				m_freem(m_new);
				m_freem(m_head);
				return (1);
			}
		}
		m_copydata(m_head, 0, m_head->m_pkthdr.len,	
		    mtod(m_new, caddr_t));
		m_new->m_pkthdr.len = m_new->m_len = m_head->m_pkthdr.len;
		m_freem(m_head);
		m_head = m_new;
		goto reload;
	}

	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREWRITE);

	if (c->map->dm_nsegs != 0) {
		bus_dmamap_sync(sc->sc_dmat, c->map,
		    0, c->map->dm_mapsize, BUS_DMASYNC_POSTWRITE);
		bus_dmamap_unload(sc->sc_dmat, c->map);
	}

	c->xl_mbuf = m_head;
	sc->sc_tx_sparemap = c->map;
	c->map = map;
	c->xl_ptr->xl_frag[frag - 1].xl_len |= htole32(XL_LAST_FRAG);
	c->xl_ptr->xl_status = htole32(total_len);
	c->xl_ptr->xl_next = 0;

	if (sc->xl_type == XL_TYPE_905B) {
		status = XL_TXSTAT_RND_DEFEAT;

#ifndef XL905B_TXCSUM_BROKEN
		if (m_head->m_pkthdr.csum_flags) {
			if (m_head->m_pkthdr.csum_flags & M_IPV4_CSUM_OUT)
				status |= XL_TXSTAT_IPCKSUM;
			if (m_head->m_pkthdr.csum_flags & M_TCP_CSUM_OUT)
				status |= XL_TXSTAT_TCPCKSUM;
			if (m_head->m_pkthdr.csum_flags & M_UDP_CSUM_OUT)
				status |= XL_TXSTAT_UDPCKSUM;
		}
#endif
		c->xl_ptr->xl_status = htole32(status);
	}

	bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,
	    offsetof(struct xl_list_data, xl_tx_list[0]),
	    sizeof(struct xl_list) * XL_TX_LIST_CNT,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

	return (0);
}

/*
 * Main transmit routine. To avoid having to do mbuf copies, we put pointers
 * to the mbuf data regions directly in the transmit lists. We also save a
 * copy of the pointers since the transmit list fragment pointers are
 * physical addresses.
 */
void
xl_start(struct ifnet *ifp)
{
	struct xl_softc		*sc;
	struct mbuf		*m_head = NULL;
	struct xl_chain		*prev = NULL, *cur_tx = NULL, *start_tx;
	struct xl_chain		*prev_tx;
	int			error;

	sc = ifp->if_softc;

	/*
	 * Check for an available queue slot. If there are none,
	 * punt.
	 */
	if (sc->xl_cdata.xl_tx_free == NULL) {
		xl_txeoc(sc);
		xl_txeof(sc);
		if (sc->xl_cdata.xl_tx_free == NULL) {
			ifq_set_oactive(&ifp->if_snd);
			return;
		}
	}

	start_tx = sc->xl_cdata.xl_tx_free;

	while (sc->xl_cdata.xl_tx_free != NULL) {
		IFQ_DEQUEUE(&ifp->if_snd, m_head);
		if (m_head == NULL)
			break;

		/* Pick a descriptor off the free list. */
		prev_tx = cur_tx;
		cur_tx = sc->xl_cdata.xl_tx_free;

		/* Pack the data into the descriptor. */
		error = xl_encap(sc, cur_tx, m_head);
		if (error) {
			cur_tx = prev_tx;
			continue;
		}

		sc->xl_cdata.xl_tx_free = cur_tx->xl_next;
		cur_tx->xl_next = NULL;

		/* Chain it together. */
		if (prev != NULL) {
			prev->xl_next = cur_tx;
			prev->xl_ptr->xl_next =
			    sc->sc_listmap->dm_segs[0].ds_addr +
			    ((caddr_t)cur_tx->xl_ptr - sc->sc_listkva);

		}
		prev = cur_tx;

#if NBPFILTER > 0
		/*
		 * If there's a BPF listener, bounce a copy of this frame
		 * to him.
		 */
		if (ifp->if_bpf)
			bpf_mtap(ifp->if_bpf, cur_tx->xl_mbuf,
			    BPF_DIRECTION_OUT);
#endif
	}

	/*
	 * If there are no packets queued, bail.
	 */
	if (cur_tx == NULL)
		return;

	/*
	 * Place the request for the upload interrupt
	 * in the last descriptor in the chain. This way, if
	 * we're chaining several packets at once, we'll only
	 * get an interrupt once for the whole chain rather than
	 * once for each packet.
	 */
	cur_tx->xl_ptr->xl_status |= htole32(XL_TXSTAT_DL_INTR);

	/*
	 * Queue the packets. If the TX channel is clear, update
	 * the downlist pointer register.
	 */
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_DOWN_STALL);
	xl_wait(sc);

	if (sc->xl_cdata.xl_tx_head != NULL) {
		sc->xl_cdata.xl_tx_tail->xl_next = start_tx;
		sc->xl_cdata.xl_tx_tail->xl_ptr->xl_next =
		    sc->sc_listmap->dm_segs[0].ds_addr +
		    ((caddr_t)start_tx->xl_ptr - sc->sc_listkva);
		sc->xl_cdata.xl_tx_tail->xl_ptr->xl_status &=
		    htole32(~XL_TXSTAT_DL_INTR);
		sc->xl_cdata.xl_tx_tail = cur_tx;
	} else {
		sc->xl_cdata.xl_tx_head = start_tx;
		sc->xl_cdata.xl_tx_tail = cur_tx;
	}
	if (!CSR_READ_4(sc, XL_DOWNLIST_PTR))
		CSR_WRITE_4(sc, XL_DOWNLIST_PTR,
		    sc->sc_listmap->dm_segs[0].ds_addr +
		    ((caddr_t)start_tx->xl_ptr - sc->sc_listkva));

	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_DOWN_UNSTALL);

	XL_SEL_WIN(7);

	/*
	 * Set a timeout in case the chip goes out to lunch.
	 */
	ifp->if_timer = 5;

	/*
	 * XXX Under certain conditions, usually on slower machines
	 * where interrupts may be dropped, it's possible for the
	 * adapter to chew up all the buffers in the receive ring
	 * and stall, without us being able to do anything about it.
	 * To guard against this, we need to make a pass over the
	 * RX queue to make sure there aren't any packets pending.
	 * Doing it here means we can flush the receive ring at the
	 * same time the chip is DMAing the transmit descriptors we
	 * just gave it.
 	 *
	 * 3Com goes to some lengths to emphasize the Parallel Tasking (tm)
	 * nature of their chips in all their marketing literature;
	 * we may as well take advantage of it. :)
	 */
	xl_rxeof(sc);
}

void
xl_start_90xB(struct ifnet *ifp)
{
	struct xl_softc	*sc;
	struct mbuf	*m_head = NULL;
	struct xl_chain	*prev = NULL, *cur_tx = NULL, *start_tx;
	struct xl_chain	*prev_tx;
	int		error, idx;

	sc = ifp->if_softc;

	if (ifq_is_oactive(&ifp->if_snd))
		return;

	idx = sc->xl_cdata.xl_tx_prod;
	start_tx = &sc->xl_cdata.xl_tx_chain[idx];

	while (sc->xl_cdata.xl_tx_chain[idx].xl_mbuf == NULL) {

		if ((XL_TX_LIST_CNT - sc->xl_cdata.xl_tx_cnt) < 3) {
			ifq_set_oactive(&ifp->if_snd);
			break;
		}

		IFQ_DEQUEUE(&ifp->if_snd, m_head);
		if (m_head == NULL)
			break;

		prev_tx = cur_tx;
		cur_tx = &sc->xl_cdata.xl_tx_chain[idx];

		/* Pack the data into the descriptor. */
		error = xl_encap(sc, cur_tx, m_head);
		if (error) {
			cur_tx = prev_tx;
			continue;
		}

		/* Chain it together. */
		if (prev != NULL)
			prev->xl_ptr->xl_next = htole32(cur_tx->xl_phys);
		prev = cur_tx;

#if NBPFILTER > 0
		/*
		 * If there's a BPF listener, bounce a copy of this frame
		 * to him.
		 */
		if (ifp->if_bpf)
			bpf_mtap(ifp->if_bpf, cur_tx->xl_mbuf,
			    BPF_DIRECTION_OUT);
#endif

		XL_INC(idx, XL_TX_LIST_CNT);
		sc->xl_cdata.xl_tx_cnt++;
	}

	/*
	 * If there are no packets queued, bail.
	 */
	if (cur_tx == NULL)
		return;

	/*
	 * Place the request for the upload interrupt
	 * in the last descriptor in the chain. This way, if
	 * we're chaining several packets at once, we'll only
	 * get an interrupt once for the whole chain rather than
	 * once for each packet.
	 */
	cur_tx->xl_ptr->xl_status |= htole32(XL_TXSTAT_DL_INTR);

	/* Start transmission */
	sc->xl_cdata.xl_tx_prod = idx;
	start_tx->xl_prev->xl_ptr->xl_next = htole32(start_tx->xl_phys);

	/*
	 * Set a timeout in case the chip goes out to lunch.
	 */
	ifp->if_timer = 5;
}

void
xl_init(void *xsc)
{
	struct xl_softc		*sc = xsc;
	struct ifnet		*ifp = &sc->sc_arpcom.ac_if;
	int			s, i;
	struct mii_data		*mii = NULL;

	s = splnet();

	/*
	 * Cancel pending I/O and free all RX/TX buffers.
	 */
	xl_stop(sc);

	/* Reset the chip to a known state. */
	xl_reset(sc);

	if (sc->xl_hasmii)
		mii = &sc->sc_mii;

	if (mii == NULL) {
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_RESET);
		xl_wait(sc);
	}
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_TX_RESET);
	xl_wait(sc);
	DELAY(10000);

	/* Init our MAC address */
	XL_SEL_WIN(2);
	for (i = 0; i < ETHER_ADDR_LEN; i++) {
		CSR_WRITE_1(sc, XL_W2_STATION_ADDR_LO + i,
				sc->sc_arpcom.ac_enaddr[i]);
	}

	/* Clear the station mask. */
	for (i = 0; i < 3; i++)
		CSR_WRITE_2(sc, XL_W2_STATION_MASK_LO + (i * 2), 0);
#ifdef notdef
	/* Reset TX and RX. */
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_RESET);
	xl_wait(sc);
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_TX_RESET);
	xl_wait(sc);
#endif
	/* Init circular RX list. */
	if (xl_list_rx_init(sc) == ENOBUFS) {
		printf("%s: initialization failed: no "
			"memory for rx buffers\n", sc->sc_dev.dv_xname);
		xl_stop(sc);
		splx(s);
		return;
	}

	/* Init TX descriptors. */
	if (sc->xl_type == XL_TYPE_905B)
		xl_list_tx_init_90xB(sc);
	else
		xl_list_tx_init(sc);

	/*
	 * Set the TX freethresh value.
	 * Note that this has no effect on 3c905B "cyclone"
	 * cards but is required for 3c900/3c905 "boomerang"
	 * cards in order to enable the download engine.
	 */
	CSR_WRITE_1(sc, XL_TX_FREETHRESH, XL_PACKET_SIZE >> 8);

	/* Set the TX start threshold for best performance. */
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_TX_SET_START|sc->xl_tx_thresh);

	/*
	 * If this is a 3c905B, also set the tx reclaim threshold.
	 * This helps cut down on the number of tx reclaim errors
	 * that could happen on a busy network. The chip multiplies
	 * the register value by 16 to obtain the actual threshold
	 * in bytes, so we divide by 16 when setting the value here.
	 * The existing threshold value can be examined by reading
	 * the register at offset 9 in window 5.
	 */
	if (sc->xl_type == XL_TYPE_905B) {
		CSR_WRITE_2(sc, XL_COMMAND,
		    XL_CMD_SET_TX_RECLAIM|(XL_PACKET_SIZE >> 4));
	}

	/* Program promiscuous mode and multicast filters. */
	xl_iff(sc);

	/*
	 * Load the address of the RX list. We have to
	 * stall the upload engine before we can manipulate
	 * the uplist pointer register, then unstall it when
	 * we're finished. We also have to wait for the
	 * stall command to complete before proceeding.
	 * Note that we have to do this after any RX resets
	 * have completed since the uplist register is cleared
	 * by a reset.
	 */
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_UP_STALL);
	xl_wait(sc);
	CSR_WRITE_4(sc, XL_UPLIST_PTR, sc->sc_listmap->dm_segs[0].ds_addr +
	    offsetof(struct xl_list_data, xl_rx_list[0]));
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_UP_UNSTALL);
	xl_wait(sc);

	if (sc->xl_type == XL_TYPE_905B) {
		/* Set polling interval */
		CSR_WRITE_1(sc, XL_DOWN_POLL, 64);
		/* Load the address of the TX list */
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_DOWN_STALL);
		xl_wait(sc);
		CSR_WRITE_4(sc, XL_DOWNLIST_PTR,
		    sc->sc_listmap->dm_segs[0].ds_addr +
		    offsetof(struct xl_list_data, xl_tx_list[0]));
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_DOWN_UNSTALL);
		xl_wait(sc);
	}

	/*
	 * If the coax transceiver is on, make sure to enable
	 * the DC-DC converter.
 	 */
	XL_SEL_WIN(3);
	if (sc->xl_xcvr == XL_XCVR_COAX)
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_COAX_START);
	else
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_COAX_STOP);

	/*
	 * increase packet size to allow reception of 802.1q or ISL packets.
	 * For the 3c90x chip, set the 'allow large packets' bit in the MAC
	 * control register. For 3c90xB/C chips, use the RX packet size
	 * register.
	 */

	if (sc->xl_type == XL_TYPE_905B)
		CSR_WRITE_2(sc, XL_W3_MAXPKTSIZE, XL_PACKET_SIZE);
	else {
		u_int8_t macctl;
		macctl = CSR_READ_1(sc, XL_W3_MAC_CTRL);
		macctl |= XL_MACCTRL_ALLOW_LARGE_PACK;
		CSR_WRITE_1(sc, XL_W3_MAC_CTRL, macctl);
	}

	/* Clear out the stats counters. */
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_STATS_DISABLE);
	sc->xl_stats_no_timeout = 1;
	xl_stats_update(sc);
	sc->xl_stats_no_timeout = 0;
	XL_SEL_WIN(4);
	CSR_WRITE_2(sc, XL_W4_NET_DIAG, XL_NETDIAG_UPPER_BYTES_ENABLE);
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_STATS_ENABLE);

	/*
	 * Enable interrupts.
	 */
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_INTR_ACK|0xFF);
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_STAT_ENB|XL_INTRS);
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_INTR_ENB|XL_INTRS);

	if (sc->intr_ack)
		(*sc->intr_ack)(sc);

	/* Set the RX early threshold */
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_SET_THRESH|(XL_PACKET_SIZE >>2));
	CSR_WRITE_4(sc, XL_DMACTL, XL_DMACTL_UP_RX_EARLY);

	/* Enable receiver and transmitter. */
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_TX_ENABLE);
	xl_wait(sc);
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_ENABLE);
	xl_wait(sc);

	/* Restore state of BMCR */
	if (mii != NULL)
		mii_mediachg(mii);

	/* Select window 7 for normal operations. */
	XL_SEL_WIN(7);

	ifp->if_flags |= IFF_RUNNING;
	ifq_clr_oactive(&ifp->if_snd);

	splx(s);

	timeout_add_sec(&sc->xl_stsup_tmo, 1);
}

/*
 * Set media options.
 */
int
xl_ifmedia_upd(struct ifnet *ifp)
{
	struct xl_softc		*sc;
	struct ifmedia		*ifm = NULL;
	struct mii_data		*mii = NULL;

	sc = ifp->if_softc;

	if (sc->xl_hasmii)
		mii = &sc->sc_mii;
	if (mii == NULL)
		ifm = &sc->ifmedia;
	else
		ifm = &mii->mii_media;

	switch(IFM_SUBTYPE(ifm->ifm_media)) {
	case IFM_100_FX:
	case IFM_10_FL:
	case IFM_10_2:
	case IFM_10_5:
		xl_setmode(sc, ifm->ifm_media);
		return (0);
		break;
	default:
		break;
	}

	if (sc->xl_media & XL_MEDIAOPT_MII || sc->xl_media & XL_MEDIAOPT_BTX
		|| sc->xl_media & XL_MEDIAOPT_BT4) {
		xl_init(sc);
	} else {
		xl_setmode(sc, ifm->ifm_media);
	}

	return (0);
}

/*
 * Report current media status.
 */
void
xl_ifmedia_sts(struct ifnet *ifp, struct ifmediareq *ifmr)
{
	struct xl_softc		*sc;
	u_int32_t		icfg;
	u_int16_t		status = 0;
	struct mii_data		*mii = NULL;

	sc = ifp->if_softc;
	if (sc->xl_hasmii != 0)
		mii = &sc->sc_mii;

	XL_SEL_WIN(4);
	status = CSR_READ_2(sc, XL_W4_MEDIA_STATUS);

	XL_SEL_WIN(3);
	icfg = CSR_READ_4(sc, XL_W3_INTERNAL_CFG) & XL_ICFG_CONNECTOR_MASK;
	icfg >>= XL_ICFG_CONNECTOR_BITS;

	ifmr->ifm_active = IFM_ETHER;
	ifmr->ifm_status = IFM_AVALID;

	if ((status & XL_MEDIASTAT_CARRIER) == 0)
		ifmr->ifm_status |= IFM_ACTIVE;

	switch(icfg) {
	case XL_XCVR_10BT:
		ifmr->ifm_active = IFM_ETHER|IFM_10_T;
		if (CSR_READ_1(sc, XL_W3_MAC_CTRL) & XL_MACCTRL_DUPLEX)
			ifmr->ifm_active |= IFM_FDX;
		else
			ifmr->ifm_active |= IFM_HDX;
		break;
	case XL_XCVR_AUI:
		if (sc->xl_type == XL_TYPE_905B &&
		    sc->xl_media == XL_MEDIAOPT_10FL) {
			ifmr->ifm_active = IFM_ETHER|IFM_10_FL;
			if (CSR_READ_1(sc, XL_W3_MAC_CTRL) & XL_MACCTRL_DUPLEX)
				ifmr->ifm_active |= IFM_FDX;
			else
				ifmr->ifm_active |= IFM_HDX;
		} else
			ifmr->ifm_active = IFM_ETHER|IFM_10_5;
		break;
	case XL_XCVR_COAX:
		ifmr->ifm_active = IFM_ETHER|IFM_10_2;
		break;
	/*
	 * XXX MII and BTX/AUTO should be separate cases.
	 */

	case XL_XCVR_100BTX:
	case XL_XCVR_AUTO:
	case XL_XCVR_MII:
		if (mii != NULL) {
			mii_pollstat(mii);
			ifmr->ifm_active = mii->mii_media_active;
			ifmr->ifm_status = mii->mii_media_status;
		}
		break;
	case XL_XCVR_100BFX:
		ifmr->ifm_active = IFM_ETHER|IFM_100_FX;
		break;
	default:
		printf("%s: unknown XCVR type: %d\n", sc->sc_dev.dv_xname, icfg);
		break;
	}
}

int
xl_ioctl(struct ifnet *ifp, u_long command, caddr_t data)
{
	struct xl_softc *sc = ifp->if_softc;
	struct ifreq *ifr = (struct ifreq *)data;
	int s, error = 0;
	struct mii_data *mii = NULL;

	s = splnet();

	switch(command) {
	case SIOCSIFADDR:
		ifp->if_flags |= IFF_UP;
		if (!(ifp->if_flags & IFF_RUNNING))
			xl_init(sc);
		break;

	case SIOCSIFFLAGS:
		if (ifp->if_flags & IFF_UP) {
			if (ifp->if_flags & IFF_RUNNING)
				error = ENETRESET;
			else
				xl_init(sc);
		} else {
			if (ifp->if_flags & IFF_RUNNING)
				xl_stop(sc);
		}
		break;

	case SIOCGIFMEDIA:
	case SIOCSIFMEDIA:
		if (sc->xl_hasmii != 0)
			mii = &sc->sc_mii;
		if (mii == NULL)
			error = ifmedia_ioctl(ifp, ifr,
			    &sc->ifmedia, command);
		else
			error = ifmedia_ioctl(ifp, ifr,
			    &mii->mii_media, command);
		break;

	case SIOCGIFRXR:
		error = if_rxr_ioctl((struct if_rxrinfo *)ifr->ifr_data,
		    NULL, MCLBYTES, &sc->xl_cdata.xl_rx_ring);
		break;

	default:
		error = ether_ioctl(ifp, &sc->sc_arpcom, command, data);
	}

	if (error == ENETRESET) {
		if (ifp->if_flags & IFF_RUNNING)
			xl_iff(sc);
		error = 0;
	}

	splx(s);
	return (error);
}

void
xl_watchdog(struct ifnet *ifp)
{
	struct xl_softc		*sc;
	u_int16_t		status = 0;

	sc = ifp->if_softc;

	ifp->if_oerrors++;
	XL_SEL_WIN(4);
	status = CSR_READ_2(sc, XL_W4_MEDIA_STATUS);
	printf("%s: watchdog timeout\n", sc->sc_dev.dv_xname);

	if (status & XL_MEDIASTAT_CARRIER)
		printf("%s: no carrier - transceiver cable problem?\n",
								sc->sc_dev.dv_xname);
	xl_txeoc(sc);
	xl_txeof(sc);
	xl_rxeof(sc);
	xl_init(sc);

	if (!IFQ_IS_EMPTY(&ifp->if_snd))
		(*ifp->if_start)(ifp);
}

void
xl_freetxrx(struct xl_softc *sc)
{
	bus_dmamap_t	map;
	int		i;

	/*
	 * Free data in the RX lists.
	 */
	for (i = 0; i < XL_RX_LIST_CNT; i++) {
		if (sc->xl_cdata.xl_rx_chain[i].map->dm_nsegs != 0) {
			map = sc->xl_cdata.xl_rx_chain[i].map;

			bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
			    BUS_DMASYNC_POSTREAD);
			bus_dmamap_unload(sc->sc_dmat, map);
		}
		if (sc->xl_cdata.xl_rx_chain[i].xl_mbuf != NULL) {
			m_freem(sc->xl_cdata.xl_rx_chain[i].xl_mbuf);
			sc->xl_cdata.xl_rx_chain[i].xl_mbuf = NULL;
		}
	}
	bzero(&sc->xl_ldata->xl_rx_list, sizeof(sc->xl_ldata->xl_rx_list));
	/*
	 * Free the TX list buffers.
	 */
	for (i = 0; i < XL_TX_LIST_CNT; i++) {
		if (sc->xl_cdata.xl_tx_chain[i].map->dm_nsegs != 0) {
			map = sc->xl_cdata.xl_tx_chain[i].map;

			bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
			    BUS_DMASYNC_POSTWRITE);
			bus_dmamap_unload(sc->sc_dmat, map);
		}
		if (sc->xl_cdata.xl_tx_chain[i].xl_mbuf != NULL) {
			m_freem(sc->xl_cdata.xl_tx_chain[i].xl_mbuf);
			sc->xl_cdata.xl_tx_chain[i].xl_mbuf = NULL;
		}
	}
	bzero(&sc->xl_ldata->xl_tx_list, sizeof(sc->xl_ldata->xl_tx_list));
}

/*
 * Stop the adapter and free any mbufs allocated to the
 * RX and TX lists.
 */
void
xl_stop(struct xl_softc *sc)
{
	struct ifnet *ifp;

	/* Stop the stats updater. */
	timeout_del(&sc->xl_stsup_tmo);

	ifp = &sc->sc_arpcom.ac_if;

	ifp->if_flags &= ~IFF_RUNNING;
	ifq_clr_oactive(&ifp->if_snd);
	ifp->if_timer = 0;

	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_DISABLE);
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_STATS_DISABLE);
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_INTR_ENB);
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_DISCARD);
	xl_wait(sc);
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_TX_DISABLE);
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_COAX_STOP);
	DELAY(800);

#ifdef foo
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_RESET);
	xl_wait(sc);
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_TX_RESET);
	xl_wait(sc);
#endif

	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_INTR_ACK|XL_STAT_INTLATCH);
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_STAT_ENB|0);
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_INTR_ENB|0);

	if (sc->intr_ack)
		(*sc->intr_ack)(sc);

	xl_freetxrx(sc);
}

#ifndef SMALL_KERNEL
void
xl_wol_power(struct xl_softc *sc)
{
	/* Re-enable RX and call upper layer WOL power routine
	 * if WOL is enabled. */
	if ((sc->xl_flags & XL_FLAG_WOL) && sc->wol_power) {
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_ENABLE);
		sc->wol_power(sc->wol_power_arg);
	}
}
#endif

void
xl_attach(struct xl_softc *sc)
{
	u_int8_t enaddr[ETHER_ADDR_LEN];
	u_int16_t		xcvr[2];
	struct ifnet *ifp = &sc->sc_arpcom.ac_if;
	int i;
	uint64_t media = IFM_ETHER|IFM_100_TX|IFM_FDX;
	struct ifmedia *ifm;

	i = splnet();
	xl_reset(sc);
	splx(i);

	/*
	 * Get station address from the EEPROM.
	 */
	if (xl_read_eeprom(sc, (caddr_t)&enaddr, XL_EE_OEM_ADR0, 3, 1)) {
		printf("\n%s: failed to read station address\n",
		    sc->sc_dev.dv_xname);
		return;
	}
	memcpy(&sc->sc_arpcom.ac_enaddr, enaddr, ETHER_ADDR_LEN);

	if (bus_dmamem_alloc(sc->sc_dmat, sizeof(struct xl_list_data),
	    PAGE_SIZE, 0, sc->sc_listseg, 1, &sc->sc_listnseg,
	    BUS_DMA_NOWAIT | BUS_DMA_ZERO) != 0) {
		printf(": can't alloc list mem\n");
		return;
	}
	if (bus_dmamem_map(sc->sc_dmat, sc->sc_listseg, sc->sc_listnseg,
	    sizeof(struct xl_list_data), &sc->sc_listkva,
	    BUS_DMA_NOWAIT) != 0) {
		printf(": can't map list mem\n");
		return;
	}
	if (bus_dmamap_create(sc->sc_dmat, sizeof(struct xl_list_data), 1,
	    sizeof(struct xl_list_data), 0, BUS_DMA_NOWAIT,
	    &sc->sc_listmap) != 0) {
		printf(": can't alloc list map\n");
		return;
	}
	if (bus_dmamap_load(sc->sc_dmat, sc->sc_listmap, sc->sc_listkva,
	    sizeof(struct xl_list_data), NULL, BUS_DMA_NOWAIT) != 0) {
		printf(": can't load list map\n");
		return;
	}
	sc->xl_ldata = (struct xl_list_data *)sc->sc_listkva;

	for (i = 0; i < XL_RX_LIST_CNT; i++) {
		if (bus_dmamap_create(sc->sc_dmat, MCLBYTES, 1, MCLBYTES,
		    0, BUS_DMA_NOWAIT,
		    &sc->xl_cdata.xl_rx_chain[i].map) != 0) {
			printf(": can't create rx map\n");
			return;
		}
	}
	if (bus_dmamap_create(sc->sc_dmat, MCLBYTES, 1, MCLBYTES, 0,
	    BUS_DMA_NOWAIT, &sc->sc_rx_sparemap) != 0) {
		printf(": can't create rx spare map\n");
		return;
	}

	for (i = 0; i < XL_TX_LIST_CNT; i++) {
		if (bus_dmamap_create(sc->sc_dmat, MCLBYTES,
		    XL_TX_LIST_CNT - 3, MCLBYTES, 0, BUS_DMA_NOWAIT,
		    &sc->xl_cdata.xl_tx_chain[i].map) != 0) {
			printf(": can't create tx map\n");
			return;
		}
	}
	if (bus_dmamap_create(sc->sc_dmat, MCLBYTES, XL_TX_LIST_CNT - 3,
	    MCLBYTES, 0, BUS_DMA_NOWAIT, &sc->sc_tx_sparemap) != 0) {
		printf(": can't create tx spare map\n");
		return;
	}

	printf(", address %s\n", ether_sprintf(sc->sc_arpcom.ac_enaddr));

	if (sc->xl_flags & (XL_FLAG_INVERT_LED_PWR|XL_FLAG_INVERT_MII_PWR)) {
		u_int16_t n;

		XL_SEL_WIN(2);
		n = CSR_READ_2(sc, 12);

		if (sc->xl_flags & XL_FLAG_INVERT_LED_PWR)
			n |= 0x0010;

		if (sc->xl_flags & XL_FLAG_INVERT_MII_PWR)
			n |= 0x4000;

		CSR_WRITE_2(sc, 12, n);
	}

	/*
	 * Figure out the card type. 3c905B adapters have the
	 * 'supportsNoTxLength' bit set in the capabilities
	 * word in the EEPROM.
	 * Note: my 3c575C cardbus card lies. It returns a value
	 * of 0x1578 for its capabilities word, which is somewhat
	 * nonsensical. Another way to distinguish a 3c90x chip
	 * from a 3c90xB/C chip is to check for the 'supportsLargePackets'
	 * bit. This will only be set for 3c90x boomerage chips.
	 */
	xl_read_eeprom(sc, (caddr_t)&sc->xl_caps, XL_EE_CAPS, 1, 0);
	if (sc->xl_caps & XL_CAPS_NO_TXLENGTH ||
	    !(sc->xl_caps & XL_CAPS_LARGE_PKTS))
		sc->xl_type = XL_TYPE_905B;
	else
		sc->xl_type = XL_TYPE_90X;

	/* Set the TX start threshold for best performance. */
	sc->xl_tx_thresh = XL_MIN_FRAMELEN;

	timeout_set(&sc->xl_stsup_tmo, xl_stats_update, sc);

	ifp->if_softc = sc;
	ifp->if_flags = IFF_BROADCAST | IFF_SIMPLEX | IFF_MULTICAST;
	ifp->if_ioctl = xl_ioctl;
	if (sc->xl_type == XL_TYPE_905B)
		ifp->if_start = xl_start_90xB;
	else
		ifp->if_start = xl_start;
	ifp->if_watchdog = xl_watchdog;
	ifp->if_baudrate = 10000000;
	IFQ_SET_MAXLEN(&ifp->if_snd, XL_TX_LIST_CNT - 1);
	memcpy(ifp->if_xname, sc->sc_dev.dv_xname, IFNAMSIZ);

	ifp->if_capabilities = IFCAP_VLAN_MTU;

#ifndef XL905B_TXCSUM_BROKEN
	ifp->if_capabilities |= IFCAP_CSUM_IPv4|IFCAP_CSUM_TCPv4|
				IFCAP_CSUM_UDPv4;
#endif

	XL_SEL_WIN(3);
	sc->xl_media = CSR_READ_2(sc, XL_W3_MEDIA_OPT);

	xl_read_eeprom(sc, (char *)&xcvr, XL_EE_ICFG_0, 2, 0);
	sc->xl_xcvr = xcvr[0] | xcvr[1] << 16;
	sc->xl_xcvr &= XL_ICFG_CONNECTOR_MASK;
	sc->xl_xcvr >>= XL_ICFG_CONNECTOR_BITS;

	xl_mediacheck(sc);

	if (sc->xl_media & XL_MEDIAOPT_MII || sc->xl_media & XL_MEDIAOPT_BTX
	    || sc->xl_media & XL_MEDIAOPT_BT4) {
		ifmedia_init(&sc->sc_mii.mii_media, 0,
		    xl_ifmedia_upd, xl_ifmedia_sts);
		sc->xl_hasmii = 1;
		sc->sc_mii.mii_ifp = ifp;
		sc->sc_mii.mii_readreg = xl_miibus_readreg;
		sc->sc_mii.mii_writereg = xl_miibus_writereg;
		sc->sc_mii.mii_statchg = xl_miibus_statchg;
		xl_setcfg(sc);
		mii_attach((struct device *)sc, &sc->sc_mii, 0xffffffff,
		    MII_PHY_ANY, MII_OFFSET_ANY, 0);

		if (LIST_FIRST(&sc->sc_mii.mii_phys) == NULL) {
			ifmedia_add(&sc->sc_mii.mii_media, IFM_ETHER|IFM_NONE,
			    0, NULL);
			ifmedia_set(&sc->sc_mii.mii_media, IFM_ETHER|IFM_NONE);
		}
		else {
			ifmedia_set(&sc->sc_mii.mii_media, IFM_ETHER|IFM_AUTO);
		}
		ifm = &sc->sc_mii.mii_media;
	}
	else {
		ifmedia_init(&sc->ifmedia, 0, xl_ifmedia_upd, xl_ifmedia_sts);
		sc->xl_hasmii = 0;
		ifm = &sc->ifmedia;
	}

	/*
	 * Sanity check. If the user has selected "auto" and this isn't
	 * a 10/100 card of some kind, we need to force the transceiver
	 * type to something sane.
	 */
	if (sc->xl_xcvr == XL_XCVR_AUTO)
		xl_choose_xcvr(sc, 0);

	if (sc->xl_media & XL_MEDIAOPT_BT) {
		ifmedia_add(ifm, IFM_ETHER|IFM_10_T, 0, NULL);
		ifmedia_add(ifm, IFM_ETHER|IFM_10_T|IFM_HDX, 0, NULL);
		if (sc->xl_caps & XL_CAPS_FULL_DUPLEX)
			ifmedia_add(ifm, IFM_ETHER|IFM_10_T|IFM_FDX, 0, NULL);
	}

	if (sc->xl_media & (XL_MEDIAOPT_AUI|XL_MEDIAOPT_10FL)) {
		/*
		 * Check for a 10baseFL board in disguise.
		 */
		if (sc->xl_type == XL_TYPE_905B &&
		    sc->xl_media == XL_MEDIAOPT_10FL) {
			ifmedia_add(ifm, IFM_ETHER|IFM_10_FL, 0, NULL);
			ifmedia_add(ifm, IFM_ETHER|IFM_10_FL|IFM_HDX,
			    0, NULL);
			if (sc->xl_caps & XL_CAPS_FULL_DUPLEX)
				ifmedia_add(ifm,
				    IFM_ETHER|IFM_10_FL|IFM_FDX, 0, NULL);
		} else {
			ifmedia_add(ifm, IFM_ETHER|IFM_10_5, 0, NULL);
		}
	}

	if (sc->xl_media & XL_MEDIAOPT_BNC) {
		ifmedia_add(ifm, IFM_ETHER|IFM_10_2, 0, NULL);
	}

	if (sc->xl_media & XL_MEDIAOPT_BFX) {
		ifp->if_baudrate = 100000000;
		ifmedia_add(ifm, IFM_ETHER|IFM_100_FX, 0, NULL);
	}

	/* Choose a default media. */
	switch(sc->xl_xcvr) {
	case XL_XCVR_10BT:
		media = IFM_ETHER|IFM_10_T;
		xl_setmode(sc, media);
		break;
	case XL_XCVR_AUI:
		if (sc->xl_type == XL_TYPE_905B &&
		    sc->xl_media == XL_MEDIAOPT_10FL) {
			media = IFM_ETHER|IFM_10_FL;
			xl_setmode(sc, media);
		} else {
			media = IFM_ETHER|IFM_10_5;
			xl_setmode(sc, media);
		}
		break;
	case XL_XCVR_COAX:
		media = IFM_ETHER|IFM_10_2;
		xl_setmode(sc, media);
		break;
	case XL_XCVR_AUTO:
	case XL_XCVR_100BTX:
	case XL_XCVR_MII:
		/* Chosen by miibus */
		break;
	case XL_XCVR_100BFX:
		media = IFM_ETHER|IFM_100_FX;
		xl_setmode(sc, media);
		break;
	default:
		printf("%s: unknown XCVR type: %d\n", sc->sc_dev.dv_xname,
							sc->xl_xcvr);
		/*
		 * This will probably be wrong, but it prevents
		 * the ifmedia code from panicking.
		 */
		media = IFM_ETHER | IFM_10_T;
		break;
	}

	if (sc->xl_hasmii == 0)
		ifmedia_set(&sc->ifmedia, media);

	if (sc->xl_flags & XL_FLAG_NO_XCVR_PWR) {
		XL_SEL_WIN(0);
		CSR_WRITE_2(sc, XL_W0_MFG_ID, XL_NO_XCVR_PWR_MAGICBITS);
	}

#ifndef SMALL_KERNEL
	/* Check availability of WOL. */
	if ((sc->xl_caps & XL_CAPS_PWRMGMT) != 0) {
		ifp->if_capabilities |= IFCAP_WOL;
		ifp->if_wol = xl_wol;
		xl_wol(ifp, 0);
	}
#endif

	/*
	 * Call MI attach routines.
	 */
	if_attach(ifp);
	ether_ifattach(ifp);
}

int
xl_detach(struct xl_softc *sc)
{
	struct ifnet *ifp = &sc->sc_arpcom.ac_if;
	extern void xl_freetxrx(struct xl_softc *);

	/* Unhook our tick handler. */
	timeout_del(&sc->xl_stsup_tmo);

	xl_freetxrx(sc);

	/* Detach all PHYs */
	if (sc->xl_hasmii)
		mii_detach(&sc->sc_mii, MII_PHY_ANY, MII_OFFSET_ANY);

	/* Delete all remaining media. */
	ifmedia_delete_instance(&sc->sc_mii.mii_media, IFM_INST_ANY);

	ether_ifdetach(ifp);
	if_detach(ifp);

	return (0);
}

#ifndef SMALL_KERNEL
int
xl_wol(struct ifnet *ifp, int enable)
{
	struct xl_softc		*sc = ifp->if_softc;

	XL_SEL_WIN(7);
	if (enable) {
		if (!(ifp->if_flags & IFF_RUNNING))
			xl_init(sc);
		CSR_WRITE_2(sc, XL_W7_BM_PME, XL_BM_PME_MAGIC);
		sc->xl_flags |= XL_FLAG_WOL;
	} else {
		CSR_WRITE_2(sc, XL_W7_BM_PME, 0);
		sc->xl_flags &= ~XL_FLAG_WOL;
	}
	return (0);	
}
#endif

struct cfdriver xl_cd = {
	0, "xl", DV_IFNET
};
@


1.131
log
@G/C IFQ_SET_READY().
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.130 2015/11/25 03:09:58 dlg Exp $	*/
a1274 1
		ifp->if_opackets++;
a1334 2

		ifp->if_opackets++;
@


1.130
log
@replace IFF_OACTIVE manipulation with mpsafe operations.

there are two things shared between the network stack and drivers
in the send path: the send queue and the IFF_OACTIVE flag. the send
queue is now protected by a mutex. this diff makes the oactive
functionality mpsafe too.

IFF_OACTIVE is part of if_flags. there are two problems with that.
firstly, if_flags is a short and we dont have any MI atomic operations
to manipulate a short. secondly, while we could make the IFF_OACTIVE
operates mpsafe, all changes to other flags would have to be made
safe at the same time, otherwise a read-modify-write cycle on their
updates could clobber the oactive change.

instead, this moves the oactive mark into struct ifqueue and provides
an API for changing it. there's ifq_set_oactive, ifq_clr_oactive,
and ifq_is_oactive. these are modelled on ifsq_set_oactive,
ifsq_clr_oactive, and ifsq_is_oactive in dragonflybsd.

this diff includes changes to all the drivers manipulating IFF_OACTIVE
to now use the ifsq_{set,clr_is}_oactive API too.

ok kettenis@@ mpi@@ jmatthew@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.129 2015/11/24 17:11:39 mpi Exp $	*/
a2467 1
	IFQ_SET_READY(&ifp->if_snd);
@


1.129
log
@You only need <net/if_dl.h> if you're using LLADDR() or a sockaddr_dl.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.128 2015/11/24 13:33:17 mpi Exp $	*/
d1292 1
a1292 1
		ifp->if_flags &= ~IFF_OACTIVE;
d1346 1
a1346 1
		ifp->if_flags &= ~IFF_OACTIVE;
d1661 1
a1661 1
			ifp->if_flags |= IFF_OACTIVE;
d1785 1
a1785 1
	if (ifp->if_flags & IFF_OACTIVE)
d1794 1
a1794 1
			ifp->if_flags |= IFF_OACTIVE;
d2038 1
a2038 1
	ifp->if_flags &= ~IFF_OACTIVE;
d2299 2
a2300 1
	ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);
@


1.128
log
@The only network driver needing <net/if_types.h> is upl(4) for IFT_OTHER.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.127 2015/10/25 12:48:46 mpi Exp $	*/
a116 1
#include <net/if_dl.h>
@


1.127
log
@arp_ifinit() is no longer needed.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.126 2015/09/11 13:02:28 stsp Exp $	*/
a117 1
#include <net/if_types.h>
@


1.126
log
@Make room for media types of the future. Extend the ifmedia word to 64 bits.
This changes numbers of the SIOCSIFMEDIA and SIOCGIFMEDIA ioctls and
grows struct ifmediareq.

Old ifconfig and dhclient binaries can still assign addresses, however
the 'media' subcommand stops working. Recompiling ifconfig and dhclient
with new headers before a reboot should not be necessary unless in very
special circumstances where non-default media settings must be used to
get link and console access is not available.

There may be some MD fallout but that will be cleared up later.

ok deraadt miod
with help and suggestions from several sharks attending l2k15
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.125 2015/06/24 09:40:54 mpi Exp $	*/
a2164 1
	struct ifaddr *ifa = (struct ifaddr *)data;
a2174 2
		if (ifa->ifa_addr->sa_family == AF_INET)
			arp_ifinit(&sc->sc_arpcom, ifa);
@


1.125
log
@Increment if_ipackets in if_input().

Note that pseudo-drivers not using if_input() are not affected by this
conversion.

ok mikeb@@, kettenis@@, claudio@@, dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.124 2015/05/21 09:25:18 mpi Exp $	*/
d169 1
a169 1
void xl_setmode(struct xl_softc *, int);
d679 1
a679 1
xl_setmode(struct xl_softc *sc, int media)
d2352 2
a2353 1
	int i, media = IFM_ETHER|IFM_100_TX|IFM_FDX;
@


1.124
log
@tedu commented out xl_testpacket(), remove one of the IFQ_ENQUEUE()
in the tree.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.123 2015/03/24 11:23:02 mpi Exp $	*/
a1196 1
		ifp->if_ipackets++;
@


1.123
log
@Convert to  if_input().

Apparently krw@@ test diffs faster than I can commit them!
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.122 2015/03/14 03:38:47 jsg Exp $	*/
a179 3
#ifdef notdef
void xl_testpacket(struct xl_softc *);
#endif
a658 29

#ifdef notdef
void
xl_testpacket(struct xl_softc *sc)
{
	struct mbuf	*m;
	struct ifnet	*ifp;
	int		error;

	ifp = &sc->sc_arpcom.ac_if;

	MGETHDR(m, M_DONTWAIT, MT_DATA);

	if (m == NULL)
		return;

	memcpy(mtod(m, struct ether_header *)->ether_dhost,
	    &sc->sc_arpcom.ac_enaddr, ETHER_ADDR_LEN);
	memcpy(mtod(m, struct ether_header *)->ether_shost,
	    &sc->sc_arpcom.ac_enaddr, ETHER_ADDR_LEN);
	mtod(m, struct ether_header *)->ether_type = htons(3);
	mtod(m, unsigned char *)[14] = 0;
	mtod(m, unsigned char *)[15] = 0;
	mtod(m, unsigned char *)[16] = 0xE3;
	m->m_len = m->m_pkthdr.len = sizeof(struct ether_header) + 3;
	IFQ_ENQUEUE(&ifp->if_snd, m, NULL, error);
	xl_start(ifp);
}
#endif
@


1.122
log
@Remove some includes include-what-you-use claims don't
have any direct symbols used.  Tested for indirect use by compiling
amd64/i386/sparc64 kernels.

ok tedu@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.121 2014/12/22 02:28:51 tedu Exp $	*/
d1167 1
a1229 1
		m->m_pkthdr.rcvif = ifp;
a1230 8
#if NBPFILTER > 0
		/*
		 * Handle BPF listeners. Let the BPF user see the packet.
		 */
		if (ifp->if_bpf) {
			bpf_mtap(ifp->if_bpf, m, BPF_DIRECTION_IN);
		}
#endif
d1248 1
a1248 1
		ether_input_mbuf(ifp, m);
d1273 2
@


1.121
log
@unifdef INET
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.120 2014/12/19 07:23:57 deraadt Exp $	*/
a123 1
#include <dev/mii/mii.h>
@


1.120
log
@another handful of bcopy -> memcpy because there is no overlap
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.119 2014/12/08 10:58:45 brad Exp $	*/
a120 1
#ifdef INET
a122 1
#endif
a2215 1
#ifdef INET
a2217 1
#endif
@


1.119
log
@Have foo_init() call foo_reset() to reset the chip to a known state
as is the case for a lot of the other drivers. Remove some redundant
calls to foo_stop() and foo_reset() before foo_init().

Tested with DP83815, 3c905C, 8139 and ST201.
Mostly from FreeBSD.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.118 2014/11/24 10:33:37 brad Exp $	*/
d681 4
a684 4
	bcopy(&sc->sc_arpcom.ac_enaddr,
		mtod(m, struct ether_header *)->ether_dhost, ETHER_ADDR_LEN);
	bcopy(&sc->sc_arpcom.ac_enaddr,
		mtod(m, struct ether_header *)->ether_shost, ETHER_ADDR_LEN);
d2411 1
a2411 1
	bcopy(enaddr, &sc->sc_arpcom.ac_enaddr, ETHER_ADDR_LEN);
d2516 1
a2516 1
	bcopy(sc->sc_dev.dv_xname, ifp->if_xname, IFNAMSIZ);
@


1.118
log
@rxr ioctl handling.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.117 2014/11/24 03:47:55 brad Exp $	*/
d204 1
a204 2
		if (ifp->if_flags & IFF_RUNNING) {
			xl_reset(sc);
a205 1
		}
a208 1
		xl_reset(sc);
d1506 1
a1506 2
		if (status & XL_STAT_ADFAIL) {
			xl_reset(sc);
a1507 1
		}
d1915 3
a2285 1
	xl_reset(sc);
d2569 1
a2569 1
	if (sc->xl_xcvr == XL_XCVR_AUTO) {
a2570 4
		i = splnet();
		xl_reset(sc);
		splx(i);
	}
@


1.117
log
@- Check IFF_RUNNING in xl_intr().

From FreeBSD

- Clear IFF_RUNNING at the top of xl_stop() before freeing resources.

Tested with 3c905C.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.116 2014/09/14 14:17:25 jsg Exp $	*/
d2248 5
@


1.116
log
@remove uneeded proc.h includes
ok mpi@@ kspillner@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.115 2014/07/22 13:12:12 mpi Exp $	*/
d1491 3
d2345 2
a2370 2

	ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);
@


1.115
log
@Fewer <netinet/in_systm.h>
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.114 2014/07/08 05:35:18 dlg Exp $	*/
a113 1
#include <sys/proc.h>   /* only for declaration of wakeup() used by vm.h */
@


1.114
log
@cut things that relied on mclgeti for rx ring accounting/restriction over
to using if_rxr.

cut the reporting systat did over to the rxr ioctl.

tested as much as i can on alpha, amd64, and sparc64.
mpi@@ has run it on macppc.
ok mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.113 2014/05/30 19:51:22 chl Exp $	*/
a123 2
#include <netinet/in_systm.h>
#include <netinet/ip.h>
@


1.113
log
@Remove dead assignment and newly created unused variable.

Found by LLVM/Clang Static Analyzer.

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.112 2013/12/28 03:35:01 deraadt Exp $	*/
d1096 1
a1096 1
	cd->xl_rx_cnt = 0;
d1105 1
d1109 2
a1110 1
	while (cd->xl_rx_cnt < XL_RX_LIST_CNT) {
a1113 1
		cd->xl_rx_cnt++;
d1115 1
d1127 1
a1127 1
	m_new = MCLGETI(NULL, M_DONTWAIT, &sc->sc_arpcom.ac_if, MCLBYTES);
d1187 1
a1187 1
	while (sc->xl_cdata.xl_rx_cnt > 0) {
d1198 1
a1198 1
		sc->xl_cdata.xl_rx_cnt--;
a2514 2

	m_clsetwms(ifp, MCLBYTES, 2, XL_RX_LIST_CNT - 1);
@


1.112
log
@The few network drivers that called their children's (ie. mii PHY
drivers) activate functions at DVACT_RESUME time do not need to do
so, since their PHYs are repaired by IFF_UP.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.111 2013/12/06 21:03:03 deraadt Exp $	*/
a1104 1
	struct xl_list_data     *ld;
a1106 1
	ld = sc->xl_ldata;
@


1.111
log
@Add a DVACT_WAKEUP op to the *_activate() API.  This is called after the
kernel resumes normal (non-cold, able to run processes, etc) operation.
Previously we were relying on specific DVACT_RESUME op's in drivers
creating callback/threads themselves, but that has become too common,
indicating the need for a built-in mechanism.
ok dlg kettenis, tested by a sufficient amount of people
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.110 2013/08/07 01:06:31 bluhm Exp $	*/
a214 1
		rv = config_activate_children(self, act);
@


1.110
log
@Most network drivers include netinet/in_var.h, but apparently they
don't have to.  Just remove these include lines.
Compiled on amd64 i386 sparc64; OK henning@@ mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.109 2013/03/14 01:42:45 brad Exp $	*/
a205 3
	case DVACT_QUIESCE:
		rv = config_activate_children(self, act);
		break;
d213 6
d225 1
a225 2
	case DVACT_RESUME:
		xl_reset(sc);
a226 2
		if (ifp->if_flags & IFF_UP)
			xl_init(sc);
@


1.109
log
@Cosmetic tweaking. No functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.108 2013/03/07 05:55:30 brad Exp $	*/
a124 1
#include <netinet/in_var.h>
@


1.108
log
@XL_DMACTL is a 32bit register, use the 32bit write macro.

From FreeBSD

ok chris@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.107 2012/10/19 02:49:55 brad Exp $	*/
a1119 1

a1129 1
	
a1170 1

d1269 1
d1271 1
a1291 1

a1498 1

d2518 2
a2672 1
	m_clsetwms(ifp, MCLBYTES, 2, XL_RX_LIST_CNT - 1);
@


1.107
log
@Simplify xl_iff_90x() a bit and only check ac->ac_multicnt since ac_multicnt
is also bumped for multicast ranges.

ok mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.106 2012/10/13 17:24:46 deraadt Exp $	*/
d2073 1
a2073 1
	CSR_WRITE_2(sc, XL_DMACTL, XL_DMACTL_UP_RX_EARLY);
@


1.106
log
@Move WOL activation to DVACT_POWERDOWN (instead of doing it twice, at
DVACT_QUIESCE and DVACT_SUSPEND time).
Tested by stsp.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.105 2012/02/24 06:19:00 guenther Exp $	*/
d604 1
a604 2
	if (ifp->if_flags & IFF_PROMISC || ac->ac_multirangecnt > 0 ||
	    ac->ac_multicnt > 0) {
@


1.105
log
@Correct the spelling of "transferred" and "transferring"

from Tobias Ulmer (tobiasu at tmux.org); ok jmc@@, krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.104 2011/07/14 16:38:27 stsp Exp $	*/
a207 3
#ifndef SMALL_KERNEL
		xl_wol_power(sc);
#endif
d215 4
a221 1
		rv = config_activate_children(self, act);
@


1.104
log
@We must not call xl_wol_power() from xl_stop(). If we do the device
can be set into D3 sleep state at the wrong time. Fixes lock-up issues
reported by Thomas Gerlach.
Also, the interface needs to be running for WOL to work, so set it up
from within xl_wol() if it's not running yet.
"you don't need an ok for this" deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.103 2011/07/08 18:56:47 stsp Exp $	*/
d80 1
a80 1
 * The 3c90x series chips use a bus-master DMA interface for transfering
@


1.103
log
@Fix WoL support in xl(4). Now works with my hardware (3Com 3c905C).
ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.102 2011/06/21 16:52:45 tedu Exp $	*/
d218 3
a2378 4

#ifndef SMALL_KERNEL
	xl_wol_power(sc);
#endif
d2710 2
@


1.102
log
@remove some unnecessary casts.  ok blambert deraadt kettenis matthew
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.101 2011/04/17 20:52:43 stsp Exp $	*/
d196 1
d208 3
d2378 12
a2389 2
	/* Call upper layer WOL power routine if WOL is enabled. */
	if ((sc->xl_flags & XL_FLAG_WOL) && sc->wol_power)
d2391 2
a2393 1
}
@


1.101
log
@Add wol support to xl(4). Not really tested, but hopefully someone will
test it now that it's in-tree. ok deraadt ("It causes no harm")
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.100 2011/04/05 18:01:21 henning Exp $	*/
d453 1
a453 1
	bzero((char *)&frame, sizeof(frame));
d471 1
a471 1
	bzero((char *)&frame, sizeof(frame));
d1052 1
a1052 1
	bzero((char *)ld->xl_tx_list, sizeof(struct xl_list) * XL_TX_LIST_CNT);
d1536 1
a1536 1
	bzero((char *)&xl_stats, sizeof(struct xl_stats));
d2311 1
a2311 2
	bzero((char *)&sc->xl_ldata->xl_rx_list,
		sizeof(sc->xl_ldata->xl_rx_list));
d2328 1
a2328 2
	bzero((char *)&sc->xl_ldata->xl_tx_list,
		sizeof(sc->xl_ldata->xl_tx_list));
d2401 1
a2401 1
	bcopy(enaddr, (char *)&sc->sc_arpcom.ac_enaddr, ETHER_ADDR_LEN);
@


1.100
log
@mechanic rename M_{TCP|UDP}V4_CSUM_OUT -> M_{TCP|UDP}_CSUM_OUT
ok claudio krw
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.99 2010/09/22 08:49:14 claudio Exp $	*/
d194 3
d2374 6
d2649 9
d2689 18
@


1.99
log
@Call bus_dmamap_sync() of a dma descriptor before checking the ownership
of the descriptor. Diff created and tested by Loganaden Velvindron.
Looks good dlg@@ and myself
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.98 2010/09/21 01:05:12 claudio Exp $	*/
d1664 1
a1664 1
			if (m_head->m_pkthdr.csum_flags & M_TCPV4_CSUM_OUT)
d1666 1
a1666 1
			if (m_head->m_pkthdr.csum_flags & M_UDPV4_CSUM_OUT)
@


1.98
log
@mclgeti() support for xl(4). All done by Loganaden Velvindron.
Tested by various people on tech@@. OK dlg@@, deraadt@@ and myself
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.97 2010/09/20 07:40:41 deraadt Exp $	*/
d1183 1
a1183 2
	while ((rxstat = letoh32(sc->xl_cdata.xl_rx_cons->xl_ptr->xl_status))
	    != 0 && sc->xl_cdata.xl_rx_cnt > 0) {
d1185 6
a1195 4
		bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,
		    ((caddr_t)cur_rx->xl_ptr - sc->sc_listkva),
		    sizeof(struct xl_list),
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
@


1.97
log
@Stop doing shutdown hooks in network drivers where possible.  We already
take all interfaces down, via their xxstop routines.  Claudio and I have
verified that none of the shutdown hooks do much extra beyond what xxstop
was already doing; it is largely a pile of junk.
ok claudio, some early comments by sthen; also read by matthew, jsg
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.96 2010/09/07 16:21:43 deraadt Exp $	*/
a155 1
int xl_rx_resync(struct xl_softc *);
d181 1
a1077 2
		if (xl_newbuf(sc, &cd->xl_rx_chain[i]) == ENOBUFS)
			return(ENOBUFS);
d1088 14
a1101 1
	cd->xl_rx_head = &cd->xl_rx_chain[0];
d1103 6
a1108 1
	return (0);
d1111 1
d1121 3
a1123 2
	MGETHDR(m_new, M_DONTWAIT, MT_DATA);
	if (m_new == NULL)
a1125 6
	MCLGET(m_new, M_DONTWAIT);
	if (!(m_new->m_flags & M_EXT)) {
		m_freem(m_new);
		return (ENOBUFS);
	}

a1163 26
int
xl_rx_resync(struct xl_softc *sc)
{
	struct xl_chain_onefrag *pos;
	int i;

	pos = sc->xl_cdata.xl_rx_head;

	for (i = 0; i < XL_RX_LIST_CNT; i++) {
		bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,
		    ((caddr_t)pos->xl_ptr - sc->sc_listkva),
		    sizeof(struct xl_list),
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

		if (pos->xl_ptr->xl_status)
			break;
		pos = pos->xl_next;
	}

	if (i == XL_RX_LIST_CNT)
		return (0);

	sc->xl_cdata.xl_rx_head = pos;

	return (EAGAIN);
}
d1183 7
a1189 4
	while ((rxstat = letoh32(sc->xl_cdata.xl_rx_head->xl_ptr->xl_status))
	    != 0) {
		cur_rx = sc->xl_cdata.xl_rx_head;
		sc->xl_cdata.xl_rx_head = cur_rx->xl_next;
a1190 1

d1214 1
d1228 1
a1228 16
			continue;
		}

		/* No errors; receive the packet. */	
		m = cur_rx->xl_mbuf;

		/*
		 * Try to conjure up a new mbuf cluster. If that
		 * fails, it means we have an out of memory condition and
		 * should leave the buffer in place and continue. This will
		 * result in a lost packet, but there's little else we
		 * can do in this situation.
		 */
		if (xl_newbuf(sc, cur_rx) == ENOBUFS) {
			ifp->if_ierrors++;
			cur_rx->xl_ptr->xl_status = htole32(0);
d1262 1
a1262 1

a1278 4
		CSR_WRITE_4(sc, XL_UPLIST_PTR,
		    sc->sc_listmap->dm_segs[0].ds_addr +
		    offsetof(struct xl_list_data, xl_rx_list[0]));
		sc->xl_cdata.xl_rx_head = &sc->xl_cdata.xl_rx_chain[0];
d1280 1
d1283 1
d1488 2
a1489 2
		if (status & XL_STAT_UP_COMPLETE) {
			int curpkts;
a1490 7
			curpkts = ifp->if_ipackets;
			xl_rxeof(sc);
			if (curpkts == ifp->if_ipackets) {
				while (xl_rx_resync(sc))
					xl_rxeof(sc);
			}
		}
d2644 1
@


1.96
log
@remove the powerhook code.  All architectures now use the ca_activate tree
traversal code to suspend/resume
ok oga kettenis blambert
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.95 2010/09/06 16:01:52 deraadt Exp $	*/
a165 1
void xl_shutdown(void *);
a2678 2

	sc->sc_sdhook = shutdownhook_establish(xl_shutdown, sc);
a2698 3
	if (sc->sc_sdhook != NULL)
		shutdownhook_disestablish(sc->sc_sdhook);

a2702 9
}

void
xl_shutdown(void *v)
{
	struct xl_softc	*sc = (struct xl_softc *)v;

	xl_reset(sc);
	xl_stop(sc);
@


1.95
log
@initialize rv to 0 in the activate function
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.94 2010/08/31 17:13:47 deraadt Exp $	*/
a195 2
void xl_powerhook(int, void *);

a223 6
void
xl_powerhook(int why, void *arg)
{
	xl_activate(arg, why);
}

a2681 1
	sc->sc_pwrhook = powerhook_establish(xl_powerhook, sc);
a2703 2
	if (sc->sc_pwrhook != NULL)
		powerhook_disestablish(sc->sc_pwrhook);
@


1.94
log
@Add DVACT_QUIECE support.  This is called before splhigh() and before
DVACT_SUSPEND, therefore DVACT_QUIECE can do standard sleeping operations
to get ready.
Discussed quite a while back with kettenis and jakemsr, oga suddenly needed
it as well and wrote half of it, so it was time to finish it.
proofread by miod.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.93 2010/08/31 16:29:56 deraadt Exp $	*/
d203 1
a203 1
	int rv;
@


1.93
log
@activate function should return result of config_activate_children
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.92 2010/08/27 15:43:41 deraadt Exp $	*/
d206 3
@


1.92
log
@Move the xl_pci_activate function into xl_activate so that it is in the
sub-driver, and then xl_powerhook can simply be a wrapper around it
ok kettenis; discussion about nested structure aliasing with miod
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.91 2010/08/12 14:21:55 kettenis Exp $	*/
d203 1
d211 1
a211 1
		config_activate_children(self, act);
d215 1
a215 1
		config_activate_children(self, act);
d220 1
a220 1
	return (0);
@


1.91
log
@Reset the chip upon suspend, to make sure it stops DMA.  Reset it again upon
resume to make sure the chip is initialized the same way as upon attach.
Fixes memory corruption after resume on the Dell Inspirion 4150.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.90 2010/08/06 02:45:53 deraadt Exp $	*/
d196 1
a196 1
void xl_power(int, void *);
d198 2
a199 2
void
xl_power(int why, void *arg)
d201 2
a202 3
	struct xl_softc *sc = arg;
	struct ifnet *ifp;
	int s;
d204 3
a206 6
	s = splnet();
	if (why != PWR_RESUME)
		xl_stop(sc);
	else {
		ifp = &sc->sc_arpcom.ac_if;
		if (ifp->if_flags & IFF_UP) {
d208 8
d217 1
a217 1
		}
d219 7
a225 1
	splx(s);
d2686 1
a2686 1
	sc->sc_pwrhook = powerhook_establish(xl_power, sc);
@


1.90
log
@ca_activate function for suspend/resume
tested by mlarkin
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.89 2010/05/19 15:27:35 oga Exp $	*/
a181 1
void xl_reset(struct xl_softc *);
@


1.89
log
@BUS_DMA_ZERO instead of alloc, map, bzero.

ok krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.88 2009/12/22 21:10:25 naddy Exp $	*/
a163 2
void xl_init(void *);
void xl_stop(struct xl_softc *);
@


1.88
log
@rewrite promiscuous mode and multicast handling; from Brad
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.87 2009/10/15 17:54:54 deraadt Exp $	*/
d2430 1
a2430 1
	    BUS_DMA_NOWAIT) != 0) {
a2451 1
	bzero(sc->xl_ldata, sizeof(struct xl_list_data));
@


1.87
log
@Add detach support to a few more drivers, and in others do the neccessary
operations in the detach function in the right order.  Also ensure that the
interrupt handlers not trust registers that go away.
read over very carefully by dms, tested by me
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.86 2009/06/02 07:55:10 deraadt Exp $	*/
d181 3
a183 3
void xl_setmulti(struct xl_softc *);
void xl_setmulti_hash(struct xl_softc *);
void xl_setpromisc(struct xl_softc *);
d559 9
d573 1
a573 1
xl_setmulti(struct xl_softc *sc)
d575 1
a575 1
	struct ifnet	*ifp;
d579 1
a579 1
	ifp = &sc->sc_arpcom.ac_if;
a580 1
	XL_SEL_WIN(5);
d582 3
d586 13
a598 4
	if (ifp->if_flags & IFF_ALLMULTI) {
		rxfilt |= XL_RXFILTER_ALLMULTI;
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_SET_FILT|rxfilt);
		return;
d601 1
a601 4
	if (ac->ac_multicnt > 0)
		rxfilt |= XL_RXFILTER_ALLMULTI;
	else
		rxfilt &= ~XL_RXFILTER_ALLMULTI;
d603 1
a603 1
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_SET_FILT|rxfilt);
d610 1
a610 1
xl_setmulti_hash(struct xl_softc *sc)
d612 2
a613 1
	struct ifnet	*ifp;
a614 1
	struct arpcom	*ac = &sc->sc_arpcom;
a617 1
	int		mcnt = 0;
d619 1
a619 1
	ifp = &sc->sc_arpcom.ac_if;
a620 1
	XL_SEL_WIN(5);
d622 4
d627 14
a640 7
	if (ifp->if_flags & IFF_ALLMULTI) {
allmulti:
		rxfilt |= XL_RXFILTER_ALLMULTI;
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_SET_FILT|rxfilt);
		return;
	} else
		rxfilt &= ~XL_RXFILTER_ALLMULTI;
d642 3
d646 7
a652 3
	/* first, zot all the existing hash bits */
	for (i = 0; i < XL_HASHFILT_SIZE; i++)
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_SET_HASH|i);
d654 1
a654 6
	/* now program new ones */
	ETHER_FIRST_MULTI(step, ac, enm);
	while (enm != NULL) {
		if (bcmp(enm->enm_addrlo, enm->enm_addrhi, ETHER_ADDR_LEN)) {
			ifp->if_flags |= IFF_ALLMULTI;
			goto allmulti;
a655 5
		h = ether_crc32_be(enm->enm_addrlo, ETHER_ADDR_LEN) &
		    0x000000FF;
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_SET_HASH|XL_HASH_SET|h);
		mcnt++;
		ETHER_NEXT_MULTI(step, enm);
d658 1
a658 4
	if (mcnt)
		rxfilt |= XL_RXFILTER_MULTIHASH;
	else
		rxfilt &= ~XL_RXFILTER_MULTIHASH;
d660 1
a660 20
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_SET_FILT|rxfilt);
}

void
xl_setpromisc(struct xl_softc *sc)
{
	struct ifnet *ifp;
	u_int8_t rxfilt;

	ifp = &sc->sc_arpcom.ac_if;

	XL_SEL_WIN(5);
	rxfilt = CSR_READ_1(sc, XL_W5_RX_FILTER);

	if (ifp->if_flags & IFF_PROMISC)
		rxfilt |= XL_RXFILTER_ALLFRAMES;
	else
		rxfilt &= ~XL_RXFILTER_ALLFRAMES;

	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_SET_FILT|rxfilt);
a662 1

a1938 1
	u_int16_t		rxfilt = 0;
d2016 2
a2017 31
	/* Set RX filter bits. */
	XL_SEL_WIN(5);
	rxfilt = CSR_READ_1(sc, XL_W5_RX_FILTER);

	/* Set the individual bit to receive frames for this host only. */
	rxfilt |= XL_RXFILTER_INDIVIDUAL;

	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_SET_FILT|rxfilt);

	/* Set promiscuous mode. */
	xl_setpromisc(sc);

	rxfilt = CSR_READ_1(sc, XL_W5_RX_FILTER);

	/*
	 * Set capture broadcast bit to capture broadcast frames.
	 */
	if (ifp->if_flags & IFF_BROADCAST)
		rxfilt |= XL_RXFILTER_BROADCAST;
	else
		rxfilt &= ~XL_RXFILTER_BROADCAST;

	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_SET_FILT|rxfilt);

	/*
	 * Program the multicast filter, if necessary.
	 */
	if (sc->xl_type == XL_TYPE_905B)
		xl_setmulti_hash(sc);
	else
		xl_setmulti(sc);
d2251 1
a2251 1
#endif /* INET */
a2254 1
		XL_SEL_WIN(5);
d2256 4
a2259 9
			if (ifp->if_flags & IFF_RUNNING &&
			    (ifp->if_flags ^ sc->xl_if_flags) &
			     IFF_PROMISC) {
				xl_setpromisc(sc);
				XL_SEL_WIN(7);
			} else {
				if (!(ifp->if_flags & IFF_RUNNING))
					xl_init(sc);
			}
a2263 1
		sc->xl_if_flags = ifp->if_flags;
d2265 1
d2277 1
d2283 2
a2284 6
		if (ifp->if_flags & IFF_RUNNING) {
			if (sc->xl_type == XL_TYPE_905B)
				xl_setmulti_hash(sc);
			else
				xl_setmulti(sc);
		}
@


1.86
log
@The xl_detach() function is now used by pci code, so it must be in the
shared code in case either cardbus or pci varients are not configured.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.85 2008/11/28 02:44:17 brad Exp $	*/
d2410 3
a2438 3
	/* Stop the stats updater. */
	timeout_del(&sc->xl_stsup_tmo);

a2739 3
	ether_ifdetach(ifp);
	if_detach(ifp);

d2744 3
@


1.85
log
@Eliminate the redundant bits of code for MTU and multicast handling
from the individual drivers now that ether_ioctl() handles this.

Shrinks the i386 kernels by..
RAMDISK - 2176 bytes
RAMDISKB - 1504 bytes
RAMDISKC - 736 bytes

Tested by naddy@@/okan@@/sthen@@/brad@@/todd@@/jmc@@ and lots of users.
Build tested on almost all archs by todd@@/brad@@

ok naddy@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.84 2008/11/19 08:20:01 brad Exp $	*/
d2720 29
@


1.84
log
@Make sure to check that the TX queue is empty before clearing the
watchdog timer.

From FreeBSD

Tested on quite a few 3c905/B/C/575 adapters.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.83 2008/11/19 08:17:37 brad Exp $	*/
a2283 7
	case SIOCSIFMTU:
		if (ifr->ifr_mtu > ETHERMTU || ifr->ifr_mtu < ETHERMIN)
			error = EINVAL;
		else if (ifp->if_mtu != ifr->ifr_mtu)
			ifp->if_mtu = ifr->ifr_mtu;
		break;

a2301 20
	case SIOCADDMULTI:
	case SIOCDELMULTI:
		error = (command == SIOCADDMULTI) ?
		    ether_addmulti(ifr, &sc->sc_arpcom) :
		    ether_delmulti(ifr, &sc->sc_arpcom);

		if (error == ENETRESET) {
			/*
			 * Multicast list has changed; set the hardware
			 * filter accordingly.
			 */
			if (ifp->if_flags & IFF_RUNNING) {
				if (sc->xl_type == XL_TYPE_905B)
					xl_setmulti_hash(sc);
				else
					xl_setmulti(sc);
			}
			error = 0;
		}
		break;
d2315 10
@


1.83
log
@Do not reset TX threshold value whenever xl_init() is called. Instead
the initial threshould is initialized at device attach. Later the
threshold could be increased if encountering a TX underrun error and
the new threshold should be used in xl_init().

From FreeBSD

Tested on quite a few 3c905/B/C/575 adapters.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.82 2008/10/02 20:21:13 brad Exp $	*/
a1323 3
	/* Clear the timeout timer. */
	ifp->if_timer = 0;

d1363 2
a1410 1
		ifp->if_timer = 0;
d1417 2
@


1.82
log
@First step towards cleaning up the Ethernet driver ioctl handling.
Move calling ether_ioctl() from the top of the ioctl function, which
at the moment does absolutely nothing, to the default switch case.
Thus allowing drivers to define their own ioctl handlers and then
falling back on ether_ioctl(). The only functional change this results
in at the moment is having all Ethernet drivers returning the proper
errno of ENOTTY instead of EINVAL/ENXIO when encountering unknown
ioctl's.

Shrinks the i386 kernels by..
RAMDISK - 1024 bytes
RAMDISKB -  1120 bytes
RAMDISKC - 832 bytes

Tested by martin@@/jsing@@/todd@@/brad@@
Build tested on almost all archs by todd@@/brad@@

ok jsing@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.81 2008/09/18 15:16:30 naddy Exp $	*/
a2000 1
	sc->xl_tx_thresh = XL_MIN_FRAMELEN;
d2571 3
@


1.81
log
@Introduce the infrastructure required to support hardware VLAN tag
stripping:  Add a field to the mbuf pkthdr to hold the tag and an
mbuf flag that tells if the tag is valid.  Inspired by FreeBSD.

Struct packing suggested by kettenis@@.   csum_flags is now 16 bits.
Adapt to this in the drivers.

ok reyk@@, henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.80 2008/09/10 14:01:22 blambert Exp $	*/
a2273 5
	if ((error = ether_ioctl(ifp, &sc->sc_arpcom, command, data)) > 0) {
		splx(s);
		return error;
	}

d2342 1
a2342 2
		error = EINVAL;
		break;
a2345 1

@


1.80
log
@Convert timeout_add() calls using multiples of hz to timeout_add_sec()

Really just the low-hanging fruit of (hopefully) forthcoming timeout
conversions.

ok art@@, krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.79 2008/05/11 03:01:29 brad Exp $	*/
d1187 1
a1187 1
	int			total_len = 0, sumflags = 0;
d1189 1
@


1.79
log
@Fix a typo with the media duplex flag being used for AUI connections
so that the status routine will properly display half duplex instead
of full.

ok henning@@ krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.78 2007/05/19 16:51:57 kettenis Exp $	*/
d1600 1
a1600 1
		timeout_add(&sc->xl_stsup_tmo, hz);
d2146 1
a2146 1
	timeout_add(&sc->xl_stsup_tmo, hz);
@


1.78
log
@My 3c905C needs a brief pause afterreset for PIO too, at least on hppa.

tested by thib@@, ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.77 2007/05/05 13:24:04 deraadt Exp $	*/
d2233 1
a2233 1
				ifmr->ifm_active |= IFM_FDX;
@


1.77
log
@move xl_detach() -- which is only used by cardbus -- to the cardbus code.
ok jsg
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.76 2006/08/10 20:10:18 brad Exp $	*/
d810 4
a813 5
	 * If we're using memory mapped register mode, pause briefly
	 * after issuing the reset command before trying to access any
	 * other registers. With my 3c575C cardbus card, failing to do
	 * this results in the system locking up while trying to poll
	 * the command busy bit in the status register.
d815 1
a815 2
	if (sc->xl_flags & XL_FLAG_USE_MMIO)
		DELAY(100000);
@


1.76
log
@- ANSI functions
- de-register
- remove return at the end of void functions
- some cosmetic tweaking
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.75 2006/08/10 18:40:54 brad Exp $	*/
a2742 28
}

int
xl_detach(struct xl_softc *sc)
{
	struct ifnet *ifp = &sc->sc_arpcom.ac_if;

	/* Unhook our tick handler. */
	timeout_del(&sc->xl_stsup_tmo);

	xl_freetxrx(sc);

	/* Detach all PHYs */
	if (sc->xl_hasmii)
		mii_detach(&sc->sc_mii, MII_PHY_ANY, MII_OFFSET_ANY);

	/* Delete all remaining media. */
	ifmedia_delete_instance(&sc->sc_mii.mii_media, IFM_INST_ANY);

	ether_ifdetach(ifp);
	if_detach(ifp);

	if (sc->sc_sdhook != NULL)
		shutdownhook_disestablish(sc->sc_sdhook);
	if (sc->sc_pwrhook != NULL)
		powerhook_disestablish(sc->sc_pwrhook);

	return (0);
@


1.75
log
@- move the promiscuous mode handling code to xl_setpromisc() and simplify
the ioctl handler.
- eliminate re-initialization's when adding IP addresses.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.74 2006/05/27 20:40:34 brad Exp $	*/
d202 1
a202 3
xl_power(why, arg)
	int why;
	void *arg;
d230 1
a230 2
xl_wait(sc)
	struct xl_softc		*sc;
d232 1
a232 1
	register int		i;
a240 2

	return;
d264 1
a264 2
xl_mii_sync(sc)
	struct xl_softc		*sc;
d266 1
a266 1
	register int		i;
a278 2

	return;
d285 1
a285 4
xl_mii_send(sc, bits, cnt)
	struct xl_softc		*sc;
	u_int32_t		bits;
	int			cnt;
d287 1
a287 1
	int			i;
d307 1
a307 4
xl_mii_readreg(sc, frame)
	struct xl_softc		*sc;
	struct xl_mii_frame	*frame;
	
d309 1
a309 1
	int			i, ack, s;
d384 2
a385 2
		return(1);
	return(0);
d392 1
a392 4
xl_mii_writereg(sc, frame)
	struct xl_softc		*sc;
	struct xl_mii_frame	*frame;
	
d394 1
a394 1
	int			s;
d397 1
d436 1
a436 1
	return(0);
d440 1
a440 3
xl_miibus_readreg(self, phy, reg)
	struct device *self;
	int phy, reg;
d454 1
a454 1
	return(frame.mii_data);
d458 1
a458 3
xl_miibus_writereg(self, phy, reg, data)
	struct device *self;
	int phy, reg, data;
a472 2

	return;
d476 1
a476 2
xl_miibus_statchg(self)
	struct device *self;
d496 1
a496 2
xl_eeprom_wait(sc)
	struct xl_softc		*sc;
d498 1
a498 1
	int			i;
d509 1
a509 1
		return(1);
d512 1
a512 1
	return(0);
d520 1
a520 6
xl_read_eeprom(sc, dest, off, cnt, swap)
	struct xl_softc		*sc;
	caddr_t			dest;
	int			off;
	int			cnt;
	int			swap;
d522 2
a523 2
	int			err = 0, i;
	u_int16_t		word = 0, *ptr;
d533 1
a533 1
		return(1);
d556 1
a556 1
	return(err ? 1 : 0);
d564 1
a564 2
xl_setmulti(sc)
	struct xl_softc		*sc;
d566 3
a568 3
	struct ifnet		*ifp;
	struct arpcom *ac = &sc->sc_arpcom;
	u_int8_t		rxfilt;
a586 2

	return;
d593 1
a593 2
xl_setmulti_hash(sc)
	struct xl_softc		*sc;
d595 3
a597 3
	struct ifnet		*ifp;
	int			h = 0, i;
	struct arpcom *ac = &sc->sc_arpcom;
d600 2
a601 2
	u_int8_t		rxfilt;
	int			mcnt = 0;
a640 2

	return;
d654 1
a654 1
	if (ifp->if_flags & IFF_RUNNING)
d665 1
a665 2
xl_testpacket(sc)
	struct xl_softc		*sc;
d667 3
a669 3
	struct mbuf		*m;
	struct ifnet		*ifp;
	int			error;
a688 2

	return;
d693 1
a693 2
xl_setcfg(sc)
	struct xl_softc *sc;
a707 2

	return;
d711 1
a711 3
xl_setmode(sc, media)
	struct xl_softc *sc;
	int media;
a796 2

	return;
d800 1
a800 2
xl_reset(sc)
	struct xl_softc		*sc;
d802 1
a802 1
	register int		i;
a851 1
        return;
d867 1
a867 2
xl_mediacheck(sc)
	struct xl_softc		*sc;
d904 1
a904 3
xl_choose_xcvr(sc, verbose)
	struct xl_softc *sc;
	int verbose;
a991 2

	return;
d998 1
a998 2
xl_list_tx_init(sc)
	struct xl_softc		*sc;
d1017 1
a1017 1
	return(0);
d1024 1
a1024 2
xl_list_tx_init_90xB(sc)
	struct xl_softc *sc;
d1026 3
a1028 3
	struct xl_chain_data *cd;
	struct xl_list_data *ld;
	int i;
d1033 8
d1045 2
a1046 10
		if (i == (XL_TX_LIST_CNT - 1))
			cd->xl_tx_chain[i].xl_next = &cd->xl_tx_chain[0];
		else
			cd->xl_tx_chain[i].xl_next = &cd->xl_tx_chain[i + 1];
		if (i == 0)
			cd->xl_tx_chain[i].xl_prev =
			    &cd->xl_tx_chain[XL_TX_LIST_CNT - 1];
		else
			cd->xl_tx_chain[i].xl_prev =
			    &cd->xl_tx_chain[i - 1];
d1065 1
a1065 2
xl_list_rx_init(sc)
	struct xl_softc		*sc;
d1069 1
a1069 1
	int			i;
d1080 7
a1086 10
		next = sc->sc_listmap->dm_segs[0].ds_addr;
		if (i == (XL_RX_LIST_CNT - 1)) {
			cd->xl_rx_chain[i].xl_next = &cd->xl_rx_chain[0];
			next +=
			    offsetof(struct xl_list_data, xl_rx_list[0]);
		} else {
			cd->xl_rx_chain[i].xl_next = &cd->xl_rx_chain[i + 1];
			next +=
			    offsetof(struct xl_list_data, xl_rx_list[i + 1]);
		}
d1092 1
a1092 1
	return(0);
d1099 1
a1099 3
xl_newbuf(sc, c)
	struct xl_softc		*sc;
	struct xl_chain_onefrag	*c;
d1101 2
a1102 2
	struct mbuf		*m_new = NULL;
	bus_dmamap_t		map;
d1106 1
a1106 1
		return(ENOBUFS);
d1111 1
a1111 1
		return(ENOBUFS);
a1116 1
		printf("%s: rx load failed\n", sc->sc_dev.dv_xname);
d1149 1
a1149 1
	return(0);
d1153 1
a1153 2
xl_rx_resync(sc)
	struct xl_softc *sc;
d1172 1
a1172 1
		return(0);
d1176 1
a1176 1
	return(EAGAIN);
d1184 1
a1184 2
xl_rxeof(sc)
	struct xl_softc		*sc;
d1284 1
a1310 2

	return;
d1318 1
a1318 2
xl_txeof(sc)
	struct xl_softc		*sc;
d1337 1
a1337 1
	while(sc->xl_cdata.xl_tx_head != NULL) {
a1377 2

	return;
d1381 1
a1381 2
xl_txeof_90xB(sc)
	struct xl_softc *sc;
d1390 1
a1390 1
	while(idx != sc->xl_cdata.xl_tx_prod) {
a1419 2

	return;
d1428 1
a1428 2
xl_txeoc(sc)
	struct xl_softc		*sc;
d1430 1
a1430 1
	u_int8_t		txstat;
d1432 1
a1432 1
	while((txstat = CSR_READ_1(sc, XL_TX_STATUS))) {
a1491 2

	return;
d1495 1
a1495 2
xl_intr(arg)
	void			*arg;
d1500 1
a1500 1
	int claimed = 0;
d1557 1
a1557 2
xl_stats_update(xsc)
	void			*xsc;
a1602 2

	return;
d1610 1
a1610 4
xl_encap(sc, c, m_head)
	struct xl_softc		*sc;
	struct xl_chain		*c;
	struct mbuf		*m_head;
d1612 3
a1614 3
	int			error, frag, total_len;
	u_int32_t		status;
	bus_dmamap_t		map;
d1651 1
a1651 1
		struct mbuf		*m_new = NULL;
d1656 1
a1656 1
			return(1);
d1663 1
a1663 1
				return(1);
d1711 1
a1711 1
	return(0);
d1721 1
a1721 2
xl_start(ifp)
	struct ifnet		*ifp;
d1746 1
a1746 1
	while(sc->xl_cdata.xl_tx_free != NULL) {
a1849 2

	return;
d1853 1
a1853 2
xl_start_90xB(ifp)
	struct ifnet *ifp;
d1855 5
a1859 5
	struct xl_softc *sc;
	struct mbuf *m_head = NULL;
	struct xl_chain *prev = NULL, *cur_tx = NULL, *start_tx;
	struct xl_chain		*prev_tx;
	int error, idx;
d1935 1
a1935 2
xl_init(xsc)
	void			*xsc;
a2148 2

	return;
d2155 1
a2155 2
xl_ifmedia_upd(ifp)
	struct ifnet		*ifp;
d2176 1
a2176 1
		return(0);
d2189 1
a2189 1
	return(0);
d2196 1
a2196 3
xl_ifmedia_sts(ifp, ifmr)
	struct ifnet		*ifp;
	struct ifmediareq	*ifmr;
a2261 2

	return;
d2265 1
a2265 4
xl_ioctl(ifp, command, data)
	struct ifnet *ifp;
	u_long command;
	caddr_t data;
d2354 1
a2354 1
	return(error);
d2358 1
a2358 2
xl_watchdog(ifp)
	struct ifnet		*ifp;
a2380 2

	return;
d2384 1
a2384 2
xl_freetxrx(sc)
	struct xl_softc *sc;
d2386 2
a2387 1
	int i;
d2394 1
a2394 1
			bus_dmamap_t map = sc->xl_cdata.xl_rx_chain[i].map;
d2412 1
a2412 1
			bus_dmamap_t map = sc->xl_cdata.xl_tx_chain[i].map;
d2432 1
a2432 2
xl_stop(sc)
	struct xl_softc *sc;
a2467 2

	return;
d2471 1
a2471 2
xl_attach(sc)
	struct xl_softc *sc;
d2746 1
a2746 2
xl_detach(sc)
	struct xl_softc *sc;
d2774 1
a2774 2
xl_shutdown(v)
	void *v;
@


1.74
log
@garbage collect vlan.h
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.73 2006/05/22 20:35:12 krw Exp $	*/
d183 1
d678 20
d2111 6
a2116 8
	/* If we want promiscuous mode, set the allframes bit. */
	if (ifp->if_flags & IFF_PROMISC) {
		rxfilt |= XL_RXFILTER_ALLFRAMES;
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_SET_FILT|rxfilt);
	} else {
		rxfilt &= ~XL_RXFILTER_ALLFRAMES;
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_SET_FILT|rxfilt);
	}
d2121 1
a2121 1
	if (ifp->if_flags & IFF_BROADCAST) {
d2123 1
a2123 2
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_SET_FILT|rxfilt);
	} else {
d2125 2
a2126 2
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_SET_FILT|rxfilt);
	}
a2366 1
	u_int8_t rxfilt;
d2378 2
a2379 1
		switch (ifa->ifa_addr->sa_family) {
d2381 1
a2381 2
		case AF_INET:
			xl_init(sc);
a2382 1
			break;
a2383 4
		default:
			xl_init(sc);
			break;
		}
a2394 1
		rxfilt = CSR_READ_1(sc, XL_W5_RX_FILTER);
d2397 3
a2399 5
			    ifp->if_flags & IFF_PROMISC &&
			    !(sc->xl_if_flags & IFF_PROMISC)) {
				rxfilt |= XL_RXFILTER_ALLFRAMES;
				CSR_WRITE_2(sc, XL_COMMAND,
				    XL_CMD_RX_SET_FILT|rxfilt);
d2401 4
a2404 9
			} else if (ifp->if_flags & IFF_RUNNING &&
			    !(ifp->if_flags & IFF_PROMISC) &&
			    sc->xl_if_flags & IFF_PROMISC) {
				rxfilt &= ~XL_RXFILTER_ALLFRAMES;
				CSR_WRITE_2(sc, XL_COMMAND,
				    XL_CMD_RX_SET_FILT|rxfilt);
				XL_SEL_WIN(7);
			} else
				xl_init(sc);
a2409 1
		error = 0;
@


1.73
log
@Attach routines can fail before calling *hook_establish(), and they
often rely on the detach routine for cleanup. So be consistant and
careful by checking for a NULL hook before calling *hook_disestablish
in detach routines.

ok mickey@@ brad@@ dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.72 2006/03/25 22:41:43 djm Exp $	*/
a103 1
#include "vlan.h"
@


1.72
log
@allow bpf(4) to ignore packets based on their direction (inbound or
outbound), using a new BIOCSDIRFILT ioctl;
guidance, feedback and ok canacar@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.71 2006/03/04 23:31:20 brad Exp $	*/
d2866 4
a2869 2
	shutdownhook_disestablish(sc->sc_sdhook);
	powerhook_disestablish(sc->sc_pwrhook);
@


1.71
log
@remove extraneous brackets.

From Mike Pechkin <mpech at mail dot ru>
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.70 2006/01/20 05:49:32 brad Exp $	*/
d1308 1
a1308 1
			bpf_mtap(ifp->if_bpf, m);
d1842 2
a1843 1
			bpf_mtap(ifp->if_bpf, cur_tx->xl_mbuf);
d1965 2
a1966 1
			bpf_mtap(ifp->if_bpf, cur_tx->xl_mbuf);
@


1.70
log
@- xl_encap(): free the mbuf chain and return if bus_dmamap_load_mbuf()
returns an error other than EFBIG.
- xl_encap(): remove a redundant check already done in xl_start_90xB().
- merge xl_encap_90xB() into xl_encap().
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.69 2006/01/11 04:19:42 brad Exp $	*/
d2374 1
a2374 1
		if(ifr->ifr_mtu > ETHERMTU || ifr->ifr_mtu < ETHERMIN) {
d2376 1
a2376 1
		} else if (ifp->if_mtu != ifr->ifr_mtu) {
a2377 1
		}
@


1.69
log
@only set Ok flag for RX checksums.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.67 2006/01/11 03:57:50 brad Exp $	*/
a155 2
int xl_encap_90xB(struct xl_softc *, struct xl_chain *,
    struct mbuf * );
d1494 10
a1503 6
				int i;
				struct xl_chain *c;
				i = sc->xl_cdata.xl_tx_cons;
				c = &sc->xl_cdata.xl_tx_chain[i];
				CSR_WRITE_4(sc, XL_DOWNLIST_PTR, c->xl_phys);
				CSR_WRITE_1(sc, XL_DOWN_POLL, 64);
d1672 2
a1673 1
	int			frag, total_len;
d1679 7
a1685 3
	if (bus_dmamap_load_mbuf(sc->sc_dmat, map,
	    m_head, BUS_DMA_NOWAIT) != 0)
		return (ENOBUFS);
a1692 2
		if ((XL_TX_LIST_CNT - (sc->xl_cdata.xl_tx_cnt + frag)) < 3)
			return (ENOBUFS);
d1710 1
a1710 1
	if (frag != map->dm_nsegs) {
d1750 16
a1913 99
int
xl_encap_90xB(sc, c, m_head)
	struct xl_softc *sc;
	struct xl_chain *c;
	struct mbuf *m_head;
{
	struct xl_frag *f = NULL;
	struct xl_list *d;
	int frag;
	bus_dmamap_t map;

	/*
	 * Start packing the mbufs in this chain into
	 * the fragment pointers. Stop when we run out
	 * of fragments or hit the end of the mbuf chain.
	 */
	map = sc->sc_tx_sparemap;
	d = c->xl_ptr;
	d->xl_status = htole32(0);
	d->xl_next = 0;

reload:
	if (bus_dmamap_load_mbuf(sc->sc_dmat, map,
	    m_head, BUS_DMA_NOWAIT) != 0)
		return (ENOBUFS);

	for (frag = 0; frag < map->dm_nsegs; frag++) {
		if (frag == XL_MAXFRAGS)
			break;
		f = &d->xl_frag[frag];
		f->xl_addr = htole32(map->dm_segs[frag].ds_addr);
		f->xl_len = htole32(map->dm_segs[frag].ds_len);
	}

	/*
	 * Handle special case: we used up all 63 fragments,
	 * but we have more mbufs left in the chain. Copy the
	 * data into an mbuf cluster. Note that we don't
	 * bother clearing the values in the other fragment
	 * pointers/counters; it wouldn't gain us anything,
	 * and would waste cycles.
	 */
	if (frag != map->dm_nsegs) {
		struct mbuf		*m_new = NULL;

		MGETHDR(m_new, M_DONTWAIT, MT_DATA);
		if (m_new == NULL) {
			m_freem(m_head);
			return (1);
		}
		if (m_head->m_pkthdr.len > MHLEN) {
			MCLGET(m_new, M_DONTWAIT);
			if (!(m_new->m_flags & M_EXT)) {
				m_freem(m_new);
				m_freem(m_head);
				return (1);
			}
		}
		m_copydata(m_head, 0, m_head->m_pkthdr.len,
		    mtod(m_new, caddr_t));
		m_new->m_pkthdr.len = m_new->m_len = m_head->m_pkthdr.len;
		m_freem(m_head);
		m_head = m_new;
		goto reload;
	}

	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREWRITE);

	/* sync the old map, and unload it (if necessary) */
	if (c->map->dm_nsegs != 0) {
		bus_dmamap_sync(sc->sc_dmat, c->map, 0, c->map->dm_mapsize,
		    BUS_DMASYNC_POSTWRITE);
		bus_dmamap_unload(sc->sc_dmat, c->map);
	}

	c->xl_mbuf = m_head;
	sc->sc_tx_sparemap = c->map;
	c->map = map;
	c->xl_ptr->xl_frag[frag - 1].xl_len |= htole32(XL_LAST_FRAG);
	c->xl_ptr->xl_status = htole32(XL_TXSTAT_RND_DEFEAT);

#ifndef XL905B_TXCSUM_BROKEN
	if (m_head->m_pkthdr.csum & M_IPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_IPCKSUM);
	if (m_head->m_pkthdr.csum & M_TCPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_TCPCKSUM);
	if (m_head->m_pkthdr.csum & M_UDPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_UDPCKSUM);
#endif

	bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,
	    offsetof(struct xl_list_data, xl_tx_list[0]),
	    sizeof(struct xl_list) * XL_TX_LIST_CNT,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

	return(0);
}

d1947 1
a1947 1
		error = xl_encap_90xB(sc, cur_tx, m_head);
@


1.68
log
@remove a printf here.
@
text
@d1315 2
a1316 3
			if (rxstat & XL_RXSTAT_IPCKERR)
				sumflags |= M_IPV4_CSUM_IN_BAD;
			else if (rxstat & XL_RXSTAT_IPCKOK)
d1319 2
a1320 3
			if (rxstat & XL_RXSTAT_TCPCKERR)
				sumflags |= M_TCP_CSUM_IN_BAD;
			else if (rxstat & XL_RXSTAT_TCPCKOK)
d1323 2
a1324 3
			if (rxstat & XL_RXSTAT_UDPCKERR)
				sumflags |= M_UDP_CSUM_IN_BAD;
			else if (rxstat & XL_RXSTAT_UDPCKOK)
@


1.67
log
@In the case that we've used up all 63 fragments then try to allocate an mbuf
cluster and copy the mbuf chain. The codepath for older xl's already dealt
with this condition.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.66 2005/11/07 03:20:00 brad Exp $	*/
a1939 2

		printf("%s: allocating a cluster\n", sc->sc_dev.dv_xname);
@


1.66
log
@splimp -> splnet
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.65 2005/07/02 23:10:16 brad Exp $	*/
d1917 1
d1928 34
@


1.65
log
@clear IFF_RUNNING & IFF_OACTIVE in foo_stop() before de-allocating resources.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.64 2005/04/25 17:55:51 brad Exp $	*/
d212 1
a212 1
	s = splimp();
d327 1
a327 1
	s = splimp();
d415 1
a415 1
	s = splimp();
d2054 1
a2054 1
	s = splimp();
d2398 1
a2398 1
	s = splimp();
d2626 1
a2626 1
	i = splimp();
d2796 1
a2796 1
		i = splimp();
@


1.64
log
@csum -> csum_flags

ok krw@@ canacar@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.63 2005/04/23 22:51:28 brad Exp $	*/
d2609 2
a2611 2

	ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);
@


1.63
log
@style
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.62 2005/01/15 05:24:11 brad Exp $	*/
d1330 1
a1330 1
			m->m_pkthdr.csum = sumflags;
@


1.62
log
@make sure interface is in RUNNING state before touching the multicast filters

From NetBSD

NetBSD PR 27678 for details

ok mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.61 2004/11/01 02:03:45 brad Exp $	*/
d2733 1
a2733 2
	ifp->if_capabilities = IFCAP_VLAN_MTU;
	if (sc->xl_type == XL_TYPE_905B) {
d2735 1
a2735 5
#ifndef XL905B_TXCSUM_BROKEN
		ifp->if_capabilities |= IFCAP_CSUM_IPv4|IFCAP_CSUM_TCPv4|
		    IFCAP_CSUM_UDPv4;
#endif
	} else
d2742 7
@


1.61
log
@back out previous commit.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.60 2004/10/31 17:41:01 brad Exp $	*/
d2467 6
a2472 4
			if (sc->xl_type == XL_TYPE_905B)
				xl_setmulti_hash(sc);
			else
				xl_setmulti(sc);
@


1.60
log
@don't swap zeros
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.59 2004/10/23 05:14:33 brad Exp $	*/
d1186 1
a1186 1
	c->xl_ptr->xl_status = 0;
d1269 1
a1269 1
			cur_rx->xl_ptr->xl_status = 0;
d1282 1
a1282 1
			cur_rx->xl_ptr->xl_status = 0;
d1298 1
a1298 1
			cur_rx->xl_ptr->xl_status = 0;
d1914 1
a1914 1
	d->xl_status = 0;
@


1.59
log
@add missing braces, noticed by mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.58 2004/10/23 05:12:55 brad Exp $	*/
d1186 1
a1186 1
	c->xl_ptr->xl_status = htole32(0);
d1269 1
a1269 1
			cur_rx->xl_ptr->xl_status = htole32(0);
d1282 1
a1282 1
			cur_rx->xl_ptr->xl_status = htole32(0);
d1298 1
a1298 1
			cur_rx->xl_ptr->xl_status = htole32(0);
d1914 1
a1914 1
	d->xl_status = htole32(0);
@


1.58
log
@re-add old xl_encap_90xB() for 905B/C cards. removed in rev 1.52.

fixes reported mbuf leaks as well as transmit side breakage on macppc,
PR 3892.

ok mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.57 2004/10/02 16:44:23 brad Exp $	*/
d1712 1
a1712 1
		if (m_new == NULL)
d1715 1
@


1.57
log
@remove if NVLAN here too
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.56 2004/09/28 05:14:44 brad Exp $	*/
d156 2
a1746 9
#ifndef XL905B_TXCSUM_BROKEN
	if (m_head->m_pkthdr.csum & M_IPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_IPCKSUM);
	if (m_head->m_pkthdr.csum & M_TCPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_TCPCKSUM);
	if (m_head->m_pkthdr.csum & M_UDPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_UDPCKSUM);
#endif

d1895 66
d1994 1
a1994 1
		error = xl_encap(sc, cur_tx, m_head);
@


1.56
log
@remove if NVLAN around IFCAP_VLAN_MTU
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.55 2004/09/23 17:45:16 brad Exp $	*/
a2144 1
#if NVLAN > 0
a2159 1
#endif
@


1.55
log
@don't need to set ifp->if_mtu or ifp->if_output in each driver,
{ether,atm,fddi}_ifattach already does this.

ok mcbride@@ markus@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.54 2004/06/04 21:49:02 brad Exp $	*/
d2673 1
a2673 3
#if NVLAN > 0
	ifp->if_capabilities |= IFCAP_VLAN_MTU;
#endif
@


1.54
log
@fix conversion to ether_crc32_be(). problem noticed by naddy@@

ok mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.53 2004/06/01 20:59:25 mickey Exp $	*/
a2670 1
	ifp->if_mtu = ETHERMTU;
a2672 1
	ifp->if_output = ether_output;
@


1.54.2.1
log
@MFC:
Fix by brad@@

rev 1.59

add missing braces, noticed by mcbride@@

rev 1.58

re-add old xl_encap_90xB() for 905B/C cards. removed in rev 1.52.

fixes reported mbuf leaks as well as transmit side breakage on macppc,
PR 3892.

ok deraadt@@ miod@@ brad@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.54 2004/06/04 21:49:02 brad Exp $	*/
a155 2
int xl_encap_90xB(struct xl_softc *, struct xl_chain *,
    struct mbuf * );
d1710 1
a1710 1
		if (m_new == NULL) {
a1712 1
		}
d1745 9
a1901 66
int
xl_encap_90xB(sc, c, m_head)
	struct xl_softc *sc;
	struct xl_chain *c;
	struct mbuf *m_head;
{
	struct xl_frag *f = NULL;
	struct xl_list *d;
	int frag;
	bus_dmamap_t map;

	/*
	 * Start packing the mbufs in this chain into
	 * the fragment pointers. Stop when we run out
	 * of fragments or hit the end of the mbuf chain.
	 */
	map = sc->sc_tx_sparemap;
	d = c->xl_ptr;
	d->xl_status = htole32(0);
	d->xl_next = 0;

	if (bus_dmamap_load_mbuf(sc->sc_dmat, map,
	    m_head, BUS_DMA_NOWAIT) != 0)
		return (ENOBUFS);

	for (frag = 0; frag < map->dm_nsegs; frag++) {
		if (frag == XL_MAXFRAGS)
			break;
		f = &d->xl_frag[frag];
		f->xl_addr = htole32(map->dm_segs[frag].ds_addr);
		f->xl_len = htole32(map->dm_segs[frag].ds_len);
	}

	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREWRITE);

	/* sync the old map, and unload it (if necessary) */
	if (c->map->dm_nsegs != 0) {
		bus_dmamap_sync(sc->sc_dmat, c->map, 0, c->map->dm_mapsize,
		    BUS_DMASYNC_POSTWRITE);
		bus_dmamap_unload(sc->sc_dmat, c->map);
	}

	c->xl_mbuf = m_head;
	sc->sc_tx_sparemap = c->map;
	c->map = map;
	c->xl_ptr->xl_frag[frag - 1].xl_len |= htole32(XL_LAST_FRAG);
	c->xl_ptr->xl_status = htole32(XL_TXSTAT_RND_DEFEAT);

#ifndef XL905B_TXCSUM_BROKEN
	if (m_head->m_pkthdr.csum & M_IPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_IPCKSUM);
	if (m_head->m_pkthdr.csum & M_TCPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_TCPCKSUM);
	if (m_head->m_pkthdr.csum & M_UDPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_UDPCKSUM);
#endif

	bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,
	    offsetof(struct xl_list_data, xl_tx_list[0]),
	    sizeof(struct xl_list) * XL_TX_LIST_CNT,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

	return(0);
}

d1935 1
a1935 1
		error = xl_encap_90xB(sc, cur_tx, m_head);
@


1.53
log
@dv_xname is not the same as dv_unit (for hell knows what reason)
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.52 2004/05/30 23:49:39 brad Exp $	*/
d661 1
a661 1
		h = (ether_crc32_be(enm->enm_addrlo, ETHER_ADDR_LEN) >> 26) &
@


1.52
log
@a bit of syncing with the FreeBSD driver, namely...

- disable TX hardware checksumming since its buggy and slow

- re-enable the hardware multicast filter setup on 3c905B/C's

- enable reception of VLAN sized frames on 3c90x's (pre B/C)

- remove all DELAY(1) calls around MII operations in the xl driver.
according to the MII specification, the delay produced by our
reads alone are sufficient for correct operation.

this reduces the time mii_tick takes from 10ms to ~1ms here. that's
still a lot, but much better than before

- report media status for bitrate PHYs

- change the method used to detect older boomerang chips

- fix an issue with reading PHY regs over the i2c bus

- fix mbuf leaks in an error (rare) code path

- reuse the TX descriptor if xl_encap() failed instead of just picking the next one

- fix bug with 3c90xB cards and newer. We weren't trying to
copy the mbuf chain into an mbuf cluster when there is
more than 63 mbufs in the chain. we were trying with older
cards though

- add some magic bits necessary to turn the transmitter on for some
(newer) 556B chips

local change...

- use ether_crc32_be() instead of hand-rolled xl_calchash()

tested on i386/3c900 by beck@@, sparc64/3c905C by me, i386/3c905C by sturm@@, naddy@@ and a few others
ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.51 2003/10/21 18:58:50 jmc Exp $	*/
d852 1
a852 1
		printf("xl%d: reset didn't complete\n", sc->sc_dev.dv_xname);
@


1.51
log
@typos from Tom Cosgrove;

Tom: I did not commit a couple of your changes.

i did not include some punctuation fixes (full stops, etc.)
mnemorable -> mnemonic: i decided memorable was probably better
instrunctions -> instruction: i kept the plural
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.50 2003/06/29 16:39:02 jason Exp $	*/
d54 1
a54 1
 * 3Com 3c900-FL/FX	10/100Mbps/Fiber-optic
d56 3
d60 1
a60 1
 * 3Com 3c555		10/100Mbps/RJ-45 (MiniPCI, Hurricane ASIC)
d63 6
a68 11
 * 3Com 3c980-TX	10/100Mbps server adapter (Hurricane ASIC)
 * 3Com 3c980C-TX	10/100Mbps server adapter (Tornado ASIC)
 * 3Com 3C575TX		10/100Mbps LAN CardBus PC Card
 * 3Com 3CCFE575BT	10/100Mbps LAN CardBus PC Card
 * 3Com 3CCFE575CT	10/100Mbps LAN CardBus PC Card
 * 3Com 3C3FE575CT	10/100Mbps LAN CardBus Type III PC Card
 * 3Com 3CCFEM656	10/100Mbps LAN+56k Modem CardBus PC Card
 * 3Com 3CCFEM656B	10/100Mbps LAN+56k Modem CardBus PC Card
 * 3Com 3CCFEM656C	10/100Mbps LAN+56k Global Modem CardBus PC Card
 * 3Com 3C3FEM656C	10/100Mbps LAN+56k Global Modem CardBus Type III PC Card
 * 3Com 3cSOHO100-TX	10/100Mbps/RJ-45 (Hurricane ASIC)
d70 1
a70 1
 * Dell on-board 3c920	10/100Mbps/RJ-45
d85 1
a85 1
 * chain into a an mbuf cluster and then DMAing the cluster. This extra
d142 10
a155 2
int xl_encap_90xB(struct xl_softc *, struct xl_chain *,
    struct mbuf * );
a181 1
u_int8_t xl_calchash(caddr_t);
d184 1
a184 1
void xl_reset(struct xl_softc *, int);
d216 1
a216 1
			xl_reset(sc, 1);
d231 2
a232 1
void xl_wait(sc)
a241 1
#ifdef DIAGNOSTIC
a243 1
#endif
d259 1
a259 1
		CSR_READ_2(sc, XL_W4_PHY_MGMT) | x)
d263 1
a263 1
		CSR_READ_2(sc, XL_W4_PHY_MGMT) & ~x)
d268 2
a269 1
void xl_mii_sync(sc)
d279 2
a280 1
		DELAY(1);
d282 2
a283 1
		DELAY(1);
d292 2
a293 1
void xl_mii_send(sc, bits, cnt)
a308 1
		DELAY(1);
a309 1
		DELAY(1);
d317 2
a318 1
int xl_mii_readreg(sc, frame)
a358 1
	DELAY(1);
a359 1
	DELAY(1);
d366 1
a366 1
	DELAY(1);
a367 2
	DELAY(1);
	ack = CSR_READ_2(sc, XL_W4_PHY_MGMT) & XL_MII_DATA;
a375 1
			DELAY(1);
a376 1
			DELAY(1);
a382 1
		DELAY(1);
a385 1
			DELAY(1);
a387 1
		DELAY(1);
a392 1
	DELAY(1);
a393 1
	DELAY(1);
d405 2
a406 1
int xl_mii_writereg(sc, frame)
a442 1
	DELAY(1);
a443 1
	DELAY(1);
d493 2
d505 1
d518 2
a519 1
int xl_eeprom_wait(sc)
d543 2
a544 1
int xl_read_eeprom(sc, dest, off, cnt, swap)
a588 39
 * This routine is taken from the 3Com Etherlink XL manual,
 * page 10-7. It calculates a CRC of the supplied multicast
 * group address and returns the lower 8 bits, which are used
 * as the multicast filter position.
 * Note: the 3c905B currently only supports a 64-bit hash table,
 * which means we really only need 6 bits, but the manual indicates
 * that future chip revisions will have a 256-bit hash table,
 * hence the routine is set up to calculate 8 bits of position
 * info in case we need it some day.
 * Note II, The Sequel: _CURRENT_ versions of the 3c905B have a
 * 256 bit hash table. This means we have to use all 8 bits regardless.
 * On older cards, the upper 2 bits will be ignored. Grrrr....
 */
u_int8_t xl_calchash(addr)
	caddr_t			addr;
{
	u_int32_t		crc, carry;
	int			i, j;
	u_int8_t		c;

	/* Compute CRC for the address value. */
	crc = 0xFFFFFFFF; /* initial value */

	for (i = 0; i < 6; i++) {
		c = *(addr + i);
		for (j = 0; j < 8; j++) {
			carry = ((crc & 0x80000000) ? 1 : 0) ^ (c & 0x01);
			crc <<= 1;
			c >>= 1;
			if (carry)
				crc = (crc ^ 0x04c11db6) | carry;
		}
	}

	/* return the filter bit position */
	return(crc & 0x000000FF);
}

/*
d592 2
a593 1
void xl_setmulti(sc)
d624 2
a625 1
void xl_setmulti_hash(sc)
d661 2
a662 1
		h = xl_calchash(enm->enm_addrlo);
d679 2
a680 1
void xl_testpacket(sc)
d710 2
a711 1
void xl_setcfg(sc)
d720 1
a720 1
	    sc->xl_media & XL_MEDIAOPT_BT4)
d727 2
d731 2
a732 1
void xl_setmode(sc, media)
d820 2
d824 2
a825 1
void xl_reset(sc, hard)
a826 1
	int hard;
d831 13
a843 7
	if (hard || (sc->xl_flags & XL_FLAG_WEIRDRESET)) {
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RESET |
		    ((sc->xl_flags & XL_FLAG_WEIRDRESET)?0xFF:0));
	}
	else
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RESET | 0x0010);
	xl_wait(sc);
d851 2
a852 1
	DELAY(100000);
d854 6
a859 1
	/* Reset TX and RX. */
d861 1
d866 2
a867 1
	if (sc->xl_flags & XL_FLAG_WEIRDRESET) {
d870 4
a873 1
		    XL_W2_RESET_OPTIONS) | 0x4010);
d893 2
a894 1
void xl_mediacheck(sc)
d931 2
a932 1
void xl_choose_xcvr(sc, verbose)
d978 7
a1015 9
	case TC_DEVICEID_3C575_CARDBUS:
	case TC_DEVICEID_3CCFE575BT_CARDBUS:
	case TC_DEVICEID_3CCFE575CT_CARDBUS:
	case TC_DEVICEID_3CCFEM656_CARDBUS:
	case TC_DEVICEID_3CCFEM656B_CARDBUS:
	case TC_DEVICEID_3CCFEM656C_CARDBUS:
		sc->xl_media = XL_MEDIAOPT_MII;
		sc->xl_xcvr = XL_XCVR_MII;
		break;
d1029 2
a1030 1
int xl_list_tx_init(sc)
d1098 2
a1099 1
int xl_list_rx_init(sc)
d1136 2
a1137 1
int xl_newbuf(sc, c)
d1193 2
a1194 1
int xl_rx_resync(sc)
d1214 1
a1214 1
		return (0);
d1218 1
a1218 1
	return (EAGAIN);
d1225 2
a1226 1
void xl_rxeof(sc)
d1243 1
d1251 9
d1272 1
a1272 1
		 * If there error bit was not set, the upload complete
d1278 1
a1278 1
			    "packet dropped", sc->sc_dev.dv_xname);
a1285 2
		total_len = letoh32(cur_rx->xl_ptr->xl_status) &
		    XL_RXSTAT_LENMASK;
d1364 2
a1365 1
void xl_txeof(sc)
d1471 2
d1480 2
a1481 1
void xl_txeoc(sc)
d1546 2
a1547 1
int xl_intr(arg)
d1558 1
a1558 1
	while ((status = CSR_READ_2(sc, XL_STATUS)) & XL_INTRS) {
d1592 1
a1592 1
			xl_reset(sc, 0);
d1609 2
a1610 1
void xl_stats_update(xsc)
d1650 1
a1650 1
	if (mii != NULL)
d1665 2
a1666 1
int xl_encap(sc, c, m_head)
d1711 1
d1717 1
d1745 9
d1768 2
a1769 1
void xl_start(ifp)
d1775 2
d1801 1
d1803 8
a1811 1

a1813 3
		/* Pack the data into the descriptor. */
		xl_encap(sc, cur_tx, m_head);

a1901 63
int xl_encap_90xB(sc, c, m_head)
	struct xl_softc *sc;
	struct xl_chain *c;
	struct mbuf *m_head;
{
	struct xl_frag *f = NULL;
	struct xl_list *d;
	int frag;
	bus_dmamap_t map;

	/*
	 * Start packing the mbufs in this chain into
	 * the fragment pointers. Stop when we run out
	 * of fragments or hit the end of the mbuf chain.
	 */
	map = sc->sc_tx_sparemap;
	d = c->xl_ptr;
	d->xl_status = htole32(0);
	d->xl_next = 0;

	if (bus_dmamap_load_mbuf(sc->sc_dmat, map,
	    m_head, BUS_DMA_NOWAIT) != 0)
		return (ENOBUFS);

	for (frag = 0; frag < map->dm_nsegs; frag++) {
		if (frag == XL_MAXFRAGS)
			break;
		f = &d->xl_frag[frag];
		f->xl_addr = htole32(map->dm_segs[frag].ds_addr);
		f->xl_len = htole32(map->dm_segs[frag].ds_len);
	}

	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREWRITE);

	/* sync the old map, and unload it (if necessary) */
	if (c->map->dm_nsegs != 0) {
		bus_dmamap_sync(sc->sc_dmat, c->map, 0, c->map->dm_mapsize,
		    BUS_DMASYNC_POSTWRITE);
		bus_dmamap_unload(sc->sc_dmat, c->map);
	}

	c->xl_mbuf = m_head;
	sc->sc_tx_sparemap = c->map;
	c->map = map;
	c->xl_ptr->xl_frag[frag - 1].xl_len |= htole32(XL_LAST_FRAG);
	c->xl_ptr->xl_status = htole32(XL_TXSTAT_RND_DEFEAT);

	if (m_head->m_pkthdr.csum & M_IPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_IPCKSUM);
	if (m_head->m_pkthdr.csum & M_TCPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_TCPCKSUM);
	if (m_head->m_pkthdr.csum & M_UDPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_UDPCKSUM);

	bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,
	    offsetof(struct xl_list_data, xl_tx_list[0]),
	    sizeof(struct xl_list) * XL_TX_LIST_CNT,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

	return(0);
}

d1909 2
a1910 1
	int idx;
d1931 1
d1935 5
a1939 1
		xl_encap_90xB(sc, cur_tx, m_head);
d1984 2
a1985 1
void xl_init(xsc)
a2011 1

a2099 1
#if 0
a2100 3
#else
	if (0)	/* xl_setmulti_hash() does not work right */
#endif
d2146 7
a2152 1
	/* Set max packet size to handle VLAN frames, only on 3c905B */
d2154 7
a2160 1
		CSR_WRITE_2(sc, XL_W3_MAX_PKT_SIZE, 1514 + 4);
d2212 2
a2213 1
int xl_ifmedia_upd(ifp)
d2235 1
a2235 1
		return (0);
d2254 2
a2255 1
void xl_ifmedia_sts(ifp, ifmr)
d2261 1
d2268 3
d2276 4
a2408 1
#if 0
a2409 3
#else
			if (0)	/* xl_setmulti_hash() does not work right */
#endif
d2437 2
a2438 1
void xl_watchdog(ifp)
d2457 1
a2457 1
	xl_reset(sc, 0);
d2514 2
a2515 1
void xl_stop(sc)
d2561 1
d2567 1
a2567 1
	xl_reset(sc, 1);
d2634 1
a2634 1
	printf(" address %s\n", ether_sprintf(sc->sc_arpcom.ac_enaddr));
d2655 5
d2662 2
a2663 1
	if (sc->xl_caps & XL_CAPS_NO_TXLENGTH)
d2675 3
d2680 2
a2681 1
		ifp->if_capabilities = IFCAP_CSUM_IPv4|IFCAP_CSUM_TCPv4|
d2683 1
a2691 10
#if NVLAN > 0
	if (sc->xl_type == XL_TYPE_905B)
		ifp->if_capabilities |= IFCAP_VLAN_MTU;
	/*
	 * XXX
	 * Do other cards filter large packets or simply pass them through?
	 * Apparently only the 905B has the capability to set a larger size.
 	 */
#endif

d2695 2
a2696 1
	xl_read_eeprom(sc, (char *)&sc->xl_xcvr, XL_EE_ICFG_0, 2, 0);
a2699 2
	DELAY(100000);

a2701 8
	if (sc->xl_flags & XL_FLAG_INVERT_MII_PWR) {
		XL_SEL_WIN(2);
		CSR_WRITE_2(sc, XL_W2_RESET_OPTIONS, XL_RESETOPT_INVMIIPWR |
		    CSR_READ_2(sc, XL_W2_RESET_OPTIONS));
	}

	DELAY(100000);

d2739 1
a2739 1
		xl_reset(sc, 0);
d2819 5
d2867 1
a2867 1
	xl_reset(sc, 1);
@


1.50
log
@remove usage of xl_unit
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.49 2003/03/24 17:40:00 jason Exp $	*/
d1817 1
a1817 1
	 * get an interupt once for the whole chain rather than
d1999 1
a1999 1
	 * get an interupt once for the whole chain rather than
@


1.49
log
@splimp() around xl_reset() during autoconf.  something in xl_reset() wants
to generate an interrupt before the rings are setup correctly on some
variants; ok deraadt.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.48 2003/01/05 20:07:44 deraadt Exp $	*/
d238 1
a238 1
		printf("xl%d: command never completed!\n", sc->xl_unit);
d533 1
a533 1
		printf("xl%d: eeprom failed to come ready\n", sc->xl_unit);
d922 4
a925 4
			printf("xl%d: bogus xcvr value "
			"in EEPROM (%x)\n", sc->xl_unit, sc->xl_xcvr);
			printf("xl%d: choosing new default based "
				"on card type\n", sc->xl_unit);
d931 6
a936 6
		printf("xl%d: WARNING: no media options bits set in "
			"the media options register!!\n", sc->xl_unit);
		printf("xl%d: this could be a manufacturing defect in "
			"your adapter or system\n", sc->xl_unit);
		printf("xl%d: attempting to guess media type; you "
			"should probably consult your vendor\n", sc->xl_unit);
d961 2
a962 2
			printf("xl%d: guessing 10BaseT transceiver\n",
			    sc->xl_unit);
d969 2
a970 2
			printf("xl%d: guessing COMBO (AUI/BNC/TP)\n",
			    sc->xl_unit);
d976 1
a976 1
			printf("xl%d: guessing TPC (BNC/TP)\n", sc->xl_unit);
d982 1
a982 1
			printf("xl%d: guessing 10baseFL\n", sc->xl_unit);
d991 1
a991 1
			printf("xl%d: guessing MII\n", sc->xl_unit);
d998 1
a998 1
			printf("xl%d: guessing 100BaseT4/MII\n", sc->xl_unit);
d1009 2
a1010 2
			printf("xl%d: guessing 10/100 internal\n",
			    sc->xl_unit);
d1016 2
a1017 2
			printf("xl%d: guessing 10/100 plus BNC/AUI\n",
			    sc->xl_unit);
d1029 2
a1030 2
		printf("xl%d: unknown device ID: %x -- "
			"defaulting to 10baseT\n", sc->xl_unit, devid);
d1274 2
a1275 2
			printf("xl%d: bad receive status -- "
			    "packet dropped", sc->xl_unit);
d1486 2
a1487 2
				printf("xl%d: transmission error: %x\n",
				    sc->xl_unit, txstat);
d1514 2
a1515 2
				printf("xl%d: tx underrun, increasing tx start"
				    " threshold to %d\n", sc->xl_unit,
d2061 2
a2062 2
		printf("xl%d: initialization failed: no "
			"memory for rx buffers\n", sc->xl_unit);
d2332 1
a2332 1
		printf("xl%d: unknown XCVR type: %d\n", sc->xl_unit, icfg);
d2464 1
a2464 1
	printf("xl%d: watchdog timeout\n", sc->xl_unit);
d2467 2
a2468 2
		printf("xl%d: no carrier - transceiver cable problem?\n",
								sc->xl_unit);
a2578 1
	sc->xl_unit = sc->sc_dev.dv_unit;
d2827 1
a2827 1
		printf("xl%d: unknown XCVR type: %d\n", sc->xl_unit,
@


1.48
log
@spelling
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.47 2002/12/02 22:04:38 jason Exp $	*/
d2580 1
d2582 1
d2760 1
d2762 1
@


1.47
log
@- Remove a few magic constants
- set baudrate for the non-mii modes
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.46 2002/11/25 16:07:08 brad Exp $	*/
d1065 1
a1065 1
 * Initialize the transmit desriptors.
@


1.46
log
@remove printf's in xl_setmode().
--
deraadt@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.45 2002/11/17 02:46:17 jason Exp $	*/
d554 1
d569 2
a570 1
			CSR_WRITE_2(sc, XL_W0_EE_CMD, (2<<8) | (off + i ));
d767 1
d778 1
d790 1
d801 1
d810 1
d822 1
d1712 1
a1712 1
					mtod(m_new, caddr_t));
d2716 2
a2717 1
		CSR_WRITE_2(sc, 12, 0x4000 | CSR_READ_2(sc, 12));
@


1.45
log
@Make sure never to put a loaded dmamap in the spare.  3c90x should work
on big endian now...
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.44 2002/11/17 02:41:30 jason Exp $	*/
a767 2
	printf("xl%d: selecting ", sc->xl_unit);

a774 1
			printf("10baseT transceiver, ");
a785 1
			printf("100baseFX port, ");
a795 1
			printf("AUI port, ");
a803 1
			printf("10baseFL transceiver, ");
a814 1
			printf("BNC port, ");
a825 1
		printf("full duplex\n");
a828 1
		printf("half duplex\n");
@


1.44
log
@this driver has never been in sys/pci (in OpenBSD at least) and supports
cardbus and pci interfaces; pointed out by brad.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.43 2002/11/17 02:34:52 jason Exp $	*/
d1722 6
@


1.43
log
@Fix another case (tx this time) where buffers were not unloaded (nor sync'd).  (bad bad aaron): 90xB works on sparc64, 90x is probably still broken.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.42 2002/11/17 02:06:28 jason Exp $	*/
a102 3
 *
 * This driver is in the /sys/pci directory because it only supports
 * PCI-based NICs.
@


1.42
log
@- lightly season with htole32 and friends... enough to get rx working
  on sparc64
- also fix a bug when dmamap's were never freed on the rx side (bad aaron),
and avoid a sync if we run out of buffers.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.41 2002/08/22 19:08:50 jason Exp $	*/
d1456 6
d1907 7
@


1.41
log
@simplify multicast setup on the 3c905 (pre-B/C, etc)
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.40 2002/07/09 05:49:53 aaron Exp $	*/
d1099 1
a1099 1
	ld->xl_tx_list[0].xl_status = XL_TXSTAT_EMPTY;
d1139 1
a1139 1
		ld->xl_rx_list[i].xl_next = next;
d1174 8
d1193 5
a1197 3
	c->xl_ptr->xl_frag.xl_addr = c->map->dm_segs[0].ds_addr + ETHER_ALIGN;
	c->xl_ptr->xl_frag.xl_len = c->map->dm_segs[0].ds_len | XL_LAST_FRAG;
	c->xl_ptr->xl_status = 0;
d1250 2
a1251 1
	while((rxstat = sc->xl_cdata.xl_rx_head->xl_ptr->xl_status)) {
d1268 1
a1268 1
			cur_rx->xl_ptr->xl_status = 0;
d1281 1
a1281 1
			cur_rx->xl_ptr->xl_status = 0;
d1287 2
a1288 4
		total_len = cur_rx->xl_ptr->xl_status & XL_RXSTAT_LENMASK;

		bus_dmamap_sync(sc->sc_dmat, cur_rx->map, 0,
		    cur_rx->map->dm_mapsize, BUS_DMASYNC_POSTREAD);
d1299 1
a1299 1
			cur_rx->xl_ptr->xl_status = 0;
d1447 2
a1448 1
		if (!(cur_tx->xl_ptr->xl_status & XL_TXSTAT_DL_COMPLETE))
d1682 4
a1685 2
		c->xl_ptr->xl_frag[frag].xl_addr = map->dm_segs[frag].ds_addr;
		c->xl_ptr->xl_frag[frag].xl_len = map->dm_segs[frag].ds_len;
d1723 2
a1724 2
	c->xl_ptr->xl_frag[frag - 1].xl_len |= XL_LAST_FRAG;
	c->xl_ptr->xl_status = total_len;
d1812 1
a1812 1
	cur_tx->xl_ptr->xl_status |= XL_TXSTAT_DL_INTR;
d1827 1
a1827 1
					~XL_TXSTAT_DL_INTR;
d1884 1
a1884 1
	d->xl_status = 0;
d1895 2
a1896 2
		f->xl_addr = map->dm_segs[frag].ds_addr;
		f->xl_len = map->dm_segs[frag].ds_len;
d1905 2
a1906 2
	c->xl_ptr->xl_frag[frag - 1].xl_len |= XL_LAST_FRAG;
	c->xl_ptr->xl_status = XL_TXSTAT_RND_DEFEAT;
d1909 1
a1909 1
		c->xl_ptr->xl_status |= XL_TXSTAT_IPCKSUM;
d1911 1
a1911 1
		c->xl_ptr->xl_status |= XL_TXSTAT_TCPCKSUM;
d1913 1
a1913 1
		c->xl_ptr->xl_status |= XL_TXSTAT_UDPCKSUM;
d1958 1
a1958 1
			prev->xl_ptr->xl_next = cur_tx->xl_phys;
d1987 1
a1987 1
	cur_tx->xl_ptr->xl_status |= XL_TXSTAT_DL_INTR;
d1991 1
a1991 1
	start_tx->xl_prev->xl_ptr->xl_next = start_tx->xl_phys;
@


1.40
log
@Don't write 32 bits to a 16-bit register.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.39 2002/06/15 19:35:29 aaron Exp $	*/
a636 2
	struct ether_multi *enm;
	struct ether_multistep step;
a637 1
	int			mcnt = 0;
d650 1
a650 7
	ETHER_FIRST_MULTI(step, ac, enm);
	while (enm != NULL) {
		mcnt++;
		ETHER_NEXT_MULTI(step, enm);
	}

	if (mcnt)
@


1.39
log
@Check the correct variable when freeing the RX/TX lists.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.38 2002/06/15 05:14:41 aaron Exp $	*/
d770 1
a770 1
	CSR_WRITE_4(sc, XL_COMMAND, XL_CMD_COAX_STOP);
@


1.38
log
@bus_dma'ify. Tested on 3c900(pci), 3c905b(pci), and 3c575c(cardbus). Thanks
to todd@@ and camiel@@ for trying it, too.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.37 2002/06/09 03:14:18 todd Exp $	*/
d2473 1
a2473 1
		if (sc->xl_cdata.xl_rx_chain[i].map->dm_segs != 0) {
d2491 1
a2491 1
		if (sc->xl_cdata.xl_tx_chain[i].map->dm_segs != 0) {
@


1.37
log
@a step towards consistancy; in general:
	'struct arpcom foo' -> 'struct arpcom sc_arpcom'
ok itojun@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.36 2002/06/08 23:38:51 aaron Exp $	*/
a144 2
#include <uvm/uvm_extern.h>              /* for vtophys */

d1092 3
a1094 1
		cd->xl_tx_chain[i].xl_phys = vtophys(&ld->xl_tx_list[i]);
d1128 1
d1138 1
d1141 2
a1142 2
			ld->xl_rx_list[i].xl_next =
			    vtophys(&ld->xl_rx_list[0]);
d1145 2
a1146 2
			ld->xl_rx_list[i].xl_next =
			    vtophys(&ld->xl_rx_list[i + 1]);
d1148 1
d1164 1
d1177 9
d1190 3
d1194 2
a1195 2
	c->xl_ptr->xl_frag.xl_addr = vtophys(mtod(m_new, caddr_t));
	c->xl_ptr->xl_frag.xl_len = MCLBYTES | XL_LAST_FRAG;
d1198 4
d1214 5
d1253 5
d1287 3
d1353 2
a1354 1
			vtophys(&sc->xl_ldata->xl_rx_list[0]));
d1390 5
a1398 2
		m_freem(cur_tx->xl_mbuf);
		cur_tx->xl_mbuf = NULL;
d1400 2
d1403 8
d1422 3
a1424 1
				vtophys(sc->xl_cdata.xl_tx_head->xl_ptr));
d1498 3
a1500 1
					    vtophys(sc->xl_cdata.xl_tx_head->xl_ptr));
d1660 9
a1668 4
	int			frag = 0;
	struct xl_frag		*f = NULL;
	int			total_len;
	struct mbuf		*m;
d1675 8
a1682 13
	m = m_head;
	total_len = 0;

	for (m = m_head, frag = 0; m != NULL; m = m->m_next) {
		if (m->m_len != 0) {
			if (frag == XL_MAXFRAGS)
				break;
			total_len+= m->m_len;
			c->xl_ptr->xl_frag[frag].xl_addr =
					vtophys(mtod(m, vm_offset_t));
			c->xl_ptr->xl_frag[frag].xl_len = m->m_len;
			frag++;
		}
d1693 1
a1693 1
	if (m != NULL) {
d1711 1
a1711 4
		f = &c->xl_ptr->xl_frag[0];
		f->xl_addr = vtophys(mtod(m_new, caddr_t));
		f->xl_len = total_len = m_new->m_len;
		frag = 1;
d1714 3
d1718 3
a1720 1
	c->xl_ptr->xl_frag[frag - 1].xl_len |=  XL_LAST_FRAG;
d1724 5
d1779 4
a1782 1
			prev->xl_ptr->xl_next = vtophys(cur_tx->xl_ptr);
d1821 2
a1822 1
					vtophys(start_tx->xl_ptr);
d1831 3
a1833 1
		CSR_WRITE_4(sc, XL_DOWNLIST_PTR, vtophys(start_tx->xl_ptr));
a1868 1
	int frag = 0;
a1869 1
	struct mbuf *m;
d1871 2
d1879 1
d1884 10
a1893 9
	for (m = m_head, frag = 0; m != NULL; m = m->m_next) {
		if (m->m_len != 0) {
			if (frag == XL_MAXFRAGS)
				break;
			f = &d->xl_frag[frag];
			f->xl_addr = vtophys(mtod(m, vm_offset_t));
			f->xl_len = m->m_len;
			frag++;
		}
d1896 3
d1900 2
d1912 5
d2133 2
a2134 1
	CSR_WRITE_4(sc, XL_UPLIST_PTR, vtophys(&sc->xl_ldata->xl_rx_list[0]));
d2145 2
a2146 1
		    vtophys(&sc->xl_ldata->xl_tx_list[0]));
d2473 7
d2491 7
a2557 2
	caddr_t roundptr;
	u_int round;
d2574 54
a2643 24

	sc->xl_ldata_ptr = malloc(sizeof(struct xl_list_data) + 8,
	    M_DEVBUF, M_NOWAIT);
	if (sc->xl_ldata_ptr == NULL) {
		printf("%s: no memory for list buffers\n",sc->sc_dev.dv_xname);
		return;
	}

	sc->xl_ldata = (struct xl_list_data *)sc->xl_ldata_ptr;
#ifdef __alpha__
	round = (u_int64_t)sc->xl_ldata_ptr & 0xf;
#else
	round = (u_int32_t)sc->xl_ldata_ptr & 0xf;
#endif
	roundptr = sc->xl_ldata_ptr;
	for (i = 0; i < 8; i++) {
		if (round % 8) {
			round++;
			roundptr++;
		} else
			break;
	}
	sc->xl_ldata = (struct xl_list_data *)roundptr;
	bzero(sc->xl_ldata, sizeof(struct xl_list_data));
@


1.36
log
@Add hardware TCP/IP checksum offloading support for receive and transmit for
the 3c905b; deraadt@@ ok.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.35 2002/03/14 01:26:55 millert Exp $	*/
d214 1
a214 1
		ifp = &sc->arpcom.ac_if;
d638 1
a638 1
	struct arpcom *ac = &sc->arpcom;
d644 1
a644 1
	ifp = &sc->arpcom.ac_if;
d679 1
a679 1
	struct arpcom *ac = &sc->arpcom;
d685 1
a685 1
	ifp = &sc->arpcom.ac_if;
d734 1
a734 1
	ifp = &sc->arpcom.ac_if;
d741 1
a741 1
	bcopy(&sc->arpcom.ac_enaddr,
d743 1
a743 1
	bcopy(&sc->arpcom.ac_enaddr,
d1220 1
a1220 1
	ifp = &sc->arpcom.ac_if;
d1339 1
a1339 1
	ifp = &sc->arpcom.ac_if;
d1391 1
a1391 1
	ifp = &sc->arpcom.ac_if;
d1496 1
a1496 1
	ifp = &sc->arpcom.ac_if;
d1562 1
a1562 1
	ifp = &sc->arpcom.ac_if;
d1924 1
a1924 1
	struct ifnet		*ifp = &sc->arpcom.ac_if;
d1952 1
a1952 1
				sc->arpcom.ac_enaddr[i]);
d2258 1
a2258 1
	if ((error = ether_ioctl(ifp, &sc->arpcom, command, data)) > 0) {
d2270 1
a2270 1
			arp_ifinit(&sc->arpcom, ifa);
d2317 2
a2318 2
		    ether_addmulti(ifr, &sc->arpcom) :
		    ether_delmulti(ifr, &sc->arpcom);
d2424 1
a2424 1
	ifp = &sc->arpcom.ac_if;
d2465 1
a2465 1
	struct ifnet *ifp = &sc->arpcom.ac_if;
d2482 1
a2482 1
	bcopy(enaddr, (char *)&sc->arpcom.ac_enaddr, ETHER_ADDR_LEN);
d2484 1
a2484 1
	printf(" address %s\n", ether_sprintf(sc->arpcom.ac_enaddr));
d2712 1
a2712 1
	struct ifnet *ifp = &sc->arpcom.ac_if;
@


1.35
log
@First round of __P removal in sys
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.34 2002/02/15 20:45:31 nordin Exp $	*/
d1217 2
a1218 2
	int			total_len = 0;
	u_int16_t		rxstat;
d1281 19
d1834 7
d2543 1
a2543 1
	if (sc->xl_type == XL_TYPE_905B)
d2545 3
a2547 1
	else
d2557 1
a2557 1
		ifp->if_capabilities = IFCAP_VLAN_MTU;
@


1.34
log
@Don't cast nonexistent return value from splx to (void). ok art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.33 2002/01/25 05:44:06 nordin Exp $	*/
d149 42
a190 42
int xl_newbuf		__P((struct xl_softc *, struct xl_chain_onefrag *));
void xl_stats_update	__P((void *));
int xl_encap		__P((struct xl_softc *, struct xl_chain *,
    struct mbuf * ));
int xl_encap_90xB	__P((struct xl_softc *, struct xl_chain *,
    struct mbuf * ));
void xl_rxeof		__P((struct xl_softc *));
int xl_rx_resync	__P((struct xl_softc *));
void xl_txeof		__P((struct xl_softc *));
void xl_txeof_90xB	__P((struct xl_softc *));
void xl_txeoc		__P((struct xl_softc *));
int xl_intr		__P((void *));
void xl_start		__P((struct ifnet *));
void xl_start_90xB	__P((struct ifnet *));
int xl_ioctl		__P((struct ifnet *, u_long, caddr_t));
void xl_init		__P((void *));
void xl_stop		__P((struct xl_softc *));
void xl_freetxrx	__P((struct xl_softc *));
void xl_watchdog	__P((struct ifnet *));
void xl_shutdown	__P((void *));
int xl_ifmedia_upd	__P((struct ifnet *));
void xl_ifmedia_sts	__P((struct ifnet *, struct ifmediareq *));

int xl_eeprom_wait	__P((struct xl_softc *));
int xl_read_eeprom	__P((struct xl_softc *, caddr_t, int, int, int));
void xl_mii_sync	__P((struct xl_softc *));
void xl_mii_send	__P((struct xl_softc *, u_int32_t, int));
int xl_mii_readreg	__P((struct xl_softc *, struct xl_mii_frame *));
int xl_mii_writereg	__P((struct xl_softc *, struct xl_mii_frame *));

void xl_setcfg		__P((struct xl_softc *));
void xl_setmode		__P((struct xl_softc *, int));
u_int8_t xl_calchash	__P((caddr_t));
void xl_setmulti	__P((struct xl_softc *));
void xl_setmulti_hash	__P((struct xl_softc *));
void xl_reset		__P((struct xl_softc *, int));
int xl_list_rx_init	__P((struct xl_softc *));
int xl_list_tx_init	__P((struct xl_softc *));
int xl_list_tx_init_90xB	__P((struct xl_softc *));
void xl_wait		__P((struct xl_softc *));
void xl_mediacheck	__P((struct xl_softc *));
void xl_choose_xcvr	__P((struct xl_softc *, int));
d192 1
a192 1
void xl_testpacket	__P((struct xl_softc *));
d195 3
a197 3
int xl_miibus_readreg	__P((struct device *, int, int));
void xl_miibus_writereg	__P((struct device *, int, int, int));
void xl_miibus_statchg	__P((struct device *));
d199 1
a199 1
void xl_power __P((int, void *));
@


1.33
log
@Disestablish *powerhook* on detach. jason@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.32 2001/12/15 05:33:53 nordin Exp $	*/
d2102 1
a2102 1
	(void)splx(s);
d2326 1
a2326 1
	(void)splx(s);
@


1.32
log
@Disestablish the powerhook on detach. ok jason@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.31 2001/11/06 19:53:18 miod Exp $	*/
d2702 1
a2702 1
	powerhook_disestablish(sc->sc_sdhook);
@


1.32.2.1
log
@Merge in -current, builds on i386, otherwise untested
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.33 2002/01/25 05:44:06 nordin Exp $	*/
d2702 1
a2702 1
	powerhook_disestablish(sc->sc_pwrhook);
@


1.32.2.2
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.32.2.1 2002/01/31 22:55:32 niklas Exp $	*/
d149 42
a190 42
int xl_newbuf(struct xl_softc *, struct xl_chain_onefrag *);
void xl_stats_update(void *);
int xl_encap(struct xl_softc *, struct xl_chain *,
    struct mbuf * );
int xl_encap_90xB(struct xl_softc *, struct xl_chain *,
    struct mbuf * );
void xl_rxeof(struct xl_softc *);
int xl_rx_resync(struct xl_softc *);
void xl_txeof(struct xl_softc *);
void xl_txeof_90xB(struct xl_softc *);
void xl_txeoc(struct xl_softc *);
int xl_intr(void *);
void xl_start(struct ifnet *);
void xl_start_90xB(struct ifnet *);
int xl_ioctl(struct ifnet *, u_long, caddr_t);
void xl_init(void *);
void xl_stop(struct xl_softc *);
void xl_freetxrx(struct xl_softc *);
void xl_watchdog(struct ifnet *);
void xl_shutdown(void *);
int xl_ifmedia_upd(struct ifnet *);
void xl_ifmedia_sts(struct ifnet *, struct ifmediareq *);

int xl_eeprom_wait(struct xl_softc *);
int xl_read_eeprom(struct xl_softc *, caddr_t, int, int, int);
void xl_mii_sync(struct xl_softc *);
void xl_mii_send(struct xl_softc *, u_int32_t, int);
int xl_mii_readreg(struct xl_softc *, struct xl_mii_frame *);
int xl_mii_writereg(struct xl_softc *, struct xl_mii_frame *);

void xl_setcfg(struct xl_softc *);
void xl_setmode(struct xl_softc *, int);
u_int8_t xl_calchash(caddr_t);
void xl_setmulti(struct xl_softc *);
void xl_setmulti_hash(struct xl_softc *);
void xl_reset(struct xl_softc *, int);
int xl_list_rx_init(struct xl_softc *);
int xl_list_tx_init(struct xl_softc *);
int xl_list_tx_init_90xB(struct xl_softc *);
void xl_wait(struct xl_softc *);
void xl_mediacheck(struct xl_softc *);
void xl_choose_xcvr(struct xl_softc *, int);
d192 1
a192 1
void xl_testpacket(struct xl_softc *);
d195 3
a197 3
int xl_miibus_readreg(struct device *, int, int);
void xl_miibus_writereg(struct device *, int, int, int);
void xl_miibus_statchg(struct device *);
d199 1
a199 1
void xl_power(int, void *);
d214 1
a214 1
		ifp = &sc->sc_arpcom.ac_if;
d638 1
a638 1
	struct arpcom *ac = &sc->sc_arpcom;
d644 1
a644 1
	ifp = &sc->sc_arpcom.ac_if;
d679 1
a679 1
	struct arpcom *ac = &sc->sc_arpcom;
d685 1
a685 1
	ifp = &sc->sc_arpcom.ac_if;
d734 1
a734 1
	ifp = &sc->sc_arpcom.ac_if;
d741 1
a741 1
	bcopy(&sc->sc_arpcom.ac_enaddr,
d743 1
a743 1
	bcopy(&sc->sc_arpcom.ac_enaddr,
d1217 2
a1218 2
	int			total_len = 0, sumflags = 0;
	u_int32_t		rxstat;
d1220 1
a1220 1
	ifp = &sc->sc_arpcom.ac_if;
a1280 19

		if (sc->xl_type == XL_TYPE_905B) {
			if (rxstat & XL_RXSTAT_IPCKERR)
				sumflags |= M_IPV4_CSUM_IN_BAD;
			else if (rxstat & XL_RXSTAT_IPCKOK)
				sumflags |= M_IPV4_CSUM_IN_OK;

			if (rxstat & XL_RXSTAT_TCPCKERR)
				sumflags |= M_TCP_CSUM_IN_BAD;
			else if (rxstat & XL_RXSTAT_TCPCKOK)
				sumflags |= M_TCP_CSUM_IN_OK;

			if (rxstat & XL_RXSTAT_UDPCKERR)
				sumflags |= M_UDP_CSUM_IN_BAD;
			else if (rxstat & XL_RXSTAT_UDPCKOK)
				sumflags |= M_UDP_CSUM_IN_OK;

			m->m_pkthdr.csum = sumflags;
		}
d1320 1
a1320 1
	ifp = &sc->sc_arpcom.ac_if;
d1372 1
a1372 1
	ifp = &sc->sc_arpcom.ac_if;
d1477 1
a1477 1
	ifp = &sc->sc_arpcom.ac_if;
d1543 1
a1543 1
	ifp = &sc->sc_arpcom.ac_if;
a1814 7
	if (m_head->m_pkthdr.csum & M_IPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= XL_TXSTAT_IPCKSUM;
	if (m_head->m_pkthdr.csum & M_TCPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= XL_TXSTAT_TCPCKSUM;
	if (m_head->m_pkthdr.csum & M_UDPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= XL_TXSTAT_UDPCKSUM;

d1898 1
a1898 1
	struct ifnet		*ifp = &sc->sc_arpcom.ac_if;
d1926 1
a1926 1
				sc->sc_arpcom.ac_enaddr[i]);
d2102 1
a2102 1
	splx(s);
d2232 1
a2232 1
	if ((error = ether_ioctl(ifp, &sc->sc_arpcom, command, data)) > 0) {
d2244 1
a2244 1
			arp_ifinit(&sc->sc_arpcom, ifa);
d2291 2
a2292 2
		    ether_addmulti(ifr, &sc->sc_arpcom) :
		    ether_delmulti(ifr, &sc->sc_arpcom);
d2326 1
a2326 1
	splx(s);
d2398 1
a2398 1
	ifp = &sc->sc_arpcom.ac_if;
d2439 1
a2439 1
	struct ifnet *ifp = &sc->sc_arpcom.ac_if;
d2456 1
a2456 1
	bcopy(enaddr, (char *)&sc->sc_arpcom.ac_enaddr, ETHER_ADDR_LEN);
d2458 1
a2458 1
	printf(" address %s\n", ether_sprintf(sc->sc_arpcom.ac_enaddr));
d2517 1
a2517 1
	if (sc->xl_type == XL_TYPE_905B) {
d2519 1
a2519 3
		ifp->if_capabilities = IFCAP_CSUM_IPv4|IFCAP_CSUM_TCPv4|
		    IFCAP_CSUM_UDPv4;
	} else
d2529 1
a2529 1
		ifp->if_capabilities |= IFCAP_VLAN_MTU;
d2684 1
a2684 1
	struct ifnet *ifp = &sc->sc_arpcom.ac_if;
@


1.32.2.3
log
@sync to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.32.2.2 2002/06/11 03:42:20 art Exp $	*/
d145 2
d639 2
d642 1
d655 7
a661 1
	if (ac->ac_multicnt > 0)
d772 1
a772 1
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_COAX_STOP);
d1094 1
a1094 3
		cd->xl_tx_chain[i].xl_phys =
		    sc->sc_listmap->dm_segs[0].ds_addr +   
		    offsetof(struct xl_list_data, xl_tx_list[i]);
a1127 1
	bus_addr_t		next;
a1136 1
		next = sc->sc_listmap->dm_segs[0].ds_addr;
d1139 2
a1140 2
			next +=
			    offsetof(struct xl_list_data, xl_rx_list[0]);
d1143 2
a1144 2
			next +=
			    offsetof(struct xl_list_data, xl_rx_list[i + 1]);
a1145 1
		ld->xl_rx_list[i].xl_next = next;
a1160 1
	bus_dmamap_t		map;
a1172 9
	if (bus_dmamap_load(sc->sc_dmat, sc->sc_rx_sparemap,
	    mtod(m_new, caddr_t), MCLBYTES, NULL, BUS_DMA_NOWAIT) != 0) {
		printf("%s: rx load failed\n", sc->sc_dev.dv_xname);
		m_freem(m_new);
		return (ENOBUFS);
	}
	map = c->map;
	c->map = sc->sc_rx_sparemap;
	sc->sc_rx_sparemap = map;
a1176 3
	bus_dmamap_sync(sc->sc_dmat, c->map, 0, c->map->dm_mapsize,
	    BUS_DMASYNC_PREREAD);

d1178 2
a1179 2
	c->xl_ptr->xl_frag.xl_addr = c->map->dm_segs[0].ds_addr + ETHER_ALIGN;
	c->xl_ptr->xl_frag.xl_len = c->map->dm_segs[0].ds_len | XL_LAST_FRAG;
a1181 4
	bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,
	    ((caddr_t)c->xl_ptr - sc->sc_listkva), sizeof(struct xl_list),
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

a1193 5
		bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,
		    ((caddr_t)pos->xl_ptr - sc->sc_listkva),
		    sizeof(struct xl_list),
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

a1227 5
		bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,
		    ((caddr_t)cur_rx->xl_ptr - sc->sc_listkva),
		    sizeof(struct xl_list),
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

a1256 3
		bus_dmamap_sync(sc->sc_dmat, cur_rx->map, 0,
		    cur_rx->map->dm_mapsize, BUS_DMASYNC_POSTREAD);

d1320 1
a1320 2
		    sc->sc_listmap->dm_segs[0].ds_addr +
		    offsetof(struct xl_list_data, xl_rx_list[0]));
a1355 5
		bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,
		    ((caddr_t)cur_tx->xl_ptr - sc->sc_listkva),
		    sizeof(struct xl_list),
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

d1360 2
a1362 2
		if (cur_tx->map->dm_nsegs != 0) {
			bus_dmamap_t map = cur_tx->map;
a1363 8
			bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
			    BUS_DMASYNC_POSTWRITE);
			bus_dmamap_unload(sc->sc_dmat, map);
		}
		if (cur_tx->xl_mbuf != NULL) {
			m_freem(cur_tx->xl_mbuf);
			cur_tx->xl_mbuf = NULL;
		}
d1375 1
a1375 3
			    sc->sc_listmap->dm_segs[0].ds_addr +
			    ((caddr_t)sc->xl_cdata.xl_tx_head->xl_ptr -
			    sc->sc_listkva));
d1449 1
a1449 3
					    sc->sc_listmap->dm_segs[0].ds_addr +
					    ((caddr_t)sc->xl_cdata.xl_tx_head->xl_ptr -
					    sc->sc_listkva));
d1609 4
a1612 9
	int			frag, total_len;
	bus_dmamap_t		map;

	map = sc->sc_tx_sparemap;

reload:
	if (bus_dmamap_load_mbuf(sc->sc_dmat, map,
	    m_head, BUS_DMA_NOWAIT) != 0)
		return (ENOBUFS);
d1619 13
a1631 8
	for (frag = 0, total_len = 0; frag < map->dm_nsegs; frag++) {
		if ((XL_TX_LIST_CNT - (sc->xl_cdata.xl_tx_cnt + frag)) < 3)
			return (ENOBUFS);
		if (frag == XL_MAXFRAGS)
			break;
		total_len += map->dm_segs[frag].ds_len;
		c->xl_ptr->xl_frag[frag].xl_addr = map->dm_segs[frag].ds_addr;
		c->xl_ptr->xl_frag[frag].xl_len = map->dm_segs[frag].ds_len;
d1642 1
a1642 1
	if (frag != map->dm_nsegs) {
d1660 4
a1663 1
		goto reload;
a1665 3
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREWRITE);

d1667 1
a1667 3
	sc->sc_tx_sparemap = c->map;
	c->map = map;
	c->xl_ptr->xl_frag[frag - 1].xl_len |= XL_LAST_FRAG;
a1670 5
	bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,
	    offsetof(struct xl_list_data, xl_tx_list[0]),
	    sizeof(struct xl_list) * XL_TX_LIST_CNT,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

d1721 1
a1721 4
			prev->xl_ptr->xl_next =
			    sc->sc_listmap->dm_segs[0].ds_addr +
			    ((caddr_t)cur_tx->xl_ptr - sc->sc_listkva);

d1760 1
a1760 2
		    sc->sc_listmap->dm_segs[0].ds_addr +
		    ((caddr_t)start_tx->xl_ptr - sc->sc_listkva);
d1769 1
a1769 3
		CSR_WRITE_4(sc, XL_DOWNLIST_PTR,
		    sc->sc_listmap->dm_segs[0].ds_addr +
		    ((caddr_t)start_tx->xl_ptr - sc->sc_listkva));
d1805 1
d1807 1
a1808 2
	int frag;
	bus_dmamap_t map;
a1814 1
	map = sc->sc_tx_sparemap;
d1819 9
a1827 10
	if (bus_dmamap_load_mbuf(sc->sc_dmat, map,
	    m_head, BUS_DMA_NOWAIT) != 0)
		return (ENOBUFS);

	for (frag = 0; frag < map->dm_nsegs; frag++) {
		if (frag == XL_MAXFRAGS)
			break;
		f = &d->xl_frag[frag];
		f->xl_addr = map->dm_segs[frag].ds_addr;
		f->xl_len = map->dm_segs[frag].ds_len;
a1829 3
	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREWRITE);

a1830 2
	sc->sc_tx_sparemap = c->map;
	c->map = map;
a1840 5
	bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,
	    offsetof(struct xl_list_data, xl_tx_list[0]),
	    sizeof(struct xl_list) * XL_TX_LIST_CNT,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

d2057 1
a2057 2
	CSR_WRITE_4(sc, XL_UPLIST_PTR, sc->sc_listmap->dm_segs[0].ds_addr +
	    offsetof(struct xl_list_data, xl_rx_list[0]));
d2068 1
a2068 2
		    sc->sc_listmap->dm_segs[0].ds_addr +
		    offsetof(struct xl_list_data, xl_tx_list[0]));
a2394 7
		if (sc->xl_cdata.xl_rx_chain[i].map->dm_nsegs != 0) {
			bus_dmamap_t map = sc->xl_cdata.xl_rx_chain[i].map;

			bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
			    BUS_DMASYNC_POSTREAD);
			bus_dmamap_unload(sc->sc_dmat, map);
		}
a2405 7
		if (sc->xl_cdata.xl_tx_chain[i].map->dm_nsegs != 0) {
			bus_dmamap_t map = sc->xl_cdata.xl_tx_chain[i].map;

			bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
			    BUS_DMASYNC_POSTWRITE);
			bus_dmamap_unload(sc->sc_dmat, map);
		}
d2466 2
a2483 54
	if (bus_dmamem_alloc(sc->sc_dmat, sizeof(struct xl_list_data),
	    PAGE_SIZE, 0, sc->sc_listseg, 1, &sc->sc_listnseg,
	    BUS_DMA_NOWAIT) != 0) {
		printf(": can't alloc list mem\n");
		return;
	}
	if (bus_dmamem_map(sc->sc_dmat, sc->sc_listseg, sc->sc_listnseg,
	    sizeof(struct xl_list_data), &sc->sc_listkva,
	    BUS_DMA_NOWAIT) != 0) {
		printf(": can't map list mem\n");
		return;
	}
	if (bus_dmamap_create(sc->sc_dmat, sizeof(struct xl_list_data), 1,
	    sizeof(struct xl_list_data), 0, BUS_DMA_NOWAIT,
	    &sc->sc_listmap) != 0) {
		printf(": can't alloc list map\n");
		return;
	}
	if (bus_dmamap_load(sc->sc_dmat, sc->sc_listmap, sc->sc_listkva,
	    sizeof(struct xl_list_data), NULL, BUS_DMA_NOWAIT) != 0) {
		printf(": can't load list map\n");
		return;
	}
	sc->xl_ldata = (struct xl_list_data *)sc->sc_listkva;
	bzero(sc->xl_ldata, sizeof(struct xl_list_data));

	for (i = 0; i < XL_RX_LIST_CNT; i++) {
		if (bus_dmamap_create(sc->sc_dmat, MCLBYTES, 1, MCLBYTES,
		    0, BUS_DMA_NOWAIT,
		    &sc->xl_cdata.xl_rx_chain[i].map) != 0) {
			printf(": can't create rx map\n");
			return;
		}
	}
	if (bus_dmamap_create(sc->sc_dmat, MCLBYTES, 1, MCLBYTES, 0,
	    BUS_DMA_NOWAIT, &sc->sc_rx_sparemap) != 0) {
		printf(": can't create rx spare map\n");
		return;
	}

	for (i = 0; i < XL_TX_LIST_CNT; i++) {
		if (bus_dmamap_create(sc->sc_dmat, MCLBYTES,
		    XL_TX_LIST_CNT - 3, MCLBYTES, 0, BUS_DMA_NOWAIT,
		    &sc->xl_cdata.xl_tx_chain[i].map) != 0) {
			printf(": can't create tx map\n");
			return;
		}
	}
	if (bus_dmamap_create(sc->sc_dmat, MCLBYTES, XL_TX_LIST_CNT - 3,
	    MCLBYTES, 0, BUS_DMA_NOWAIT, &sc->sc_tx_sparemap) != 0) {
		printf(": can't create tx spare map\n");
		return;
	}

d2500 24
@


1.32.2.4
log
@sync
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d103 3
a556 1
#define EEPROM_8BIT_OFFSET(A) ((A) & 0x003F)
d571 1
a571 2
			CSR_WRITE_2(sc, XL_W0_EE_CMD,
			    XL_EE_8BIT_READ | EEPROM_8BIT_OFFSET(off + i));
a767 1
	struct ifnet *ifp = &sc->sc_arpcom.ac_if;
d771 2
d780 1
a780 1
			ifp->if_baudrate = IF_Mbps(10);
d792 1
a792 1
			ifp->if_baudrate = IF_Mbps(100);
d803 1
a803 1
			ifp->if_baudrate = IF_Mbps(10);
d812 1
a812 1
			ifp->if_baudrate = IF_Mbps(10);
d824 1
a824 1
			ifp->if_baudrate = IF_Mbps(10);
d836 1
d840 1
d1069 1
a1069 1
 * Initialize the transmit descriptors.
d1099 1
a1099 1
	ld->xl_tx_list[0].xl_status = htole32(XL_TXSTAT_EMPTY);
d1139 1
a1139 1
		ld->xl_rx_list[i].xl_next = htole32(next);
a1173 8

	/* sync the old map, and unload it (if necessary) */
	if (c->map->dm_nsegs != 0) {
		bus_dmamap_sync(sc->sc_dmat, c->map,
		    0, c->map->dm_mapsize, BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->sc_dmat, c->map);
	}

d1185 3
a1187 5
	c->xl_ptr->xl_frag.xl_addr =
	    htole32(c->map->dm_segs[0].ds_addr + ETHER_ALIGN);
	c->xl_ptr->xl_frag.xl_len =
	    htole32(c->map->dm_segs[0].ds_len | XL_LAST_FRAG);
	c->xl_ptr->xl_status = htole32(0);
d1240 1
a1240 2
	while ((rxstat = letoh32(sc->xl_cdata.xl_rx_head->xl_ptr->xl_status))
	    != 0) {
d1257 1
a1257 1
			cur_rx->xl_ptr->xl_status = htole32(0);
d1270 1
a1270 1
			cur_rx->xl_ptr->xl_status = htole32(0);
d1276 4
a1279 2
		total_len = letoh32(cur_rx->xl_ptr->xl_status) &
		    XL_RXSTAT_LENMASK;
d1290 1
a1290 1
			cur_rx->xl_ptr->xl_status = htole32(0);
d1438 1
a1438 2
		if ((cur_tx->xl_ptr->xl_status &
		    htole32(XL_TXSTAT_DL_COMPLETE)) == 0)
a1445 6
		if (cur_tx->map->dm_nsegs != 0) {
			bus_dmamap_sync(sc->sc_dmat, cur_tx->map,
			    0, cur_tx->map->dm_mapsize, BUS_DMASYNC_POSTWRITE);
			bus_dmamap_unload(sc->sc_dmat, cur_tx->map);
		}

d1672 2
a1673 4
		c->xl_ptr->xl_frag[frag].xl_addr =
		    htole32(map->dm_segs[frag].ds_addr);
		c->xl_ptr->xl_frag[frag].xl_len =
		    htole32(map->dm_segs[frag].ds_len);
d1698 1
a1698 1
		    mtod(m_new, caddr_t));
a1707 6
	if (c->map->dm_nsegs != 0) {
		bus_dmamap_sync(sc->sc_dmat, c->map,
		    0, c->map->dm_mapsize, BUS_DMASYNC_POSTWRITE);
		bus_dmamap_unload(sc->sc_dmat, c->map);
	}

d1711 2
a1712 2
	c->xl_ptr->xl_frag[frag - 1].xl_len |= htole32(XL_LAST_FRAG);
	c->xl_ptr->xl_status = htole32(total_len);
d1800 1
a1800 1
	cur_tx->xl_ptr->xl_status |= htole32(XL_TXSTAT_DL_INTR);
d1815 1
a1815 1
		    htole32(~XL_TXSTAT_DL_INTR);
d1872 1
a1872 1
	d->xl_status = htole32(0);
d1883 2
a1884 2
		f->xl_addr = htole32(map->dm_segs[frag].ds_addr);
		f->xl_len = htole32(map->dm_segs[frag].ds_len);
a1889 7
	/* sync the old map, and unload it (if necessary) */
	if (c->map->dm_nsegs != 0) {
		bus_dmamap_sync(sc->sc_dmat, c->map, 0, c->map->dm_mapsize,
		    BUS_DMASYNC_POSTWRITE);
		bus_dmamap_unload(sc->sc_dmat, c->map);
	}

d1893 2
a1894 2
	c->xl_ptr->xl_frag[frag - 1].xl_len |= htole32(XL_LAST_FRAG);
	c->xl_ptr->xl_status = htole32(XL_TXSTAT_RND_DEFEAT);
d1897 1
a1897 1
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_IPCKSUM);
d1899 1
a1899 1
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_TCPCKSUM);
d1901 1
a1901 1
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_UDPCKSUM);
d1946 1
a1946 1
			prev->xl_ptr->xl_next = htole32(cur_tx->xl_phys);
d1975 1
a1975 1
	cur_tx->xl_ptr->xl_status |= htole32(XL_TXSTAT_DL_INTR);
d1979 1
a1979 1
	start_tx->xl_prev->xl_ptr->xl_next = htole32(start_tx->xl_phys);
a2552 1
	i = splimp();
a2553 1
	splx(i);
d2689 1
a2689 2
		CSR_WRITE_2(sc, XL_W2_RESET_OPTIONS, XL_RESETOPT_INVMIIPWR |
		    CSR_READ_2(sc, XL_W2_RESET_OPTIONS));
a2729 1
		i = splimp();
a2730 1
		splx(i);
@


1.31
log
@Replace inclusion of <vm/foo.h> with the correct <uvm/bar.h> when necessary.
(Look ma, I might have broken the tree)
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.30 2001/08/19 18:07:33 jason Exp $	*/
d870 1
d2702 1
@


1.30
log
@Don't reset rx/tx without turning them back on after suspend (Beck is now
able to do "Real Work" after a suspend)
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.29 2001/08/19 01:45:55 jason Exp $	*/
d145 1
a145 1
#include <vm/vm.h>              /* for vtophys */
@


1.29
log
@Add a powerhook for bringing the 556 out of sleepy mode after suspend.
(This isn't perfect... it still requires an down up transition, but Bob is
kicking me off his laptop so he can do "Real Work").
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.28 2001/08/12 20:12:12 mickey Exp $	*/
d215 1
a215 1
		if (ifp->if_flags & IFF_UP)
d217 2
@


1.28
log
@remove some of the redundant vm includes
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.27 2001/08/03 23:31:52 chris Exp $	*/
d199 22
d2674 1
@


1.27
log
@This driver allows vlan sized frames on 905B, set IFCAP_VLAN_MTU on that chip
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.26 2001/07/02 01:28:21 jason Exp $	*/
a145 1
#include <vm/pmap.h>            /* for vtophys */
@


1.26
log
@these don't depend on pci register defs
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.25 2001/06/27 06:34:43 kjc Exp $	*/
d2502 10
@


1.25
log
@ALTQ'ify network drivers.
- use the new queue macros.
- use IFQ_POLL() to peek at the next packet.
- use IFQ_IS_EMPTY() for empty check.
- drivers should always check if (m == NULL) after IFQ_DEQUEUE(),
since it could return NULL even when IFQ_IS_EMPTY() is FALSE
under rate-limiting.
- drivers are supposed to call if_start from tx complete interrupts
(in order to trigger the next dequeue under rate-limiting).
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.24 2001/06/23 23:17:35 fgsch Exp $	*/
d139 1
a139 3
#include <dev/pci/pcireg.h>
#include <dev/pci/pcivar.h>
#include <dev/pci/pcidevs.h>
@


1.24
log
@ether_input_mbuf().
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.23 2001/04/08 01:05:12 aaron Exp $	*/
d711 1
d729 1
a729 1
	IF_ENQUEUE(&ifp->if_snd, m);
d1502 1
a1502 1
	if (ifp->if_snd.ifq_head != NULL)
d1664 1
a1664 1
		IF_DEQUEUE(&ifp->if_snd, m_head);
d1820 1
a1820 1
		IF_DEQUEUE(&ifp->if_snd, m_head);
d1988 1
d1990 3
d2277 1
d2279 3
d2331 1
a2331 1
	if (ifp->if_snd.ifq_head != NULL)
d2501 2
a2502 1
	ifp->if_snd.ifq_maxlen = XL_TX_LIST_CNT - 1;
@


1.23
log
@Don't print anything for transmission error 90, since the driver always
recovers from the situation, and there's not much point in knowing about it.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.22 2001/03/25 06:27:44 csapuntz Exp $	*/
a1190 1
        struct ether_header	*eh;
a1247 1
		eh = mtod(m, struct ether_header *);
d1249 1
a1254 1
			m->m_pkthdr.len = m->m_len = total_len;
d1258 1
a1258 5
		/* Remove header from mbuf and pass it on. */
		m->m_pkthdr.len = m->m_len =
				total_len - sizeof(struct ether_header);
		m->m_data += sizeof(struct ether_header);
		ether_input(ifp, eh, m);
@


1.23.4.1
log
@merge in approximately 2.9 into SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.23 2001/04/08 01:05:12 aaron Exp $	*/
@


1.23.4.2
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.23.4.1 2001/05/14 22:24:26 niklas Exp $	*/
d139 3
a141 1
#include <machine/bus.h>
a710 1
	int			error;
d728 1
a728 1
	IFQ_ENQUEUE(&ifp->if_snd, m, NULL, error);
d1191 1
d1249 1
a1250 1
		m->m_pkthdr.len = m->m_len = total_len;
d1256 1
d1260 5
a1264 1
		ether_input_mbuf(ifp, m);
d1507 1
a1507 1
	if (!IFQ_IS_EMPTY(&ifp->if_snd))
d1669 1
a1669 1
		IFQ_DEQUEUE(&ifp->if_snd, m_head);
d1825 1
a1825 1
		IFQ_DEQUEUE(&ifp->if_snd, m_head);
a1992 1
#if 0
a1993 3
#else
	if (0)	/* xl_setmulti_hash() does not work right */
#endif
a2277 1
#if 0
a2278 3
#else
			if (0)	/* xl_setmulti_hash() does not work right */
#endif
d2328 1
a2328 1
	if (!IFQ_IS_EMPTY(&ifp->if_snd))
d2498 1
a2498 2
	IFQ_SET_MAXLEN(&ifp->if_snd, XL_TX_LIST_CNT - 1);
	IFQ_SET_READY(&ifp->if_snd);
@


1.23.4.3
log
@Sync the SMP branch to something just after 3.0
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.23.4.2 2001/07/04 10:41:21 niklas Exp $	*/
d146 1
a199 24
void xl_power __P((int, void *));

void
xl_power(why, arg)
	int why;
	void *arg;
{
	struct xl_softc *sc = arg;
	struct ifnet *ifp;
	int s;

	s = splimp();
	if (why != PWR_RESUME)
		xl_stop(sc);
	else {
		ifp = &sc->arpcom.ac_if;
		if (ifp->if_flags & IFF_UP) {
			xl_reset(sc, 1);
			xl_init(sc);
		}
	}
	splx(s);
}

a2502 10
#if NVLAN > 0
	if (sc->xl_type == XL_TYPE_905B)
		ifp->if_capabilities = IFCAP_VLAN_MTU;
	/*
	 * XXX
	 * Do other cards filter large packets or simply pass them through?
	 * Apparently only the 905B has the capability to set a larger size.
 	 */
#endif

a2642 1
	sc->sc_pwrhook = powerhook_establish(xl_power, sc);
@


1.23.4.4
log
@Merge in -current
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d145 1
a145 1
#include <uvm/uvm_extern.h>              /* for vtophys */
@


1.23.4.5
log
@Merge in trunk
@
text
@a869 1
	int hard;
d2101 1
a2101 1
	splx(s);
d2325 1
a2325 1
	splx(s);
a2700 1
	powerhook_disestablish(sc->sc_pwrhook);
@


1.23.4.6
log
@Merge in -current from about a week ago
@
text
@d149 22
a170 22
int xl_newbuf(struct xl_softc *, struct xl_chain_onefrag *);
void xl_stats_update(void *);
int xl_encap(struct xl_softc *, struct xl_chain *,
    struct mbuf * );
int xl_encap_90xB(struct xl_softc *, struct xl_chain *,
    struct mbuf * );
void xl_rxeof(struct xl_softc *);
int xl_rx_resync(struct xl_softc *);
void xl_txeof(struct xl_softc *);
void xl_txeof_90xB(struct xl_softc *);
void xl_txeoc(struct xl_softc *);
int xl_intr(void *);
void xl_start(struct ifnet *);
void xl_start_90xB(struct ifnet *);
int xl_ioctl(struct ifnet *, u_long, caddr_t);
void xl_init(void *);
void xl_stop(struct xl_softc *);
void xl_freetxrx(struct xl_softc *);
void xl_watchdog(struct ifnet *);
void xl_shutdown(void *);
int xl_ifmedia_upd(struct ifnet *);
void xl_ifmedia_sts(struct ifnet *, struct ifmediareq *);
d172 6
a177 6
int xl_eeprom_wait(struct xl_softc *);
int xl_read_eeprom(struct xl_softc *, caddr_t, int, int, int);
void xl_mii_sync(struct xl_softc *);
void xl_mii_send(struct xl_softc *, u_int32_t, int);
int xl_mii_readreg(struct xl_softc *, struct xl_mii_frame *);
int xl_mii_writereg(struct xl_softc *, struct xl_mii_frame *);
d179 12
a190 12
void xl_setcfg(struct xl_softc *);
void xl_setmode(struct xl_softc *, int);
u_int8_t xl_calchash(caddr_t);
void xl_setmulti(struct xl_softc *);
void xl_setmulti_hash(struct xl_softc *);
void xl_reset(struct xl_softc *, int);
int xl_list_rx_init(struct xl_softc *);
int xl_list_tx_init(struct xl_softc *);
int xl_list_tx_init_90xB(struct xl_softc *);
void xl_wait(struct xl_softc *);
void xl_mediacheck(struct xl_softc *);
void xl_choose_xcvr(struct xl_softc *, int);
d192 1
a192 1
void xl_testpacket(struct xl_softc *);
d195 3
a197 3
int xl_miibus_readreg(struct device *, int, int);
void xl_miibus_writereg(struct device *, int, int, int);
void xl_miibus_statchg(struct device *);
d199 1
a199 1
void xl_power(int, void *);
@


1.23.4.7
log
@Sync the SMP branch with 3.3
@
text
@d103 3
d145 2
d214 1
a214 1
		ifp = &sc->sc_arpcom.ac_if;
a558 1
#define EEPROM_8BIT_OFFSET(A) ((A) & 0x003F)
d573 1
a573 2
			CSR_WRITE_2(sc, XL_W0_EE_CMD,
			    XL_EE_8BIT_READ | EEPROM_8BIT_OFFSET(off + i));
d638 3
a640 1
	struct arpcom *ac = &sc->sc_arpcom;
d642 1
d644 1
a644 1
	ifp = &sc->sc_arpcom.ac_if;
d655 7
a661 1
	if (ac->ac_multicnt > 0)
d679 1
a679 1
	struct arpcom *ac = &sc->sc_arpcom;
d685 1
a685 1
	ifp = &sc->sc_arpcom.ac_if;
d734 1
a734 1
	ifp = &sc->sc_arpcom.ac_if;
d741 1
a741 1
	bcopy(&sc->sc_arpcom.ac_enaddr,
d743 1
a743 1
	bcopy(&sc->sc_arpcom.ac_enaddr,
d772 1
a772 1
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_COAX_STOP);
a778 1
	struct ifnet *ifp = &sc->sc_arpcom.ac_if;
d782 2
d791 1
a791 1
			ifp->if_baudrate = IF_Mbps(10);
d803 1
a803 1
			ifp->if_baudrate = IF_Mbps(100);
d814 1
a814 1
			ifp->if_baudrate = IF_Mbps(10);
d823 1
a823 1
			ifp->if_baudrate = IF_Mbps(10);
d835 1
a835 1
			ifp->if_baudrate = IF_Mbps(10);
d847 1
d851 1
d1080 1
a1080 1
 * Initialize the transmit descriptors.
d1094 1
a1094 3
		cd->xl_tx_chain[i].xl_phys =
		    sc->sc_listmap->dm_segs[0].ds_addr +   
		    offsetof(struct xl_list_data, xl_tx_list[i]);
d1108 1
a1108 1
	ld->xl_tx_list[0].xl_status = htole32(XL_TXSTAT_EMPTY);
a1127 1
	bus_addr_t		next;
a1136 1
		next = sc->sc_listmap->dm_segs[0].ds_addr;
d1139 2
a1140 2
			next +=
			    offsetof(struct xl_list_data, xl_rx_list[0]);
d1143 2
a1144 2
			next +=
			    offsetof(struct xl_list_data, xl_rx_list[i + 1]);
a1145 1
		ld->xl_rx_list[i].xl_next = htole32(next);
a1160 1
	bus_dmamap_t		map;
a1172 17
	if (bus_dmamap_load(sc->sc_dmat, sc->sc_rx_sparemap,
	    mtod(m_new, caddr_t), MCLBYTES, NULL, BUS_DMA_NOWAIT) != 0) {
		printf("%s: rx load failed\n", sc->sc_dev.dv_xname);
		m_freem(m_new);
		return (ENOBUFS);
	}

	/* sync the old map, and unload it (if necessary) */
	if (c->map->dm_nsegs != 0) {
		bus_dmamap_sync(sc->sc_dmat, c->map,
		    0, c->map->dm_mapsize, BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->sc_dmat, c->map);
	}

	map = c->map;
	c->map = sc->sc_rx_sparemap;
	sc->sc_rx_sparemap = map;
a1176 3
	bus_dmamap_sync(sc->sc_dmat, c->map, 0, c->map->dm_mapsize,
	    BUS_DMASYNC_PREREAD);

d1178 3
a1180 9
	c->xl_ptr->xl_frag.xl_addr =
	    htole32(c->map->dm_segs[0].ds_addr + ETHER_ALIGN);
	c->xl_ptr->xl_frag.xl_len =
	    htole32(c->map->dm_segs[0].ds_len | XL_LAST_FRAG);
	c->xl_ptr->xl_status = htole32(0);

	bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,
	    ((caddr_t)c->xl_ptr - sc->sc_listkva), sizeof(struct xl_list),
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
a1193 5
		bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,
		    ((caddr_t)pos->xl_ptr - sc->sc_listkva),
		    sizeof(struct xl_list),
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

d1217 2
a1218 2
	int			total_len = 0, sumflags = 0;
	u_int32_t		rxstat;
d1220 1
a1220 1
	ifp = &sc->sc_arpcom.ac_if;
d1224 1
a1224 2
	while ((rxstat = letoh32(sc->xl_cdata.xl_rx_head->xl_ptr->xl_status))
	    != 0) {
a1227 5
		bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,
		    ((caddr_t)cur_rx->xl_ptr - sc->sc_listkva),
		    sizeof(struct xl_list),
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

d1236 1
a1236 1
			cur_rx->xl_ptr->xl_status = htole32(0);
d1249 1
a1249 1
			cur_rx->xl_ptr->xl_status = htole32(0);
d1255 1
a1255 2
		total_len = letoh32(cur_rx->xl_ptr->xl_status) &
		    XL_RXSTAT_LENMASK;
d1266 1
a1266 1
			cur_rx->xl_ptr->xl_status = htole32(0);
a1280 19

		if (sc->xl_type == XL_TYPE_905B) {
			if (rxstat & XL_RXSTAT_IPCKERR)
				sumflags |= M_IPV4_CSUM_IN_BAD;
			else if (rxstat & XL_RXSTAT_IPCKOK)
				sumflags |= M_IPV4_CSUM_IN_OK;

			if (rxstat & XL_RXSTAT_TCPCKERR)
				sumflags |= M_TCP_CSUM_IN_BAD;
			else if (rxstat & XL_RXSTAT_TCPCKOK)
				sumflags |= M_TCP_CSUM_IN_OK;

			if (rxstat & XL_RXSTAT_UDPCKERR)
				sumflags |= M_UDP_CSUM_IN_BAD;
			else if (rxstat & XL_RXSTAT_UDPCKOK)
				sumflags |= M_UDP_CSUM_IN_OK;

			m->m_pkthdr.csum = sumflags;
		}
d1301 1
a1301 2
		    sc->sc_listmap->dm_segs[0].ds_addr +
		    offsetof(struct xl_list_data, xl_rx_list[0]));
d1320 1
a1320 1
	ifp = &sc->sc_arpcom.ac_if;
a1336 5
		bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,
		    ((caddr_t)cur_tx->xl_ptr - sc->sc_listkva),
		    sizeof(struct xl_list),
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

d1341 2
a1343 2
		if (cur_tx->map->dm_nsegs != 0) {
			bus_dmamap_t map = cur_tx->map;
a1344 8
			bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
			    BUS_DMASYNC_POSTWRITE);
			bus_dmamap_unload(sc->sc_dmat, map);
		}
		if (cur_tx->xl_mbuf != NULL) {
			m_freem(cur_tx->xl_mbuf);
			cur_tx->xl_mbuf = NULL;
		}
d1356 1
a1356 3
			    sc->sc_listmap->dm_segs[0].ds_addr +
			    ((caddr_t)sc->xl_cdata.xl_tx_head->xl_ptr -
			    sc->sc_listkva));
d1372 1
a1372 1
	ifp = &sc->sc_arpcom.ac_if;
d1379 1
a1379 2
		if ((cur_tx->xl_ptr->xl_status &
		    htole32(XL_TXSTAT_DL_COMPLETE)) == 0)
a1386 6
		if (cur_tx->map->dm_nsegs != 0) {
			bus_dmamap_sync(sc->sc_dmat, cur_tx->map,
			    0, cur_tx->map->dm_mapsize, BUS_DMASYNC_POSTWRITE);
			bus_dmamap_unload(sc->sc_dmat, cur_tx->map);
		}

d1430 1
a1430 3
					    sc->sc_listmap->dm_segs[0].ds_addr +
					    ((caddr_t)sc->xl_cdata.xl_tx_head->xl_ptr -
					    sc->sc_listkva));
d1477 1
a1477 1
	ifp = &sc->sc_arpcom.ac_if;
d1543 1
a1543 1
	ifp = &sc->sc_arpcom.ac_if;
d1590 4
a1593 9
	int			frag, total_len;
	bus_dmamap_t		map;

	map = sc->sc_tx_sparemap;

reload:
	if (bus_dmamap_load_mbuf(sc->sc_dmat, map,
	    m_head, BUS_DMA_NOWAIT) != 0)
		return (ENOBUFS);
d1600 13
a1612 10
	for (frag = 0, total_len = 0; frag < map->dm_nsegs; frag++) {
		if ((XL_TX_LIST_CNT - (sc->xl_cdata.xl_tx_cnt + frag)) < 3)
			return (ENOBUFS);
		if (frag == XL_MAXFRAGS)
			break;
		total_len += map->dm_segs[frag].ds_len;
		c->xl_ptr->xl_frag[frag].xl_addr =
		    htole32(map->dm_segs[frag].ds_addr);
		c->xl_ptr->xl_frag[frag].xl_len =
		    htole32(map->dm_segs[frag].ds_len);
d1623 1
a1623 1
	if (frag != map->dm_nsegs) {
d1637 1
a1637 1
		    mtod(m_new, caddr_t));
d1641 4
a1644 10
		goto reload;
	}

	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREWRITE);

	if (c->map->dm_nsegs != 0) {
		bus_dmamap_sync(sc->sc_dmat, c->map,
		    0, c->map->dm_mapsize, BUS_DMASYNC_POSTWRITE);
		bus_dmamap_unload(sc->sc_dmat, c->map);
d1648 2
a1649 4
	sc->sc_tx_sparemap = c->map;
	c->map = map;
	c->xl_ptr->xl_frag[frag - 1].xl_len |= htole32(XL_LAST_FRAG);
	c->xl_ptr->xl_status = htole32(total_len);
a1651 5
	bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,
	    offsetof(struct xl_list_data, xl_tx_list[0]),
	    sizeof(struct xl_list) * XL_TX_LIST_CNT,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

d1702 1
a1702 4
			prev->xl_ptr->xl_next =
			    sc->sc_listmap->dm_segs[0].ds_addr +
			    ((caddr_t)cur_tx->xl_ptr - sc->sc_listkva);

d1729 1
a1729 1
	cur_tx->xl_ptr->xl_status |= htole32(XL_TXSTAT_DL_INTR);
d1741 1
a1741 2
		    sc->sc_listmap->dm_segs[0].ds_addr +
		    ((caddr_t)start_tx->xl_ptr - sc->sc_listkva);
d1743 1
a1743 1
		    htole32(~XL_TXSTAT_DL_INTR);
d1750 1
a1750 3
		CSR_WRITE_4(sc, XL_DOWNLIST_PTR,
		    sc->sc_listmap->dm_segs[0].ds_addr +
		    ((caddr_t)start_tx->xl_ptr - sc->sc_listkva));
d1786 1
d1788 1
a1789 2
	int frag;
	bus_dmamap_t map;
a1795 1
	map = sc->sc_tx_sparemap;
d1797 1
a1797 1
	d->xl_status = htole32(0);
d1800 9
a1808 20
	if (bus_dmamap_load_mbuf(sc->sc_dmat, map,
	    m_head, BUS_DMA_NOWAIT) != 0)
		return (ENOBUFS);

	for (frag = 0; frag < map->dm_nsegs; frag++) {
		if (frag == XL_MAXFRAGS)
			break;
		f = &d->xl_frag[frag];
		f->xl_addr = htole32(map->dm_segs[frag].ds_addr);
		f->xl_len = htole32(map->dm_segs[frag].ds_len);
	}

	bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
	    BUS_DMASYNC_PREWRITE);

	/* sync the old map, and unload it (if necessary) */
	if (c->map->dm_nsegs != 0) {
		bus_dmamap_sync(sc->sc_dmat, c->map, 0, c->map->dm_mapsize,
		    BUS_DMASYNC_POSTWRITE);
		bus_dmamap_unload(sc->sc_dmat, c->map);
d1812 2
a1813 16
	sc->sc_tx_sparemap = c->map;
	c->map = map;
	c->xl_ptr->xl_frag[frag - 1].xl_len |= htole32(XL_LAST_FRAG);
	c->xl_ptr->xl_status = htole32(XL_TXSTAT_RND_DEFEAT);

	if (m_head->m_pkthdr.csum & M_IPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_IPCKSUM);
	if (m_head->m_pkthdr.csum & M_TCPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_TCPCKSUM);
	if (m_head->m_pkthdr.csum & M_UDPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_UDPCKSUM);

	bus_dmamap_sync(sc->sc_dmat, sc->sc_listmap,
	    offsetof(struct xl_list_data, xl_tx_list[0]),
	    sizeof(struct xl_list) * XL_TX_LIST_CNT,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
d1853 1
a1853 1
			prev->xl_ptr->xl_next = htole32(cur_tx->xl_phys);
d1882 1
a1882 1
	cur_tx->xl_ptr->xl_status |= htole32(XL_TXSTAT_DL_INTR);
d1886 1
a1886 1
	start_tx->xl_prev->xl_ptr->xl_next = htole32(start_tx->xl_phys);
d1898 1
a1898 1
	struct ifnet		*ifp = &sc->sc_arpcom.ac_if;
d1926 1
a1926 1
				sc->sc_arpcom.ac_enaddr[i]);
d2031 1
a2031 2
	CSR_WRITE_4(sc, XL_UPLIST_PTR, sc->sc_listmap->dm_segs[0].ds_addr +
	    offsetof(struct xl_list_data, xl_rx_list[0]));
d2042 1
a2042 2
		    sc->sc_listmap->dm_segs[0].ds_addr +
		    offsetof(struct xl_list_data, xl_tx_list[0]));
d2232 1
a2232 1
	if ((error = ether_ioctl(ifp, &sc->sc_arpcom, command, data)) > 0) {
d2244 1
a2244 1
			arp_ifinit(&sc->sc_arpcom, ifa);
d2291 2
a2292 2
		    ether_addmulti(ifr, &sc->sc_arpcom) :
		    ether_delmulti(ifr, &sc->sc_arpcom);
a2368 7
		if (sc->xl_cdata.xl_rx_chain[i].map->dm_nsegs != 0) {
			bus_dmamap_t map = sc->xl_cdata.xl_rx_chain[i].map;

			bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
			    BUS_DMASYNC_POSTREAD);
			bus_dmamap_unload(sc->sc_dmat, map);
		}
a2379 7
		if (sc->xl_cdata.xl_tx_chain[i].map->dm_nsegs != 0) {
			bus_dmamap_t map = sc->xl_cdata.xl_tx_chain[i].map;

			bus_dmamap_sync(sc->sc_dmat, map, 0, map->dm_mapsize,
			    BUS_DMASYNC_POSTWRITE);
			bus_dmamap_unload(sc->sc_dmat, map);
		}
d2398 1
a2398 1
	ifp = &sc->sc_arpcom.ac_if;
d2439 3
a2441 1
	struct ifnet *ifp = &sc->sc_arpcom.ac_if;
a2445 1
	i = splimp();
a2446 1
	splx(i);
d2456 1
a2456 55
	bcopy(enaddr, (char *)&sc->sc_arpcom.ac_enaddr, ETHER_ADDR_LEN);

	if (bus_dmamem_alloc(sc->sc_dmat, sizeof(struct xl_list_data),
	    PAGE_SIZE, 0, sc->sc_listseg, 1, &sc->sc_listnseg,
	    BUS_DMA_NOWAIT) != 0) {
		printf(": can't alloc list mem\n");
		return;
	}
	if (bus_dmamem_map(sc->sc_dmat, sc->sc_listseg, sc->sc_listnseg,
	    sizeof(struct xl_list_data), &sc->sc_listkva,
	    BUS_DMA_NOWAIT) != 0) {
		printf(": can't map list mem\n");
		return;
	}
	if (bus_dmamap_create(sc->sc_dmat, sizeof(struct xl_list_data), 1,
	    sizeof(struct xl_list_data), 0, BUS_DMA_NOWAIT,
	    &sc->sc_listmap) != 0) {
		printf(": can't alloc list map\n");
		return;
	}
	if (bus_dmamap_load(sc->sc_dmat, sc->sc_listmap, sc->sc_listkva,
	    sizeof(struct xl_list_data), NULL, BUS_DMA_NOWAIT) != 0) {
		printf(": can't load list map\n");
		return;
	}
	sc->xl_ldata = (struct xl_list_data *)sc->sc_listkva;
	bzero(sc->xl_ldata, sizeof(struct xl_list_data));

	for (i = 0; i < XL_RX_LIST_CNT; i++) {
		if (bus_dmamap_create(sc->sc_dmat, MCLBYTES, 1, MCLBYTES,
		    0, BUS_DMA_NOWAIT,
		    &sc->xl_cdata.xl_rx_chain[i].map) != 0) {
			printf(": can't create rx map\n");
			return;
		}
	}
	if (bus_dmamap_create(sc->sc_dmat, MCLBYTES, 1, MCLBYTES, 0,
	    BUS_DMA_NOWAIT, &sc->sc_rx_sparemap) != 0) {
		printf(": can't create rx spare map\n");
		return;
	}

	for (i = 0; i < XL_TX_LIST_CNT; i++) {
		if (bus_dmamap_create(sc->sc_dmat, MCLBYTES,
		    XL_TX_LIST_CNT - 3, MCLBYTES, 0, BUS_DMA_NOWAIT,
		    &sc->xl_cdata.xl_tx_chain[i].map) != 0) {
			printf(": can't create tx map\n");
			return;
		}
	}
	if (bus_dmamap_create(sc->sc_dmat, MCLBYTES, XL_TX_LIST_CNT - 3,
	    MCLBYTES, 0, BUS_DMA_NOWAIT, &sc->sc_tx_sparemap) != 0) {
		printf(": can't create tx spare map\n");
		return;
	}
d2458 1
a2458 1
	printf(" address %s\n", ether_sprintf(sc->sc_arpcom.ac_enaddr));
d2475 24
d2517 1
a2517 1
	if (sc->xl_type == XL_TYPE_905B) {
d2519 1
a2519 3
		ifp->if_capabilities = IFCAP_CSUM_IPv4|IFCAP_CSUM_TCPv4|
		    IFCAP_CSUM_UDPv4;
	} else
d2529 1
a2529 1
		ifp->if_capabilities |= IFCAP_VLAN_MTU;
d2550 1
a2550 2
		CSR_WRITE_2(sc, XL_W2_RESET_OPTIONS, XL_RESETOPT_INVMIIPWR |
		    CSR_READ_2(sc, XL_W2_RESET_OPTIONS));
a2590 1
		i = splimp();
a2591 1
		splx(i);
d2684 1
a2684 1
	struct ifnet *ifp = &sc->sc_arpcom.ac_if;
@


1.23.4.8
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d238 1
a238 1
		printf("%s: command never completed!\n", sc->sc_dev.dv_xname);
d533 1
a533 1
		printf("%s: eeprom failed to come ready\n", sc->sc_dev.dv_xname);
d922 4
a925 4
			printf("%s: bogus xcvr value "
			"in EEPROM (%x)\n", sc->sc_dev.dv_xname, sc->xl_xcvr);
			printf("%s: choosing new default based "
				"on card type\n", sc->sc_dev.dv_xname);
d931 6
a936 6
		printf("%s: WARNING: no media options bits set in "
			"the media options register!!\n", sc->sc_dev.dv_xname);
		printf("%s: this could be a manufacturing defect in "
			"your adapter or system\n", sc->sc_dev.dv_xname);
		printf("%s: attempting to guess media type; you "
			"should probably consult your vendor\n", sc->sc_dev.dv_xname);
d961 2
a962 2
			printf("%s: guessing 10BaseT transceiver\n",
			    sc->sc_dev.dv_xname);
d969 2
a970 2
			printf("%s: guessing COMBO (AUI/BNC/TP)\n",
			    sc->sc_dev.dv_xname);
d976 1
a976 1
			printf("%s: guessing TPC (BNC/TP)\n", sc->sc_dev.dv_xname);
d982 1
a982 1
			printf("%s: guessing 10baseFL\n", sc->sc_dev.dv_xname);
d991 1
a991 1
			printf("%s: guessing MII\n", sc->sc_dev.dv_xname);
d998 1
a998 1
			printf("%s: guessing 100BaseT4/MII\n", sc->sc_dev.dv_xname);
d1009 2
a1010 2
			printf("%s: guessing 10/100 internal\n",
			    sc->sc_dev.dv_xname);
d1016 2
a1017 2
			printf("%s: guessing 10/100 plus BNC/AUI\n",
			    sc->sc_dev.dv_xname);
d1029 2
a1030 2
		printf("%s: unknown device ID: %x -- "
			"defaulting to 10baseT\n", sc->sc_dev.dv_xname, devid);
d1274 2
a1275 2
			printf("%s: bad receive status -- "
			    "packet dropped", sc->sc_dev.dv_xname);
d1486 2
a1487 2
				printf("%s: transmission error: %x\n",
				    sc->sc_dev.dv_xname, txstat);
d1514 2
a1515 2
				printf("%s: tx underrun, increasing tx start"
				    " threshold to %d\n", sc->sc_dev.dv_xname,
d1817 1
a1817 1
	 * get an interrupt once for the whole chain rather than
d1999 1
a1999 1
	 * get an interrupt once for the whole chain rather than
d2061 2
a2062 2
		printf("%s: initialization failed: no "
			"memory for rx buffers\n", sc->sc_dev.dv_xname);
d2332 1
a2332 1
		printf("%s: unknown XCVR type: %d\n", sc->sc_dev.dv_xname, icfg);
d2464 1
a2464 1
	printf("%s: watchdog timeout\n", sc->sc_dev.dv_xname);
d2467 2
a2468 2
		printf("%s: no carrier - transceiver cable problem?\n",
								sc->sc_dev.dv_xname);
d2579 1
d2828 1
a2828 1
		printf("%s: unknown XCVR type: %d\n", sc->sc_dev.dv_xname,
@


1.23.4.9
log
@Merge with the trunk
@
text
@d54 1
a54 1
 * 3Com 3c905B-FL/FX	10/100Mbps/Fiber-optic
d56 4
d62 8
a70 10
 * 3Com 3c450-TX	10/100Mbps/RJ-45 (Tornado ASIC)
 * 3Com 3c555		10/100Mbps/RJ-45 (MiniPCI, Laptop Hurricane)
 * 3Com 3c556		10/100Mbps/RJ-45 (MiniPCI, Hurricane ASIC)
 * 3Com 3c556B		10/100Mbps/RJ-45 (MiniPCI, Hurricane ASIC)
 * 3Com 3c575TX		10/100Mbps/RJ-45 (Cardbus, Hurricane ASIC)
 * 3Com 3c575B		10/100Mbps/RJ-45 (Cardbus, Hurricane ASIC)
 * 3Com 3c575C		10/100Mbps/RJ-45 (Cardbus, Hurricane ASIC)
 * 3Com 3cxfem656	10/100Mbps/RJ-45 (Cardbus, Hurricane ASIC)
 * 3Com 3cxfem656b	10/100Mbps/RJ-45 (Cardbus, Hurricane ASIC)
 * 3Com 3cxfem656c	10/100Mbps/RJ-45 (Cardbus, Tornado ASIC)
d72 1
a72 1
 * Dell on-board 3c920 10/100Mbps/RJ-45
d87 1
a87 1
 * chain into an mbuf cluster and then DMAing the cluster. This extra
a143 10
/* 
 * TX Checksumming is disabled by default for two reasons:
 * - TX Checksumming will occasionally produce corrupt packets
 * - TX Checksumming seems to reduce performance
 *
 * Only 905B/C cards were reported to have this problem, it is possible
 * that later chips _may_ be immune.
 */
#define	XL905B_TXCSUM_BROKEN	1

d148 2
d176 1
d179 1
a179 1
void xl_reset(struct xl_softc *);
d211 1
a211 1
			xl_reset(sc);
d226 1
a226 2
void
xl_wait(sc)
d236 1
d239 1
d255 1
a255 1
		CSR_READ_2(sc, XL_W4_PHY_MGMT) | (x))
d259 1
a259 1
		CSR_READ_2(sc, XL_W4_PHY_MGMT) & ~(x))
d264 1
a264 2
void
xl_mii_sync(sc)
d274 1
a274 2
		MII_SET(XL_MII_DATA);
		MII_SET(XL_MII_DATA);
d276 1
a276 2
		MII_SET(XL_MII_DATA);
		MII_SET(XL_MII_DATA);
d285 1
a285 2
void
xl_mii_send(sc, bits, cnt)
d301 1
d303 1
d311 1
a311 2
int
xl_mii_readreg(sc, frame)
d352 1
d354 1
d361 3
a364 1
	MII_SET(XL_MII_CLK);
d373 1
d375 1
d382 1
d386 1
d389 1
d395 1
d397 1
d409 1
a409 2
int
xl_mii_writereg(sc, frame)
d446 1
d448 1
a497 2

	return;
a507 1
	/* Set ASIC's duplex mode to match the PHY. */
d520 1
a520 2
int
xl_eeprom_wait(sc)
d544 1
a544 2
int
xl_read_eeprom(sc, dest, off, cnt, swap)
d589 39
d631 1
a631 2
void
xl_setmulti(sc)
d662 1
a662 2
void
xl_setmulti_hash(sc)
d698 1
a698 2
		h = ether_crc32_be(enm->enm_addrlo, ETHER_ADDR_LEN) &
		    0x000000FF;
d715 1
a715 2
void
xl_testpacket(sc)
d745 1
a745 2
void
xl_setcfg(sc)
d754 1
a754 1
		sc->xl_media & XL_MEDIAOPT_BT4)
a760 2

	return;
d763 1
a763 2
void
xl_setmode(sc, media)
a850 2

	return;
d853 1
a853 2
void
xl_reset(sc)
d855 1
d860 7
a866 13
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RESET |
		    ((sc->xl_flags & XL_FLAG_WEIRDRESET) ?
		     XL_RESETOPT_DISADVFD:0));

	/*
	 * If we're using memory mapped register mode, pause briefly
	 * after issuing the reset command before trying to access any
	 * other registers. With my 3c575C cardbus card, failing to do
	 * this results in the system locking up while trying to poll
	 * the command busy bit in the status register.
	 */
	if (sc->xl_flags & XL_FLAG_USE_MMIO)
		DELAY(100000);
d874 1
a874 2
	if (i == XL_TIMEOUT)
		printf("%s: reset didn't complete\n", sc->sc_dev.dv_xname);
d876 1
a876 6
	/* Note: the RX reset takes an absurd amount of time
	 * on newer versions of the Tornado chips such as those
	 * on the 3c905CX and newer 3c908C cards. We wait an
	 * extra amount of time so that xl_wait() doesn't complain
	 * and annoy the users.
	 */
a877 1
	DELAY(100000);
d882 1
a882 2
	if (sc->xl_flags & XL_FLAG_INVERT_LED_PWR || 
	    sc->xl_flags & XL_FLAG_INVERT_MII_PWR) {
d885 1
a885 4
		    XL_W2_RESET_OPTIONS) 
		    | ((sc->xl_flags & XL_FLAG_INVERT_LED_PWR)?XL_RESETOPT_INVERT_LED:0)
		    | ((sc->xl_flags & XL_FLAG_INVERT_MII_PWR)?XL_RESETOPT_INVERT_MII:0)
		    );
d905 1
a905 2
void
xl_mediacheck(sc)
d942 1
a942 2
void
xl_choose_xcvr(sc, verbose)
a987 7
	case TC_DEVICEID_HURRICANE_575A:	/* 3c575TX */
	case TC_DEVICEID_HURRICANE_575B:	/* 3c575B */
	case TC_DEVICEID_HURRICANE_575C:	/* 3c575C */
	case TC_DEVICEID_HURRICANE_656:		/* 3c656 */
	case TC_DEVICEID_HURRICANE_656B:	/* 3c656B */
	case TC_DEVICEID_TORNADO_656C:		/* 3c656C */
	case TC_DEVICEID_TORNADO_10_100BT_920B: /* 3c920B-EMB */
d1019 9
d1041 1
a1041 2
int
xl_list_tx_init(sc)
d1109 1
a1109 2
int
xl_list_rx_init(sc)
d1146 1
a1146 2
int
xl_newbuf(sc, c)
d1202 1
a1202 2
int
xl_rx_resync(sc)
d1222 1
a1222 1
		return(0);
d1226 1
a1226 1
	return(EAGAIN);
d1233 1
a1233 2
void
xl_rxeof(sc)
a1249 1
		total_len = rxstat & XL_RXSTAT_LENMASK;
a1256 9
		 * Since we have told the chip to allow large frames,
		 * we need to trap giant frame errors in software. We allow
		 * a little more than the normal frame size to account for
		 * frames with VLAN tags.
		 */
		if (total_len > XL_MAX_FRAMELEN)
			rxstat |= (XL_RXSTAT_UP_ERROR|XL_RXSTAT_OVERSIZE);

		/*
d1269 1
a1269 1
		 * If the error bit was not set, the upload complete
d1275 1
a1275 1
			    "packet dropped\n", sc->sc_dev.dv_xname);
d1283 2
d1363 1
a1363 2
void
xl_txeof(sc)
a1468 2

	return;
d1476 1
a1476 2
void
xl_txeoc(sc)
d1541 1
a1541 2
int
xl_intr(arg)
d1552 1
a1552 1
	while ((status = CSR_READ_2(sc, XL_STATUS)) & XL_INTRS && status != 0xFFFF) {
d1586 1
a1586 1
			xl_reset(sc);
d1603 1
a1603 2
void
xl_stats_update(xsc)
d1643 1
a1643 1
	if (mii != NULL && (!sc->xl_stats_no_timeout))
d1658 1
a1658 2
int
xl_encap(sc, c, m_head)
a1702 1
			m_freem(m_head);
a1707 1
				m_freem(m_head);
a1734 9
#ifndef XL905B_TXCSUM_BROKEN
	if (m_head->m_pkthdr.csum & M_IPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_IPCKSUM);
	if (m_head->m_pkthdr.csum & M_TCPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_TCPCKSUM);
	if (m_head->m_pkthdr.csum & M_UDPV4_CSUM_OUT)
		c->xl_ptr->xl_status |= htole32(XL_TXSTAT_UDPCKSUM);
#endif

d1749 1
a1749 2
void
xl_start(ifp)
a1754 2
	struct xl_chain		*prev_tx;
	int			error;
a1778 1
		prev_tx = cur_tx;
d1780 3
d1785 1
a1785 8
		error = xl_encap(sc, cur_tx, m_head);
		if (error) {
			cur_tx = prev_tx;
			continue;
		}

		sc->xl_cdata.xl_tx_free = cur_tx->xl_next;
		cur_tx->xl_next = NULL;
d1875 63
d1945 1
a1945 2
	struct xl_chain		*prev_tx;
	int error, idx;
a1965 1
		prev_tx = cur_tx;
d1969 1
a1969 5
		error = xl_encap(sc, cur_tx, m_head);
		if (error) {
			cur_tx = prev_tx;
			continue;
		}
d2014 1
a2014 2
void
xl_init(xsc)
d2041 1
d2130 1
d2132 3
d2180 1
a2180 7
	/*
	 * increase packet size to allow reception of 802.1q or ISL packets.
	 * For the 3c90x chip, set the 'allow large packets' bit in the MAC
	 * control register. For 3c90xB/C chips, use the RX packet size
	 * register.
	 */

d2182 1
a2182 7
		CSR_WRITE_2(sc, XL_W3_MAXPKTSIZE, XL_PACKET_SIZE);
	else {
		u_int8_t macctl;
		macctl = CSR_READ_1(sc, XL_W3_MAC_CTRL);
		macctl |= XL_MACCTRL_ALLOW_LARGE_PACK;
		CSR_WRITE_1(sc, XL_W3_MAC_CTRL, macctl);
	}
d2234 1
a2234 2
int
xl_ifmedia_upd(ifp)
d2256 1
a2256 1
		return(0);
d2275 1
a2275 2
void
xl_ifmedia_sts(ifp, ifmr)
a2280 1
	u_int16_t		status = 0;
a2286 3
	XL_SEL_WIN(4);
	status = CSR_READ_2(sc, XL_W4_MEDIA_STATUS);

a2291 4
	ifmr->ifm_status = IFM_AVALID;

	if ((status & XL_MEDIASTAT_CARRIER) == 0)
		ifmr->ifm_status |= IFM_ACTIVE;
d2421 1
d2423 3
d2453 1
a2453 2
void
xl_watchdog(ifp)
d2472 1
a2472 1
	xl_reset(sc);
d2529 1
a2529 2
void
xl_stop(sc)
a2574 1
	u_int16_t		xcvr[2];
d2580 1
a2580 1
	xl_reset(sc);
d2647 1
a2647 1
	printf(", address %s\n", ether_sprintf(sc->sc_arpcom.ac_enaddr));
a2667 5
	 * Note: my 3c575C cardbus card lies. It returns a value
	 * of 0x1578 for its capabilities word, which is somewhat
	 * nonsensical. Another way to distinguish a 3c90x chip
	 * from a 3c90xB/C chip is to check for the 'supportsLargePackets'
	 * bit. This will only be set for 3c90x boomerage chips.
d2670 1
a2670 2
	if (sc->xl_caps & XL_CAPS_NO_TXLENGTH ||
	    !(sc->xl_caps & XL_CAPS_LARGE_PKTS))
a2681 3
#if NVLAN > 0
	ifp->if_capabilities |= IFCAP_VLAN_MTU;
#endif
d2684 1
a2684 2
#ifndef XL905B_TXCSUM_BROKEN
		ifp->if_capabilities |= IFCAP_CSUM_IPv4|IFCAP_CSUM_TCPv4|
a2685 1
#endif
d2694 10
d2707 1
a2707 2
	xl_read_eeprom(sc, (char *)&xcvr, XL_EE_ICFG_0, 2, 0);
	sc->xl_xcvr = xcvr[0] | xcvr[1] << 16;
d2711 2
d2715 8
d2760 1
a2760 1
		xl_reset(sc);
a2839 5
	if (sc->xl_flags & XL_FLAG_NO_XCVR_PWR) {
		XL_SEL_WIN(0);
		CSR_WRITE_2(sc, XL_W0_MFG_ID, XL_NO_XCVR_PWR_MAGICBITS);
	}

d2883 1
a2883 1
	xl_reset(sc);
@


1.22
log
@Missing splx(). Thanks to Dawson and team for finding this
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.21 2001/02/20 19:39:38 mickey Exp $	*/
d1397 4
a1400 2
			printf("xl%d: transmission error: %x\n",
						sc->xl_unit, txstat);
@


1.21
log
@for ethernet ifaces attach bpf from ether_ifattach; jason@@, aaron@@, itojun@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.20 2001/02/02 08:35:31 aaron Exp $	*/
d1925 1
@


1.20
log
@No need for xl(4) to report tx underruns, they are much too common, and the
driver adjusts itself to compensate anyway; jason@@ ok.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.19 2001/01/12 21:48:25 todd Exp $	*/
a2636 4
#if NBPFILTER > 0
	bpfattach(&sc->arpcom.ac_if.if_bpf, ifp,
	    DLT_EN10MB, sizeof(struct ether_header));
#endif
@


1.19
log
@add SIOCSIFMTU; angelos@@ coached
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.18 2000/11/09 17:39:06 mickey Exp $	*/
d1421 1
d1425 1
@


1.18
log
@new timeouts
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.17 2000/10/19 16:33:51 jason Exp $	*/
d2226 9
@


1.17
log
@if vlans are in use, then set the 3c905b to accept frames of size 1518.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.16 2000/10/16 17:08:07 aaron Exp $	*/
d1555 1
a1555 1
		timeout(xl_stats_update, sc, hz);
d2078 1
a2078 1
	timeout(xl_stats_update, sc, hz);
d2386 1
a2386 1
	untimeout(xl_stats_update, sc);
d2471 2
d2640 1
a2640 1
	untimeout(xl_stats_update, sc);
@


1.16
log
@Use mii_attach() directly instead of mii_phy_probe().
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.15 2000/10/15 18:46:02 aaron Exp $	*/
d109 1
d2030 6
@


1.15
log
@Do not pass uninitialized ifmedia structures to ifmedia_add(). Fixes PR1426.
Thanks to reinhard@@ for testing.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.14 2000/10/14 18:10:37 aaron Exp $	*/
d2506 2
a2507 1
		mii_phy_probe((struct device *)sc, &sc->sc_mii, 0xffffffff);
@


1.14
log
@There's a Type III 3c656C card, too.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.13 2000/10/13 15:02:02 aaron Exp $	*/
d2538 1
a2538 2
			ifmedia_add(&sc->ifmedia,
			    IFM_ETHER|IFM_10_T|IFM_FDX, 0, NULL);
@


1.13
log
@Do reset properly on MiniPCI adapters.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.12 2000/10/07 16:15:11 aaron Exp $	*/
d69 1
@


1.12
log
@Correct interrupt ack'ing for CardBus and MiniPCI. I hope this fixes 3c556.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.11 2000/09/30 14:07:10 aaron Exp $	*/
d850 1
a850 1
	if (hard)
d853 1
@


1.11
log
@Whoops, forgot to list the 3c555 device ID under media selection parts.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.10 2000/09/29 05:28:28 aaron Exp $	*/
d2041 2
a2046 3
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_STAT_ENB|XL_INTRS);
	CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_INTR_ENB|XL_INTRS);

d2373 2
a2374 5
#if 0
	if (sc->xl_bustype == XL_BUS_CARDBUS)
		bus_space_write_4(sc->xl_funct, sc->xl_funch, XL_CARDBUS_INTR,
		    XL_CARDBUS_INTR_ACK);
#endif
@


1.10
log
@- Add support for 3Com 3C555 MiniPCI.
- Clean up configuration flags mess. The MiniPCI adapters share some properties
  with the CardBus adapters.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.9 2000/09/16 21:50:56 aaron Exp $	*/
d974 1
@


1.9
log
@- No need to do bpfdetach(), that's done in if_detach().
- No need to keep around NetBSD NRND cruft.
- Indentation fixes.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.8 2000/09/16 21:48:46 aaron Exp $	*/
d57 1
d450 1
a450 2
	if (!(sc->xl_flags & XL_FLAG_PHYOK) &&
	    sc->xl_bustype != XL_BUS_CARDBUS && phy != 24)
d470 1
a470 2
	if (!(sc->xl_flags & XL_FLAG_PHYOK) &&
	    sc->xl_bustype != XL_BUS_CARDBUS && phy != 24)
d1461 2
a1462 3
		if (sc->xl_bustype == XL_BUS_CARDBUS)
			bus_space_write_4(sc->xl_funct,sc->xl_funch,
			    XL_CARDBUS_INTR, XL_CARDBUS_INTR_ACK);
d2041 2
a2042 3
	if (sc->xl_bustype == XL_BUS_CARDBUS)
		bus_space_write_4(sc->xl_funct, sc->xl_funch, XL_CARDBUS_INTR,
		    XL_CARDBUS_INTR_ACK);
a2045 2
	if (sc->xl_flags & XL_FLAG_FUNCREG)
		bus_space_write_4(sc->xl_ftag, sc->xl_fhandle, 4, 0x8000);
a2371 2
	if (sc->xl_flags & XL_FLAG_FUNCREG)
		bus_space_write_4(sc->xl_ftag, sc->xl_fhandle, 4, 0x8000);
d2373 1
d2377 1
d2415 1
a2415 1
	if (sc->xl_bustype == XL_BUS_CARDBUS) {
d2421 1
a2421 1
		if (sc->xl_cb_flags & XL_CARDBUS_INVERT_LED_PWR)
d2424 1
a2424 1
		if (sc->xl_cb_flags & XL_CARDBUS_INVERT_MII_PWR)
d2490 3
a2492 5
	if (sc->xl_bustype == XL_BUS_CARDBUS) {
		if (sc->xl_cb_flags & XL_CARDBUS_INVERT_MII_PWR) {
			XL_SEL_WIN(2);
			CSR_WRITE_2(sc, 12, 0x4000 | CSR_READ_2(sc, 12));
		}
@


1.8
log
@Note support for the new 3Com 3C3FE575CT LAN CardBus Type III PC Card. No
actual code changes here, just a comment added to the list of supported
cards, since the 3C3 has the same product ID as the 3CC (according to
dahinds@@users.sourceforge.net).
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.7 2000/09/16 21:42:16 aaron Exp $	*/
d2645 1
a2645 1
	  mii_detach(&sc->sc_mii, MII_PHY_ANY, MII_OFFSET_ANY);
a2649 6
#if NRND > 0
	rnd_detach_source(&sc->rnd_source);
#endif
#if NBPFILTER > 0
	bpfdetach(ifp);
#endif
@


1.7
log
@Add support for 3C556[B] MiniPCI Ethernet adapters, found on some laptops
(i.e., HP OmniBooks). I have sent these changes to a tester but I haven't
heard back yet. Assume for now the changes are OK since all of the other
variants I have still work.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.6 2000/09/05 18:18:49 aaron Exp $	*/
d64 1
@


1.6
log
@Support detach of xl(4) devices, mainly to allow the ejection and insertion of
3Com575-based CardBus PC Cards; from nate@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.5 2000/07/01 03:19:14 aaron Exp $	*/
d34 1
a34 1
 * $FreeBSD: if_xl.c,v 1.72 2000/01/09 21:12:59 wpaul Exp $
d57 2
d448 2
a449 1
	if (sc->xl_bustype != XL_BUS_CARDBUS && phy != 24)
d469 2
a470 1
	if (sc->xl_bustype != XL_BUS_CARDBUS && phy != 24)
d535 5
a539 1

d545 3
d549 5
a553 8
		switch (sc->xl_bustype) {
		case XL_BUS_PCI:
			CSR_WRITE_2(sc, XL_W0_EE_CMD, XL_EE_READ | (off + i));
			break;
		case XL_BUS_CARDBUS:
			CSR_WRITE_2(sc, XL_W0_EE_CMD, 0x230 + (off + i));
			break;
		}
d851 2
a852 1
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RESET);
d871 6
d974 2
d2048 2
d2376 2
@


1.5
log
@- Make the 3CCFE575BT work.
- Add support for the 3CCFEM656C.
- Lots of code cleanup.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.4 2000/06/29 14:07:03 jason Exp $	*/
d163 1
d2296 30
a2332 1
	int i;
d2365 1
a2365 22
	/*
	 * Free data in the RX lists.
	 */
	for (i = 0; i < XL_RX_LIST_CNT; i++) {
		if (sc->xl_cdata.xl_rx_chain[i].xl_mbuf != NULL) {
			m_freem(sc->xl_cdata.xl_rx_chain[i].xl_mbuf);
			sc->xl_cdata.xl_rx_chain[i].xl_mbuf = NULL;
		}
	}
	bzero((char *)&sc->xl_ldata->xl_rx_list,
		sizeof(sc->xl_ldata->xl_rx_list));
	/*
	 * Free the TX list buffers.
	 */
	for (i = 0; i < XL_TX_LIST_CNT; i++) {
		if (sc->xl_cdata.xl_tx_chain[i].xl_mbuf != NULL) {
			m_freem(sc->xl_cdata.xl_tx_chain[i].xl_mbuf);
			sc->xl_cdata.xl_tx_chain[i].xl_mbuf = NULL;
		}
	}
	bzero((char *)&sc->xl_ldata->xl_tx_list,
		sizeof(sc->xl_ldata->xl_tx_list));
d2607 33
a2639 1
	shutdownhook_establish(xl_shutdown, sc);
@


1.4
log
@after computing the hash value, inform the card [delete-o from when this
was imported].  Also, backout previous.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.2 2000/04/18 14:32:49 aaron Exp $	*/
d60 1
a60 1
 * 3Com 3C575BTX	10/100Mbps LAN CardBus PC Card
d62 3
d989 1
a989 1
	case TC_DEVICEID_3CCFE575_CARDBUS:
d992 3
d1444 2
a1445 1
			bus_space_write_4(sc->xl_funct,sc->xl_funch, 4, 0x8000);
d2025 2
a2026 1
		bus_space_write_4(sc->xl_funct, sc->xl_funch, 4, 0x8000);
d2329 2
a2330 1
		bus_space_write_4(sc->xl_funct, sc->xl_funch, 4, 0x8000);
a2389 1
		u_int16_t devid;
a2393 1
		xl_read_eeprom(sc, (caddr_t)&devid, XL_EE_PRODID, 1, 0);
d2395 1
a2395 1
		if (devid != 0x5257)
d2397 2
a2398 1
		if (devid == 0x5257 || devid == 0x6560 || devid == 0x6562)
a2459 4
	if (sc->xl_bustype == XL_BUS_CARDBUS) {
		XL_SEL_WIN(2);
		CSR_WRITE_2(sc, 12, 0x4000 | CSR_READ_2(sc, 12));
	}
d2465 4
a2468 2
		XL_SEL_WIN(2);
		CSR_WRITE_2(sc, 12, 0x4000 | CSR_READ_2(sc, 12));
d2470 1
@


1.3
log
@xl_setmulti_hash() does not work right.  tested at usenix2000 term room.
affects 905B only.
@
text
@d676 1
a1959 1
#if 0
a1960 3
#else
	if (0)	/* xl_setmulti_hash() does not work right */
#endif
a2230 1
#if 0
a2231 3
#else
			if (0)	/* xl_setmulti_hash() does not work right */
#endif
@


1.2
log
@Set MII parameters for the other 3Com CardBus cards, not just 'C' revision.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.1 2000/04/08 05:50:50 aaron Exp $	*/
d1959 1
d1961 3
d2234 1
d2236 3
@


1.2.2.1
log
@Pull in patch from current:
Fix (itojun):
xl_setmulti_hash() does not work right.  tested at usenix2000 term room.
affects 905B only.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.2 2000/04/18 14:32:49 aaron Exp $	*/
a1958 1
#if 0
a1959 3
#else
	if (0)	/* xl_setmulti_hash() does not work right */
#endif
a2229 1
#if 0
a2230 3
#else
			if (0)	/* xl_setmulti_hash() does not work right */
#endif
@


1.2.2.2
log
@Pull in patch from current:
Errata:
Fix multicast hashing problem in xl(4)
Fix (jason):
after computing the hash value, inform the card [delete-o from when this
was imported].  Also, backout previous.
@
text
@d1 1
a1 1
/*	$OpenBSD: xl.c,v 1.4 2000/06/29 14:07:03 jason Exp $	*/
a675 1
		CSR_WRITE_2(sc, XL_COMMAND, XL_CMD_RX_SET_HASH|XL_HASH_SET|h);
d1959 1
d1961 3
d2234 1
d2236 3
@


1.1
log
@Initial check-in for support of 32-bit CardBus PC Cards; from NetBSD. On many
machines, this code needs the new PCIBIOS* options enabled in the kernel config
file to work, but your mileage may vary. Included is a working 3c575 driver for
3Com 10/100 CardBus PC Card NICs (tested only with the 'C' revision). The 3c575
is the pccard version of the PCI EtherLink XL cards, and thus the xl driver has
been split into /sys/dev/ic.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_xl.c,v 1.38 2000/02/15 13:47:52 jason Exp $	*/
d59 2
d985 2
@

