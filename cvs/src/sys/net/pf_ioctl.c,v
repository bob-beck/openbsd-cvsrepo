head	1.314;
access;
symbols
	OPENBSD_6_1:1.308.0.4
	OPENBSD_6_1_BASE:1.308
	OPENBSD_6_0:1.297.0.6
	OPENBSD_6_0_BASE:1.297
	OPENBSD_5_9:1.297.0.2
	OPENBSD_5_9_BASE:1.297
	OPENBSD_5_8:1.289.0.4
	OPENBSD_5_8_BASE:1.289
	OPENBSD_5_7:1.283.0.2
	OPENBSD_5_7_BASE:1.283
	OPENBSD_5_6:1.274.0.4
	OPENBSD_5_6_BASE:1.274
	OPENBSD_5_5:1.269.0.4
	OPENBSD_5_5_BASE:1.269
	OPENBSD_5_4:1.259.0.2
	OPENBSD_5_4_BASE:1.259
	OPENBSD_5_3:1.257.0.2
	OPENBSD_5_3_BASE:1.257
	OPENBSD_5_2:1.253.0.2
	OPENBSD_5_2_BASE:1.253
	OPENBSD_5_1_BASE:1.248
	OPENBSD_5_1:1.248.0.2
	OPENBSD_5_0:1.241.0.2
	OPENBSD_5_0_BASE:1.241
	OPENBSD_4_9:1.236.0.2
	OPENBSD_4_9_BASE:1.236
	OPENBSD_4_8:1.235.0.2
	OPENBSD_4_8_BASE:1.235
	OPENBSD_4_7:1.232.0.2
	OPENBSD_4_7_BASE:1.232
	OPENBSD_4_6:1.219.0.4
	OPENBSD_4_6_BASE:1.219
	OPENBSD_4_5:1.214.0.2
	OPENBSD_4_5_BASE:1.214
	OPENBSD_4_4:1.209.0.2
	OPENBSD_4_4_BASE:1.209
	OPENBSD_4_3:1.193.0.2
	OPENBSD_4_3_BASE:1.193
	OPENBSD_4_2:1.182.0.2
	OPENBSD_4_2_BASE:1.182
	OPENBSD_4_1:1.175.0.2
	OPENBSD_4_1_BASE:1.175
	OPENBSD_4_0:1.169.0.2
	OPENBSD_4_0_BASE:1.169
	OPENBSD_3_9:1.164.0.2
	OPENBSD_3_9_BASE:1.164
	OPENBSD_3_8:1.157.0.2
	OPENBSD_3_8_BASE:1.157
	OPENBSD_3_7:1.139.0.2
	OPENBSD_3_7_BASE:1.139
	OPENBSD_3_6:1.130.0.2
	OPENBSD_3_6_BASE:1.130
	SMP_SYNC_A:1.125
	SMP_SYNC_B:1.124
	OPENBSD_3_5:1.112.0.2
	OPENBSD_3_5_BASE:1.112
	OPENBSD_3_4:1.81.0.2
	OPENBSD_3_4_BASE:1.81
	UBC_SYNC_A:1.65
	SMP:1.50.0.4
	OPENBSD_3_3:1.50.0.2
	OPENBSD_3_3_BASE:1.50
	UBC_SYNC_B:1.13
	OPENBSD_3_2:1.8.0.2
	OPENBSD_3_2_BASE:1.8
	UBC:1.5.0.2;
locks; strict;
comment	@ * @;


1.314
date	2017.06.01.14.38.28;	author patrick;	state Exp;
branches;
next	1.313;
commitid	Pz82BaXFYwoiyHnm;

1.313
date	2017.05.30.19.37.54;	author henning;	state Exp;
branches;
next	1.312;
commitid	TZX21WHCToJLlT7I;

1.312
date	2017.05.15.12.26.00;	author mpi;	state Exp;
branches;
next	1.311;
commitid	WMZaI3vIHNC1J8ol;

1.311
date	2017.05.15.11.23.25;	author mikeb;	state Exp;
branches;
next	1.310;
commitid	MV7SeE82QLGXQJBO;

1.310
date	2017.05.02.12.27.37;	author mikeb;	state Exp;
branches;
next	1.309;
commitid	rOAHa272RNs62JfW;

1.309
date	2017.04.21.23.21.02;	author yasuoka;	state Exp;
branches;
next	1.308;
commitid	G3rhxdNTjNYgqa0p;

1.308
date	2017.03.17.17.19.16;	author mpi;	state Exp;
branches;
next	1.307;
commitid	CxqvXOMqotM60GAI;

1.307
date	2017.01.30.17.41.34;	author benno;	state Exp;
branches;
next	1.306;
commitid	jxfz0zamCXSbKEUx;

1.306
date	2017.01.24.10.08.30;	author krw;	state Exp;
branches;
next	1.305;
commitid	6c6qq5OdS4VVnyVM;

1.305
date	2016.11.16.08.46.05;	author mpi;	state Exp;
branches;
next	1.304;
commitid	pUZOAlSRSuvtMpYj;

1.304
date	2016.10.28.07.54.19;	author sashan;	state Exp;
branches;
next	1.303;
commitid	Rv7MhoGDNXtOE6x2;

1.303
date	2016.10.26.21.07.22;	author bluhm;	state Exp;
branches;
next	1.302;
commitid	aaKAr0kv3QWNHoVo;

1.302
date	2016.09.27.04.57.17;	author dlg;	state Exp;
branches;
next	1.301;
commitid	irzdR7hwk1GHVaEu;

1.301
date	2016.09.27.02.51.12;	author dlg;	state Exp;
branches;
next	1.300;
commitid	bZuzILta8BoFCDiT;

1.300
date	2016.09.15.02.00.18;	author dlg;	state Exp;
branches;
next	1.299;
commitid	RlO92XR575sygHqm;

1.299
date	2016.09.03.17.11.40;	author sashan;	state Exp;
branches;
next	1.298;
commitid	JAk2J5vzbGC5EyfM;

1.298
date	2016.09.02.10.19.49;	author dlg;	state Exp;
branches;
next	1.297;
commitid	BjJg5d9vjutHaOpJ;

1.297
date	2015.12.03.13.30.18;	author claudio;	state Exp;
branches;
next	1.296;
commitid	4OpWrNae30XIiKdb;

1.296
date	2015.12.03.10.34.11;	author blambert;	state Exp;
branches;
next	1.295;
commitid	MfWrm5YqNBLzxNqu;

1.295
date	2015.12.03.09.49.15;	author bluhm;	state Exp;
branches;
next	1.294;
commitid	6HkfIaw2ROsrfw1Q;

1.294
date	2015.11.24.13.37.16;	author mpi;	state Exp;
branches;
next	1.293;
commitid	djjKhPvMtRdFfuFJ;

1.293
date	2015.11.23.15.53.35;	author mpi;	state Exp;
branches;
next	1.292;
commitid	oUay5xUsF5SD1zqV;

1.292
date	2015.11.20.03.35.23;	author dlg;	state Exp;
branches;
next	1.291;
commitid	eYnPulzvLjDImPCa;

1.291
date	2015.10.13.19.32.31;	author sashan;	state Exp;
branches;
next	1.290;
commitid	2CkJMFIEZK18G5IB;

1.290
date	2015.09.04.21.40.25;	author kettenis;	state Exp;
branches;
next	1.289;
commitid	9bdTRxc2FCD8lXug;

1.289
date	2015.07.21.02.32.04;	author sashan;	state Exp;
branches;
next	1.288;
commitid	cPDXdho3rjhTprUk;

1.288
date	2015.07.19.05.54.54;	author sashan;	state Exp;
branches;
next	1.287;
commitid	3OqwzR5DhzPainHM;

1.287
date	2015.07.19.05.48.12;	author sashan;	state Exp;
branches;
next	1.286;
commitid	SIH047fmULS8uLq7;

1.286
date	2015.07.18.19.19.00;	author sashan;	state Exp;
branches;
next	1.285;
commitid	JLCIxhdc71KA1Osw;

1.285
date	2015.04.11.13.00.12;	author dlg;	state Exp;
branches;
next	1.284;
commitid	uT17hi9tQuyDqgaw;

1.284
date	2015.03.14.03.38.51;	author jsg;	state Exp;
branches;
next	1.283;
commitid	p4LJxGKbi0BU2cG6;

1.283
date	2015.02.20.11.08.31;	author tedu;	state Exp;
branches;
next	1.282;
commitid	44BWwJfYvQV14tvd;

1.282
date	2015.02.10.06.45.55;	author henning;	state Exp;
branches;
next	1.281;
commitid	eD7tXFa7upGCZ3zN;

1.281
date	2015.01.24.00.29.06;	author deraadt;	state Exp;
branches;
next	1.280;
commitid	VK3ncyiP3NS1N4Sy;

1.280
date	2014.12.19.17.14.40;	author tedu;	state Exp;
branches;
next	1.279;
commitid	zhW8jJrfVCoAthrR;

1.279
date	2014.12.09.07.05.06;	author doug;	state Exp;
branches;
next	1.278;
commitid	zM5ckwX4kwwmipG0;

1.278
date	2014.12.05.15.50.04;	author mpi;	state Exp;
branches;
next	1.277;
commitid	t9FBKDfc4VDxpEy2;

1.277
date	2014.11.18.02.37.31;	author tedu;	state Exp;
branches;
next	1.276;
commitid	Z1vcFtHO8wRH0yRt;

1.276
date	2014.08.12.15.29.33;	author mikeb;	state Exp;
branches;
next	1.275;
commitid	VQXfMjKroH5JkPuJ;

1.275
date	2014.08.12.14.38.28;	author mikeb;	state Exp;
branches;
next	1.274;
commitid	rj3vXaJ8TiOS9RoX;

1.274
date	2014.07.22.11.06.09;	author mpi;	state Exp;
branches;
next	1.273;
commitid	DQakU8LLWV6Iwx84;

1.273
date	2014.07.12.18.44.22;	author tedu;	state Exp;
branches;
next	1.272;
commitid	B4dZSbxas1X1IpXI;

1.272
date	2014.04.22.14.41.03;	author mpi;	state Exp;
branches;
next	1.271;

1.271
date	2014.04.19.12.59.53;	author henning;	state Exp;
branches;
next	1.270;

1.270
date	2014.03.30.21.54.48;	author guenther;	state Exp;
branches;
next	1.269;

1.269
date	2014.02.04.01.04.03;	author tedu;	state Exp;
branches;
next	1.268;

1.268
date	2014.01.20.02.57.50;	author henning;	state Exp;
branches;
next	1.267;

1.267
date	2014.01.03.12.48.58;	author pelikan;	state Exp;
branches;
next	1.266;

1.266
date	2014.01.03.12.43.09;	author pelikan;	state Exp;
branches;
next	1.265;

1.265
date	2013.11.13.18.25.57;	author deraadt;	state Exp;
branches;
next	1.264;

1.264
date	2013.11.12.20.14.22;	author deraadt;	state Exp;
branches;
next	1.263;

1.263
date	2013.10.20.16.35.31;	author deraadt;	state Exp;
branches;
next	1.262;

1.262
date	2013.10.17.16.27.42;	author bluhm;	state Exp;
branches;
next	1.261;

1.261
date	2013.10.12.12.13.11;	author henning;	state Exp;
branches;
next	1.260;

1.260
date	2013.10.12.11.55.45;	author henning;	state Exp;
branches;
next	1.259;

1.259
date	2013.03.28.16.45.16;	author tedu;	state Exp;
branches;
next	1.258;

1.258
date	2013.03.27.13.32.28;	author mcbride;	state Exp;
branches;
next	1.257;

1.257
date	2013.02.26.14.56.05;	author mikeb;	state Exp;
branches;
next	1.256;

1.256
date	2012.10.30.12.09.05;	author florian;	state Exp;
branches;
next	1.255;

1.255
date	2012.09.20.09.43.49;	author camield;	state Exp;
branches;
next	1.254;

1.254
date	2012.09.18.10.11.53;	author henning;	state Exp;
branches;
next	1.253;

1.253
date	2012.07.08.07.58.09;	author henning;	state Exp;
branches;
next	1.252;

1.252
date	2012.07.07.16.24.32;	author henning;	state Exp;
branches;
next	1.251;

1.251
date	2012.07.07.15.20.14;	author henning;	state Exp;
branches;
next	1.250;

1.250
date	2012.04.03.15.09.03;	author mikeb;	state Exp;
branches;
next	1.249;

1.249
date	2012.03.28.19.41.05;	author claudio;	state Exp;
branches;
next	1.248;

1.248
date	2011.12.12.21.30.27;	author mikeb;	state Exp;
branches;
next	1.247;

1.247
date	2011.11.29.10.17.52;	author dlg;	state Exp;
branches;
next	1.246;

1.246
date	2011.11.28.01.04.50;	author dlg;	state Exp;
branches;
next	1.245;

1.245
date	2011.11.25.12.52.10;	author dlg;	state Exp;
branches;
next	1.244;

1.244
date	2011.10.13.18.23.40;	author claudio;	state Exp;
branches;
next	1.243;

1.243
date	2011.10.07.17.10.08;	author henning;	state Exp;
branches;
next	1.242;

1.242
date	2011.08.30.00.40.47;	author mikeb;	state Exp;
branches;
next	1.241;

1.241
date	2011.07.08.18.50.51;	author henning;	state Exp;
branches;
next	1.240;

1.240
date	2011.06.02.22.03.30;	author sthen;	state Exp;
branches;
next	1.239;

1.239
date	2011.04.19.21.58.03;	author chl;	state Exp;
branches;
next	1.238;

1.238
date	2011.04.06.13.18.39;	author claudio;	state Exp;
branches;
next	1.237;

1.237
date	2011.03.25.10.54.22;	author claudio;	state Exp;
branches;
next	1.236;

1.236
date	2010.12.15.14.22.25;	author claudio;	state Exp;
branches;
next	1.235;

1.235
date	2010.06.30.18.10.55;	author henning;	state Exp;
branches
	1.235.2.1;
next	1.234;

1.234
date	2010.06.28.23.21.41;	author mcbride;	state Exp;
branches;
next	1.233;

1.233
date	2010.06.27.01.28.44;	author mcbride;	state Exp;
branches;
next	1.232;

1.232
date	2010.01.18.23.52.46;	author mcbride;	state Exp;
branches
	1.232.2.1;
next	1.231;

1.231
date	2010.01.12.03.20.51;	author mcbride;	state Exp;
branches;
next	1.230;

1.230
date	2009.12.24.04.24.19;	author dlg;	state Exp;
branches;
next	1.229;

1.229
date	2009.12.14.12.31.45;	author henning;	state Exp;
branches;
next	1.228;

1.228
date	2009.11.24.13.23.55;	author henning;	state Exp;
branches;
next	1.227;

1.227
date	2009.11.23.16.03.10;	author henning;	state Exp;
branches;
next	1.226;

1.226
date	2009.11.22.22.34.50;	author henning;	state Exp;
branches;
next	1.225;

1.225
date	2009.11.11.10.31.44;	author jsg;	state Exp;
branches;
next	1.224;

1.224
date	2009.11.03.17.41.02;	author claudio;	state Exp;
branches;
next	1.223;

1.223
date	2009.11.03.10.59.04;	author claudio;	state Exp;
branches;
next	1.222;

1.222
date	2009.10.28.20.11.01;	author jsg;	state Exp;
branches;
next	1.221;

1.221
date	2009.10.06.02.31.36;	author mcbride;	state Exp;
branches;
next	1.220;

1.220
date	2009.09.01.13.42.00;	author henning;	state Exp;
branches;
next	1.219;

1.219
date	2009.05.31.19.10.51;	author henning;	state Exp;
branches;
next	1.218;

1.218
date	2009.04.16.04.40.19;	author david;	state Exp;
branches;
next	1.217;

1.217
date	2009.04.07.12.48.40;	author henning;	state Exp;
branches;
next	1.216;

1.216
date	2009.04.06.12.05.55;	author henning;	state Exp;
branches;
next	1.215;

1.215
date	2009.03.09.13.53.10;	author mcbride;	state Exp;
branches;
next	1.214;

1.214
date	2009.02.16.00.31.25;	author dlg;	state Exp;
branches;
next	1.213;

1.213
date	2009.02.15.21.46.12;	author mbalmer;	state Exp;
branches;
next	1.212;

1.212
date	2009.02.15.20.42.33;	author mbalmer;	state Exp;
branches;
next	1.211;

1.211
date	2008.11.24.13.22.09;	author mikeb;	state Exp;
branches;
next	1.210;

1.210
date	2008.10.23.22.22.44;	author deraadt;	state Exp;
branches;
next	1.209;

1.209
date	2008.06.29.08.42.15;	author mcbride;	state Exp;
branches;
next	1.208;

1.208
date	2008.06.22.13.01.33;	author mcbride;	state Exp;
branches;
next	1.207;

1.207
date	2008.06.14.19.09.52;	author jsing;	state Exp;
branches;
next	1.206;

1.206
date	2008.06.14.02.22.13;	author henning;	state Exp;
branches;
next	1.205;

1.205
date	2008.06.11.20.51.34;	author mcbride;	state Exp;
branches;
next	1.204;

1.204
date	2008.06.10.22.39.31;	author mcbride;	state Exp;
branches;
next	1.203;

1.203
date	2008.06.10.20.14.02;	author henning;	state Exp;
branches;
next	1.202;

1.202
date	2008.06.10.19.32.13;	author henning;	state Exp;
branches;
next	1.201;

1.201
date	2008.06.10.04.24.17;	author henning;	state Exp;
branches;
next	1.200;

1.200
date	2008.05.30.14.22.48;	author henning;	state Exp;
branches;
next	1.199;

1.199
date	2008.05.29.01.00.53;	author mcbride;	state Exp;
branches;
next	1.198;

1.198
date	2008.05.29.00.28.08;	author henning;	state Exp;
branches;
next	1.197;

1.197
date	2008.05.18.11.54.04;	author mcbride;	state Exp;
branches;
next	1.196;

1.196
date	2008.05.09.13.59.31;	author mpf;	state Exp;
branches;
next	1.195;

1.195
date	2008.05.06.03.45.22;	author mpf;	state Exp;
branches;
next	1.194;

1.194
date	2008.05.06.03.24.25;	author weingart;	state Exp;
branches;
next	1.193;

1.193
date	2007.12.02.12.08.04;	author pascoe;	state Exp;
branches;
next	1.192;

1.192
date	2007.12.02.12.00.20;	author pascoe;	state Exp;
branches;
next	1.191;

1.191
date	2007.12.02.11.56.29;	author dhartmei;	state Exp;
branches;
next	1.190;

1.190
date	2007.12.02.11.53.06;	author pascoe;	state Exp;
branches;
next	1.189;

1.189
date	2007.12.02.11.42.05;	author pascoe;	state Exp;
branches;
next	1.188;

1.188
date	2007.12.02.11.39.45;	author pascoe;	state Exp;
branches;
next	1.187;

1.187
date	2007.12.02.11.36.39;	author pascoe;	state Exp;
branches;
next	1.186;

1.186
date	2007.09.27.22.24.05;	author mpf;	state Exp;
branches;
next	1.185;

1.185
date	2007.09.15.16.43.51;	author henning;	state Exp;
branches;
next	1.184;

1.184
date	2007.09.01.15.14.44;	author martin;	state Exp;
branches;
next	1.183;

1.183
date	2007.08.30.13.07.06;	author henning;	state Exp;
branches;
next	1.182;

1.182
date	2007.06.24.11.17.13;	author mcbride;	state Exp;
branches;
next	1.181;

1.181
date	2007.06.21.19.31.49;	author henning;	state Exp;
branches;
next	1.180;

1.180
date	2007.06.07.13.32.06;	author henning;	state Exp;
branches;
next	1.179;

1.179
date	2007.06.01.18.44.23;	author henning;	state Exp;
branches;
next	1.178;

1.178
date	2007.05.31.18.48.05;	author mcbride;	state Exp;
branches;
next	1.177;

1.177
date	2007.05.31.04.11.42;	author mcbride;	state Exp;
branches;
next	1.176;

1.176
date	2007.05.29.00.17.32;	author thib;	state Exp;
branches;
next	1.175;

1.175
date	2007.02.26.22.47.43;	author deraadt;	state Exp;
branches;
next	1.174;

1.174
date	2007.02.23.21.31.51;	author deraadt;	state Exp;
branches;
next	1.173;

1.173
date	2007.02.09.11.20.39;	author henning;	state Exp;
branches;
next	1.172;

1.172
date	2006.11.20.14.25.11;	author mcbride;	state Exp;
branches;
next	1.171;

1.171
date	2006.10.27.13.56.51;	author mcbride;	state Exp;
branches;
next	1.170;

1.170
date	2006.10.25.11.26.47;	author henning;	state Exp;
branches;
next	1.169;

1.169
date	2006.08.30.11.31.02;	author djm;	state Exp;
branches;
next	1.168;

1.168
date	2006.07.21.01.21.17;	author dhartmei;	state Exp;
branches;
next	1.167;

1.167
date	2006.07.06.13.25.40;	author henning;	state Exp;
branches;
next	1.166;

1.166
date	2006.05.28.02.45.45;	author mcbride;	state Exp;
branches;
next	1.165;

1.165
date	2006.03.04.22.40.16;	author brad;	state Exp;
branches;
next	1.164;

1.164
date	2006.01.06.00.41.21;	author dhartmei;	state Exp;
branches;
next	1.163;

1.163
date	2006.01.06.00.37.27;	author dhartmei;	state Exp;
branches;
next	1.162;

1.162
date	2006.01.05.02.23.39;	author deraadt;	state Exp;
branches;
next	1.161;

1.161
date	2005.12.10.14.41.07;	author krw;	state Exp;
branches;
next	1.160;

1.160
date	2005.10.27.12.34.40;	author mcbride;	state Exp;
branches;
next	1.159;

1.159
date	2005.09.28.01.46.32;	author pascoe;	state Exp;
branches;
next	1.158;

1.158
date	2005.09.05.14.51.08;	author dhartmei;	state Exp;
branches;
next	1.157;

1.157
date	2005.08.18.10.32.56;	author pascoe;	state Exp;
branches
	1.157.2.1;
next	1.156;

1.156
date	2005.08.18.10.28.14;	author pascoe;	state Exp;
branches;
next	1.155;

1.155
date	2005.08.12.04.15.38;	author pascoe;	state Exp;
branches;
next	1.154;

1.154
date	2005.08.07.11.54.02;	author pascoe;	state Exp;
branches;
next	1.153;

1.153
date	2005.08.07.11.37.33;	author dhartmei;	state Exp;
branches;
next	1.152;

1.152
date	2005.08.05.09.03.19;	author dhartmei;	state Exp;
branches;
next	1.151;

1.151
date	2005.08.04.20.33.45;	author dhartmei;	state Exp;
branches;
next	1.150;

1.150
date	2005.08.02.12.40.42;	author pascoe;	state Exp;
branches;
next	1.149;

1.149
date	2005.08.01.05.39.27;	author pascoe;	state Exp;
branches;
next	1.148;

1.148
date	2005.07.31.05.20.57;	author pascoe;	state Exp;
branches;
next	1.147;

1.147
date	2005.07.26.05.21.27;	author pascoe;	state Exp;
branches;
next	1.146;

1.146
date	2005.07.11.14.14.14;	author dhartmei;	state Exp;
branches;
next	1.145;

1.145
date	2005.06.30.20.52.20;	author sturm;	state Exp;
branches;
next	1.144;

1.144
date	2005.06.13.20.17.25;	author henning;	state Exp;
branches;
next	1.143;

1.143
date	2005.05.27.21.41.03;	author mpf;	state Exp;
branches;
next	1.142;

1.142
date	2005.05.27.17.22.41;	author dhartmei;	state Exp;
branches;
next	1.141;

1.141
date	2005.05.21.21.03.57;	author henning;	state Exp;
branches;
next	1.140;

1.140
date	2005.05.10.13.15.15;	author joel;	state Exp;
branches;
next	1.139;

1.139
date	2005.03.03.07.13.39;	author dhartmei;	state Exp;
branches
	1.139.2.1;
next	1.138;

1.138
date	2005.01.05.18.11.55;	author mcbride;	state Exp;
branches;
next	1.137;

1.137
date	2004.12.22.17.17.55;	author dhartmei;	state Exp;
branches;
next	1.136;

1.136
date	2004.12.10.22.13.26;	author henning;	state Exp;
branches;
next	1.135;

1.135
date	2004.12.07.18.02.04;	author mcbride;	state Exp;
branches;
next	1.134;

1.134
date	2004.12.05.10.46.26;	author dhartmei;	state Exp;
branches;
next	1.133;

1.133
date	2004.12.04.07.49.48;	author mcbride;	state Exp;
branches;
next	1.132;

1.132
date	2004.12.01.23.22.43;	author dhartmei;	state Exp;
branches;
next	1.131;

1.131
date	2004.09.21.16.59.12;	author aaron;	state Exp;
branches;
next	1.130;

1.130
date	2004.09.09.22.08.42;	author dhartmei;	state Exp;
branches
	1.130.2.1;
next	1.129;

1.129
date	2004.07.22.23.21.10;	author msf;	state Exp;
branches;
next	1.128;

1.128
date	2004.07.05.00.15.20;	author henning;	state Exp;
branches;
next	1.127;

1.127
date	2004.06.21.23.50.36;	author tholo;	state Exp;
branches;
next	1.126;

1.126
date	2004.06.14.20.53.27;	author cedric;	state Exp;
branches;
next	1.125;

1.125
date	2004.06.10.14.22.54;	author dhartmei;	state Exp;
branches;
next	1.124;

1.124
date	2004.05.31.20.35.46;	author dhartmei;	state Exp;
branches;
next	1.123;

1.123
date	2004.05.21.23.10.47;	author dhartmei;	state Exp;
branches;
next	1.122;

1.122
date	2004.05.21.08.03.29;	author dhartmei;	state Exp;
branches;
next	1.121;

1.121
date	2004.05.19.17.50.52;	author dhartmei;	state Exp;
branches;
next	1.120;

1.120
date	2004.05.18.10.35.22;	author dhartmei;	state Exp;
branches;
next	1.119;

1.119
date	2004.05.05.23.16.03;	author frantzen;	state Exp;
branches;
next	1.118;

1.118
date	2004.05.03.07.51.59;	author kjc;	state Exp;
branches;
next	1.117;

1.117
date	2004.04.28.02.43.09;	author pb;	state Exp;
branches;
next	1.116;

1.116
date	2004.04.27.02.56.20;	author kjc;	state Exp;
branches;
next	1.115;

1.115
date	2004.04.26.02.01.47;	author mcbride;	state Exp;
branches;
next	1.114;

1.114
date	2004.04.26.00.12.28;	author cedric;	state Exp;
branches;
next	1.113;

1.113
date	2004.04.09.19.30.41;	author frantzen;	state Exp;
branches;
next	1.112;

1.112
date	2004.03.22.04.54.18;	author mcbride;	state Exp;
branches
	1.112.2.1;
next	1.111;

1.111
date	2004.03.18.23.24.02;	author cedric;	state Exp;
branches;
next	1.110;

1.110
date	2004.03.15.10.59.07;	author henning;	state Exp;
branches;
next	1.109;

1.109
date	2004.03.09.21.44.41;	author mcbride;	state Exp;
branches;
next	1.108;

1.108
date	2004.02.20.19.22.03;	author mcbride;	state Exp;
branches;
next	1.107;

1.107
date	2004.02.19.21.29.51;	author cedric;	state Exp;
branches;
next	1.106;

1.106
date	2004.02.19.07.41.45;	author kjc;	state Exp;
branches;
next	1.105;

1.105
date	2004.02.13.19.32.49;	author mpf;	state Exp;
branches;
next	1.104;

1.104
date	2004.02.10.22.42.57;	author dhartmei;	state Exp;
branches;
next	1.103;

1.103
date	2004.02.10.18.49.10;	author henning;	state Exp;
branches;
next	1.102;

1.102
date	2004.02.09.13.27.50;	author cedric;	state Exp;
branches;
next	1.101;

1.101
date	2004.02.04.10.43.18;	author mcbride;	state Exp;
branches;
next	1.100;

1.100
date	2004.01.05.13.33.11;	author cedric;	state Exp;
branches;
next	1.99;

1.99
date	2004.01.05.12.54.47;	author cedric;	state Exp;
branches;
next	1.98;

1.98
date	2003.12.31.22.14.42;	author deraadt;	state Exp;
branches;
next	1.97;

1.97
date	2003.12.31.11.18.25;	author cedric;	state Exp;
branches;
next	1.96;

1.96
date	2003.12.22.10.10.06;	author dhartmei;	state Exp;
branches;
next	1.95;

1.95
date	2003.12.19.16.12.43;	author henning;	state Exp;
branches;
next	1.94;

1.94
date	2003.12.18.20.55.20;	author mcbride;	state Exp;
branches;
next	1.93;

1.93
date	2003.12.18.20.52.19;	author mcbride;	state Exp;
branches;
next	1.92;

1.92
date	2003.12.15.09.10.26;	author henning;	state Exp;
branches;
next	1.91;

1.91
date	2003.12.15.07.28.25;	author mcbride;	state Exp;
branches;
next	1.90;

1.90
date	2003.12.15.07.11.30;	author mcbride;	state Exp;
branches;
next	1.89;

1.89
date	2003.12.15.00.02.04;	author mcbride;	state Exp;
branches;
next	1.88;

1.88
date	2003.12.12.20.05.45;	author cedric;	state Exp;
branches;
next	1.87;

1.87
date	2003.11.02.01.33.56;	author mcbride;	state Exp;
branches;
next	1.86;

1.86
date	2003.10.25.20.27.07;	author mcbride;	state Exp;
branches;
next	1.85;

1.85
date	2003.10.19.06.50.07;	author mcbride;	state Exp;
branches;
next	1.84;

1.84
date	2003.10.08.15.06.08;	author henning;	state Exp;
branches;
next	1.83;

1.83
date	2003.10.08.14.44.35;	author henning;	state Exp;
branches;
next	1.82;

1.82
date	2003.09.26.21.44.08;	author cedric;	state Exp;
branches;
next	1.81;

1.81
date	2003.08.22.21.50.34;	author david;	state Exp;
branches
	1.81.2.1;
next	1.80;

1.80
date	2003.08.21.19.12.08;	author frantzen;	state Exp;
branches;
next	1.79;

1.79
date	2003.08.11.20.15.45;	author dhartmei;	state Exp;
branches;
next	1.78;

1.78
date	2003.08.09.14.56.48;	author cedric;	state Exp;
branches;
next	1.77;

1.77
date	2003.07.31.22.25.54;	author cedric;	state Exp;
branches;
next	1.76;

1.76
date	2003.07.19.13.08.58;	author cedric;	state Exp;
branches;
next	1.75;

1.75
date	2003.06.30.19.09.25;	author henning;	state Exp;
branches;
next	1.74;

1.74
date	2003.06.30.17.45.01;	author dhartmei;	state Exp;
branches;
next	1.73;

1.73
date	2003.06.30.10.50.16;	author henning;	state Exp;
branches;
next	1.72;

1.72
date	2003.06.27.14.38.02;	author henning;	state Exp;
branches;
next	1.71;

1.71
date	2003.06.27.11.38.23;	author henning;	state Exp;
branches;
next	1.70;

1.70
date	2003.06.23.02.33.39;	author cedric;	state Exp;
branches;
next	1.69;

1.69
date	2003.06.21.09.07.01;	author djm;	state Exp;
branches;
next	1.68;

1.68
date	2003.06.08.09.41.08;	author cedric;	state Exp;
branches;
next	1.67;

1.67
date	2003.06.03.12.34.04;	author henning;	state Exp;
branches;
next	1.66;

1.66
date	2003.06.03.12.30.33;	author henning;	state Exp;
branches;
next	1.65;

1.65
date	2003.05.14.01.39.51;	author frantzen;	state Exp;
branches;
next	1.64;

1.64
date	2003.05.13.17.45.24;	author henning;	state Exp;
branches;
next	1.63;

1.63
date	2003.05.12.17.43.29;	author mcbride;	state Exp;
branches;
next	1.62;

1.62
date	2003.05.12.01.25.31;	author dhartmei;	state Exp;
branches;
next	1.61;

1.61
date	2003.05.12.00.02.32;	author henning;	state Exp;
branches;
next	1.60;

1.60
date	2003.04.30.12.30.27;	author cedric;	state Exp;
branches;
next	1.59;

1.59
date	2003.04.27.16.02.07;	author cedric;	state Exp;
branches;
next	1.58;

1.58
date	2003.04.11.14.40.57;	author henning;	state Exp;
branches;
next	1.57;

1.57
date	2003.04.09.15.32.59;	author cedric;	state Exp;
branches;
next	1.56;

1.56
date	2003.04.07.13.44.22;	author dhartmei;	state Exp;
branches;
next	1.55;

1.55
date	2003.04.05.20.24.58;	author cedric;	state Exp;
branches;
next	1.54;

1.54
date	2003.04.05.20.20.58;	author cedric;	state Exp;
branches;
next	1.53;

1.53
date	2003.04.03.15.27.17;	author cedric;	state Exp;
branches;
next	1.52;

1.52
date	2003.04.03.13.17.24;	author cedric;	state Exp;
branches;
next	1.51;

1.51
date	2003.03.31.13.15.27;	author cedric;	state Exp;
branches;
next	1.50;

1.50
date	2003.03.11.13.26.09;	author dhartmei;	state Exp;
branches
	1.50.2.1
	1.50.4.1;
next	1.49;

1.49
date	2003.01.20.20.29.52;	author cedric;	state Exp;
branches;
next	1.48;

1.48
date	2003.01.09.18.36.48;	author henning;	state Exp;
branches;
next	1.47;

1.47
date	2003.01.09.15.58.35;	author dhartmei;	state Exp;
branches;
next	1.46;

1.46
date	2003.01.09.10.40.44;	author cedric;	state Exp;
branches;
next	1.45;

1.45
date	2003.01.07.00.21.07;	author dhartmei;	state Exp;
branches;
next	1.44;

1.44
date	2003.01.06.14.19.40;	author cedric;	state Exp;
branches;
next	1.43;

1.43
date	2003.01.05.22.14.23;	author dhartmei;	state Exp;
branches;
next	1.42;

1.42
date	2003.01.04.00.33.49;	author dhartmei;	state Exp;
branches;
next	1.41;

1.41
date	2003.01.03.10.39.09;	author cedric;	state Exp;
branches;
next	1.40;

1.40
date	2003.01.02.11.34.59;	author mcbride;	state Exp;
branches;
next	1.39;

1.39
date	2003.01.01.16.07.01;	author henning;	state Exp;
branches;
next	1.38;

1.38
date	2003.01.01.03.53.22;	author dhartmei;	state Exp;
branches;
next	1.37;

1.37
date	2002.12.31.19.18.41;	author mcbride;	state Exp;
branches;
next	1.36;

1.36
date	2002.12.31.00.00.44;	author dhartmei;	state Exp;
branches;
next	1.35;

1.35
date	2002.12.30.02.24.35;	author henning;	state Exp;
branches;
next	1.34;

1.34
date	2002.12.29.20.07.34;	author cedric;	state Exp;
branches;
next	1.33;

1.33
date	2002.12.27.21.45.14;	author mcbride;	state Exp;
branches;
next	1.32;

1.32
date	2002.12.27.15.20.30;	author dhartmei;	state Exp;
branches;
next	1.31;

1.31
date	2002.12.23.13.15.18;	author mcbride;	state Exp;
branches;
next	1.30;

1.30
date	2002.12.19.16.25.51;	author dhartmei;	state Exp;
branches;
next	1.29;

1.29
date	2002.12.18.19.40.41;	author dhartmei;	state Exp;
branches;
next	1.28;

1.28
date	2002.12.18.18.25.14;	author henning;	state Exp;
branches;
next	1.27;

1.27
date	2002.12.18.16.28.40;	author dhartmei;	state Exp;
branches;
next	1.26;

1.26
date	2002.12.17.12.30.13;	author mcbride;	state Exp;
branches;
next	1.25;

1.25
date	2002.12.13.21.48.30;	author henning;	state Exp;
branches;
next	1.24;

1.24
date	2002.12.12.20.24.20;	author aaron;	state Exp;
branches;
next	1.23;

1.23
date	2002.12.06.00.47.32;	author dhartmei;	state Exp;
branches;
next	1.22;

1.22
date	2002.12.01.19.56.38;	author henning;	state Exp;
branches;
next	1.21;

1.21
date	2002.12.01.19.54.32;	author mcbride;	state Exp;
branches;
next	1.20;

1.20
date	2002.11.29.13.03.24;	author mcbride;	state Exp;
branches;
next	1.19;

1.19
date	2002.11.26.03.44.53;	author kjc;	state Exp;
branches;
next	1.18;

1.18
date	2002.11.23.09.37.02;	author deraadt;	state Exp;
branches;
next	1.17;

1.17
date	2002.11.23.05.16.58;	author mcbride;	state Exp;
branches;
next	1.16;

1.16
date	2002.11.12.15.38.36;	author mpech;	state Exp;
branches;
next	1.15;

1.15
date	2002.11.07.22.24.46;	author dhartmei;	state Exp;
branches;
next	1.14;

1.14
date	2002.11.02.17.04.13;	author mcbride;	state Exp;
branches;
next	1.13;

1.13
date	2002.10.25.15.18.20;	author dhartmei;	state Exp;
branches;
next	1.12;

1.12
date	2002.10.22.00.39.23;	author mcbride;	state Exp;
branches;
next	1.11;

1.11
date	2002.10.20.13.08.29;	author mcbride;	state Exp;
branches;
next	1.10;

1.10
date	2002.10.08.05.12.08;	author kjc;	state Exp;
branches;
next	1.9;

1.9
date	2002.10.07.14.53.00;	author dhartmei;	state Exp;
branches;
next	1.8;

1.8
date	2002.08.12.16.41.25;	author dhartmei;	state Exp;
branches;
next	1.7;

1.7
date	2002.07.05.14.05.44;	author henning;	state Exp;
branches;
next	1.6;

1.6
date	2002.06.16.17.00.39;	author aaron;	state Exp;
branches;
next	1.5;

1.5
date	2002.06.11.01.58.00;	author henning;	state Exp;
branches
	1.5.2.1;
next	1.4;

1.4
date	2002.06.10.18.52.44;	author dhartmei;	state Exp;
branches;
next	1.3;

1.3
date	2002.06.10.17.05.11;	author dhartmei;	state Exp;
branches;
next	1.2;

1.2
date	2002.06.09.20.20.58;	author dhartmei;	state Exp;
branches;
next	1.1;

1.1
date	2002.06.09.03.57.18;	author pb;	state Exp;
branches;
next	;

1.5.2.1
date	2002.06.11.03.30.46;	author art;	state Exp;
branches;
next	1.5.2.2;

1.5.2.2
date	2002.10.29.00.36.46;	author art;	state Exp;
branches;
next	1.5.2.3;

1.5.2.3
date	2003.05.19.22.29.35;	author tedu;	state Exp;
branches;
next	;

1.50.2.1
date	2003.08.12.02.23.47;	author brad;	state Exp;
branches;
next	1.50.2.2;

1.50.2.2
date	2004.03.29.19.58.02;	author brad;	state Exp;
branches;
next	;

1.50.4.1
date	2003.05.13.19.36.16;	author ho;	state Exp;
branches;
next	1.50.4.2;

1.50.4.2
date	2003.05.16.00.29.44;	author niklas;	state Exp;
branches;
next	1.50.4.3;

1.50.4.3
date	2003.06.07.11.06.07;	author ho;	state Exp;
branches;
next	1.50.4.4;

1.50.4.4
date	2004.02.19.10.57.22;	author niklas;	state Exp;
branches;
next	1.50.4.5;

1.50.4.5
date	2004.06.05.23.11.24;	author niklas;	state Exp;
branches;
next	1.50.4.6;

1.50.4.6
date	2004.06.13.08.50.17;	author niklas;	state Exp;
branches;
next	;

1.81.2.1
date	2004.03.28.01.34.15;	author brad;	state Exp;
branches;
next	1.81.2.2;

1.81.2.2
date	2004.04.30.23.28.58;	author brad;	state Exp;
branches;
next	1.81.2.3;

1.81.2.3
date	2004.07.24.18.29.27;	author brad;	state Exp;
branches;
next	;

1.112.2.1
date	2004.04.30.21.43.30;	author brad;	state Exp;
branches;
next	1.112.2.2;

1.112.2.2
date	2004.07.24.18.28.12;	author brad;	state Exp;
branches;
next	;

1.130.2.1
date	2004.12.19.19.01.50;	author brad;	state Exp;
branches;
next	;

1.139.2.1
date	2005.10.07.19.56.15;	author brad;	state Exp;
branches;
next	1.139.2.2;

1.139.2.2
date	2006.01.26.22.38.32;	author brad;	state Exp;
branches;
next	;

1.157.2.1
date	2006.01.26.21.37.04;	author brad;	state Exp;
branches;
next	;

1.232.2.1
date	2010.07.07.08.18.50;	author sthen;	state Exp;
branches;
next	1.232.2.2;

1.232.2.2
date	2010.12.17.06.13.48;	author stephan;	state Exp;
branches;
next	;

1.235.2.1
date	2010.12.16.11.11.18;	author stephan;	state Exp;
branches;
next	;


desc
@@


1.314
log
@Return time_uptime as value for when pf was enabled instead of
time_second.  Since time_second changes depending on the wall-
clock time, time_second is not a reliable source for the status.
We can even end up with a negative time delta.  Thus, use the
monotonically growing time_uptime and export it to userland.

ok bluhm@@ mikeb@@
@
text
@/*	$OpenBSD: pf_ioctl.c,v 1.313 2017/05/30 19:37:54 henning Exp $ */

/*
 * Copyright (c) 2001 Daniel Hartmeier
 * Copyright (c) 2002 - 2013 Henning Brauer <henning@@openbsd.org>
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 *
 *    - Redistributions of source code must retain the above copyright
 *      notice, this list of conditions and the following disclaimer.
 *    - Redistributions in binary form must reproduce the above
 *      copyright notice, this list of conditions and the following
 *      disclaimer in the documentation and/or other materials provided
 *      with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
 * FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
 * COPYRIGHT HOLDERS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
 * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
 * BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
 * ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 *
 * Effort sponsored in part by the Defense Advanced Research Projects
 * Agency (DARPA) and Air Force Research Laboratory, Air Force
 * Materiel Command, USAF, under agreement number F30602-01-2-0537.
 *
 */

#include "pfsync.h"
#include "pflog.h"

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/mbuf.h>
#include <sys/filio.h>
#include <sys/fcntl.h>
#include <sys/socket.h>
#include <sys/socketvar.h>
#include <sys/kernel.h>
#include <sys/time.h>
#include <sys/timeout.h>
#include <sys/pool.h>
#include <sys/malloc.h>
#include <sys/kthread.h>
#include <sys/rwlock.h>
#include <sys/syslog.h>
#include <uvm/uvm_extern.h>

#include <crypto/md5.h>

#include <net/if.h>
#include <net/if_var.h>
#include <net/route.h>
#include <net/hfsc.h>
#include <net/fq_codel.h>

#include <netinet/in.h>
#include <netinet/ip.h>
#include <netinet/in_pcb.h>
#include <netinet/ip_var.h>
#include <netinet/ip_icmp.h>
#include <netinet/tcp.h>
#include <netinet/udp.h>

#ifdef INET6
#include <netinet/ip6.h>
#include <netinet/icmp6.h>
#endif /* INET6 */

#include <net/pfvar.h>
#include <net/pfvar_priv.h>

#if NPFSYNC > 0
#include <netinet/ip_ipsp.h>
#include <net/if_pfsync.h>
#endif /* NPFSYNC > 0 */

void			 pfattach(int);
void			 pf_thread_create(void *);
int			 pfopen(dev_t, int, int, struct proc *);
int			 pfclose(dev_t, int, int, struct proc *);
int			 pfioctl(dev_t, u_long, caddr_t, int, struct proc *);
int			 pf_begin_rules(u_int32_t *, const char *);
int			 pf_rollback_rules(u_int32_t, char *);
void			 pf_remove_queues(void);
int			 pf_commit_queues(void);
void			 pf_free_queues(struct pf_queuehead *);
int			 pf_setup_pfsync_matching(struct pf_ruleset *);
void			 pf_hash_rule(MD5_CTX *, struct pf_rule *);
void			 pf_hash_rule_addr(MD5_CTX *, struct pf_rule_addr *);
int			 pf_commit_rules(u_int32_t, char *);
int			 pf_addr_setup(struct pf_ruleset *,
			    struct pf_addr_wrap *, sa_family_t);
int			 pf_kif_setup(char *, struct pfi_kif **);
void			 pf_addr_copyout(struct pf_addr_wrap *);
void			 pf_trans_set_commit(void);
void			 pf_pool_copyin(struct pf_pool *, struct pf_pool *);
int			 pf_rule_copyin(struct pf_rule *, struct pf_rule *,
			    struct pf_ruleset *);
u_int16_t		 pf_qname2qid(char *, int);
void			 pf_qid2qname(u_int16_t, char *);
void			 pf_qid_unref(u_int16_t);

struct pf_rule		 pf_default_rule, pf_default_rule_new;

struct {
	char		statusif[IFNAMSIZ];
	u_int32_t	debug;
	u_int32_t	hostid;
	u_int32_t	reass;
	u_int32_t	mask;
} pf_trans_set;

#define	PF_TSET_STATUSIF	0x01
#define	PF_TSET_DEBUG		0x02
#define	PF_TSET_HOSTID		0x04
#define	PF_TSET_REASS		0x08

#define	TAGID_MAX	 50000
TAILQ_HEAD(pf_tags, pf_tagname)	pf_tags = TAILQ_HEAD_INITIALIZER(pf_tags),
				pf_qids = TAILQ_HEAD_INITIALIZER(pf_qids);

#if (PF_QNAME_SIZE != PF_TAG_NAME_SIZE)
#error PF_QNAME_SIZE must be equal to PF_TAG_NAME_SIZE
#endif
u_int16_t		 tagname2tag(struct pf_tags *, char *, int);
void			 tag2tagname(struct pf_tags *, u_int16_t, char *);
void			 tag_unref(struct pf_tags *, u_int16_t);
int			 pf_rtlabel_add(struct pf_addr_wrap *);
void			 pf_rtlabel_remove(struct pf_addr_wrap *);
void			 pf_rtlabel_copyout(struct pf_addr_wrap *);


void
pfattach(int num)
{
	u_int32_t *timeout = pf_default_rule.timeout;

	pool_init(&pf_rule_pl, sizeof(struct pf_rule), 0,
	    IPL_SOFTNET, 0, "pfrule", NULL);
	pool_init(&pf_src_tree_pl, sizeof(struct pf_src_node), 0,
	    IPL_SOFTNET, 0, "pfsrctr", NULL);
	pool_init(&pf_sn_item_pl, sizeof(struct pf_sn_item), 0,
	    IPL_SOFTNET, 0, "pfsnitem", NULL);
	pool_init(&pf_state_pl, sizeof(struct pf_state), 0,
	    IPL_SOFTNET, 0, "pfstate", NULL);
	pool_init(&pf_state_key_pl, sizeof(struct pf_state_key), 0,
	    IPL_SOFTNET, 0, "pfstkey", NULL);
	pool_init(&pf_state_item_pl, sizeof(struct pf_state_item), 0,
	    IPL_SOFTNET, 0, "pfstitem", NULL);
	pool_init(&pf_rule_item_pl, sizeof(struct pf_rule_item), 0,
	    IPL_SOFTNET, 0, "pfruleitem", NULL);
	pool_init(&pf_queue_pl, sizeof(struct pf_queuespec), 0,
	    IPL_SOFTNET, 0, "pfqueue", NULL);
	hfsc_initialize();
	pfr_initialize();
	pfi_initialize();
	pf_osfp_initialize();

	pool_sethardlimit(pf_pool_limits[PF_LIMIT_STATES].pp,
	    pf_pool_limits[PF_LIMIT_STATES].limit, NULL, 0);

	if (physmem <= atop(100*1024*1024))
		pf_pool_limits[PF_LIMIT_TABLE_ENTRIES].limit =
		    PFR_KENTRY_HIWAT_SMALL;

	RB_INIT(&tree_src_tracking);
	RB_INIT(&pf_anchors);
	pf_init_ruleset(&pf_main_ruleset);
	TAILQ_INIT(&pf_queues[0]);
	TAILQ_INIT(&pf_queues[1]);
	pf_queues_active = &pf_queues[0];
	pf_queues_inactive = &pf_queues[1];
	TAILQ_INIT(&state_list);

	/* default rule should never be garbage collected */
	pf_default_rule.entries.tqe_prev = &pf_default_rule.entries.tqe_next;
	pf_default_rule.action = PF_PASS;
	pf_default_rule.nr = (u_int32_t)-1;
	pf_default_rule.rtableid = -1;

	/* initialize default timeouts */
	timeout[PFTM_TCP_FIRST_PACKET] = PFTM_TCP_FIRST_PACKET_VAL;
	timeout[PFTM_TCP_OPENING] = PFTM_TCP_OPENING_VAL;
	timeout[PFTM_TCP_ESTABLISHED] = PFTM_TCP_ESTABLISHED_VAL;
	timeout[PFTM_TCP_CLOSING] = PFTM_TCP_CLOSING_VAL;
	timeout[PFTM_TCP_FIN_WAIT] = PFTM_TCP_FIN_WAIT_VAL;
	timeout[PFTM_TCP_CLOSED] = PFTM_TCP_CLOSED_VAL;
	timeout[PFTM_UDP_FIRST_PACKET] = PFTM_UDP_FIRST_PACKET_VAL;
	timeout[PFTM_UDP_SINGLE] = PFTM_UDP_SINGLE_VAL;
	timeout[PFTM_UDP_MULTIPLE] = PFTM_UDP_MULTIPLE_VAL;
	timeout[PFTM_ICMP_FIRST_PACKET] = PFTM_ICMP_FIRST_PACKET_VAL;
	timeout[PFTM_ICMP_ERROR_REPLY] = PFTM_ICMP_ERROR_REPLY_VAL;
	timeout[PFTM_OTHER_FIRST_PACKET] = PFTM_OTHER_FIRST_PACKET_VAL;
	timeout[PFTM_OTHER_SINGLE] = PFTM_OTHER_SINGLE_VAL;
	timeout[PFTM_OTHER_MULTIPLE] = PFTM_OTHER_MULTIPLE_VAL;
	timeout[PFTM_FRAG] = PFTM_FRAG_VAL;
	timeout[PFTM_INTERVAL] = PFTM_INTERVAL_VAL;
	timeout[PFTM_SRC_NODE] = PFTM_SRC_NODE_VAL;
	timeout[PFTM_TS_DIFF] = PFTM_TS_DIFF_VAL;
	timeout[PFTM_ADAPTIVE_START] = PFSTATE_ADAPT_START;
	timeout[PFTM_ADAPTIVE_END] = PFSTATE_ADAPT_END;

	pf_default_rule.src.addr.type =  PF_ADDR_ADDRMASK;
	pf_default_rule.dst.addr.type =  PF_ADDR_ADDRMASK;
	pf_default_rule.rdr.addr.type =  PF_ADDR_NONE;
	pf_default_rule.nat.addr.type =  PF_ADDR_NONE;
	pf_default_rule.route.addr.type =  PF_ADDR_NONE;

	pf_normalize_init();
	bzero(&pf_status, sizeof(pf_status));
	pf_status.debug = LOG_ERR;
	pf_status.reass = PF_REASS_ENABLED;

	/* XXX do our best to avoid a conflict */
	pf_status.hostid = arc4random();

	/* require process context to purge states, so perform in a thread */
	kthread_create_deferred(pf_thread_create, NULL);
}

void
pf_thread_create(void *v)
{
	if (kthread_create(pf_purge_thread, NULL, NULL, "pfpurge"))
		panic("pfpurge thread");
}

int
pfopen(dev_t dev, int flags, int fmt, struct proc *p)
{
	if (minor(dev) >= 1)
		return (ENXIO);
	return (0);
}

int
pfclose(dev_t dev, int flags, int fmt, struct proc *p)
{
	if (minor(dev) >= 1)
		return (ENXIO);
	return (0);
}

void
pf_rm_rule(struct pf_rulequeue *rulequeue, struct pf_rule *rule)
{
	if (rulequeue != NULL) {
		if (rule->states_cur == 0 && rule->src_nodes == 0) {
			/*
			 * XXX - we need to remove the table *before* detaching
			 * the rule to make sure the table code does not delete
			 * the anchor under our feet.
			 */
			pf_tbladdr_remove(&rule->src.addr);
			pf_tbladdr_remove(&rule->dst.addr);
			pf_tbladdr_remove(&rule->rdr.addr);
			pf_tbladdr_remove(&rule->nat.addr);
			pf_tbladdr_remove(&rule->route.addr);
			if (rule->overload_tbl)
				pfr_detach_table(rule->overload_tbl);
		}
		TAILQ_REMOVE(rulequeue, rule, entries);
		rule->entries.tqe_prev = NULL;
		rule->nr = (u_int32_t)-1;
	}

	if (rule->states_cur > 0 || rule->src_nodes > 0 ||
	    rule->entries.tqe_prev != NULL)
		return;
	pf_tag_unref(rule->tag);
	pf_tag_unref(rule->match_tag);
	pf_rtlabel_remove(&rule->src.addr);
	pf_rtlabel_remove(&rule->dst.addr);
	pfi_dynaddr_remove(&rule->src.addr);
	pfi_dynaddr_remove(&rule->dst.addr);
	pfi_dynaddr_remove(&rule->rdr.addr);
	pfi_dynaddr_remove(&rule->nat.addr);
	pfi_dynaddr_remove(&rule->route.addr);
	if (rulequeue == NULL) {
		pf_tbladdr_remove(&rule->src.addr);
		pf_tbladdr_remove(&rule->dst.addr);
		pf_tbladdr_remove(&rule->rdr.addr);
		pf_tbladdr_remove(&rule->nat.addr);
		pf_tbladdr_remove(&rule->route.addr);
		if (rule->overload_tbl)
			pfr_detach_table(rule->overload_tbl);
	}
	pfi_kif_unref(rule->rcv_kif, PFI_KIF_REF_RULE);
	pfi_kif_unref(rule->kif, PFI_KIF_REF_RULE);
	pfi_kif_unref(rule->rdr.kif, PFI_KIF_REF_RULE);
	pfi_kif_unref(rule->nat.kif, PFI_KIF_REF_RULE);
	pfi_kif_unref(rule->route.kif, PFI_KIF_REF_RULE);
	pf_anchor_remove(rule);
	pool_put(&pf_rule_pl, rule);
}

void
pf_purge_rule(struct pf_rule *rule)
{
	u_int32_t		 nr = 0;
	struct pf_ruleset	*ruleset;

	KASSERT((rule != NULL) && (rule->ruleset != NULL));
	ruleset = rule->ruleset;

	pf_rm_rule(ruleset->rules.active.ptr, rule);
	ruleset->rules.active.rcount--;
	TAILQ_FOREACH(rule, ruleset->rules.active.ptr, entries)
		rule->nr = nr++;
	ruleset->rules.active.ticket++;
	pf_calc_skip_steps(ruleset->rules.active.ptr);
	pf_remove_if_empty_ruleset(ruleset);
}

u_int16_t
tagname2tag(struct pf_tags *head, char *tagname, int create)
{
	struct pf_tagname	*tag, *p = NULL;
	u_int16_t		 new_tagid = 1;

	TAILQ_FOREACH(tag, head, entries)
		if (strcmp(tagname, tag->name) == 0) {
			tag->ref++;
			return (tag->tag);
		}

	if (!create)
		return (0);

	/*
	 * to avoid fragmentation, we do a linear search from the beginning
	 * and take the first free slot we find. if there is none or the list
	 * is empty, append a new entry at the end.
	 */

	/* new entry */
	if (!TAILQ_EMPTY(head))
		for (p = TAILQ_FIRST(head); p != NULL &&
		    p->tag == new_tagid; p = TAILQ_NEXT(p, entries))
			new_tagid = p->tag + 1;

	if (new_tagid > TAGID_MAX)
		return (0);

	/* allocate and fill new struct pf_tagname */
	tag = malloc(sizeof(*tag), M_RTABLE, M_NOWAIT|M_ZERO);
	if (tag == NULL)
		return (0);
	strlcpy(tag->name, tagname, sizeof(tag->name));
	tag->tag = new_tagid;
	tag->ref++;

	if (p != NULL)	/* insert new entry before p */
		TAILQ_INSERT_BEFORE(p, tag, entries);
	else	/* either list empty or no free slot in between */
		TAILQ_INSERT_TAIL(head, tag, entries);

	return (tag->tag);
}

void
tag2tagname(struct pf_tags *head, u_int16_t tagid, char *p)
{
	struct pf_tagname	*tag;

	TAILQ_FOREACH(tag, head, entries)
		if (tag->tag == tagid) {
			strlcpy(p, tag->name, PF_TAG_NAME_SIZE);
			return;
		}
}

void
tag_unref(struct pf_tags *head, u_int16_t tag)
{
	struct pf_tagname	*p, *next;

	if (tag == 0)
		return;

	for (p = TAILQ_FIRST(head); p != NULL; p = next) {
		next = TAILQ_NEXT(p, entries);
		if (tag == p->tag) {
			if (--p->ref == 0) {
				TAILQ_REMOVE(head, p, entries);
				free(p, M_RTABLE, sizeof(*p));
			}
			break;
		}
	}
}

u_int16_t
pf_tagname2tag(char *tagname, int create)
{
	return (tagname2tag(&pf_tags, tagname, create));
}

void
pf_tag2tagname(u_int16_t tagid, char *p)
{
	tag2tagname(&pf_tags, tagid, p);
}

void
pf_tag_ref(u_int16_t tag)
{
	struct pf_tagname *t;

	TAILQ_FOREACH(t, &pf_tags, entries)
		if (t->tag == tag)
			break;
	if (t != NULL)
		t->ref++;
}

void
pf_tag_unref(u_int16_t tag)
{
	tag_unref(&pf_tags, tag);
}

int
pf_rtlabel_add(struct pf_addr_wrap *a)
{
	if (a->type == PF_ADDR_RTLABEL &&
	    (a->v.rtlabel = rtlabel_name2id(a->v.rtlabelname)) == 0)
		return (-1);
	return (0);
}

void
pf_rtlabel_remove(struct pf_addr_wrap *a)
{
	if (a->type == PF_ADDR_RTLABEL)
		rtlabel_unref(a->v.rtlabel);
}

void
pf_rtlabel_copyout(struct pf_addr_wrap *a)
{
	const char	*name;

	if (a->type == PF_ADDR_RTLABEL && a->v.rtlabel) {
		if ((name = rtlabel_id2name(a->v.rtlabel)) == NULL)
			strlcpy(a->v.rtlabelname, "?",
			    sizeof(a->v.rtlabelname));
		else
			strlcpy(a->v.rtlabelname, name,
			    sizeof(a->v.rtlabelname));
	}
}

u_int16_t
pf_qname2qid(char *qname, int create)
{
	return (tagname2tag(&pf_qids, qname, create));
}

void
pf_qid2qname(u_int16_t qid, char *p)
{
	tag2tagname(&pf_qids, qid, p);
}

void
pf_qid_unref(u_int16_t qid)
{
	tag_unref(&pf_qids, (u_int16_t)qid);
}

int
pf_begin_rules(u_int32_t *ticket, const char *anchor)
{
	struct pf_ruleset	*rs;
	struct pf_rule		*rule;

	if ((rs = pf_find_or_create_ruleset(anchor)) == NULL)
		return (EINVAL);
	while ((rule = TAILQ_FIRST(rs->rules.inactive.ptr)) != NULL) {
		pf_rm_rule(rs->rules.inactive.ptr, rule);
		rs->rules.inactive.rcount--;
	}
	*ticket = ++rs->rules.inactive.ticket;
	rs->rules.inactive.open = 1;
	return (0);
}

int
pf_rollback_rules(u_int32_t ticket, char *anchor)
{
	struct pf_ruleset	*rs;
	struct pf_rule		*rule;

	rs = pf_find_ruleset(anchor);
	if (rs == NULL || !rs->rules.inactive.open ||
	    rs->rules.inactive.ticket != ticket)
		return (0);
	while ((rule = TAILQ_FIRST(rs->rules.inactive.ptr)) != NULL) {
		pf_rm_rule(rs->rules.inactive.ptr, rule);
		rs->rules.inactive.rcount--;
	}
	rs->rules.inactive.open = 0;

	/* queue defs only in the main ruleset */
	if (anchor[0])
		return (0);

	pf_free_queues(pf_queues_inactive);

	return (0);
}

void
pf_free_queues(struct pf_queuehead *where)
{
	struct pf_queuespec	*q, *qtmp;

	TAILQ_FOREACH_SAFE(q, where, entries, qtmp) {
		TAILQ_REMOVE(where, q, entries);
		pfi_kif_unref(q->kif, PFI_KIF_REF_RULE);
		pool_put(&pf_queue_pl, q);
	}
}

void
pf_remove_queues(void)
{
	struct pf_queuespec	*q;
	struct ifnet		*ifp;

	/* put back interfaces in normal queueing mode */
	TAILQ_FOREACH(q, pf_queues_active, entries) {
		if (q->parent_qid != 0)
			continue;

		ifp = q->kif->pfik_ifp;
		if (ifp == NULL)
			continue;

		ifq_attach(&ifp->if_snd, ifq_priq_ops, NULL);
	}
}

struct pf_queue_if {
	struct ifnet		*ifp;
	const struct ifq_ops	*ifqops;
	const struct pfq_ops	*pfqops;
	void			*disc;
	struct pf_queue_if	*next;
};

static inline struct pf_queue_if *
pf_ifp2q(struct pf_queue_if *list, struct ifnet *ifp)
{
	struct pf_queue_if *qif = list;

	while (qif != NULL) {
		if (qif->ifp == ifp)
			return (qif);

		qif = qif->next;
	}

	return (qif);
}

int
pf_create_queues(void)
{
	struct pf_queuespec	*q;
	struct ifnet		*ifp;
	struct pf_queue_if		*list = NULL, *qif;
	int			 error;

	/*
	 * Find root queues and allocate traffic conditioner
	 * private data for these interfaces
	 */
	TAILQ_FOREACH(q, pf_queues_active, entries) {
		if (q->parent_qid != 0)
			continue;

		ifp = q->kif->pfik_ifp;
		if (ifp == NULL)
			continue;

		qif = malloc(sizeof(*qif), M_TEMP, M_WAITOK);
		qif->ifp = ifp;

		if (q->flags & PFQS_FLOWQUEUE) {
			qif->ifqops = ifq_fqcodel_ops;
			qif->pfqops = pfq_fqcodel_ops;
		} else {
			qif->ifqops = ifq_hfsc_ops;
			qif->pfqops = pfq_hfsc_ops;
		}

		qif->disc = qif->pfqops->pfq_alloc(ifp);

		qif->next = list;
		list = qif;
	}

	/* and now everything */
	TAILQ_FOREACH(q, pf_queues_active, entries) {
		ifp = q->kif->pfik_ifp;
		if (ifp == NULL)
			continue;

		qif = pf_ifp2q(list, ifp);
		KASSERT(qif != NULL);

		error = qif->pfqops->pfq_addqueue(qif->disc, q);
		if (error != 0)
			goto error;
	}

	/* find root queues in old list to disable them if necessary */
	TAILQ_FOREACH(q, pf_queues_inactive, entries) {
		if (q->parent_qid != 0)
			continue;

		ifp = q->kif->pfik_ifp;
		if (ifp == NULL)
			continue;

		qif = pf_ifp2q(list, ifp);
		if (qif != NULL)
			continue;

		ifq_attach(&ifp->if_snd, ifq_priq_ops, NULL);
	}

	/* commit the new queues */
	while (list != NULL) {
		qif = list;
		list = qif->next;

		ifp = qif->ifp;

		ifq_attach(&ifp->if_snd, qif->ifqops, qif->disc);
		free(qif, M_TEMP, sizeof(*qif));
	}

	return (0);

error:
	while (list != NULL) {
		qif = list;
		list = qif->next;

		qif->pfqops->pfq_free(qif->disc);
		free(qif, M_TEMP, sizeof(*qif));
	}

	return (error);
}

int
pf_commit_queues(void)
{
	struct pf_queuehead	*qswap;
	int error;

        /* swap */
        qswap = pf_queues_active;
        pf_queues_active = pf_queues_inactive;
        pf_queues_inactive = qswap;

	error = pf_create_queues();
	if (error != 0) {
		pf_queues_inactive = pf_queues_active;
		pf_queues_active = qswap;
		return (error);
	}

        pf_free_queues(pf_queues_inactive);

	return (0);
}

#define PF_MD5_UPD(st, elm)						\
		MD5Update(ctx, (u_int8_t *) &(st)->elm, sizeof((st)->elm))

#define PF_MD5_UPD_STR(st, elm)						\
		MD5Update(ctx, (u_int8_t *) (st)->elm, strlen((st)->elm))

#define PF_MD5_UPD_HTONL(st, elm, stor) do {				\
		(stor) = htonl((st)->elm);				\
		MD5Update(ctx, (u_int8_t *) &(stor), sizeof(u_int32_t));\
} while (0)

#define PF_MD5_UPD_HTONS(st, elm, stor) do {				\
		(stor) = htons((st)->elm);				\
		MD5Update(ctx, (u_int8_t *) &(stor), sizeof(u_int16_t));\
} while (0)

void
pf_hash_rule_addr(MD5_CTX *ctx, struct pf_rule_addr *pfr)
{
	PF_MD5_UPD(pfr, addr.type);
	switch (pfr->addr.type) {
		case PF_ADDR_DYNIFTL:
			PF_MD5_UPD(pfr, addr.v.ifname);
			PF_MD5_UPD(pfr, addr.iflags);
			break;
		case PF_ADDR_TABLE:
			PF_MD5_UPD(pfr, addr.v.tblname);
			break;
		case PF_ADDR_ADDRMASK:
			/* XXX ignore af? */
			PF_MD5_UPD(pfr, addr.v.a.addr.addr32);
			PF_MD5_UPD(pfr, addr.v.a.mask.addr32);
			break;
		case PF_ADDR_RTLABEL:
			PF_MD5_UPD(pfr, addr.v.rtlabelname);
			break;
	}

	PF_MD5_UPD(pfr, port[0]);
	PF_MD5_UPD(pfr, port[1]);
	PF_MD5_UPD(pfr, neg);
	PF_MD5_UPD(pfr, port_op);
}

void
pf_hash_rule(MD5_CTX *ctx, struct pf_rule *rule)
{
	u_int16_t x;
	u_int32_t y;

	pf_hash_rule_addr(ctx, &rule->src);
	pf_hash_rule_addr(ctx, &rule->dst);
	PF_MD5_UPD_STR(rule, label);
	PF_MD5_UPD_STR(rule, ifname);
	PF_MD5_UPD_STR(rule, rcv_ifname);
	PF_MD5_UPD_STR(rule, match_tagname);
	PF_MD5_UPD_HTONS(rule, match_tag, x); /* dup? */
	PF_MD5_UPD_HTONL(rule, os_fingerprint, y);
	PF_MD5_UPD_HTONL(rule, prob, y);
	PF_MD5_UPD_HTONL(rule, uid.uid[0], y);
	PF_MD5_UPD_HTONL(rule, uid.uid[1], y);
	PF_MD5_UPD(rule, uid.op);
	PF_MD5_UPD_HTONL(rule, gid.gid[0], y);
	PF_MD5_UPD_HTONL(rule, gid.gid[1], y);
	PF_MD5_UPD(rule, gid.op);
	PF_MD5_UPD_HTONL(rule, rule_flag, y);
	PF_MD5_UPD(rule, action);
	PF_MD5_UPD(rule, direction);
	PF_MD5_UPD(rule, af);
	PF_MD5_UPD(rule, quick);
	PF_MD5_UPD(rule, ifnot);
	PF_MD5_UPD(rule, rcvifnot);
	PF_MD5_UPD(rule, match_tag_not);
	PF_MD5_UPD(rule, keep_state);
	PF_MD5_UPD(rule, proto);
	PF_MD5_UPD(rule, type);
	PF_MD5_UPD(rule, code);
	PF_MD5_UPD(rule, flags);
	PF_MD5_UPD(rule, flagset);
	PF_MD5_UPD(rule, allow_opts);
	PF_MD5_UPD(rule, rt);
	PF_MD5_UPD(rule, tos);
}

int
pf_commit_rules(u_int32_t ticket, char *anchor)
{
	struct pf_ruleset	*rs;
	struct pf_rule		*rule, **old_array;
	struct pf_rulequeue	*old_rules;
	int			 error;
	u_int32_t		 old_rcount;

	/* Make sure any expired rules get removed from active rules first. */
	pf_purge_expired_rules(1);

	rs = pf_find_ruleset(anchor);
	if (rs == NULL || !rs->rules.inactive.open ||
	    ticket != rs->rules.inactive.ticket)
		return (EBUSY);

	/* Calculate checksum for the main ruleset */
	if (rs == &pf_main_ruleset) {
		error = pf_setup_pfsync_matching(rs);
		if (error != 0)
			return (error);
	}

	/* Swap rules, keep the old. */
	old_rules = rs->rules.active.ptr;
	old_rcount = rs->rules.active.rcount;
	old_array = rs->rules.active.ptr_array;

	rs->rules.active.ptr = rs->rules.inactive.ptr;
	rs->rules.active.ptr_array = rs->rules.inactive.ptr_array;
	rs->rules.active.rcount = rs->rules.inactive.rcount;
	rs->rules.inactive.ptr = old_rules;
	rs->rules.inactive.ptr_array = old_array;
	rs->rules.inactive.rcount = old_rcount;

	rs->rules.active.ticket = rs->rules.inactive.ticket;
	pf_calc_skip_steps(rs->rules.active.ptr);


	/* Purge the old rule list. */
	while ((rule = TAILQ_FIRST(old_rules)) != NULL)
		pf_rm_rule(old_rules, rule);
	if (rs->rules.inactive.ptr_array)
		free(rs->rules.inactive.ptr_array, M_TEMP, 0);
	rs->rules.inactive.ptr_array = NULL;
	rs->rules.inactive.rcount = 0;
	rs->rules.inactive.open = 0;
	pf_remove_if_empty_ruleset(rs);

	/* queue defs only in the main ruleset */
	if (anchor[0])
		return (0);
	return (pf_commit_queues());
}

int
pf_setup_pfsync_matching(struct pf_ruleset *rs)
{
	MD5_CTX			 ctx;
	struct pf_rule		*rule;
	u_int8_t		 digest[PF_MD5_DIGEST_LENGTH];

	MD5Init(&ctx);
	if (rs->rules.inactive.ptr_array)
		free(rs->rules.inactive.ptr_array, M_TEMP, 0);
	rs->rules.inactive.ptr_array = NULL;

	if (rs->rules.inactive.rcount) {
		rs->rules.inactive.ptr_array =
		    mallocarray(rs->rules.inactive.rcount, sizeof(caddr_t),
		    M_TEMP, M_NOWAIT);

		if (!rs->rules.inactive.ptr_array)
			return (ENOMEM);

		TAILQ_FOREACH(rule, rs->rules.inactive.ptr, entries) {
			pf_hash_rule(&ctx, rule);
			(rs->rules.inactive.ptr_array)[rule->nr] = rule;
		}
	}

	MD5Final(digest, &ctx);
	memcpy(pf_status.pf_chksum, digest, sizeof(pf_status.pf_chksum));
	return (0);
}

int
pf_addr_setup(struct pf_ruleset *ruleset, struct pf_addr_wrap *addr,
    sa_family_t af)
{
	if (pfi_dynaddr_setup(addr, af) ||
	    pf_tbladdr_setup(ruleset, addr) ||
	    pf_rtlabel_add(addr))
		return (EINVAL);

	return (0);
}

int
pf_kif_setup(char *ifname, struct pfi_kif **kif)
{
	if (ifname[0]) {
		*kif = pfi_kif_get(ifname);
		if (*kif == NULL)
			return (EINVAL);

		pfi_kif_ref(*kif, PFI_KIF_REF_RULE);
	} else
		*kif = NULL;

	return (0);
}

void
pf_addr_copyout(struct pf_addr_wrap *addr)
{
	pfi_dynaddr_copyout(addr);
	pf_tbladdr_copyout(addr);
	pf_rtlabel_copyout(addr);
}

int
pfioctl(dev_t dev, u_long cmd, caddr_t addr, int flags, struct proc *p)
{
	int			 s;
	int			 error = 0;

	/* XXX keep in sync with switch() below */
	if (securelevel > 1)
		switch (cmd) {
		case DIOCGETRULES:
		case DIOCGETRULE:
		case DIOCGETSTATE:
		case DIOCSETSTATUSIF:
		case DIOCGETSTATUS:
		case DIOCCLRSTATUS:
		case DIOCNATLOOK:
		case DIOCSETDEBUG:
		case DIOCGETSTATES:
		case DIOCGETTIMEOUT:
		case DIOCGETLIMIT:
		case DIOCGETRULESETS:
		case DIOCGETRULESET:
		case DIOCGETQUEUES:
		case DIOCGETQUEUE:
		case DIOCGETQSTATS:
		case DIOCRGETTABLES:
		case DIOCRGETTSTATS:
		case DIOCRCLRTSTATS:
		case DIOCRCLRADDRS:
		case DIOCRADDADDRS:
		case DIOCRDELADDRS:
		case DIOCRSETADDRS:
		case DIOCRGETASTATS:
		case DIOCRCLRASTATS:
		case DIOCRTSTADDRS:
		case DIOCOSFPGET:
		case DIOCGETSRCNODES:
		case DIOCCLRSRCNODES:
		case DIOCIGETIFACES:
		case DIOCSETIFFLAG:
		case DIOCCLRIFFLAG:
			break;
		case DIOCRCLRTABLES:
		case DIOCRADDTABLES:
		case DIOCRDELTABLES:
		case DIOCRSETTFLAGS:
			if (((struct pfioc_table *)addr)->pfrio_flags &
			    PFR_FLAG_DUMMY)
				break; /* dummy operation ok */
			return (EPERM);
		default:
			return (EPERM);
		}

	if (!(flags & FWRITE))
		switch (cmd) {
		case DIOCGETRULES:
		case DIOCGETSTATE:
		case DIOCGETSTATUS:
		case DIOCGETSTATES:
		case DIOCGETTIMEOUT:
		case DIOCGETLIMIT:
		case DIOCGETRULESETS:
		case DIOCGETRULESET:
		case DIOCGETQUEUES:
		case DIOCGETQUEUE:
		case DIOCGETQSTATS:
		case DIOCNATLOOK:
		case DIOCRGETTABLES:
		case DIOCRGETTSTATS:
		case DIOCRGETADDRS:
		case DIOCRGETASTATS:
		case DIOCRTSTADDRS:
		case DIOCOSFPGET:
		case DIOCGETSRCNODES:
		case DIOCIGETIFACES:
			break;
		case DIOCRCLRTABLES:
		case DIOCRADDTABLES:
		case DIOCRDELTABLES:
		case DIOCRCLRTSTATS:
		case DIOCRCLRADDRS:
		case DIOCRADDADDRS:
		case DIOCRDELADDRS:
		case DIOCRSETADDRS:
		case DIOCRSETTFLAGS:
			if (((struct pfioc_table *)addr)->pfrio_flags &
			    PFR_FLAG_DUMMY) {
				flags |= FWRITE; /* need write lock for dummy */
				break; /* dummy operation ok */
			}
			return (EACCES);
		case DIOCGETRULE:
			if (((struct pfioc_rule *)addr)->action ==
			    PF_GET_CLR_CNTR)
				return (EACCES);
			break;
		default:
			return (EACCES);
		}

	NET_LOCK(s);
	switch (cmd) {

	case DIOCSTART:
		if (pf_status.running)
			error = EEXIST;
		else {
			pf_status.running = 1;
			pf_status.since = time_uptime;
			if (pf_status.stateid == 0) {
				pf_status.stateid = time_second;
				pf_status.stateid = pf_status.stateid << 32;
			}
			pf_create_queues();
			DPFPRINTF(LOG_NOTICE, "pf: started");
		}
		break;

	case DIOCSTOP:
		if (!pf_status.running)
			error = ENOENT;
		else {
			pf_status.running = 0;
			pf_status.since = time_uptime;
			pf_remove_queues();
			DPFPRINTF(LOG_NOTICE, "pf: stopped");
		}
		break;

	case DIOCGETQUEUES: {
		struct pfioc_queue	*pq = (struct pfioc_queue *)addr;
		struct pf_queuespec	*qs;
		u_int32_t		 nr = 0;

		pq->ticket = pf_main_ruleset.rules.active.ticket;

		/* save state to not run over them all each time? */
		qs = TAILQ_FIRST(pf_queues_active);
		while (qs != NULL) {
			qs = TAILQ_NEXT(qs, entries);
			nr++;
		}
		pq->nr = nr;
		break;
	}

	case DIOCGETQUEUE: {
		struct pfioc_queue	*pq = (struct pfioc_queue *)addr;
		struct pf_queuespec	*qs;
		u_int32_t		 nr = 0;

		if (pq->ticket != pf_main_ruleset.rules.active.ticket) {
			error = EBUSY;
			break;
		}

		/* save state to not run over them all each time? */
		qs = TAILQ_FIRST(pf_queues_active);
		while ((qs != NULL) && (nr++ < pq->nr))
			qs = TAILQ_NEXT(qs, entries);
		if (qs == NULL) {
			error = EBUSY;
			break;
		}
		bcopy(qs, &pq->queue, sizeof(pq->queue));
		break;
	}

	case DIOCGETQSTATS: {
		struct pfioc_qstats	*pq = (struct pfioc_qstats *)addr;
		struct pf_queuespec	*qs;
		u_int32_t		 nr;
		int			 nbytes;

		if (pq->ticket != pf_main_ruleset.rules.active.ticket) {
			error = EBUSY;
			break;
		}
		nbytes = pq->nbytes;
		nr = 0;

		/* save state to not run over them all each time? */
		qs = TAILQ_FIRST(pf_queues_active);
		while ((qs != NULL) && (nr++ < pq->nr))
			qs = TAILQ_NEXT(qs, entries);
		if (qs == NULL) {
			error = EBUSY;
			break;
		}
		bcopy(qs, &pq->queue, sizeof(pq->queue));
		if (qs->flags & PFQS_FLOWQUEUE)
			error = pfq_fqcodel_ops->pfq_qstats(qs, pq->buf,
			    &nbytes);
		else
			error = pfq_hfsc_ops->pfq_qstats(qs, pq->buf,
			    &nbytes);
		if (error == 0)
			pq->nbytes = nbytes;
		break;
	}

	case DIOCADDQUEUE: {
		struct pfioc_queue	*q = (struct pfioc_queue *)addr;
		struct pf_queuespec	*qs;

		if (q->ticket != pf_main_ruleset.rules.inactive.ticket) {
			error = EBUSY;
			break;
		}
		qs = pool_get(&pf_queue_pl, PR_WAITOK|PR_LIMITFAIL|PR_ZERO);
		if (qs == NULL) {
			error = ENOMEM;
			break;
		}
		bcopy(&q->queue, qs, sizeof(*qs));
		qs->qid = pf_qname2qid(qs->qname, 1);
		if (qs->parent[0] && (qs->parent_qid =
		    pf_qname2qid(qs->parent, 0)) == 0) {
			pool_put(&pf_queue_pl, qs);
			error = ESRCH;
			break;
		}
		qs->kif = pfi_kif_get(qs->ifname);
		if (qs->kif == NULL) {
			pool_put(&pf_queue_pl, qs);
			error = ESRCH;
			break;
		}
		/* XXX resolve bw percentage specs */
		pfi_kif_ref(qs->kif, PFI_KIF_REF_RULE);

		TAILQ_INSERT_TAIL(pf_queues_inactive, qs, entries);

		break;
	}

	case DIOCADDRULE: {
		struct pfioc_rule	*pr = (struct pfioc_rule *)addr;
		struct pf_ruleset	*ruleset;
		struct pf_rule		*rule, *tail;

		pr->anchor[sizeof(pr->anchor) - 1] = 0;
		ruleset = pf_find_ruleset(pr->anchor);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		if (pr->rule.return_icmp >> 8 > ICMP_MAXTYPE) {
			error = EINVAL;
			break;
		}
		if (pr->ticket != ruleset->rules.inactive.ticket) {
			error = EBUSY;
			break;
		}
		rule = pool_get(&pf_rule_pl, PR_WAITOK|PR_LIMITFAIL|PR_ZERO);
		if (rule == NULL) {
			error = ENOMEM;
			break;
		}
		if ((error = pf_rule_copyin(&pr->rule, rule, ruleset))) {
			pf_rm_rule(NULL, rule);
			rule = NULL;
			break;
		}
		rule->cuid = p->p_ucred->cr_ruid;
		rule->cpid = p->p_p->ps_pid;

		switch (rule->af) {
		case 0:
			break;
		case AF_INET:
			break;
#ifdef INET6
		case AF_INET6:
			break;
#endif /* INET6 */
		default:
			pf_rm_rule(NULL, rule);
			rule = NULL;
			error = EAFNOSUPPORT;
			goto fail;
		}
		tail = TAILQ_LAST(ruleset->rules.inactive.ptr,
		    pf_rulequeue);
		if (tail)
			rule->nr = tail->nr + 1;
		else
			rule->nr = 0;

		if (rule->src.addr.type == PF_ADDR_NONE ||
		    rule->dst.addr.type == PF_ADDR_NONE)
			error = EINVAL;

		if (pf_addr_setup(ruleset, &rule->src.addr, rule->af))
			error = EINVAL;
		if (pf_addr_setup(ruleset, &rule->dst.addr, rule->af))
			error = EINVAL;
		if (pf_addr_setup(ruleset, &rule->rdr.addr, rule->af))
			error = EINVAL;
		if (pf_addr_setup(ruleset, &rule->nat.addr, rule->af))
			error = EINVAL;
		if (pf_addr_setup(ruleset, &rule->route.addr, rule->af))
			error = EINVAL;
		if (pf_anchor_setup(rule, ruleset, pr->anchor_call))
			error = EINVAL;
		if (rule->rt && !rule->direction)
			error = EINVAL;
		if (rule->scrub_flags & PFSTATE_SETPRIO &&
		    (rule->set_prio[0] > IFQ_MAXPRIO ||
		    rule->set_prio[1] > IFQ_MAXPRIO))
			error = EINVAL;

		if (error) {
			pf_rm_rule(NULL, rule);
			break;
		}
		TAILQ_INSERT_TAIL(ruleset->rules.inactive.ptr,
		    rule, entries);
		rule->ruleset = ruleset;
		ruleset->rules.inactive.rcount++;
		break;
	}

	case DIOCGETRULES: {
		struct pfioc_rule	*pr = (struct pfioc_rule *)addr;
		struct pf_ruleset	*ruleset;
		struct pf_rule		*tail;

		pr->anchor[sizeof(pr->anchor) - 1] = 0;
		ruleset = pf_find_ruleset(pr->anchor);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		tail = TAILQ_LAST(ruleset->rules.active.ptr, pf_rulequeue);
		if (tail)
			pr->nr = tail->nr + 1;
		else
			pr->nr = 0;
		pr->ticket = ruleset->rules.active.ticket;
		break;
	}

	case DIOCGETRULE: {
		struct pfioc_rule	*pr = (struct pfioc_rule *)addr;
		struct pf_ruleset	*ruleset;
		struct pf_rule		*rule;
		int			 i;

		pr->anchor[sizeof(pr->anchor) - 1] = 0;
		ruleset = pf_find_ruleset(pr->anchor);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		if (pr->ticket != ruleset->rules.active.ticket) {
			error = EBUSY;
			break;
		}
		rule = TAILQ_FIRST(ruleset->rules.active.ptr);
		while ((rule != NULL) && (rule->nr != pr->nr))
			rule = TAILQ_NEXT(rule, entries);
		if (rule == NULL) {
			error = EBUSY;
			break;
		}
		bcopy(rule, &pr->rule, sizeof(struct pf_rule));
		bzero(&pr->rule.entries, sizeof(pr->rule.entries));
		pr->rule.kif = NULL;
		pr->rule.nat.kif = NULL;
		pr->rule.rdr.kif = NULL;
		pr->rule.route.kif = NULL;
		pr->rule.rcv_kif = NULL;
		pr->rule.anchor = NULL;
		pr->rule.overload_tbl = NULL;
		bzero(&pr->rule.gcle, sizeof(pr->rule.gcle));
		pr->rule.ruleset = NULL;
		if (pf_anchor_copyout(ruleset, rule, pr)) {
			error = EBUSY;
			break;
		}
		pf_addr_copyout(&pr->rule.src.addr);
		pf_addr_copyout(&pr->rule.dst.addr);
		pf_addr_copyout(&pr->rule.rdr.addr);
		pf_addr_copyout(&pr->rule.nat.addr);
		pf_addr_copyout(&pr->rule.route.addr);
		for (i = 0; i < PF_SKIP_COUNT; ++i)
			if (rule->skip[i].ptr == NULL)
				pr->rule.skip[i].nr = (u_int32_t)-1;
			else
				pr->rule.skip[i].nr =
				    rule->skip[i].ptr->nr;

		if (pr->action == PF_GET_CLR_CNTR) {
			rule->evaluations = 0;
			rule->packets[0] = rule->packets[1] = 0;
			rule->bytes[0] = rule->bytes[1] = 0;
			rule->states_tot = 0;
		}
		break;
	}

	case DIOCCHANGERULE: {
		struct pfioc_rule	*pcr = (struct pfioc_rule *)addr;
		struct pf_ruleset	*ruleset;
		struct pf_rule		*oldrule = NULL, *newrule = NULL;
		u_int32_t		 nr = 0;

		if (pcr->action < PF_CHANGE_ADD_HEAD ||
		    pcr->action > PF_CHANGE_GET_TICKET) {
			error = EINVAL;
			break;
		}
		ruleset = pf_find_ruleset(pcr->anchor);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}

		if (pcr->action == PF_CHANGE_GET_TICKET) {
			pcr->ticket = ++ruleset->rules.active.ticket;
			break;
		} else {
			if (pcr->ticket !=
			    ruleset->rules.active.ticket) {
				error = EINVAL;
				break;
			}
			if (pcr->rule.return_icmp >> 8 > ICMP_MAXTYPE) {
				error = EINVAL;
				break;
			}
		}

		if (pcr->action != PF_CHANGE_REMOVE) {
			newrule = pool_get(&pf_rule_pl,
			    PR_WAITOK|PR_LIMITFAIL|PR_ZERO);
			if (newrule == NULL) {
				error = ENOMEM;
				break;
			}
			pf_rule_copyin(&pcr->rule, newrule, ruleset);
			newrule->cuid = p->p_ucred->cr_ruid;
			newrule->cpid = p->p_p->ps_pid;

			switch (newrule->af) {
			case 0:
				break;
			case AF_INET:
				break;
#ifdef INET6
			case AF_INET6:
				break;
#endif /* INET6 */
			default:
				pool_put(&pf_rule_pl, newrule);
				error = EAFNOSUPPORT;
				goto fail;
			}

			if (newrule->rt && !newrule->direction)
				error = EINVAL;
			if (pf_addr_setup(ruleset, &newrule->src.addr, newrule->af))
				error = EINVAL;
			if (pf_addr_setup(ruleset, &newrule->dst.addr, newrule->af))
				error = EINVAL;
			if (pf_addr_setup(ruleset, &newrule->rdr.addr, newrule->af))
				error = EINVAL;
			if (pf_addr_setup(ruleset, &newrule->nat.addr, newrule->af))
				error = EINVAL;
			if (pf_addr_setup(ruleset, &newrule->route.addr, newrule->af))
				error = EINVAL;
			if (pf_anchor_setup(newrule, ruleset, pcr->anchor_call))
				error = EINVAL;

			if (error) {
				pf_rm_rule(NULL, newrule);
				break;
			}
		}

		if (pcr->action == PF_CHANGE_ADD_HEAD)
			oldrule = TAILQ_FIRST(ruleset->rules.active.ptr);
		else if (pcr->action == PF_CHANGE_ADD_TAIL)
			oldrule = TAILQ_LAST(ruleset->rules.active.ptr,
			    pf_rulequeue);
		else {
			oldrule = TAILQ_FIRST(ruleset->rules.active.ptr);
			while ((oldrule != NULL) && (oldrule->nr != pcr->nr))
				oldrule = TAILQ_NEXT(oldrule, entries);
			if (oldrule == NULL) {
				if (newrule != NULL)
					pf_rm_rule(NULL, newrule);
				error = EINVAL;
				break;
			}
		}

		if (pcr->action == PF_CHANGE_REMOVE) {
			pf_rm_rule(ruleset->rules.active.ptr, oldrule);
			ruleset->rules.active.rcount--;
		} else {
			if (oldrule == NULL)
				TAILQ_INSERT_TAIL(
				    ruleset->rules.active.ptr,
				    newrule, entries);
			else if (pcr->action == PF_CHANGE_ADD_HEAD ||
			    pcr->action == PF_CHANGE_ADD_BEFORE)
				TAILQ_INSERT_BEFORE(oldrule, newrule, entries);
			else
				TAILQ_INSERT_AFTER(
				    ruleset->rules.active.ptr,
				    oldrule, newrule, entries);
			ruleset->rules.active.rcount++;
		}

		nr = 0;
		TAILQ_FOREACH(oldrule, ruleset->rules.active.ptr, entries)
			oldrule->nr = nr++;

		ruleset->rules.active.ticket++;

		pf_calc_skip_steps(ruleset->rules.active.ptr);
		pf_remove_if_empty_ruleset(ruleset);

		break;
	}

	case DIOCCLRSTATES: {
		struct pf_state		*s, *nexts;
		struct pfioc_state_kill *psk = (struct pfioc_state_kill *)addr;
		u_int			 killed = 0;

		for (s = RB_MIN(pf_state_tree_id, &tree_id); s; s = nexts) {
			nexts = RB_NEXT(pf_state_tree_id, &tree_id, s);

			if (!psk->psk_ifname[0] || !strcmp(psk->psk_ifname,
			    s->kif->pfik_name)) {
#if NPFSYNC > 0
				/* don't send out individual delete messages */
				SET(s->state_flags, PFSTATE_NOSYNC);
#endif	/* NPFSYNC > 0 */
				pf_remove_state(s);
				killed++;
			}
		}
		psk->psk_killed = killed;
#if NPFSYNC > 0
		pfsync_clear_states(pf_status.hostid, psk->psk_ifname);
#endif	/* NPFSYNC > 0 */
		break;
	}

	case DIOCKILLSTATES: {
		struct pf_state		*s, *nexts;
		struct pf_state_item	*si, *sit;
		struct pf_state_key	*sk, key;
		struct pf_addr		*srcaddr, *dstaddr;
		u_int16_t		 srcport, dstport;
		struct pfioc_state_kill	*psk = (struct pfioc_state_kill *)addr;
		u_int			 i, killed = 0;
		const int 		 dirs[] = { PF_IN, PF_OUT };
		int			 sidx, didx;

		if (psk->psk_pfcmp.id) {
			if (psk->psk_pfcmp.creatorid == 0)
				psk->psk_pfcmp.creatorid = pf_status.hostid;
			if ((s = pf_find_state_byid(&psk->psk_pfcmp))) {
				pf_remove_state(s);
				psk->psk_killed = 1;
			}
			break;
		}

		if (psk->psk_af && psk->psk_proto &&
		    psk->psk_src.port_op == PF_OP_EQ &&
		    psk->psk_dst.port_op == PF_OP_EQ) {

			key.af = psk->psk_af;
			key.proto = psk->psk_proto;
			key.rdomain = psk->psk_rdomain;

			for (i = 0; i < nitems(dirs); i++) {
				if (dirs[i] == PF_IN) {
					sidx = 0;
					didx = 1;
				} else {
					sidx = 1;
					didx = 0;
				}
				PF_ACPY(&key.addr[sidx],
				    &psk->psk_src.addr.v.a.addr, key.af);
				PF_ACPY(&key.addr[didx],
				    &psk->psk_dst.addr.v.a.addr, key.af);
				key.port[sidx] = psk->psk_src.port[0];
				key.port[didx] = psk->psk_dst.port[0];

				sk = RB_FIND(pf_state_tree, &pf_statetbl, &key);
				if (sk == NULL)
					continue;

				TAILQ_FOREACH_SAFE(si, &sk->states, entry, sit)
					if (((si->s->key[PF_SK_WIRE]->af ==
					    si->s->key[PF_SK_STACK]->af &&
					    sk == (dirs[i] == PF_IN ?
					    si->s->key[PF_SK_WIRE] :
					    si->s->key[PF_SK_STACK])) ||
					    (si->s->key[PF_SK_WIRE]->af !=
					    si->s->key[PF_SK_STACK]->af &&
					    dirs[i] == PF_IN &&
					    (sk == si->s->key[PF_SK_STACK] ||
					    sk == si->s->key[PF_SK_WIRE]))) &&
					    (!psk->psk_ifname[0] ||
					    (si->s->kif != pfi_all &&
					    !strcmp(psk->psk_ifname,
					    si->s->kif->pfik_name)))) {
						pf_remove_state(si->s);
						killed++;
					}
			}
			if (killed)
				psk->psk_killed = killed;
			break;
		}

		for (s = RB_MIN(pf_state_tree_id, &tree_id); s;
		    s = nexts) {
			nexts = RB_NEXT(pf_state_tree_id, &tree_id, s);

			if (s->direction == PF_OUT) {
				sk = s->key[PF_SK_STACK];
				srcaddr = &sk->addr[1];
				dstaddr = &sk->addr[0];
				srcport = sk->port[1];
				dstport = sk->port[0];
			} else {
				sk = s->key[PF_SK_WIRE];
				srcaddr = &sk->addr[0];
				dstaddr = &sk->addr[1];
				srcport = sk->port[0];
				dstport = sk->port[1];
			}
			if ((!psk->psk_af || sk->af == psk->psk_af)
			    && (!psk->psk_proto || psk->psk_proto ==
			    sk->proto) && psk->psk_rdomain == sk->rdomain &&
			    PF_MATCHA(psk->psk_src.neg,
			    &psk->psk_src.addr.v.a.addr,
			    &psk->psk_src.addr.v.a.mask,
			    srcaddr, sk->af) &&
			    PF_MATCHA(psk->psk_dst.neg,
			    &psk->psk_dst.addr.v.a.addr,
			    &psk->psk_dst.addr.v.a.mask,
			    dstaddr, sk->af) &&
			    (psk->psk_src.port_op == 0 ||
			    pf_match_port(psk->psk_src.port_op,
			    psk->psk_src.port[0], psk->psk_src.port[1],
			    srcport)) &&
			    (psk->psk_dst.port_op == 0 ||
			    pf_match_port(psk->psk_dst.port_op,
			    psk->psk_dst.port[0], psk->psk_dst.port[1],
			    dstport)) &&
			    (!psk->psk_label[0] || (s->rule.ptr->label[0] &&
			    !strcmp(psk->psk_label, s->rule.ptr->label))) &&
			    (!psk->psk_ifname[0] || !strcmp(psk->psk_ifname,
			    s->kif->pfik_name))) {
				pf_remove_state(s);
				killed++;
			}
		}
		psk->psk_killed = killed;
		break;
	}

#if NPFSYNC > 0
	case DIOCADDSTATE: {
		struct pfioc_state	*ps = (struct pfioc_state *)addr;
		struct pfsync_state	*sp = &ps->state;

		if (sp->timeout >= PFTM_MAX) {
			error = EINVAL;
			break;
		}
		error = pfsync_state_import(sp, PFSYNC_SI_IOCTL);
		break;
	}
#endif	/* NPFSYNC > 0 */

	case DIOCGETSTATE: {
		struct pfioc_state	*ps = (struct pfioc_state *)addr;
		struct pf_state		*s;
		struct pf_state_cmp	 id_key;

		bzero(&id_key, sizeof(id_key));
		id_key.id = ps->state.id;
		id_key.creatorid = ps->state.creatorid;

		s = pf_find_state_byid(&id_key);
		if (s == NULL) {
			error = ENOENT;
			break;
		}

		pf_state_export(&ps->state, s);
		break;
	}

	case DIOCGETSTATES: {
		struct pfioc_states	*ps = (struct pfioc_states *)addr;
		struct pf_state		*state;
		struct pfsync_state	*p, *pstore;
		u_int32_t		 nr = 0;

		if (ps->ps_len == 0) {
			nr = pf_status.states;
			ps->ps_len = sizeof(struct pfsync_state) * nr;
			break;
		}

		pstore = malloc(sizeof(*pstore), M_TEMP, M_WAITOK);

		p = ps->ps_states;

		state = TAILQ_FIRST(&state_list);
		while (state) {
			if (state->timeout != PFTM_UNLINKED) {
				if ((nr+1) * sizeof(*p) > (unsigned)ps->ps_len)
					break;
				pf_state_export(pstore, state);
				error = copyout(pstore, p, sizeof(*p));
				if (error) {
					free(pstore, M_TEMP, sizeof(*pstore));
					goto fail;
				}
				p++;
				nr++;
			}
			state = TAILQ_NEXT(state, entry_list);
		}

		ps->ps_len = sizeof(struct pfsync_state) * nr;

		free(pstore, M_TEMP, sizeof(*pstore));
		break;
	}

	case DIOCGETSTATUS: {
		struct pf_status *s = (struct pf_status *)addr;
		bcopy(&pf_status, s, sizeof(struct pf_status));
		pfi_update_status(s->ifname, s);
		break;
	}

	case DIOCSETSTATUSIF: {
		struct pfioc_iface	*pi = (struct pfioc_iface *)addr;

		if (pi->pfiio_name[0] == 0) {
			bzero(pf_status.ifname, IFNAMSIZ);
			break;
		}
		strlcpy(pf_trans_set.statusif, pi->pfiio_name, IFNAMSIZ);
		pf_trans_set.mask |= PF_TSET_STATUSIF;
		break;
	}

	case DIOCCLRSTATUS: {
		struct pfioc_iface	*pi = (struct pfioc_iface *)addr;

		/* if ifname is specified, clear counters there only */
		if (pi->pfiio_name[0]) {
			pfi_update_status(pi->pfiio_name, NULL);
			break;
		}

		bzero(pf_status.counters, sizeof(pf_status.counters));
		bzero(pf_status.fcounters, sizeof(pf_status.fcounters));
		bzero(pf_status.scounters, sizeof(pf_status.scounters));
		pf_status.since = time_uptime;

		break;
	}

	case DIOCNATLOOK: {
		struct pfioc_natlook	*pnl = (struct pfioc_natlook *)addr;
		struct pf_state_key	*sk;
		struct pf_state		*state;
		struct pf_state_key_cmp	 key;
		int			 m = 0, direction = pnl->direction;
		int			 sidx, didx;

		/* NATLOOK src and dst are reversed, so reverse sidx/didx */
		sidx = (direction == PF_IN) ? 1 : 0;
		didx = (direction == PF_IN) ? 0 : 1;

		if (!pnl->proto ||
		    PF_AZERO(&pnl->saddr, pnl->af) ||
		    PF_AZERO(&pnl->daddr, pnl->af) ||
		    ((pnl->proto == IPPROTO_TCP ||
		    pnl->proto == IPPROTO_UDP) &&
		    (!pnl->dport || !pnl->sport)) ||
		    pnl->rdomain > RT_TABLEID_MAX)
			error = EINVAL;
		else {
			key.af = pnl->af;
			key.proto = pnl->proto;
			key.rdomain = pnl->rdomain;
			PF_ACPY(&key.addr[sidx], &pnl->saddr, pnl->af);
			key.port[sidx] = pnl->sport;
			PF_ACPY(&key.addr[didx], &pnl->daddr, pnl->af);
			key.port[didx] = pnl->dport;

			state = pf_find_state_all(&key, direction, &m);

			if (m > 1)
				error = E2BIG;	/* more than one state */
			else if (state != NULL) {
				sk = state->key[sidx];
				PF_ACPY(&pnl->rsaddr, &sk->addr[sidx], sk->af);
				pnl->rsport = sk->port[sidx];
				PF_ACPY(&pnl->rdaddr, &sk->addr[didx], sk->af);
				pnl->rdport = sk->port[didx];
				pnl->rrdomain = sk->rdomain;
			} else
				error = ENOENT;
		}
		break;
	}

	case DIOCSETTIMEOUT: {
		struct pfioc_tm	*pt = (struct pfioc_tm *)addr;

		if (pt->timeout < 0 || pt->timeout >= PFTM_MAX ||
		    pt->seconds < 0) {
			error = EINVAL;
			goto fail;
		}
		if (pt->timeout == PFTM_INTERVAL && pt->seconds == 0)
			pt->seconds = 1;
		pf_default_rule_new.timeout[pt->timeout] = pt->seconds;
		pt->seconds = pf_default_rule.timeout[pt->timeout];
		break;
	}

	case DIOCGETTIMEOUT: {
		struct pfioc_tm	*pt = (struct pfioc_tm *)addr;

		if (pt->timeout < 0 || pt->timeout >= PFTM_MAX) {
			error = EINVAL;
			goto fail;
		}
		pt->seconds = pf_default_rule.timeout[pt->timeout];
		break;
	}

	case DIOCGETLIMIT: {
		struct pfioc_limit	*pl = (struct pfioc_limit *)addr;

		if (pl->index < 0 || pl->index >= PF_LIMIT_MAX) {
			error = EINVAL;
			goto fail;
		}
		pl->limit = pf_pool_limits[pl->index].limit;
		break;
	}

	case DIOCSETLIMIT: {
		struct pfioc_limit	*pl = (struct pfioc_limit *)addr;

		if (pl->index < 0 || pl->index >= PF_LIMIT_MAX ||
		    pf_pool_limits[pl->index].pp == NULL) {
			error = EINVAL;
			goto fail;
		}
		if (((struct pool *)pf_pool_limits[pl->index].pp)->pr_nout >
		    pl->limit) {
			error = EBUSY;
			goto fail;
		}
		/* Fragments reference mbuf clusters. */
		if (pl->index == PF_LIMIT_FRAGS && pl->limit > nmbclust) {
			error = EINVAL;
			goto fail;
		}

		pf_pool_limits[pl->index].limit_new = pl->limit;
		pl->limit = pf_pool_limits[pl->index].limit;
		break;
	}

	case DIOCSETDEBUG: {
		u_int32_t	*level = (u_int32_t *)addr;

		pf_trans_set.debug = *level;
		pf_trans_set.mask |= PF_TSET_DEBUG;
		break;
	}

	case DIOCGETRULESETS: {
		struct pfioc_ruleset	*pr = (struct pfioc_ruleset *)addr;
		struct pf_ruleset	*ruleset;
		struct pf_anchor	*anchor;

		pr->path[sizeof(pr->path) - 1] = 0;
		if ((ruleset = pf_find_ruleset(pr->path)) == NULL) {
			error = EINVAL;
			break;
		}
		pr->nr = 0;
		if (ruleset->anchor == NULL) {
			/* XXX kludge for pf_main_ruleset */
			RB_FOREACH(anchor, pf_anchor_global, &pf_anchors)
				if (anchor->parent == NULL)
					pr->nr++;
		} else {
			RB_FOREACH(anchor, pf_anchor_node,
			    &ruleset->anchor->children)
				pr->nr++;
		}
		break;
	}

	case DIOCGETRULESET: {
		struct pfioc_ruleset	*pr = (struct pfioc_ruleset *)addr;
		struct pf_ruleset	*ruleset;
		struct pf_anchor	*anchor;
		u_int32_t		 nr = 0;

		pr->path[sizeof(pr->path) - 1] = 0;
		if ((ruleset = pf_find_ruleset(pr->path)) == NULL) {
			error = EINVAL;
			break;
		}
		pr->name[0] = 0;
		if (ruleset->anchor == NULL) {
			/* XXX kludge for pf_main_ruleset */
			RB_FOREACH(anchor, pf_anchor_global, &pf_anchors)
				if (anchor->parent == NULL && nr++ == pr->nr) {
					strlcpy(pr->name, anchor->name,
					    sizeof(pr->name));
					break;
				}
		} else {
			RB_FOREACH(anchor, pf_anchor_node,
			    &ruleset->anchor->children)
				if (nr++ == pr->nr) {
					strlcpy(pr->name, anchor->name,
					    sizeof(pr->name));
					break;
				}
		}
		if (!pr->name[0])
			error = EBUSY;
		break;
	}

	case DIOCRCLRTABLES: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != 0) {
			error = ENODEV;
			break;
		}
		error = pfr_clr_tables(&io->pfrio_table, &io->pfrio_ndel,
		    io->pfrio_flags | PFR_FLAG_USERIOCTL);
		break;
	}

	case DIOCRADDTABLES: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_table)) {
			error = ENODEV;
			break;
		}
		error = pfr_add_tables(io->pfrio_buffer, io->pfrio_size,
		    &io->pfrio_nadd, io->pfrio_flags | PFR_FLAG_USERIOCTL);
		break;
	}

	case DIOCRDELTABLES: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_table)) {
			error = ENODEV;
			break;
		}
		error = pfr_del_tables(io->pfrio_buffer, io->pfrio_size,
		    &io->pfrio_ndel, io->pfrio_flags | PFR_FLAG_USERIOCTL);
		break;
	}

	case DIOCRGETTABLES: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_table)) {
			error = ENODEV;
			break;
		}
		error = pfr_get_tables(&io->pfrio_table, io->pfrio_buffer,
		    &io->pfrio_size, io->pfrio_flags | PFR_FLAG_USERIOCTL);
		break;
	}

	case DIOCRGETTSTATS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_tstats)) {
			error = ENODEV;
			break;
		}
		error = pfr_get_tstats(&io->pfrio_table, io->pfrio_buffer,
		    &io->pfrio_size, io->pfrio_flags | PFR_FLAG_USERIOCTL);
		break;
	}

	case DIOCRCLRTSTATS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_table)) {
			error = ENODEV;
			break;
		}
		error = pfr_clr_tstats(io->pfrio_buffer, io->pfrio_size,
		    &io->pfrio_nzero, io->pfrio_flags | PFR_FLAG_USERIOCTL);
		break;
	}

	case DIOCRSETTFLAGS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_table)) {
			error = ENODEV;
			break;
		}
		error = pfr_set_tflags(io->pfrio_buffer, io->pfrio_size,
		    io->pfrio_setflag, io->pfrio_clrflag, &io->pfrio_nchange,
		    &io->pfrio_ndel, io->pfrio_flags | PFR_FLAG_USERIOCTL);
		break;
	}

	case DIOCRCLRADDRS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != 0) {
			error = ENODEV;
			break;
		}
		error = pfr_clr_addrs(&io->pfrio_table, &io->pfrio_ndel,
		    io->pfrio_flags | PFR_FLAG_USERIOCTL);
		break;
	}

	case DIOCRADDADDRS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
		error = pfr_add_addrs(&io->pfrio_table, io->pfrio_buffer,
		    io->pfrio_size, &io->pfrio_nadd, io->pfrio_flags |
		    PFR_FLAG_USERIOCTL);
		break;
	}

	case DIOCRDELADDRS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
		error = pfr_del_addrs(&io->pfrio_table, io->pfrio_buffer,
		    io->pfrio_size, &io->pfrio_ndel, io->pfrio_flags |
		    PFR_FLAG_USERIOCTL);
		break;
	}

	case DIOCRSETADDRS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
		error = pfr_set_addrs(&io->pfrio_table, io->pfrio_buffer,
		    io->pfrio_size, &io->pfrio_size2, &io->pfrio_nadd,
		    &io->pfrio_ndel, &io->pfrio_nchange, io->pfrio_flags |
		    PFR_FLAG_USERIOCTL, 0);
		break;
	}

	case DIOCRGETADDRS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
		error = pfr_get_addrs(&io->pfrio_table, io->pfrio_buffer,
		    &io->pfrio_size, io->pfrio_flags | PFR_FLAG_USERIOCTL);
		break;
	}

	case DIOCRGETASTATS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_astats)) {
			error = ENODEV;
			break;
		}
		error = pfr_get_astats(&io->pfrio_table, io->pfrio_buffer,
		    &io->pfrio_size, io->pfrio_flags | PFR_FLAG_USERIOCTL);
		break;
	}

	case DIOCRCLRASTATS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
		error = pfr_clr_astats(&io->pfrio_table, io->pfrio_buffer,
		    io->pfrio_size, &io->pfrio_nzero, io->pfrio_flags |
		    PFR_FLAG_USERIOCTL);
		break;
	}

	case DIOCRTSTADDRS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
		error = pfr_tst_addrs(&io->pfrio_table, io->pfrio_buffer,
		    io->pfrio_size, &io->pfrio_nmatch, io->pfrio_flags |
		    PFR_FLAG_USERIOCTL);
		break;
	}

	case DIOCRINADEFINE: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
		error = pfr_ina_define(&io->pfrio_table, io->pfrio_buffer,
		    io->pfrio_size, &io->pfrio_nadd, &io->pfrio_naddr,
		    io->pfrio_ticket, io->pfrio_flags | PFR_FLAG_USERIOCTL);
		break;
	}

	case DIOCOSFPADD: {
		struct pf_osfp_ioctl *io = (struct pf_osfp_ioctl *)addr;
		error = pf_osfp_add(io);
		break;
	}

	case DIOCOSFPGET: {
		struct pf_osfp_ioctl *io = (struct pf_osfp_ioctl *)addr;
		error = pf_osfp_get(io);
		break;
	}

	case DIOCXBEGIN: {
		struct pfioc_trans	*io = (struct pfioc_trans *)addr;
		struct pfioc_trans_e	*ioe;
		struct pfr_table	*table;
		int			 i;

		if (io->esize != sizeof(*ioe)) {
			error = ENODEV;
			goto fail;
		}
		ioe = malloc(sizeof(*ioe), M_TEMP, M_WAITOK);
		table = malloc(sizeof(*table), M_TEMP, M_WAITOK);
		pf_default_rule_new = pf_default_rule;
		bzero(&pf_trans_set, sizeof(pf_trans_set));
		for (i = 0; i < io->size; i++) {
			if (copyin(io->array+i, ioe, sizeof(*ioe))) {
				free(table, M_TEMP, sizeof(*table));
				free(ioe, M_TEMP, sizeof(*ioe));
				error = EFAULT;
				goto fail;
			}
			switch (ioe->type) {
			case PF_TRANS_TABLE:
				bzero(table, sizeof(*table));
				strlcpy(table->pfrt_anchor, ioe->anchor,
				    sizeof(table->pfrt_anchor));
				if ((error = pfr_ina_begin(table,
				    &ioe->ticket, NULL, 0))) {
					free(table, M_TEMP, sizeof(*table));
					free(ioe, M_TEMP, sizeof(*ioe));
					goto fail;
				}
				break;
			default:
				if ((error = pf_begin_rules(&ioe->ticket,
				    ioe->anchor))) {
					free(table, M_TEMP, sizeof(*table));
					free(ioe, M_TEMP, sizeof(*ioe));
					goto fail;
				}
				break;
			}
			if (copyout(ioe, io->array+i, sizeof(io->array[i]))) {
				free(table, M_TEMP, sizeof(*table));
				free(ioe, M_TEMP, sizeof(*ioe));
				error = EFAULT;
				goto fail;
			}
		}
		free(table, M_TEMP, sizeof(*table));
		free(ioe, M_TEMP, sizeof(*ioe));
		break;
	}

	case DIOCXROLLBACK: {
		struct pfioc_trans	*io = (struct pfioc_trans *)addr;
		struct pfioc_trans_e	*ioe;
		struct pfr_table	*table;
		int			 i;

		if (io->esize != sizeof(*ioe)) {
			error = ENODEV;
			goto fail;
		}
		ioe = malloc(sizeof(*ioe), M_TEMP, M_WAITOK);
		table = malloc(sizeof(*table), M_TEMP, M_WAITOK);
		for (i = 0; i < io->size; i++) {
			if (copyin(io->array+i, ioe, sizeof(*ioe))) {
				free(table, M_TEMP, sizeof(*table));
				free(ioe, M_TEMP, sizeof(*ioe));
				error = EFAULT;
				goto fail;
			}
			switch (ioe->type) {
			case PF_TRANS_TABLE:
				bzero(table, sizeof(*table));
				strlcpy(table->pfrt_anchor, ioe->anchor,
				    sizeof(table->pfrt_anchor));
				if ((error = pfr_ina_rollback(table,
				    ioe->ticket, NULL, 0))) {
					free(table, M_TEMP, sizeof(*table));
					free(ioe, M_TEMP, sizeof(*ioe));
					goto fail; /* really bad */
				}
				break;
			default:
				if ((error = pf_rollback_rules(ioe->ticket,
				    ioe->anchor))) {
					free(table, M_TEMP, sizeof(*table));
					free(ioe, M_TEMP, sizeof(*ioe));
					goto fail; /* really bad */
				}
				break;
			}
		}
		free(table, M_TEMP, sizeof(*table));
		free(ioe, M_TEMP, sizeof(*ioe));
		break;
	}

	case DIOCXCOMMIT: {
		struct pfioc_trans	*io = (struct pfioc_trans *)addr;
		struct pfioc_trans_e	*ioe;
		struct pfr_table	*table;
		struct pf_ruleset	*rs;
		int			 i;

		if (io->esize != sizeof(*ioe)) {
			error = ENODEV;
			goto fail;
		}
		ioe = malloc(sizeof(*ioe), M_TEMP, M_WAITOK);
		table = malloc(sizeof(*table), M_TEMP, M_WAITOK);
		/* first makes sure everything will succeed */
		for (i = 0; i < io->size; i++) {
			if (copyin(io->array+i, ioe, sizeof(*ioe))) {
				free(table, M_TEMP, sizeof(*table));
				free(ioe, M_TEMP, sizeof(*ioe));
				error = EFAULT;
				goto fail;
			}
			switch (ioe->type) {
			case PF_TRANS_TABLE:
				rs = pf_find_ruleset(ioe->anchor);
				if (rs == NULL || !rs->topen || ioe->ticket !=
				     rs->tticket) {
					free(table, M_TEMP, sizeof(*table));
					free(ioe, M_TEMP, sizeof(*ioe));
					error = EBUSY;
					goto fail;
				}
				break;
			default:
				rs = pf_find_ruleset(ioe->anchor);
				if (rs == NULL ||
				    !rs->rules.inactive.open ||
				    rs->rules.inactive.ticket !=
				    ioe->ticket) {
					free(table, M_TEMP, sizeof(*table));
					free(ioe, M_TEMP, sizeof(*ioe));
					error = EBUSY;
					goto fail;
				}
				break;
			}
		}

		/*
		 * Checked already in DIOCSETLIMIT, but check again as the
		 * situation might have changed.
		 */
		for (i = 0; i < PF_LIMIT_MAX; i++) {
			if (((struct pool *)pf_pool_limits[i].pp)->pr_nout >
			    pf_pool_limits[i].limit_new) {
				free(table, M_TEMP, sizeof(*table));
				free(ioe, M_TEMP, sizeof(*ioe));
				error = EBUSY;
				goto fail;
			}
		}
		/* now do the commit - no errors should happen here */
		for (i = 0; i < io->size; i++) {
			if (copyin(io->array+i, ioe, sizeof(*ioe))) {
				free(table, M_TEMP, sizeof(*table));
				free(ioe, M_TEMP, sizeof(*ioe));
				error = EFAULT;
				goto fail;
			}
			switch (ioe->type) {
			case PF_TRANS_TABLE:
				bzero(table, sizeof(*table));
				strlcpy(table->pfrt_anchor, ioe->anchor,
				    sizeof(table->pfrt_anchor));
				if ((error = pfr_ina_commit(table, ioe->ticket,
				    NULL, NULL, 0))) {
					free(table, M_TEMP, sizeof(*table));
					free(ioe, M_TEMP, sizeof(*ioe));
					goto fail; /* really bad */
				}
				break;
			default:
				if ((error = pf_commit_rules(ioe->ticket,
				    ioe->anchor))) {
					free(table, M_TEMP, sizeof(*table));
					free(ioe, M_TEMP, sizeof(*ioe));
					goto fail; /* really bad */
				}
				break;
			}
		}
		for (i = 0; i < PF_LIMIT_MAX; i++) {
			if (pf_pool_limits[i].limit_new !=
			    pf_pool_limits[i].limit &&
			    pool_sethardlimit(pf_pool_limits[i].pp,
			    pf_pool_limits[i].limit_new, NULL, 0) != 0) {
				free(table, M_TEMP, sizeof(*table));
				free(ioe, M_TEMP, sizeof(*ioe));
				error = EBUSY;
				goto fail; /* really bad */
			}
			pf_pool_limits[i].limit = pf_pool_limits[i].limit_new;
		}
		for (i = 0; i < PFTM_MAX; i++) {
			int old = pf_default_rule.timeout[i];

			pf_default_rule.timeout[i] =
			    pf_default_rule_new.timeout[i];
			if (pf_default_rule.timeout[i] == PFTM_INTERVAL &&
			    pf_default_rule.timeout[i] < old)
				wakeup(pf_purge_thread);
		}
		pfi_xcommit();
		pf_trans_set_commit();
		free(table, M_TEMP, sizeof(*table));
		free(ioe, M_TEMP, sizeof(*ioe));
		break;
	}

	case DIOCGETSRCNODES: {
		struct pfioc_src_nodes	*psn = (struct pfioc_src_nodes *)addr;
		struct pf_src_node	*n, *p, *pstore;
		u_int32_t		 nr = 0;
		int			 space = psn->psn_len;

		if (space == 0) {
			RB_FOREACH(n, pf_src_tree, &tree_src_tracking)
				nr++;
			psn->psn_len = sizeof(struct pf_src_node) * nr;
			break;
		}

		pstore = malloc(sizeof(*pstore), M_TEMP, M_WAITOK);

		p = psn->psn_src_nodes;
		RB_FOREACH(n, pf_src_tree, &tree_src_tracking) {
			int	secs = time_uptime, diff;

			if ((nr + 1) * sizeof(*p) > (unsigned)psn->psn_len)
				break;

			bcopy(n, pstore, sizeof(*pstore));
			bzero(&pstore->entry, sizeof(pstore->entry));
			pstore->rule.ptr = NULL;
			pstore->kif = NULL;
			pstore->rule.nr = n->rule.ptr->nr;
			pstore->creation = secs - pstore->creation;
			if (pstore->expire > secs)
				pstore->expire -= secs;
			else
				pstore->expire = 0;

			/* adjust the connection rate estimate */
			diff = secs - n->conn_rate.last;
			if (diff >= n->conn_rate.seconds)
				pstore->conn_rate.count = 0;
			else
				pstore->conn_rate.count -=
				    n->conn_rate.count * diff /
				    n->conn_rate.seconds;

			error = copyout(pstore, p, sizeof(*p));
			if (error) {
				free(pstore, M_TEMP, sizeof(*pstore));
				goto fail;
			}
			p++;
			nr++;
		}
		psn->psn_len = sizeof(struct pf_src_node) * nr;

		free(pstore, M_TEMP, sizeof(*pstore));
		break;
	}

	case DIOCCLRSRCNODES: {
		struct pf_src_node	*n;
		struct pf_state		*state;

		RB_FOREACH(state, pf_state_tree_id, &tree_id)
			pf_src_tree_remove_state(state);
		RB_FOREACH(n, pf_src_tree, &tree_src_tracking)
			n->expire = 1;
		pf_purge_expired_src_nodes(1);
		break;
	}

	case DIOCKILLSRCNODES: {
		struct pf_src_node	*sn;
		struct pf_state		*s;
		struct pfioc_src_node_kill *psnk =
		    (struct pfioc_src_node_kill *)addr;
		u_int			killed = 0;

		RB_FOREACH(sn, pf_src_tree, &tree_src_tracking) {
			if (PF_MATCHA(psnk->psnk_src.neg,
				&psnk->psnk_src.addr.v.a.addr,
				&psnk->psnk_src.addr.v.a.mask,
				&sn->addr, sn->af) &&
			    PF_MATCHA(psnk->psnk_dst.neg,
				&psnk->psnk_dst.addr.v.a.addr,
				&psnk->psnk_dst.addr.v.a.mask,
				&sn->raddr, sn->af)) {
				/* Handle state to src_node linkage */
				if (sn->states != 0)
					RB_FOREACH(s, pf_state_tree_id,
					   &tree_id)
						pf_state_rm_src_node(s, sn);
				sn->expire = 1;
				killed++;
			}
		}

		if (killed > 0)
			pf_purge_expired_src_nodes(1);

		psnk->psnk_killed = killed;
		break;
	}

	case DIOCSETHOSTID: {
		u_int32_t	*hostid = (u_int32_t *)addr;

		if (*hostid == 0)
			pf_trans_set.hostid = arc4random();
		else
			pf_trans_set.hostid = *hostid;
		pf_trans_set.mask |= PF_TSET_HOSTID;
		break;
	}

	case DIOCOSFPFLUSH:
		pf_osfp_flush();
		break;

	case DIOCIGETIFACES: {
		struct pfioc_iface *io = (struct pfioc_iface *)addr;

		if (io->pfiio_esize != sizeof(struct pfi_kif)) {
			error = ENODEV;
			break;
		}
		error = pfi_get_ifaces(io->pfiio_name, io->pfiio_buffer,
		    &io->pfiio_size);
		break;
	}

	case DIOCSETIFFLAG: {
		struct pfioc_iface *io = (struct pfioc_iface *)addr;

		error = pfi_set_flags(io->pfiio_name, io->pfiio_flags);
		break;
	}

	case DIOCCLRIFFLAG: {
		struct pfioc_iface *io = (struct pfioc_iface *)addr;

		error = pfi_clear_flags(io->pfiio_name, io->pfiio_flags);
		break;
	}

	case DIOCSETREASS: {
		u_int32_t	*reass = (u_int32_t *)addr;

		pf_trans_set.reass = *reass;
		pf_trans_set.mask |= PF_TSET_REASS;
		break;
	}

	default:
		error = ENODEV;
		break;
	}
fail:
	NET_UNLOCK(s);
	return (error);
}

void
pf_trans_set_commit(void)
{
	if (pf_trans_set.mask & PF_TSET_STATUSIF)
		strlcpy(pf_status.ifname, pf_trans_set.statusif, IFNAMSIZ);
	if (pf_trans_set.mask & PF_TSET_DEBUG)
		pf_status.debug = pf_trans_set.debug;
	if (pf_trans_set.mask & PF_TSET_HOSTID)
		pf_status.hostid = pf_trans_set.hostid;
	if (pf_trans_set.mask & PF_TSET_REASS)
		pf_status.reass = pf_trans_set.reass;
}

void
pf_pool_copyin(struct pf_pool *from, struct pf_pool *to)
{
	bcopy(from, to, sizeof(*to));
	to->kif = NULL;
}

int
pf_rule_copyin(struct pf_rule *from, struct pf_rule *to,
    struct pf_ruleset *ruleset)
{
	int i;

	to->src = from->src;
	to->dst = from->dst;

	/* XXX union skip[] */

	strlcpy(to->label, from->label, sizeof(to->label));
	strlcpy(to->ifname, from->ifname, sizeof(to->ifname));
	strlcpy(to->rcv_ifname, from->rcv_ifname, sizeof(to->rcv_ifname));
	strlcpy(to->qname, from->qname, sizeof(to->qname));
	strlcpy(to->pqname, from->pqname, sizeof(to->pqname));
	strlcpy(to->tagname, from->tagname, sizeof(to->tagname));
	strlcpy(to->match_tagname, from->match_tagname,
	    sizeof(to->match_tagname));
	strlcpy(to->overload_tblname, from->overload_tblname,
	    sizeof(to->overload_tblname));

	pf_pool_copyin(&from->nat, &to->nat);
	pf_pool_copyin(&from->rdr, &to->rdr);
	pf_pool_copyin(&from->route, &to->route);

	if (pf_kif_setup(to->ifname, &to->kif))
		return (EINVAL);
	if (pf_kif_setup(to->rcv_ifname, &to->rcv_kif))
		return (EINVAL);
	if (to->overload_tblname[0]) {
		if ((to->overload_tbl = pfr_attach_table(ruleset,
		    to->overload_tblname, 0)) == NULL)
			return (EINVAL);
		else
			to->overload_tbl->pfrkt_flags |= PFR_TFLAG_ACTIVE;
	}

	if (pf_kif_setup(to->rdr.ifname, &to->rdr.kif))
		return (EINVAL);
	if (pf_kif_setup(to->nat.ifname, &to->nat.kif))
		return (EINVAL);
	if (pf_kif_setup(to->route.ifname, &to->route.kif))
		return (EINVAL);

	to->os_fingerprint = from->os_fingerprint;

	to->rtableid = from->rtableid;
	if (to->rtableid >= 0 && !rtable_exists(to->rtableid))
		return (EBUSY);
	to->onrdomain = from->onrdomain;
	if (to->onrdomain >= 0 && !rtable_exists(to->onrdomain))
		return (EBUSY);
	if (to->onrdomain >= 0)		/* make sure it is a real rdomain */
		to->onrdomain = rtable_l2(to->onrdomain);

	for (i = 0; i < PFTM_MAX; i++)
		to->timeout[i] = from->timeout[i];
	to->states_tot = from->states_tot;
	to->max_states = from->max_states;
	to->max_src_nodes = from->max_src_nodes;
	to->max_src_states = from->max_src_states;
	to->max_src_conn = from->max_src_conn;
	to->max_src_conn_rate.limit = from->max_src_conn_rate.limit;
	to->max_src_conn_rate.seconds = from->max_src_conn_rate.seconds;

	if (to->qname[0] != 0) {
		if ((to->qid = pf_qname2qid(to->qname, 0)) == 0)
			return (EBUSY);
		if (to->pqname[0] != 0) {
			if ((to->pqid = pf_qname2qid(to->pqname, 0)) == 0)
				return (EBUSY);
		} else
			to->pqid = to->qid;
	}
	to->rt_listid = from->rt_listid;
	to->prob = from->prob;
	to->return_icmp = from->return_icmp;
	to->return_icmp6 = from->return_icmp6;
	to->max_mss = from->max_mss;
	if (to->tagname[0])
		if ((to->tag = pf_tagname2tag(to->tagname, 1)) == 0)
			return (EBUSY);
	if (to->match_tagname[0])
		if ((to->match_tag = pf_tagname2tag(to->match_tagname, 1)) == 0)
			return (EBUSY);
	to->scrub_flags = from->scrub_flags;
	to->uid = from->uid;
	to->gid = from->gid;
	to->rule_flag = from->rule_flag;
	to->action = from->action;
	to->direction = from->direction;
	to->log = from->log;
	to->logif = from->logif;
#if NPFLOG > 0
	if (!to->log)
		to->logif = 0;
#endif	/* NPFLOG > 0 */
	to->quick = from->quick;
	to->ifnot = from->ifnot;
	to->rcvifnot = from->rcvifnot;
	to->match_tag_not = from->match_tag_not;
	to->keep_state = from->keep_state;
	to->af = from->af;
	to->naf = from->naf;
	to->proto = from->proto;
	to->type = from->type;
	to->code = from->code;
	to->flags = from->flags;
	to->flagset = from->flagset;
	to->min_ttl = from->min_ttl;
	to->allow_opts = from->allow_opts;
	to->rt = from->rt;
	to->return_ttl = from->return_ttl;
	to->tos = from->tos;
	to->set_tos = from->set_tos;
	to->anchor_relative = from->anchor_relative; /* XXX */
	to->anchor_wildcard = from->anchor_wildcard; /* XXX */
	to->flush = from->flush;
	to->divert.addr = from->divert.addr;
	to->divert.port = from->divert.port;
	to->divert_packet.addr = from->divert_packet.addr;
	to->divert_packet.port = from->divert_packet.port;
	to->prio = from->prio;
	to->set_prio[0] = from->set_prio[0];
	to->set_prio[1] = from->set_prio[1];

	return (0);
}
@


1.313
log
@g/c DIOCCLRRULECTRS
kinda deprecated for a decade now, nothing in base uses it, nothing in
ports uses it (thanks sthen)
ok phessler sashan
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.311 2017/05/15 11:23:25 mikeb Exp $ */
d1008 1
a1008 1
			pf_status.since = time_second;
d1023 1
a1023 1
			pf_status.since = time_second;
d1677 1
a1677 1
		pf_status.since = time_second;
@


1.312
log
@Enable the NET_LOCK(), take 3.

Recursions are still marked as XXXSMP.

ok deraadt@@, bluhm@@
@
text
@a917 1
		case DIOCCLRRULECTRS:
a1793 14
		break;
	}

	case DIOCCLRRULECTRS: {
		/* obsoleted by DIOCGETRULE with action=PF_GET_CLR_CNTR */
		struct pf_ruleset	*ruleset = &pf_main_ruleset;
		struct pf_rule		*rule;

		TAILQ_FOREACH(rule,
		    ruleset->rules.active.ptr, entries) {
			rule->evaluations = 0;
			rule->packets[0] = rule->packets[1] = 0;
			rule->bytes[0] = rule->bytes[1] = 0;
		}
@


1.311
log
@Hook up FQ-CoDel to the tree and enable configuration in the pfctl(8)

OK sthen, visa
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.310 2017/05/02 12:27:37 mikeb Exp $ */
a113 1
struct rwlock		 pf_consistency_lock = RWLOCK_INITIALIZER("pfcnslk");
d1001 1
a1001 6
	if (flags & FWRITE)
		rw_enter_write(&pf_consistency_lock);
	else
		rw_enter_read(&pf_consistency_lock);

	s = splsoftnet();
d2455 1
a2455 5
	splx(s);
	if (flags & FWRITE)
		rw_exit_write(&pf_consistency_lock);
	else
		rw_exit_read(&pf_consistency_lock);
@


1.310
log
@Provide pluggable queueing interface for pf

By hiding H-FSC behind pfq_ops structure similar to the ifq_ops,
we provide a possibility to plug alternative queueing interfaces
for use in pf.  This reduces amount of H-FSC specific code in the
pf ioctl handler

While here, change the the order of elements in hfsc_class_stats
to provide some compatibility between queue stat structures of
different traffic conditioners.

No objections from henning@@, ok sthen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.309 2017/04/21 23:21:02 yasuoka Exp $ */
d64 1
d602 7
a608 2
		qif->ifqops = ifq_hfsc_ops;
		qif->pfqops = pfq_hfsc_ops;
d1097 6
a1102 1
		error = pfq_hfsc_ops->pfq_qstats(qs, pq->buf, &nbytes);
@


1.309
log
@
Speed up DIOCKILLSTATES by using the RB tree index if all fields used
by the tree of given state key are filled.

ok sasha
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.308 2017/03/17 17:19:16 mpi Exp $ */
a92 1
int			 pf_enable_queues(void);
a550 2
		KASSERT(HFSC_ENABLED(&ifp->if_snd));

d555 1
a555 1
struct pf_hfsc_queue {
d557 4
a560 2
	struct hfsc_if		*hif;
	struct pf_hfsc_queue	*next;
d563 2
a564 2
static inline struct pf_hfsc_queue *
pf_hfsc_ifp2q(struct pf_hfsc_queue *list, struct ifnet *ifp)
d566 1
a566 1
	struct pf_hfsc_queue *phq = list;
d568 3
a570 3
	while (phq != NULL) {
		if (phq->ifp == ifp)
			return (phq);
d572 1
a572 1
		phq = phq->next;
d575 1
a575 1
	return (phq);
d583 1
a583 1
	struct pf_hfsc_queue	*list = NULL, *phq;
d586 4
a589 1
	/* find root queues and alloc hfsc for these interfaces */
d598 2
a599 3
		phq = malloc(sizeof(*phq), M_TEMP, M_WAITOK);
		phq->ifp = ifp;
		phq->hif = hfsc_pf_alloc(ifp);
d601 7
a607 2
		phq->next = list;
		list = phq;
d616 2
a617 2
		phq = pf_hfsc_ifp2q(list, ifp);
		KASSERT(phq != NULL);
d619 1
a619 1
		error = hfsc_pf_addqueue(phq->hif, q);
d633 2
a634 2
		phq = pf_hfsc_ifp2q(list, ifp);
		if (phq != NULL)
d642 2
a643 2
		phq = list;
		list = phq->next;
d645 1
a645 1
		ifp = phq->ifp;
d647 2
a648 2
		ifq_attach(&ifp->if_snd, ifq_hfsc_ops, phq->hif);
		free(phq, M_TEMP, sizeof(*phq));
d655 2
a656 2
		phq = list;
		list = phq->next;
d658 2
a659 2
		hfsc_pf_free(phq->hif);
		free(phq, M_TEMP, sizeof(*phq));
d1091 1
a1091 1
		error = hfsc_pf_qstats(qs, pq->buf, &nbytes);
d1126 1
a1126 2
		if (qs->qlimit == 0)
			qs->qlimit = HFSC_DEFAULT_QLIMIT;
@


1.308
log
@Revert the NET_LOCK() and bring back pf's contention lock for release.

For the moment the NET_LOCK() is always taken by threads running under
KERNEL_LOCK().  That means it doesn't buy us anything except a possible
deadlock that we did not spot.  So make sure this doesn't happen, we'll
have plenty of time in the next release cycle to stress test it.

ok visa@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.307 2017/01/30 17:41:34 benno Exp $ */
d1447 2
a1448 1
		struct pf_state_key	*sk;
d1452 3
a1454 1
		u_int			 killed = 0;
d1463 51
@


1.307
log
@removes the pf_consistency_lock and protects the users with
NET_LOCK().  pfioctl() will need the NET_LOCK() anyway. So better keep
things simple until we're going to redesign PF for a MP world.
fixes the crash reported by Kaya Saman.
ok mpi@@, bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.306 2017/01/24 10:08:30 krw Exp $ */
d114 1
d990 6
a995 1
	NET_LOCK(s);
d2391 5
a2395 1
	NET_UNLOCK(s);
@


1.306
log
@A space here, a space there. Soon we're talking real whitespace
rectification.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.305 2016/11/16 08:46:05 mpi Exp $ */
a113 1
struct rwlock		 pf_consistency_lock = RWLOCK_INITIALIZER("pfcnslk");
d989 1
a989 6
	if (flags & FWRITE)
		rw_enter_write(&pf_consistency_lock);
	else
		rw_enter_read(&pf_consistency_lock);

	s = splsoftnet();
d2385 1
a2385 5
	splx(s);
	if (flags & FWRITE)
		rw_exit_write(&pf_consistency_lock);
	else
		rw_exit_read(&pf_consistency_lock);
@


1.305
log
@Kill recursive splsoftnet()s.

ok bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.304 2016/10/28 07:54:19 sashan Exp $ */
d543 1
a543 1
	/* put back interfaces in normal queueing mode */	
d547 1
a547 1
			
d1126 1
a1126 1
	
d1615 1
a1615 1
		
@


1.304
log
@- once rule should not attempt to remove its parent rule.
  (problem pointed out by Petr, fix proposed by Dilli) _at_ oracle
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.303 2016/10/26 21:07:22 bluhm Exp $ */
d772 1
a772 1
	int			 s, error;
a790 1
	s = splsoftnet();
a814 1
	splx(s);
@


1.303
log
@Put union pf_headers and struct pf_pdesc into separate header file
pfvar_priv.h.  The pf_headers had to be defined in multiple .c files
before.  In pfvar.h it would have unknown storage size, this file
is included in too many places.  The idea is to have a private pf
header that is only included in the pf part of the kernel.  For now
it contains pf_pdesc and pf_headers, it may be extended later.
discussion, input and OK henning@@ procter@@ sashan@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.302 2016/09/27 04:57:17 dlg Exp $ */
d323 1
@


1.302
log
@roll back turning RB into RBT until i get better at this process.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.301 2016/09/27 02:51:12 dlg Exp $ */
d58 2
d67 1
d70 7
a77 1
#include <crypto/md5.h>
d79 1
a84 5

#ifdef INET6
#include <netinet/ip6.h>
#include <netinet/in_pcb.h>
#endif /* INET6 */
@


1.301
log
@move pf from the RB macros to the RBT functions.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.300 2016/09/15 02:00:18 dlg Exp $ */
d172 2
a173 2
	RBT_INIT(pf_src_tree, &tree_src_tracking);
	RBT_INIT(pf_anchor_global, &pf_anchors);
d1421 2
a1422 2
		for (s = RBT_MIN(pf_state_tree_id, &tree_id); s; s = nexts) {
			nexts = RBT_NEXT(pf_state_tree_id, s);
d1459 3
a1461 2
		for (s = RBT_MIN(pf_state_tree_id, &tree_id); s; s = nexts) {
			nexts = RBT_NEXT(pf_state_tree_id, s);
d1757 1
a1757 1
			RBT_FOREACH(anchor, pf_anchor_global, &pf_anchors)
d1761 1
a1761 1
			RBT_FOREACH(anchor, pf_anchor_node,
d1782 1
a1782 1
			RBT_FOREACH(anchor, pf_anchor_global, &pf_anchors)
d1789 1
a1789 1
			RBT_FOREACH(anchor, pf_anchor_node,
d2239 1
a2239 1
			RBT_FOREACH(n, pf_src_tree, &tree_src_tracking)
d2248 1
a2248 1
		RBT_FOREACH(n, pf_src_tree, &tree_src_tracking) {
d2292 1
a2292 1
		RBT_FOREACH(state, pf_state_tree_id, &tree_id)
d2294 1
a2294 1
		RBT_FOREACH(n, pf_src_tree, &tree_src_tracking)
d2307 1
a2307 1
		RBT_FOREACH(sn, pf_src_tree, &tree_src_tracking) {
d2318 1
a2318 1
					RBT_FOREACH(s, pf_state_tree_id,
@


1.300
log
@all pools have their ipl set via pool_setipl, so fold it into pool_init.

the ioff argument to pool_init() is unused and has been for many
years, so this replaces it with an ipl argument. because the ipl
will be set on init we no longer need pool_setipl.

most of these changes have been done with coccinelle using the spatch
below. cocci sucks at formatting code though, so i fixed that by hand.

the manpage and subr_pool.c bits i did myself.

ok tedu@@ jmatthew@@

@@ipl@@
expression pp;
expression ipl;
expression s, a, o, f, m, p;
@@@@
-pool_init(pp, s, a, o, f, m, p);
-pool_setipl(pp, ipl);
+pool_init(pp, s, a, ipl, f, m, p);
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.299 2016/09/03 17:11:40 sashan Exp $ */
d172 2
a173 2
	RB_INIT(&tree_src_tracking);
	RB_INIT(&pf_anchors);
d1421 2
a1422 2
		for (s = RB_MIN(pf_state_tree_id, &tree_id); s; s = nexts) {
			nexts = RB_NEXT(pf_state_tree_id, &tree_id, s);
d1459 2
a1460 3
		for (s = RB_MIN(pf_state_tree_id, &tree_id); s;
		    s = nexts) {
			nexts = RB_NEXT(pf_state_tree_id, &tree_id, s);
d1756 1
a1756 1
			RB_FOREACH(anchor, pf_anchor_global, &pf_anchors)
d1760 1
a1760 1
			RB_FOREACH(anchor, pf_anchor_node,
d1781 1
a1781 1
			RB_FOREACH(anchor, pf_anchor_global, &pf_anchors)
d1788 1
a1788 1
			RB_FOREACH(anchor, pf_anchor_node,
d2238 1
a2238 1
			RB_FOREACH(n, pf_src_tree, &tree_src_tracking)
d2247 1
a2247 1
		RB_FOREACH(n, pf_src_tree, &tree_src_tracking) {
d2291 1
a2291 1
		RB_FOREACH(state, pf_state_tree_id, &tree_id)
d2293 1
a2293 1
		RB_FOREACH(n, pf_src_tree, &tree_src_tracking)
d2306 1
a2306 1
		RB_FOREACH(sn, pf_src_tree, &tree_src_tracking) {
d2317 1
a2317 1
					RB_FOREACH(s, pf_state_tree_id,
@


1.299
log
@Let purge thread to remove once rules, not packets.
Thanks mikeb@@ for idea to add expire time.

OK mpi@@, OK mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.298 2016/09/02 10:19:49 dlg Exp $ */
d144 16
a159 24
	pool_init(&pf_rule_pl, sizeof(struct pf_rule), 0, 0, 0, "pfrule",
	    NULL);
	pool_setipl(&pf_rule_pl, IPL_SOFTNET);
	pool_init(&pf_src_tree_pl, sizeof(struct pf_src_node), 0, 0, 0,
	    "pfsrctr", NULL);
	pool_setipl(&pf_src_tree_pl, IPL_SOFTNET);
	pool_init(&pf_sn_item_pl, sizeof(struct pf_sn_item), 0, 0, 0,
	    "pfsnitem", NULL);
	pool_setipl(&pf_sn_item_pl, IPL_SOFTNET);
	pool_init(&pf_state_pl, sizeof(struct pf_state), 0, 0, 0, "pfstate",
	    NULL);
	pool_setipl(&pf_state_pl, IPL_SOFTNET);
	pool_init(&pf_state_key_pl, sizeof(struct pf_state_key), 0, 0, 0,
	    "pfstkey", NULL);
	pool_setipl(&pf_state_key_pl, IPL_SOFTNET);
	pool_init(&pf_state_item_pl, sizeof(struct pf_state_item), 0, 0, 0,
	    "pfstitem", NULL);
	pool_setipl(&pf_state_item_pl, IPL_SOFTNET);
	pool_init(&pf_rule_item_pl, sizeof(struct pf_rule_item), 0, 0, 0,
	    "pfruleitem", NULL);
	pool_setipl(&pf_rule_item_pl, IPL_SOFTNET);
	pool_init(&pf_queue_pl, sizeof(struct pf_queuespec), 0, 0, 0, 
	    "pfqueue", NULL);
	pool_setipl(&pf_queue_pl, IPL_SOFTNET);
@


1.298
log
@pool_setipl for pf bits

ok phessler@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.297 2015/12/03 13:30:18 claudio Exp $ */
d312 1
a312 2
pf_purge_rule(struct pf_ruleset *ruleset, struct pf_rule *rule,
    struct pf_ruleset *aruleset, struct pf_rule *arule)
d315 1
d317 2
a318 1
	KASSERT(ruleset != NULL && rule != NULL);
a325 10

	/* remove the parent anchor rule */
	if (nr == 0 && arule && aruleset) {
		pf_rm_rule(aruleset->rules.active.ptr, arule);
		aruleset->rules.active.rcount--;
		TAILQ_FOREACH(rule, aruleset->rules.active.ptr, entries)
			rule->nr = nr++;
		aruleset->rules.active.ticket++;
		pf_calc_skip_steps(aruleset->rules.active.ptr);
	}
d777 3
d1214 1
d1271 2
@


1.297
log
@Add sizes to most free calls. OK sashan@@ tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.296 2015/12/03 10:34:11 blambert Exp $ */
d146 1
d149 1
d152 1
d155 1
d158 1
d161 1
d164 1
d167 1
@


1.296
log
@allocate PF tags as M_RTABLE vice M_TEMP

ok henning@@ claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.295 2015/12/03 09:49:15 bluhm Exp $ */
d400 1
a400 1
				free(p, M_RTABLE, 0);
d1567 1
a1567 1
					free(pstore, M_TEMP, 0);
d1578 1
a1578 1
		free(pstore, M_TEMP, 0);
d2033 2
a2034 2
				free(table, M_TEMP, 0);
				free(ioe, M_TEMP, 0);
d2045 2
a2046 2
					free(table, M_TEMP, 0);
					free(ioe, M_TEMP, 0);
d2053 2
a2054 2
					free(table, M_TEMP, 0);
					free(ioe, M_TEMP, 0);
d2060 2
a2061 2
				free(table, M_TEMP, 0);
				free(ioe, M_TEMP, 0);
d2066 2
a2067 2
		free(table, M_TEMP, 0);
		free(ioe, M_TEMP, 0);
d2085 2
a2086 2
				free(table, M_TEMP, 0);
				free(ioe, M_TEMP, 0);
d2097 2
a2098 2
					free(table, M_TEMP, 0);
					free(ioe, M_TEMP, 0);
d2105 2
a2106 2
					free(table, M_TEMP, 0);
					free(ioe, M_TEMP, 0);
d2112 2
a2113 2
		free(table, M_TEMP, 0);
		free(ioe, M_TEMP, 0);
d2133 2
a2134 2
				free(table, M_TEMP, 0);
				free(ioe, M_TEMP, 0);
d2143 2
a2144 2
					free(table, M_TEMP, 0);
					free(ioe, M_TEMP, 0);
d2155 2
a2156 2
					free(table, M_TEMP, 0);
					free(ioe, M_TEMP, 0);
d2171 2
a2172 2
				free(table, M_TEMP, 0);
				free(ioe, M_TEMP, 0);
d2180 2
a2181 2
				free(table, M_TEMP, 0);
				free(ioe, M_TEMP, 0);
d2192 2
a2193 2
					free(table, M_TEMP, 0);
					free(ioe, M_TEMP, 0);
d2200 2
a2201 2
					free(table, M_TEMP, 0);
					free(ioe, M_TEMP, 0);
d2212 2
a2213 2
				free(table, M_TEMP, 0);
				free(ioe, M_TEMP, 0);
d2230 2
a2231 2
		free(table, M_TEMP, 0);
		free(ioe, M_TEMP, 0);
d2279 1
a2279 1
				free(pstore, M_TEMP, 0);
d2287 1
a2287 1
		free(pstore, M_TEMP, 0);
@


1.295
log
@Rename pf_unlink_state() to pf_remove_state() so the name does not
collide with the statekey to inp unlinking.
OK sashan@@ mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.294 2015/11/24 13:37:16 mpi Exp $ */
d360 1
a360 1
	tag = malloc(sizeof(*tag), M_TEMP, M_NOWAIT|M_ZERO);
d400 1
a400 1
				free(p, M_TEMP, 0);
@


1.294
log
@No need for <net/if_types.h>

As a bonus this removes a "#if NCARP > 0", say yeah!
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.293 2015/11/23 15:53:35 mpi Exp $ */
d1433 1
a1433 1
				pf_unlink_state(s);
d1456 1
a1456 1
				pf_unlink_state(s);
d1502 1
a1502 1
				pf_unlink_state(s);
@


1.293
log
@There's no longer a need to include <net/hfsc.h> in <net/if_var.h>
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.292 2015/11/20 03:35:23 dlg Exp $ */
a59 1
#include <net/if_types.h>
@


1.292
log
@shuffle struct ifqueue so in flight mbufs are protected by a mutex.

the code is refactored so the IFQ macros call newly implemented ifq
functions. the ifq code is split so each discipline (priq and hfsc
in our case) is an opaque set of operations that the common ifq
code can call. the common code does the locking, accounting (ifq_len
manipulation), and freeing of the mbuf if the disciplines enqueue
function rejects it. theyre kind of like bufqs in the block layer
with their fifo and nscan disciplines.

the new api also supports atomic switching of disciplines at runtime.
the hfsc setup in pf_ioctl.c has been tweaked to build a complete
hfsc_if structure which it attaches to the send queue in a single
operation, rather than attaching to the interface up front and
building up a list of queues.

the send queue is now mutexed, which raises the expectation that
packets can be enqueued or purged on one cpu while another cpu is
dequeueing them in a driver for transmission. a lot of drivers use
IFQ_POLL to peek at an mbuf and attempt to fit it on the ring before
committing to it with a later IFQ_DEQUEUE operation. if the mbuf
gets freed in between the POLL and DEQUEUE operations, fireworks
will ensue.

to avoid this, the ifq api introduces ifq_deq_begin, ifq_deq_rollback,
and ifq_deq_commit. ifq_deq_begin allows a driver to take the ifq
mutex and get a reference to the mbuf they wish to try and tx. if
there's space, they can ifq_deq_commit it to remove the mbuf and
release the mutex. if there's no space, ifq_deq_rollback simply
releases the mutex. this api was developed to make updating the
drivers using IFQ_POLL easy, instead of having to do significant
semantic changes to avoid POLL that we cannot test on all the
hardware.

the common code has been tested pretty hard, and all the driver
modifications are straightforward except for de(4). if that breaks
it can be dealt with later.

ok mpi@@ jmatthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.291 2015/10/13 19:32:31 sashan Exp $ */
d62 1
@


1.291
log
@- pf_insert_src_node(): global argument (arg6) is useless, function
  always gets pointer to rule.

- pf_remove_src_node(): function should always remove matching src node,
  regardless the sn->rule.ptr being NULL or valid rule

- sn->rule.ptr is never NULL, spotted by mpi and Richard Procter _von_ gmail.com

OK mpi@@, OK mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.290 2015/09/04 21:40:25 kettenis Exp $ */
d88 2
a89 1
int			 pf_create_queues(void);
d91 1
d522 4
a525 1
	return (pf_free_queues(pf_queues_inactive, NULL));
d528 2
a529 2
int
pf_free_queues(struct pf_queuehead *where, struct ifnet *ifp)
a533 2
		if (ifp && q->kif->pfik_ifp != ifp)
			continue;
a537 1
	return (0);
d540 2
a541 2
int
pf_remove_queues(struct ifnet *ifp)
d544 1
a544 1
	int			 error = 0;
d546 7
a552 3
	/* remove queues */
	TAILQ_FOREACH_REVERSE(q, pf_queues_active, pf_queuehead, entries) {
		if (ifp && q->kif->pfik_ifp != ifp)
d554 4
a557 2
		if ((error = hfsc_delqueue(q)) != 0)
			return (error);
d559 16
d576 1
a576 7
	/* put back interfaces in normal queueing mode */	
	TAILQ_FOREACH(q, pf_queues_active, entries) {
		if (ifp && q->kif->pfik_ifp != ifp)
			continue;
		if (q->parent_qid == 0)
			if ((error = hfsc_detach(q->kif->pfik_ifp)) != 0)
				return (error);
d579 1
a579 1
	return (0);
d586 16
a601 1
	int			 error = 0;
d603 3
a605 5
	/* find root queues and attach hfsc to these interfaces */
	TAILQ_FOREACH(q, pf_queues_active, entries)
		if (q->parent_qid == 0)
			if ((error = hfsc_attach(q->kif->pfik_ifp)) != 0)
				return (error);
d608 39
a646 3
	TAILQ_FOREACH(q, pf_queues_active, entries)
		if ((error = hfsc_addqueue(q)) != 0)
			return (error);
d649 11
d668 9
a676 1
	if ((error = pf_remove_queues(NULL)) != 0)
d678 1
d680 1
a680 5
	/* swap */
	qswap = pf_queues_active;
	pf_queues_active = pf_queues_inactive;
	pf_queues_inactive = qswap;
	pf_free_queues(pf_queues_inactive, NULL);
d682 1
a682 1
	return (pf_create_queues());
d1021 1
a1021 1
			pf_remove_queues(NULL);
d1087 1
a1087 1
		error = hfsc_qstats(qs, pq->buf, &nbytes);
@


1.290
log
@The pf_osfp_pl and pf_osfp_entry_pl never get used in interrupt context.
Drop the explicit pool backend allocator here and add PR_WAITOK to the
flags passed to pool_init(9).

The pfi_addr_pl and pf_rule_pl can get used in interrupt context though.
So simply drop the explicit pool backend allocator without adding PR_WAITOK
to the flags passed to pool_init(9).

ok mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.289 2015/07/21 02:32:04 sashan Exp $ */
d2178 1
a2178 2
			if (n->rule.ptr != NULL)
				pstore->rule.nr = n->rule.ptr->nr;
@


1.289
log
@- added /* FALLTHROUGH */ comments, typecasts (u_int32_t)-1, ...


ok mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.288 2015/07/19 05:54:54 sashan Exp $ */
d143 1
a143 1
	    &pool_allocator_nointr);
@


1.288
log
@potential memory leak in SIOCADDRULE

ok mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.287 2015/07/19 05:48:12 sashan Exp $ */
d182 1
a182 1
	pf_default_rule.nr = -1;
d268 1
a268 1
		rule->nr = -1;
d1196 1
a1196 1
				pr->rule.skip[i].nr = -1;
@


1.287
log
@unsinged variables should not be compared to be leq than 0 (unsigned a <= 0)

ok mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.286 2015/07/18 19:19:00 sashan Exp $ */
d1071 2
a1072 1
			pool_put(&pf_rule_pl, rule);
d1088 2
a1089 1
			pool_put(&pf_rule_pl, rule);
@


1.286
log
@msg.mpi
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.285 2015/04/11 13:00:12 dlg Exp $ */
d252 1
a252 1
		if (rule->states_cur <= 0 && rule->src_nodes <= 0) {
@


1.285
log
@the hfsc pools are only used in hfsc.c, so move the init of them
there instead of pf_ioctl.c.

ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.284 2015/03/14 03:38:51 jsg Exp $ */
d1347 1
a1347 1
#endif
d1355 1
a1355 1
#endif
d1437 1
a1437 1
#endif
d2431 1
a2431 1
#endif
@


1.284
log
@Remove some includes include-what-you-use claims don't
have any direct symbols used.  Tested for indirect use by compiling
amd64/i386/sparc64 kernels.

ok tedu@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.283 2015/02/20 11:08:31 tedu Exp $ */
d158 1
a158 6
	pool_init(&hfsc_class_pl, sizeof(struct hfsc_class), 0, 0, PR_WAITOK,
	    "hfscclass", NULL);
	pool_init(&hfsc_classq_pl, sizeof(struct hfsc_classq), 0, 0, PR_WAITOK,
	    "hfscclassq", NULL);
	pool_init(&hfsc_internal_sc_pl, sizeof(struct hfsc_internal_sc), 0, 0,
	    PR_WAITOK, "hfscintsc", NULL);
@


1.283
log
@fix a memory leak in the error case found by Maxime Villard's Brainy
code scanner. Changing return to break also fixes a failure to unlock.
Also fix a NULL check for that variable noticed by bluhm.
ok bluhm henning millert
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.282 2015/02/10 06:45:55 henning Exp $ */
a69 4

#if NPFLOG > 0
#include <net/if_pflog.h>
#endif /* NPFLOG > 0 */
@


1.282
log
@since we inherit prio (as in, the queuing priority) from outside sources,
i. e. on vlan interfaces, it is useful to be able to match on it -
effectively matching on classification done elsewhere.
i thought i had long implemented that, but chrisz@@ asking for it made
me notice that wasn't the case.
tests by chrisz, ok phessler pelikan
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.280 2014/12/19 17:14:40 tedu Exp $ */
d1035 5
a1039 2
		    pf_qname2qid(qs->parent, 0)) == 0)
			return (ESRCH);
d1041 2
a1042 1
		if (!qs->kif->pfik_ifp) {
@


1.281
log
@Userland (base & ports) was adapted to always include <netinet/in.h>
before <net/pfvar.h> or <net/if_pflog.h>.  The kernel files can be
cleaned up next.  Some sockaddr_union steps make it into here as well.
ok naddy
@
text
@d2462 1
@


1.280
log
@unifdef INET in net code as a precursor to removing the pretend option.
long live the one true internet.
ok henning mikeb
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.279 2014/12/09 07:05:06 doug Exp $ */
d71 4
d76 1
a78 4

#if NPFLOG > 0
#include <net/if_pflog.h>
#endif /* NPFLOG > 0 */
@


1.279
log
@More malloc() -> mallocarray() in the kernel.

ok deraadt@@ tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.278 2014/12/05 15:50:04 mpi Exp $ */
a1083 1
#ifdef INET
a1085 1
#endif /* INET */
a1257 1
#ifdef INET
a1259 1
#endif /* INET */
@


1.278
log
@Explicitly include <net/if_var.h> instead of pulling it in <net/if.h>.

ok mikeb@@, krw@@, bluhm@@, tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.277 2014/11/18 02:37:31 tedu Exp $ */
d762 3
a764 2
		rs->rules.inactive.ptr_array = malloc(sizeof(caddr_t) *
		    rs->rules.inactive.rcount,  M_TEMP, M_NOWAIT);
@


1.277
log
@move arc4random prototype to systm.h. more appropriate for most code
to include that than rdnvar.h. ok deraadt dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.276 2014/08/12 15:29:33 mikeb Exp $ */
d59 1
@


1.276
log
@Finally implement what's stated in the man page regarding parent
anchors for "once" rules: "In case this is the only rule in the
anchor, the anchor will be destroyed automatically after the rule
is matched."  Employ an additional pointer pair to keep track of
the parent ruleset containing the anchor that we want to remove.

OK henning
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.275 2014/08/12 14:38:28 mikeb Exp $ */
a66 1
#include <dev/rndvar.h>
@


1.275
log
@Apart from some minor code reshuffling the big change is that we
start with a ruleset pointer assigned to pf_main_ruleset so that
pf_purge_rule doesn't get called with a NULL.

Prompted by the discussion with Alexandr Nedvedicky <alexandr !
nedvedicky at oracle ! com>.

OK henning
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.274 2014/07/22 11:06:09 mpi Exp $ */
d310 2
a311 1
pf_purge_rule(struct pf_ruleset *ruleset, struct pf_rule *rule)
d313 1
a313 1
	u_int32_t	 nr = 0;
d323 10
a332 1
	pf_remove_if_empty_ruleset(ruleset);
@


1.274
log
@Fewer <netinet/in_systm.h> !
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.273 2014/07/12 18:44:22 tedu Exp $ */
d312 1
a312 1
	u_int32_t		 nr;
d314 1
a314 2
	if (ruleset == NULL || ruleset->anchor == NULL)
		return;
a317 2

	nr = 0;
a319 1

a320 1

@


1.273
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.272 2014/04/22 14:41:03 mpi Exp $ */
a62 1
#include <netinet/in_systm.h>
@


1.272
log
@Remove some altq tentacles.

ok pelikan@@, henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.271 2014/04/19 12:59:53 henning Exp $ */
d402 1
a402 1
				free(p, M_TEMP);
d732 1
a732 1
		free(rs->rules.inactive.ptr_array, M_TEMP);
d754 1
a754 1
		free(rs->rules.inactive.ptr_array, M_TEMP);
d1485 1
a1485 1
					free(pstore, M_TEMP);
d1496 1
a1496 1
		free(pstore, M_TEMP);
d1951 2
a1952 2
				free(table, M_TEMP);
				free(ioe, M_TEMP);
d1963 2
a1964 2
					free(table, M_TEMP);
					free(ioe, M_TEMP);
d1971 2
a1972 2
					free(table, M_TEMP);
					free(ioe, M_TEMP);
d1978 2
a1979 2
				free(table, M_TEMP);
				free(ioe, M_TEMP);
d1984 2
a1985 2
		free(table, M_TEMP);
		free(ioe, M_TEMP);
d2003 2
a2004 2
				free(table, M_TEMP);
				free(ioe, M_TEMP);
d2015 2
a2016 2
					free(table, M_TEMP);
					free(ioe, M_TEMP);
d2023 2
a2024 2
					free(table, M_TEMP);
					free(ioe, M_TEMP);
d2030 2
a2031 2
		free(table, M_TEMP);
		free(ioe, M_TEMP);
d2051 2
a2052 2
				free(table, M_TEMP);
				free(ioe, M_TEMP);
d2061 2
a2062 2
					free(table, M_TEMP);
					free(ioe, M_TEMP);
d2073 2
a2074 2
					free(table, M_TEMP);
					free(ioe, M_TEMP);
d2089 2
a2090 2
				free(table, M_TEMP);
				free(ioe, M_TEMP);
d2098 2
a2099 2
				free(table, M_TEMP);
				free(ioe, M_TEMP);
d2110 2
a2111 2
					free(table, M_TEMP);
					free(ioe, M_TEMP);
d2118 2
a2119 2
					free(table, M_TEMP);
					free(ioe, M_TEMP);
d2130 2
a2131 2
				free(table, M_TEMP);
				free(ioe, M_TEMP);
d2148 2
a2149 2
		free(table, M_TEMP);
		free(ioe, M_TEMP);
d2198 1
a2198 1
				free(pstore, M_TEMP);
d2206 1
a2206 1
		free(pstore, M_TEMP);
@


1.271
log
@shrink pf by 445 lines.
while there, get rid of the altq ioctls and assciated now obsolete code
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.269 2014/02/04 01:04:03 tedu Exp $ */
a159 2
	pool_init(&pf_altq_pl, sizeof(struct pf_altq), 0, 0, 0, "pfaltq",
	    &pool_allocator_nointr);
a185 4
	TAILQ_INIT(&pf_altqs[0]);
	TAILQ_INIT(&pf_altqs[1]);
	pf_altqs_active = &pf_altqs[0];
	pf_altqs_inactive = &pf_altqs[1];
a2402 1
	/* set queue IDs. little ugly due to both altq and new system... */
@


1.270
log
@Eliminates struct pcred by moving the real and saved ugids into
struct ucred; struct process then directly links to the ucred

Based on a discussion at c2k10 or so before noting that FreeBSD and
NetBSD did this too.

ok matthew@@
@
text
@a84 4
#ifdef ALTQ
#include <altq/altq.h>
#endif

a89 7
#ifdef ALTQ
int			 pf_begin_altq(u_int32_t *);
int			 pf_rollback_altq(u_int32_t);
int			 pf_commit_altq(u_int32_t);
int			 pf_enable_altq(struct pf_altq *);
int			 pf_disable_altq(struct pf_altq *);
#endif /* ALTQ */
a105 3
u_int32_t		 pf_oqname2qid(char *);
void			 pf_oqid2qname(u_int32_t, char *);
void			 pf_oqid_unref(u_int32_t);
a111 3
#ifdef ALTQ
static int		 pf_altq_running;
#endif
a127 1
				pf_oqids = TAILQ_HEAD_INITIALIZER(pf_oqids),
a290 5
#ifdef ALTQ
	if (rule->pqid != rule->qid)
		pf_oqid_unref(rule->pqid);
	pf_oqid_unref(rule->qid);
#endif
a493 174
#ifdef ALTQ
u_int32_t
pf_oqname2qid(char *qname)
{
	return ((u_int32_t)tagname2tag(&pf_oqids, qname, 1));
}

void
pf_oqid2qname(u_int32_t qid, char *p)
{
	tag2tagname(&pf_oqids, (u_int16_t)qid, p);
}

void
pf_oqid_unref(u_int32_t qid)
{
	tag_unref(&pf_oqids, (u_int16_t)qid);
}

int
pf_begin_altq(u_int32_t *ticket)
{
	struct pf_altq	*altq;
	int		 error = 0;

	/* Purge the old altq list */
	while ((altq = TAILQ_FIRST(pf_altqs_inactive)) != NULL) {
		TAILQ_REMOVE(pf_altqs_inactive, altq, entries);
		if (altq->qname[0] == 0) {
			/* detach and destroy the discipline */
			error = altq_remove(altq);
		} else
			pf_oqid_unref(altq->qid);
		pool_put(&pf_altq_pl, altq);
	}
	if (error)
		return (error);
	*ticket = ++ticket_altqs_inactive;
	altqs_inactive_open = 1;
	return (0);
}

int
pf_rollback_altq(u_int32_t ticket)
{
	struct pf_altq	*altq;
	int		 error = 0;

	if (!altqs_inactive_open || ticket != ticket_altqs_inactive)
		return (0);
	/* Purge the old altq list */
	while ((altq = TAILQ_FIRST(pf_altqs_inactive)) != NULL) {
		TAILQ_REMOVE(pf_altqs_inactive, altq, entries);
		if (altq->qname[0] == 0) {
			/* detach and destroy the discipline */
			error = altq_remove(altq);
		} else
			pf_oqid_unref(altq->qid);
		pool_put(&pf_altq_pl, altq);
	}
	altqs_inactive_open = 0;
	return (error);
}

int
pf_commit_altq(u_int32_t ticket)
{
	struct pf_altqqueue	*old_altqs;
	struct pf_altq		*altq;
	int			 s, err, error = 0;

	if (!altqs_inactive_open || ticket != ticket_altqs_inactive)
		return (EBUSY);

	/* swap altqs, keep the old. */
	s = splsoftnet();
	old_altqs = pf_altqs_active;
	pf_altqs_active = pf_altqs_inactive;
	pf_altqs_inactive = old_altqs;
	ticket_altqs_active = ticket_altqs_inactive;

	/* Attach new disciplines */
	TAILQ_FOREACH(altq, pf_altqs_active, entries) {
		if (altq->qname[0] == 0) {
			/* attach the discipline */
			error = altq_pfattach(altq);
			if (error == 0 && pf_altq_running)
				error = pf_enable_altq(altq);
			if (error != 0) {
				splx(s);
				return (error);
			}
		}
	}

	/* Purge the old altq list */
	while ((altq = TAILQ_FIRST(pf_altqs_inactive)) != NULL) {
		TAILQ_REMOVE(pf_altqs_inactive, altq, entries);
		if (altq->qname[0] == 0) {
			/* detach and destroy the discipline */
			if (pf_altq_running)
				error = pf_disable_altq(altq);
			err = altq_pfdetach(altq);
			if (err != 0 && error == 0)
				error = err;
			err = altq_remove(altq);
			if (err != 0 && error == 0)
				error = err;
		} else
			pf_oqid_unref(altq->qid);
		pool_put(&pf_altq_pl, altq);
	}
	splx(s);

	altqs_inactive_open = 0;
	return (error);
}

int
pf_enable_altq(struct pf_altq *altq)
{
	struct ifnet		*ifp;
	struct oldtb_profile	 tb;
	int			 s, error = 0;

	if ((ifp = ifunit(altq->ifname)) == NULL)
		return (EINVAL);

	if (ifp->if_snd.altq_type != ALTQT_NONE)
		error = altq_enable(&ifp->if_snd);

	/* set tokenbucket regulator */
	if (error == 0 && ifp != NULL && ALTQ_IS_ENABLED(&ifp->if_snd)) {
		tb.rate = altq->ifbandwidth;
		tb.depth = altq->tbrsize;
		s = splnet();
		error = oldtbr_set(&ifp->if_snd, &tb);
		splx(s);
	}

	return (error);
}

int
pf_disable_altq(struct pf_altq *altq)
{
	struct ifnet		*ifp;
	struct oldtb_profile	 tb;
	int			 s, error;

	if ((ifp = ifunit(altq->ifname)) == NULL)
		return (EINVAL);

	/*
	 * when the discipline is no longer referenced, it was overridden
	 * by a new one.  if so, just return.
	 */
	if (altq->altq_disc != ifp->if_snd.altq_disc)
		return (0);

	error = altq_disable(&ifp->if_snd);

	if (error == 0) {
		/* clear tokenbucket regulator */
		tb.rate = 0;
		s = splnet();
		error = oldtbr_set(&ifp->if_snd, &tb);
		splx(s);
	}

	return (error);
}
#endif /* ALTQ */

a836 3
		case DIOCGETALTQS:
		case DIOCGETALTQ:
		case DIOCGETALTQSTATS:
a878 3
		case DIOCGETALTQS:
		case DIOCGETALTQ:
		case DIOCGETALTQSTATS:
a1670 150
#ifdef ALTQ
	case DIOCSTARTALTQ: {
		struct pf_altq		*altq;

		/* enable all altq interfaces on active list */
		TAILQ_FOREACH(altq, pf_altqs_active, entries) {
			if (altq->qname[0] == 0) {
				error = pf_enable_altq(altq);
				if (error != 0)
					break;
			}
		}
		if (error == 0)
			pf_altq_running = 1;
		DPFPRINTF(LOG_NOTICE, "altq: started");
		break;
	}

	case DIOCSTOPALTQ: {
		struct pf_altq		*altq;

		/* disable all altq interfaces on active list */
		TAILQ_FOREACH(altq, pf_altqs_active, entries) {
			if (altq->qname[0] == 0) {
				error = pf_disable_altq(altq);
				if (error != 0)
					break;
			}
		}
		if (error == 0)
			pf_altq_running = 0;
		DPFPRINTF(LOG_NOTICE, "altq: stopped");
		break;
	}

	case DIOCADDALTQ: {
		struct pfioc_altq	*pa = (struct pfioc_altq *)addr;
		struct pf_altq		*altq, *a;

		if (pa->ticket != ticket_altqs_inactive) {
			error = EBUSY;
			break;
		}
		altq = pool_get(&pf_altq_pl, PR_WAITOK|PR_LIMITFAIL);
		if (altq == NULL) {
			error = ENOMEM;
			break;
		}
		bcopy(&pa->altq, altq, sizeof(struct pf_altq));
		altq->altq_disc = NULL;

		/*
		 * if this is for a queue, find the discipline and
		 * copy the necessary fields
		 */
		if (altq->qname[0] != 0) {
			if ((altq->qid = pf_oqname2qid(altq->qname)) == 0) {
				error = EBUSY;
				pool_put(&pf_altq_pl, altq);
				break;
			}
			TAILQ_FOREACH(a, pf_altqs_inactive, entries) {
				if (strncmp(a->ifname, altq->ifname,
				    IFNAMSIZ) == 0 && a->qname[0] == 0) {
					altq->altq_disc = a->altq_disc;
					break;
				}
			}
		}

		error = altq_add(altq);
		if (error) {
			pool_put(&pf_altq_pl, altq);
			break;
		}

		TAILQ_INSERT_TAIL(pf_altqs_inactive, altq, entries);
		bcopy(altq, &pa->altq, sizeof(struct pf_altq));
		break;
	}

	case DIOCGETALTQS: {
		struct pfioc_altq	*pa = (struct pfioc_altq *)addr;
		struct pf_altq		*altq;

		pa->nr = 0;
		TAILQ_FOREACH(altq, pf_altqs_active, entries)
			pa->nr++;
		pa->ticket = ticket_altqs_active;
		break;
	}

	case DIOCGETALTQ: {
		struct pfioc_altq	*pa = (struct pfioc_altq *)addr;
		struct pf_altq		*altq;
		u_int32_t		 nr;

		if (pa->ticket != ticket_altqs_active) {
			error = EBUSY;
			break;
		}
		nr = 0;
		altq = TAILQ_FIRST(pf_altqs_active);
		while ((altq != NULL) && (nr < pa->nr)) {
			altq = TAILQ_NEXT(altq, entries);
			nr++;
		}
		if (altq == NULL) {
			error = EBUSY;
			break;
		}
		bcopy(altq, &pa->altq, sizeof(struct pf_altq));
		break;
	}

	case DIOCCHANGEALTQ:
		/* CHANGEALTQ not supported yet! */
		error = ENODEV;
		break;

	case DIOCGETALTQSTATS: {
		struct pfioc_altqstats	*pq = (struct pfioc_altqstats *)addr;
		struct pf_altq		*altq;
		u_int32_t		 nr;
		int			 nbytes;

		if (pq->ticket != ticket_altqs_active) {
			error = EBUSY;
			break;
		}
		nbytes = pq->nbytes;
		nr = 0;
		altq = TAILQ_FIRST(pf_altqs_active);
		while ((altq != NULL) && (nr < pq->nr)) {
			altq = TAILQ_NEXT(altq, entries);
			nr++;
		}
		if (altq == NULL) {
			error = EBUSY;
			break;
		}
		error = altq_getqstats(altq, pq->buf, &nbytes);
		if (error == 0) {
			pq->scheduler = altq->scheduler;
			pq->nbytes = nbytes;
		}
		break;
	}
#endif /* ALTQ */

a1962 15
#ifdef ALTQ
			case PF_TRANS_ALTQ:
				if (ioe->anchor[0]) {
					free(table, M_TEMP);
					free(ioe, M_TEMP);
					error = EINVAL;
					goto fail;
				}
				if ((error = pf_begin_altq(&ioe->ticket))) {
					free(table, M_TEMP);
					free(ioe, M_TEMP);
					goto fail;
				}
				break;
#endif /* ALTQ */
a2014 15
#ifdef ALTQ
			case PF_TRANS_ALTQ:
				if (ioe->anchor[0]) {
					free(table, M_TEMP);
					free(ioe, M_TEMP);
					error = EINVAL;
					goto fail;
				}
				if ((error = pf_rollback_altq(ioe->ticket))) {
					free(table, M_TEMP);
					free(ioe, M_TEMP);
					goto fail; /* really bad */
				}
				break;
#endif /* ALTQ */
a2062 17
#ifdef ALTQ
			case PF_TRANS_ALTQ:
				if (ioe->anchor[0]) {
					free(table, M_TEMP);
					free(ioe, M_TEMP);
					error = EINVAL;
					goto fail;
				}
				if (!altqs_inactive_open || ioe->ticket !=
				    ticket_altqs_inactive) {
					free(table, M_TEMP);
					free(ioe, M_TEMP);
					error = EBUSY;
					goto fail;
				}
				break;
#endif /* ALTQ */
a2109 9
#ifdef ALTQ
			case PF_TRANS_ALTQ:
				if ((error = pf_commit_altq(ioe->ticket))) {
					free(table, M_TEMP);
					free(ioe, M_TEMP);
					goto fail; /* really bad */
				}
				break;
#endif /* ALTQ */
d2412 1
a2412 4
#ifdef ALTQ
			if ((to->qid = pf_oqname2qid(to->qname)) == 0)
#endif
				return (EBUSY);
d2415 1
a2415 4
#ifdef ALTQ
				if ((to->pqid = pf_oqname2qid(to->pqname)) == 0)
#endif
					return (EBUSY);
@


1.269
log
@reduce the length of some pool names. ok deraadt guenther mpi
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.268 2014/01/20 02:57:50 henning Exp $ */
d1282 1
a1282 1
		rule->cuid = p->p_cred->p_ruid;
d1458 1
a1458 1
			newrule->cuid = p->p_cred->p_ruid;
@


1.268
log
@support negated matches on the rcvif, ok dlg benno
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.266 2014/01/03 12:43:09 pelikan Exp $ */
d164 1
a164 1
	pool_init(&pf_rule_pl, sizeof(struct pf_rule), 0, 0, 0, "pfrulepl",
d167 1
a167 1
	    "pfsrctrpl", NULL);
d169 2
a170 2
	    "pfsnitempl", NULL);
	pool_init(&pf_state_pl, sizeof(struct pf_state), 0, 0, 0, "pfstatepl",
d173 1
a173 1
	    "pfstatekeypl", NULL);
d175 1
a175 1
	    "pfstateitempl", NULL);
d177 2
a178 2
	    "pfruleitempl", NULL);
	pool_init(&pf_altq_pl, sizeof(struct pf_altq), 0, 0, 0, "pfaltqpl",
d181 1
a181 1
	    "pfqueuepl", NULL);
@


1.267
log
@Switch frequently allocated structs from malloc(M_DEVBUF) to separate pools.

ok henning, "looks fine" mikeb, input from guenther.
@
text
@d880 1
d2859 1
@


1.266
log
@Make queues disappear correctly on interfaces being destroyed.

ok henning
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.265 2013/11/13 18:25:57 deraadt Exp $ */
d182 6
@


1.265
log
@DIOCGETSRCNODES was leaking a little bit more kernel information
ok benno
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.264 2013/11/12 20:14:22 deraadt Exp $ */
a102 2
int			 pf_free_queues(char *);
int			 pf_remove_queues(void);
d104 1
a104 1
int			 pf_commit_queues(char *);
d717 5
a721 1
	return (pf_free_queues(anchor));
d725 1
a725 1
pf_free_queues(char *anchor)
d727 1
a727 1
	struct pf_queuespec	*q;
d729 4
a732 6
	/* queue defs only in the main ruleset */
	if (anchor[0])
		return (0);

	while ((q = TAILQ_FIRST(pf_queues_inactive)) != NULL) {
		TAILQ_REMOVE(pf_queues_inactive, q, entries);
d740 1
a740 1
pf_remove_queues(void)
d746 3
a748 1
	TAILQ_FOREACH_REVERSE(q, pf_queues_active, pf_queuehead, entries)
d751 1
d754 3
a756 1
	TAILQ_FOREACH(q, pf_queues_active, entries)
d760 1
d786 1
a786 1
pf_commit_queues(char *anchor)
d791 1
a791 5
	/* queue defs only in the main ruleset */
	if (anchor[0])
		return (0);

	if ((error = pf_remove_queues()) != 0)
d798 1
a798 1
	pf_free_queues(anchor);
d934 5
a938 1
	return (pf_commit_queues(anchor));
d1143 1
a1143 1
			pf_remove_queues();
@


1.264
log
@two ioctl's were disclosing kernel pointers and such.
ok henning benno
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.263 2013/10/20 16:35:31 deraadt Exp $ */
d2578 1
@


1.263
log
@Deep inside DIOCXCOMMIT, should return a real errno instead of -1
ok henning pelikan
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.262 2013/10/17 16:27:42 bluhm Exp $ */
d1372 8
d2578 2
@


1.262
log
@The header file netinet/in_var.h included netinet6/in6_var.h.  This
created a bunch of useless dependencies.  Remove this implicit
inclusion and do an explicit #include <netinet6/in6_var.h> when it
is needed.
OK mpi@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.261 2013/10/12 12:13:11 henning Exp $ */
d783 1
d789 2
a790 2
	if (pf_remove_queues() != 0)
		return (-1);
@


1.261
log
@new bandwidth shaping subsystem, kernel side
uses hfsc behind the scenes; altq stays in parallel for a migration phase.
if.h even more messy for the transition, but eventuelly it should become
readable...
looked over & tested by many, ok phessler sthen
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.260 2013/10/12 11:55:45 henning Exp $ */
a62 1
#include <netinet/in_var.h>
@


1.260
log
@give tagname2tag and its siblings an extra "create" parameter. if 1, it
behaves like before and creates the mapping if needed. if 0, lookup only.
looked over by many, ok phessler sthen
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.259 2013/03/28 16:45:16 tedu Exp $ */
d5 1
a5 1
 * Copyright (c) 2002,2003 Henning Brauer
d104 4
d123 3
d148 2
a149 1
				pf_oqids = TAILQ_HEAD_INITIALIZER(pf_oqids);
d183 2
d199 4
d496 18
d720 17
d740 61
d932 1
a932 1
	return (0);
d1023 1
a1023 1
		case DIOCGETQSTATS:
d1026 3
d1068 1
a1068 1
		case DIOCGETQSTATS:
d1071 3
d1126 1
d1137 1
d1142 99
d1973 2
a1974 2
	case DIOCGETQSTATS: {
		struct pfioc_qstats	*pq = (struct pfioc_qstats *)addr;
d2466 1
d2794 3
d2798 2
a2799 6
	/* set queue IDs */
	if (to->qname[0] != 0) {
		if ((to->qid = pf_oqname2qid(to->qname)) == 0)
			return (EBUSY);
		else if (to->pqname[0] != 0) {
			if ((to->pqid = pf_oqname2qid(to->pqname)) == 0)
d2801 6
a2809 1
#endif
@


1.259
log
@no need for a lot of code to include proc.h
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.258 2013/03/27 13:32:28 mcbride Exp $ */
d146 1
a146 1
u_int16_t		 tagname2tag(struct pf_tags *, char *);
d344 1
a344 1
tagname2tag(struct pf_tags *head, char *tagname)
d355 3
d422 1
a422 1
pf_tagname2tag(char *tagname)
d424 1
a424 1
	return (tagname2tag(&pf_tags, tagname));
d486 1
a486 1
	return ((u_int32_t)tagname2tag(&pf_oqids, qname));
d2594 1
a2594 1
		if ((to->tag = pf_tagname2tag(to->tagname)) == 0)
d2597 1
a2597 1
		if ((to->match_tag = pf_tagname2tag(to->match_tagname)) == 0)
@


1.258
log
@Use the correct src/dst ports depending on direction (one of src or dst was
wrong in each direction).

Report and fix from UMEZAWA Takeshi <umezawa@@iij.ad.jp>
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.257 2013/02/26 14:56:05 mikeb Exp $ */
a51 1
#include <sys/proc.h>
@


1.257
log
@Don't try to purge one-time rules from the main ruleset.
Reported by Wesley M.A. on misc@@,  ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.256 2012/10/30 12:09:05 florian Exp $ */
d1357 1
a1357 1
				srcport = sk->port[0];
d1364 1
a1364 1
				dstport = sk->port[0];
@


1.256
log
@Use time_uptime for expiration values as time_second can be skewed at
runtime while time_uptime is monotonic. Prevent underflows in
pfsync(4) and pflow(4) by using signed variables.  pfsync(4) problem
pointed out by camield.

Diff originally by dlg, frag and pflow bits by me.

feedback dlg
man page tweak jmc

Various versions of the pflow bits tested by Hrvoje Popovski
(hrvoje AT srce DOT hr), thanks!

ok benno, henning, dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.255 2012/09/20 09:43:49 camield Exp $ */
d327 3
@


1.255
log
@Lower pf frags limit to not risk running out of mbuf clusters
when dealing with lots of IP fragments.

This sets the default to 25% of the mbuf cluster maximum (hint
from beck).  And the example in the manpage is sane now.

ok mikeb henning beck deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.254 2012/09/18 10:11:53 henning Exp $ */
d2341 1
a2341 1
			int	secs = time_second, diff;
d2349 1
a2349 1
			pstore->creation = time_uptime - pstore->creation;
@


1.254
log
@prio 0 is valid, therefore, I chose an "impossible" value for prio meaning
"not set" and used a PF_PRIO_NOTSET define for it. now that means that
everything that creates a struct pf_rule doesn't get away with bzero'ing it,
which turned out to be not so nice. so get rid of PF_PRIO_NOTSET, instead,
make a rule+state flag PFSTATE_SETPRIO which indicates wether the prio
should be set. ok benno claudio mikeb
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.252 2012/07/07 16:24:32 henning Exp $ */
d1598 6
@


1.253
log
@there was a limit on the number of pflog interfaces - 16. remove that.
mostly by dynamically allocating pflogifs instead of making that a static
array. ok claudio zinke
@
text
@d1091 3
a1093 4
		if ((rule->set_prio[0] != PF_PRIO_NOTSET &&
		    rule->set_prio[0] > IFQ_MAXPRIO) ||
		    (rule->set_prio[1] != PF_PRIO_NOTSET &&
                    rule->set_prio[1] > IFQ_MAXPRIO))
@


1.252
log
@rename prio in struct pf_rule and related structs to set_prio so it is
utterly clear this is not a filter criteria but a packet modification thing.
also preparation for upcoming changes, including one to unscrew this mess
(I should not have to touch half the tree for this - ifixitlater)
not user visible, ok gcc
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.251 2012/07/07 15:20:14 henning Exp $ */
a2599 2
	if (to->logif >= PFLOGIFS_MAX)
		return (EINVAL);
@


1.251
log
@restore DIOCKILLSTATE semantics to what they were before the NAT rewrite.
when you kill states by IP, it is not all that clear which IP we're talking
about - before or after rewriting?
the old semantics were to always look at the "original" IP, i. e. before
rewriting. ever since the NAT rewrite we were unconditionally looking
at the wire side state key, which is the original address for PF_IN states,
but not for PF_OUT. So look at the SK_STACK state key in the PF_OUT case.
should fix "authpf doesn't remove NAT states" seen on misc a while ago
ok & testing & half of the analysis bob (he sez beck)
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.249 2012/03/28 19:41:05 claudio Exp $ */
d1091 4
a1094 3
		if ((rule->prio[0] != PF_PRIO_NOTSET && rule->prio[0] >
		    IFQ_MAXPRIO) || (rule->prio[1] != PF_PRIO_NOTSET &&
                    rule->prio[1] > IFQ_MAXPRIO))
d2627 2
a2628 2
	to->prio[0] = from->prio[0];
	to->prio[1] = from->prio[1];
@


1.250
log
@Fix kernel compilation with pf but without pfsync pseudo-device by
moving the state export functionality from pfsync code into pf.
Based on the initial diff diff by guenther, ok henning.
@
text
@a1348 1
			sk = s->key[PF_SK_WIRE];
d1351 1
d1357 1
@


1.249
log
@Another pid that needs to be the process pid and not the thread one.
OK deraadt@@, guenther@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.248 2011/12/12 21:30:27 mikeb Exp $ */
d1393 1
d1405 1
d1422 1
a1422 1
		pfsync_state_export(&ps->state, s);
d1447 1
a1447 1
				pfsync_state_export(pstore, state);
@


1.248
log
@fixup af-to regression with match rules

pfctl should not infer the af-to behavior from the af/naf difference.
instead, we should be clear that this is an af-to rule.  essentially
this change converts FOM_AFTO marker into a rule flag PFRULE_AFTO so
that we don't rely on ambiguous checks (like r->af != r->naf) when
setting things up.

positive review and comments from claudio, ok henning, sperreault
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.247 2011/11/29 10:17:52 dlg Exp $ */
d1048 1
a1048 1
		rule->cpid = p->p_pid;
d1216 1
a1216 1
			newrule->cpid = p->p_pid;
@


1.247
log
@use a u_int64_t for the state id in pfsync_state. this makes it consistent
with every other thing that stores the state id (including other pfsync
messages).

includes improvements to the systat code to consider the creatorid as well
as the state id in its cache to avoid collisions between states created on
different hosts.

tested by me in production and on amd64 talking to sparc64.
ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.246 2011/11/28 01:04:50 dlg Exp $ */
a2521 2
	to->naf = from->naf;

d2604 1
@


1.246
log
@deprecate PFTM_UNTIL_PACKET. nothing in the tree uses it, and
pf_state_expires() handled it incorrectly.

discussed with mikeb@@
ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.245 2011/11/25 12:52:10 dlg Exp $ */
d1411 1
a1411 1
		bcopy(ps->state.id, &id_key.id, sizeof(id_key.id));
@


1.245
log
@use time_uptime to set state creation values as time_second can be
skewed at runtime by things like date(1) and ntpd. time_uptime is
monotonic and therefore more useful to compare against.

ok deraadt@@ mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.244 2011/10/13 18:23:40 claudio Exp $ */
d1397 1
a1397 2
		if (sp->timeout >= PFTM_MAX &&
		    sp->timeout != PFTM_UNTIL_PACKET) {
@


1.244
log
@Since the IPv6 madness is not enough introduce NAT64 -- which is actually
"af-to" a generic IP version translator for pf(4).
Not everything perfect yet but lets fix these things in the tree.
Insane amount of work done by sperreault@@, mikeb@@ and reyk@@.
Looked over by mcbride@@ henning@@ and myself at eurobsdcon.
OK mcbride@@ and general put it in from deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.243 2011/10/07 17:10:08 henning Exp $ */
d2341 1
a2341 1
			pstore->creation = secs - pstore->creation;
@


1.243
log
@rename some vars and functions
unfortunately altq is one giant namespace violation. rename just those that
conflict with new stuff for now only to be found on my laptop. reduce pain,
the diff is huge already. ok ryan
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.241 2011/07/08 18:50:51 henning Exp $ */
d2522 2
@


1.242
log
@Add support for one shot rules that remove themselves from an active
ruleset after match.  In case this is the only rule in the anchor,
the anchor will be destroyed automatically after the rule is matched.
This is an extremely handy technique for firewall proxies.

ok henning, mcbride
@
text
@d117 3
d142 1
a142 1
				pf_qids = TAILQ_HEAD_INITIALIZER(pf_qids);
d295 2
a296 2
		pf_qid_unref(rule->pqid);
	pf_qid_unref(rule->qid);
d479 1
a479 1
pf_qname2qid(char *qname)
d481 1
a481 1
	return ((u_int32_t)tagname2tag(&pf_qids, qname));
d485 1
a485 1
pf_qid2qname(u_int32_t qid, char *p)
d487 1
a487 1
	tag2tagname(&pf_qids, (u_int16_t)qid, p);
d491 1
a491 1
pf_qid_unref(u_int32_t qid)
d493 1
a493 1
	tag_unref(&pf_qids, (u_int16_t)qid);
d509 1
a509 1
			pf_qid_unref(altq->qid);
d534 1
a534 1
			pf_qid_unref(altq->qid);
d586 1
a586 1
			pf_qid_unref(altq->qid);
d599 1
a599 1
	struct tb_profile	 tb;
d613 1
a613 1
		error = tbr_set(&ifp->if_snd, &tb);
d624 1
a624 1
	struct tb_profile	 tb;
d643 1
a643 1
		error = tbr_set(&ifp->if_snd, &tb);
d1679 1
a1679 1
			if ((altq->qid = pf_qname2qid(altq->qname)) == 0) {
d2566 1
a2566 1
		if ((to->qid = pf_qname2qid(to->qname)) == 0)
d2569 1
a2569 1
			if ((to->pqid = pf_qname2qid(to->pqname)) == 0)
@


1.241
log
@surprisingly, we use pf as classifier for the new priority queueing
implementation. ok ryan mpf sthen and also testing pea and halex looked
at it and commented as well
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.239 2011/04/19 21:58:03 chl Exp $ */
d318 18
@


1.240
log
@Don't destroy a non-persistent table if referenced by src_nodes. Fixes
a crash if max-src-* options are triggered both before and after a ruleset
reload, when the rules are overloading to a non-persistent table.
Discovered by and fix from Martin Pelikan.
@
text
@d1070 4
d2602 2
@


1.239
log
@Fix potential null dereference.

Found by LLVM/Clang Static Analyzer.

ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.238 2011/04/06 13:18:39 claudio Exp $ */
d266 1
a266 1
		if (rule->states_cur <= 0) {
@


1.238
log
@Allow PF to filter on the rdomain a packet belongs to. This allows to
write rules like "pass in on rdomain 1".
Tested by phessler@@, OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.237 2011/03/25 10:54:22 claudio Exp $ */
a816 1
	}
d818 4
a821 3
	TAILQ_FOREACH(rule, rs->rules.inactive.ptr, entries) {
		pf_hash_rule(&ctx, rule);
		(rs->rules.inactive.ptr_array)[rule->nr] = rule;
@


1.237
log
@Include original rdomain in DIOCNATLOOK. This allows userland proxies
to establish cross rdomain proxy sessions.
OK henning@@, mpf@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.236 2010/12/15 14:22:25 claudio Exp $ */
d2520 1
a2520 1
	if (to->rtableid > 0 && !rtable_exists(to->rtableid))
d2522 5
@


1.236
log
@Be more careful when copying the pf rule from userland into the kernel.
All pointers in the struct need to be cleared and reset. So instead of
bcopy the struct and clear some fields start with a clean struct and
assign the values that need to be copied.
Fixes a local vulnerability but only root can issue the problematic ioctl().
Reported by Jean Sigwald, has been in snaps for a while and OK deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.235 2010/06/30 18:10:55 henning Exp $ */
d1514 1
@


1.235
log
@fix route label awesomeness, issue also known as PR6416
broken by ryan in australia
problem found & nagging by sthen
jsg found the fix but failed to apply the cluestick correctly ;)
test & ok sthen
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.234 2010/06/28 23:21:41 mcbride Exp $ */
d114 3
d1017 1
a1017 1
		rule = pool_get(&pf_rule_pl, PR_WAITOK|PR_LIMITFAIL);
d1022 4
a1025 1
		bcopy(&pr->rule, rule, sizeof(struct pf_rule));
a1027 7
		rule->anchor = NULL;
		rule->kif = NULL;
		rule->rcv_kif = NULL;
		/* initialize refcounting */
		rule->states_cur = 0;
		rule->src_nodes = 0;
		rule->entries.tqe_prev = NULL;
a1055 42
		if (pf_kif_setup(rule->ifname, &rule->kif))
			error = EINVAL;
		if (pf_kif_setup(rule->rcv_ifname, &rule->rcv_kif))
			error = EINVAL;
		if (pf_kif_setup(rule->rdr.ifname, &rule->rdr.kif))
			error = EINVAL;
		if (pf_kif_setup(rule->nat.ifname, &rule->nat.kif))
			error = EINVAL;
		if (pf_kif_setup(rule->route.ifname, &rule->route.kif))
			error = EINVAL;

		if (rule->rtableid > 0 && !rtable_exists(rule->rtableid))
			error = EBUSY;

#ifdef ALTQ
		/* set queue IDs */
		if (rule->qname[0] != 0) {
			if ((rule->qid = pf_qname2qid(rule->qname)) == 0)
				error = EBUSY;
			else if (rule->pqname[0] != 0) {
				if ((rule->pqid =
				    pf_qname2qid(rule->pqname)) == 0)
					error = EBUSY;
			} else
				rule->pqid = rule->qid;
		}
#endif
		if (rule->tagname[0])
			if ((rule->tag = pf_tagname2tag(rule->tagname)) == 0)
				error = EBUSY;
		if (rule->match_tagname[0])
			if ((rule->match_tag =
			    pf_tagname2tag(rule->match_tagname)) == 0)
				error = EBUSY;
		if (rule->rt && !rule->direction)
			error = EINVAL;
#if NPFLOG > 0
		if (!rule->log)
			rule->logif = 0;
		if (rule->logif >= PFLOGIFS_MAX)
			error = EINVAL;
#endif
d1068 2
a1069 9

		if (rule->overload_tblname[0]) {
			if ((rule->overload_tbl = pfr_attach_table(ruleset,
			    rule->overload_tblname, 0)) == NULL)
				error = EINVAL;
			else
				rule->overload_tbl->pfrkt_flags |=
				    PFR_TFLAG_ACTIVE;
		}
a1074 2
		rule->evaluations = rule->packets[0] = rule->packets[1] =
		    rule->bytes[0] = rule->bytes[1] = 0;
d1183 2
a1184 1
			newrule = pool_get(&pf_rule_pl, PR_WAITOK|PR_LIMITFAIL);
d1189 1
a1189 1
			bcopy(&pcr->rule, newrule, sizeof(struct pf_rule));
a1191 3
			/* initialize refcounting */
			newrule->states_cur = 0;
			newrule->entries.tqe_prev = NULL;
a1209 37
			if (pf_kif_setup(newrule->ifname, &newrule->kif))
				error = EINVAL;
			if (pf_kif_setup(newrule->rcv_ifname, &newrule->rcv_kif))
				error = EINVAL;
			if (pf_kif_setup(newrule->rdr.ifname, &newrule->rdr.kif))
				error = EINVAL;
			if (pf_kif_setup(newrule->nat.ifname, &newrule->nat.kif))
				error = EINVAL;
			if (pf_kif_setup(newrule->route.ifname, &newrule->route.kif))
				error = EINVAL;

			if (newrule->rtableid > 0 &&
			    !rtable_exists(newrule->rtableid))
				error = EBUSY;

#ifdef ALTQ
			/* set queue IDs */
			if (newrule->qname[0] != 0) {
				if ((newrule->qid =
				    pf_qname2qid(newrule->qname)) == 0)
					error = EBUSY;
				else if (newrule->pqname[0] != 0) {
					if ((newrule->pqid =
					    pf_qname2qid(newrule->pqname)) == 0)
						error = EBUSY;
				} else
					newrule->pqid = newrule->qid;
			}
#endif /* ALTQ */
			if (newrule->tagname[0])
				if ((newrule->tag =
				    pf_tagname2tag(newrule->tagname)) == 0)
					error = EBUSY;
			if (newrule->match_tagname[0])
				if ((newrule->match_tag = pf_tagname2tag(
				    newrule->match_tagname)) == 0)
					error = EBUSY;
a1211 6
#if NPFLOG > 0
			if (!newrule->log)
				newrule->logif = 0;
			if (newrule->logif >= PFLOGIFS_MAX)
				error = EINVAL;
#endif
a1224 10
			if (newrule->overload_tblname[0]) {
				if ((newrule->overload_tbl = pfr_attach_table(
				    ruleset, newrule->overload_tblname, 0)) ==
				    NULL)
					error = EINVAL;
				else
					newrule->overload_tbl->pfrkt_flags |=
					    PFR_TFLAG_ACTIVE;
			}

a1228 3
			newrule->evaluations = 0;
			newrule->packets[0] = newrule->packets[1] = 0;
			newrule->bytes[0] = newrule->bytes[1] = 0;
d1646 1
a1657 1
			altq->altq_disc = NULL;
d2462 132
@


1.235.2.1
log
@MFC, original commit from claudio@@:
- - - - - - - - - - - - - - - - - -
Be more careful when copying the pf rule from userland into the kernel.
All pointers in the struct need to be cleared and reset. So instead of
bcopy the struct and clear some fields start with a clean struct and
assign the values that need to be copied.
Fixes a local vulnerability but only root can issue the problematic ioctl().
Reported by Jean Sigwald, has been in snaps for a while and OK deraadt@@
- - - - - - - - - - - - - - - - - -

requested by and ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.236 2010/12/15 14:22:25 claudio Exp $ */
a113 3
void			 pf_pool_copyin(struct pf_pool *, struct pf_pool *);
int			 pf_rule_copyin(struct pf_rule *, struct pf_rule *,
			    struct pf_ruleset *);
d1014 1
a1014 1
		rule = pool_get(&pf_rule_pl, PR_WAITOK|PR_LIMITFAIL|PR_ZERO);
d1019 1
a1019 4
		if ((error = pf_rule_copyin(&pr->rule, rule, ruleset))) {
			pool_put(&pf_rule_pl, rule);
			break;
		}
d1022 7
d1057 42
d1111 9
a1119 2
		if (rule->rt && !rule->direction)
			error = EINVAL;
d1125 2
d1235 1
a1235 2
			newrule = pool_get(&pf_rule_pl,
			    PR_WAITOK|PR_LIMITFAIL|PR_ZERO);
d1240 1
a1240 1
			pf_rule_copyin(&pcr->rule, newrule, ruleset);
d1243 3
d1264 37
d1303 6
d1322 10
d1336 3
a1755 1
		altq->altq_disc = NULL;
d1767 1
a2571 132
}

void
pf_pool_copyin(struct pf_pool *from, struct pf_pool *to)
{
	bcopy(from, to, sizeof(*to));
	to->kif = NULL;
}

int
pf_rule_copyin(struct pf_rule *from, struct pf_rule *to,
    struct pf_ruleset *ruleset)
{
	int i;

	to->src = from->src;
	to->dst = from->dst;

	/* XXX union skip[] */

	strlcpy(to->label, from->label, sizeof(to->label));
	strlcpy(to->ifname, from->ifname, sizeof(to->ifname));
	strlcpy(to->rcv_ifname, from->rcv_ifname, sizeof(to->rcv_ifname));
	strlcpy(to->qname, from->qname, sizeof(to->qname));
	strlcpy(to->pqname, from->pqname, sizeof(to->pqname));
	strlcpy(to->tagname, from->tagname, sizeof(to->tagname));
	strlcpy(to->match_tagname, from->match_tagname,
	    sizeof(to->match_tagname));
	strlcpy(to->overload_tblname, from->overload_tblname,
	    sizeof(to->overload_tblname));

	pf_pool_copyin(&from->nat, &to->nat);
	pf_pool_copyin(&from->rdr, &to->rdr);
	pf_pool_copyin(&from->route, &to->route);

	if (pf_kif_setup(to->ifname, &to->kif))
		return (EINVAL);
	if (pf_kif_setup(to->rcv_ifname, &to->rcv_kif))
		return (EINVAL);
	if (to->overload_tblname[0]) {
		if ((to->overload_tbl = pfr_attach_table(ruleset,
		    to->overload_tblname, 0)) == NULL)
			return (EINVAL);
		else
			to->overload_tbl->pfrkt_flags |= PFR_TFLAG_ACTIVE;
	}

	if (pf_kif_setup(to->rdr.ifname, &to->rdr.kif))
		return (EINVAL);
	if (pf_kif_setup(to->nat.ifname, &to->nat.kif))
		return (EINVAL);
	if (pf_kif_setup(to->route.ifname, &to->route.kif))
		return (EINVAL);

	to->os_fingerprint = from->os_fingerprint;

	to->rtableid = from->rtableid;
	if (to->rtableid > 0 && !rtable_exists(to->rtableid))
		return (EBUSY);

	for (i = 0; i < PFTM_MAX; i++)
		to->timeout[i] = from->timeout[i];
	to->states_tot = from->states_tot;
	to->max_states = from->max_states;
	to->max_src_nodes = from->max_src_nodes;
	to->max_src_states = from->max_src_states;
	to->max_src_conn = from->max_src_conn;
	to->max_src_conn_rate.limit = from->max_src_conn_rate.limit;
	to->max_src_conn_rate.seconds = from->max_src_conn_rate.seconds;

#ifdef ALTQ
	/* set queue IDs */
	if (to->qname[0] != 0) {
		if ((to->qid = pf_qname2qid(to->qname)) == 0)
			return (EBUSY);
		else if (to->pqname[0] != 0) {
			if ((to->pqid = pf_qname2qid(to->pqname)) == 0)
				return (EBUSY);
		} else
			to->pqid = to->qid;
	}
#endif
	to->rt_listid = from->rt_listid;
	to->prob = from->prob;
	to->return_icmp = from->return_icmp;
	to->return_icmp6 = from->return_icmp6;
	to->max_mss = from->max_mss;
	if (to->tagname[0])
		if ((to->tag = pf_tagname2tag(to->tagname)) == 0)
			return (EBUSY);
	if (to->match_tagname[0])
		if ((to->match_tag = pf_tagname2tag(to->match_tagname)) == 0)
			return (EBUSY);
	to->scrub_flags = from->scrub_flags;
	to->uid = from->uid;
	to->gid = from->gid;
	to->rule_flag = from->rule_flag;
	to->action = from->action;
	to->direction = from->direction;
	to->log = from->log;
	to->logif = from->logif;
#if NPFLOG > 0
	if (!to->log)
		to->logif = 0;
	if (to->logif >= PFLOGIFS_MAX)
		return (EINVAL);
#endif
	to->quick = from->quick;
	to->ifnot = from->ifnot;
	to->match_tag_not = from->match_tag_not;
	to->keep_state = from->keep_state;
	to->af = from->af;
	to->proto = from->proto;
	to->type = from->type;
	to->code = from->code;
	to->flags = from->flags;
	to->flagset = from->flagset;
	to->min_ttl = from->min_ttl;
	to->allow_opts = from->allow_opts;
	to->rt = from->rt;
	to->return_ttl = from->return_ttl;
	to->tos = from->tos;
	to->set_tos = from->set_tos;
	to->anchor_relative = from->anchor_relative; /* XXX */
	to->anchor_wildcard = from->anchor_wildcard; /* XXX */
	to->flush = from->flush;
	to->divert.addr = from->divert.addr;
	to->divert.port = from->divert.port;
	to->divert_packet.addr = from->divert_packet.addr;
	to->divert_packet.port = from->divert_packet.port;

	return (0);
@


1.234
log
@Clean up iterface stats handling:
- 'make -Fi' reset ALL the interface statistics
     can be restricted with -i ifname
- 'make -Fa -i ifname' fail (it's meaningless)
- get rid of a silly little struct that's only used for one thing

ok henning
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.233 2010/06/27 01:28:44 mcbride Exp $ */
a1098 3
		if (pf_rtlabel_add(&rule->src.addr) ||
		    pf_rtlabel_add(&rule->dst.addr))
			error = EBUSY;
a1308 3
			if (pf_rtlabel_add(&newrule->src.addr) ||
			    pf_rtlabel_add(&newrule->dst.addr))
				error = EBUSY;
@


1.233
log
@Fix DIOCCHANGERULE ioctl broken in the remove of the address pools.
Reported by Alexander Vladimirov.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.232 2010/01/18 23:52:46 mcbride Exp $ */
d1563 1
a1563 1
		struct pfioc_if	*pi = (struct pfioc_if *)addr;
d1565 1
a1565 1
		if (pi->ifname[0] == 0) {
d1569 1
a1569 1
		strlcpy(pf_trans_set.statusif, pi->ifname, IFNAMSIZ);
d1575 8
d1587 1
a1587 2
		if (*pf_status.ifname)
			pfi_update_status(pf_status.ifname, NULL);
@


1.232
log
@Convert pf debug logging to using log()/addlog(), a single standardised
definition of DPFPRINTF(), and log priorities from syslog.h. Old debug
levels will still work for now, but will eventually be phased out.

discussed with henning, ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.231 2010/01/12 03:20:51 mcbride Exp $ */
a1209 6

		if (!(pcr->action == PF_CHANGE_REMOVE ||
		    pcr->action == PF_CHANGE_GET_TICKET)) {
			error = EBUSY;
			break;
		}
@


1.232.2.1
log
@MFC the fix for PR6416 (problem using route labels in pf.conf, originally
reported by Joe McDonagh). Thanks william@@ for testing. ok henning@@

revision 1.235
date: 2010/06/30 18:10:55;  author: henning;  state: Exp;  lines: +1 -7
fix route label awesomeness, issue also known as PR6416
broken by ryan in australia
problem found & nagging by sthen
jsg found the fix but failed to apply the cluestick correctly ;)
test & ok sthen
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.235 2010/06/30 18:10:55 henning Exp $ */
d1099 3
d1318 3
@


1.232.2.2
log
@MFC, original commit from claudio@@:
- - - - - - - - - - - - - - - - - -
Be more careful when copying the pf rule from userland into the kernel.
All pointers in the struct need to be cleared and reset. So instead of
bcopy the struct and clear some fields start with a clean struct and
assign the values that need to be copied.
Fixes a local vulnerability but only root can issue the problematic ioctl().
Reported by Jean Sigwald, has been in snaps for a while and OK deraadt@@
- - - - - - - - - - - - - - - - - -

requested by and ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.236 2010/12/15 14:22:25 claudio Exp $ */
a113 3
void			 pf_pool_copyin(struct pf_pool *, struct pf_pool *);
int			 pf_rule_copyin(struct pf_rule *, struct pf_rule *,
			    struct pf_ruleset *);
d1014 1
a1014 1
		rule = pool_get(&pf_rule_pl, PR_WAITOK|PR_LIMITFAIL|PR_ZERO);
d1019 1
a1019 4
		if ((error = pf_rule_copyin(&pr->rule, rule, ruleset))) {
			pool_put(&pf_rule_pl, rule);
			break;
		}
d1022 7
d1057 42
d1111 9
a1119 2
		if (rule->rt && !rule->direction)
			error = EINVAL;
d1125 2
d1241 1
a1241 2
			newrule = pool_get(&pf_rule_pl,
			    PR_WAITOK|PR_LIMITFAIL|PR_ZERO);
d1246 1
a1246 1
			pf_rule_copyin(&pcr->rule, newrule, ruleset);
d1249 3
d1270 37
d1309 6
d1328 10
d1342 3
a1754 1
		altq->altq_disc = NULL;
d1766 1
a2570 132
}

void
pf_pool_copyin(struct pf_pool *from, struct pf_pool *to)
{
	bcopy(from, to, sizeof(*to));
	to->kif = NULL;
}

int
pf_rule_copyin(struct pf_rule *from, struct pf_rule *to,
    struct pf_ruleset *ruleset)
{
	int i;

	to->src = from->src;
	to->dst = from->dst;

	/* XXX union skip[] */

	strlcpy(to->label, from->label, sizeof(to->label));
	strlcpy(to->ifname, from->ifname, sizeof(to->ifname));
	strlcpy(to->rcv_ifname, from->rcv_ifname, sizeof(to->rcv_ifname));
	strlcpy(to->qname, from->qname, sizeof(to->qname));
	strlcpy(to->pqname, from->pqname, sizeof(to->pqname));
	strlcpy(to->tagname, from->tagname, sizeof(to->tagname));
	strlcpy(to->match_tagname, from->match_tagname,
	    sizeof(to->match_tagname));
	strlcpy(to->overload_tblname, from->overload_tblname,
	    sizeof(to->overload_tblname));

	pf_pool_copyin(&from->nat, &to->nat);
	pf_pool_copyin(&from->rdr, &to->rdr);
	pf_pool_copyin(&from->route, &to->route);

	if (pf_kif_setup(to->ifname, &to->kif))
		return (EINVAL);
	if (pf_kif_setup(to->rcv_ifname, &to->rcv_kif))
		return (EINVAL);
	if (to->overload_tblname[0]) {
		if ((to->overload_tbl = pfr_attach_table(ruleset,
		    to->overload_tblname, 0)) == NULL)
			return (EINVAL);
		else
			to->overload_tbl->pfrkt_flags |= PFR_TFLAG_ACTIVE;
	}

	if (pf_kif_setup(to->rdr.ifname, &to->rdr.kif))
		return (EINVAL);
	if (pf_kif_setup(to->nat.ifname, &to->nat.kif))
		return (EINVAL);
	if (pf_kif_setup(to->route.ifname, &to->route.kif))
		return (EINVAL);

	to->os_fingerprint = from->os_fingerprint;

	to->rtableid = from->rtableid;
	if (to->rtableid > 0 && !rtable_exists(to->rtableid))
		return (EBUSY);

	for (i = 0; i < PFTM_MAX; i++)
		to->timeout[i] = from->timeout[i];
	to->states_tot = from->states_tot;
	to->max_states = from->max_states;
	to->max_src_nodes = from->max_src_nodes;
	to->max_src_states = from->max_src_states;
	to->max_src_conn = from->max_src_conn;
	to->max_src_conn_rate.limit = from->max_src_conn_rate.limit;
	to->max_src_conn_rate.seconds = from->max_src_conn_rate.seconds;

#ifdef ALTQ
	/* set queue IDs */
	if (to->qname[0] != 0) {
		if ((to->qid = pf_qname2qid(to->qname)) == 0)
			return (EBUSY);
		else if (to->pqname[0] != 0) {
			if ((to->pqid = pf_qname2qid(to->pqname)) == 0)
				return (EBUSY);
		} else
			to->pqid = to->qid;
	}
#endif
	to->rt_listid = from->rt_listid;
	to->prob = from->prob;
	to->return_icmp = from->return_icmp;
	to->return_icmp6 = from->return_icmp6;
	to->max_mss = from->max_mss;
	if (to->tagname[0])
		if ((to->tag = pf_tagname2tag(to->tagname)) == 0)
			return (EBUSY);
	if (to->match_tagname[0])
		if ((to->match_tag = pf_tagname2tag(to->match_tagname)) == 0)
			return (EBUSY);
	to->scrub_flags = from->scrub_flags;
	to->uid = from->uid;
	to->gid = from->gid;
	to->rule_flag = from->rule_flag;
	to->action = from->action;
	to->direction = from->direction;
	to->log = from->log;
	to->logif = from->logif;
#if NPFLOG > 0
	if (!to->log)
		to->logif = 0;
	if (to->logif >= PFLOGIFS_MAX)
		return (EINVAL);
#endif
	to->quick = from->quick;
	to->ifnot = from->ifnot;
	to->match_tag_not = from->match_tag_not;
	to->keep_state = from->keep_state;
	to->af = from->af;
	to->proto = from->proto;
	to->type = from->type;
	to->code = from->code;
	to->flags = from->flags;
	to->flagset = from->flagset;
	to->min_ttl = from->min_ttl;
	to->allow_opts = from->allow_opts;
	to->rt = from->rt;
	to->return_ttl = from->return_ttl;
	to->tos = from->tos;
	to->set_tos = from->set_tos;
	to->anchor_relative = from->anchor_relative; /* XXX */
	to->anchor_wildcard = from->anchor_wildcard; /* XXX */
	to->flush = from->flush;
	to->divert.addr = from->divert.addr;
	to->divert.port = from->divert.port;
	to->divert_packet.addr = from->divert_packet.addr;
	to->divert_packet.port = from->divert_packet.port;

	return (0);
@


1.231
log
@First pass at removing the 'pf_pool' mechanism for translation and routing
actions. Allow interfaces to be specified in special table entries for
the routing actions. Lists of addresses can now only be done using tables,
which pfctl will generate automatically from the existing syntax.

Functionally, this deprecates the use of multiple tables or dynamic
interfaces in a single nat or rdr rule.

ok henning dlg claudio
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.230 2009/12/24 04:24:19 dlg Exp $ */
d56 1
a147 1
#define DPFPRINTF(n, x) if (pf_status.debug >= (n)) printf x
d226 1
a226 1
	pf_status.debug = PF_DEBUG_URGENT;
d981 1
a981 1
			DPFPRINTF(PF_DEBUG_MISC, ("pf: started\n"));
d991 1
a991 1
			DPFPRINTF(PF_DEBUG_MISC, ("pf: stopped\n"));
d1726 1
a1726 1
		DPFPRINTF(PF_DEBUG_MISC, ("altq: started\n"));
d1743 1
a1743 1
		DPFPRINTF(PF_DEBUG_MISC, ("altq: stopped\n"));
@


1.230
log
@add support to pf for filtering a packet by the interface it was received
on. use the received-on IFNAME filter option on a pf.conf rule to restrict
which packet the interface had to be received on. eg:

  pass out on em0 from $foo to $bar received-on fxp0

ive been running this in production for a week now. i find it particularly
usefull with interface groups.

no objections, and a few "i like"s from henning, claudio, deraadt, mpf
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.229 2009/12/14 12:31:45 henning Exp $ */
a93 5
struct pf_pool		*pf_get_pool(char *, u_int32_t, u_int8_t, u_int32_t,
			    u_int8_t, u_int8_t, u_int8_t, int);

void			 pf_mv_pool(struct pf_palist *, struct pf_palist *);
void			 pf_empty_pool(struct pf_palist *);
d110 1
a169 2
	pool_init(&pf_pooladdr_pl, sizeof(struct pf_pooladdr), 0, 0, 0,
	    "pfpooladdrpl", &pool_allocator_nointr);
a185 3
	TAILQ_INIT(&pf_pabuf[0]);
	TAILQ_INIT(&pf_pabuf[1]);
	TAILQ_INIT(&pf_pabuf[2]);
d218 6
a258 67
struct pf_pool *
pf_get_pool(char *anchor, u_int32_t ticket, u_int8_t rule_action,
    u_int32_t rule_number, u_int8_t r_last, u_int8_t active,
    u_int8_t check_ticket, int which)
{
	struct pf_ruleset	*ruleset;
	struct pf_rule		*rule;

	ruleset = pf_find_ruleset(anchor);
	if (ruleset == NULL)
		return (NULL);
	if (active) {
		if (check_ticket && ticket != ruleset->rules.active.ticket)
			return (NULL);
		if (r_last)
			rule = TAILQ_LAST(ruleset->rules.active.ptr,
			    pf_rulequeue);
		else
			rule = TAILQ_FIRST(ruleset->rules.active.ptr);
	} else {
		if (check_ticket && ticket != ruleset->rules.inactive.ticket)
			return (NULL);
		if (r_last)
			rule = TAILQ_LAST(ruleset->rules.inactive.ptr,
			    pf_rulequeue);
		else
			rule = TAILQ_FIRST(ruleset->rules.inactive.ptr);
	}
	if (!r_last) {
		while ((rule != NULL) && (rule->nr != rule_number))
			rule = TAILQ_NEXT(rule, entries);
	}
	if (rule == NULL)
		return (NULL);
	if (which == PF_NAT)
		return (&rule->nat);
	else if (which == PF_RT)
		return (&rule->route);
	else
		return (&rule->rdr);
}

void
pf_mv_pool(struct pf_palist *poola, struct pf_palist *poolb)
{
	struct pf_pooladdr	*mv_pool_pa;

	while ((mv_pool_pa = TAILQ_FIRST(poola)) != NULL) {
		TAILQ_REMOVE(poola, mv_pool_pa, entries);
		TAILQ_INSERT_TAIL(poolb, mv_pool_pa, entries);
	}
}

void
pf_empty_pool(struct pf_palist *poola)
{
	struct pf_pooladdr	*empty_pool_pa;

	while ((empty_pool_pa = TAILQ_FIRST(poola)) != NULL) {
		pfi_dynaddr_remove(&empty_pool_pa->addr);
		pf_tbladdr_remove(&empty_pool_pa->addr);
		pfi_kif_unref(empty_pool_pa->kif, PFI_KIF_REF_RULE);
		TAILQ_REMOVE(poola, empty_pool_pa, entries);
		pool_put(&pf_pooladdr_pl, empty_pool_pa);
	}
}

d271 3
d296 3
d302 3
d310 3
a313 3
	pf_empty_pool(&rule->rdr.list);
	pf_empty_pool(&rule->nat.list);
	pf_empty_pool(&rule->route.list);
d831 2
a832 1
	    pf_tbladdr_setup(ruleset, addr))
d838 15
a863 2
	struct pf_pooladdr	*pa = NULL;
	struct pf_pool		*pool = NULL;
a871 2
		case DIOCGETADDRS:
		case DIOCGETADDR:
a893 1
		case DIOCRGETADDRS:
a918 2
		case DIOCGETADDRS:
		case DIOCGETADDR:
a998 1
		struct pf_pooladdr	*pa;
a1013 4
		if (pr->pool_ticket != ticket_pabuf) {
			error = EBUSY;
			break;
		}
a1024 3
		TAILQ_INIT(&rule->rdr.list);
		TAILQ_INIT(&rule->nat.list);
		TAILQ_INIT(&rule->route.list);
d1052 15
a1066 16
		if (rule->ifname[0]) {
			rule->kif = pfi_kif_get(rule->ifname);
			if (rule->kif == NULL) {
				pool_put(&pf_rule_pl, rule);
				error = EINVAL;
				break;
			}
			pfi_kif_ref(rule->kif, PFI_KIF_REF_RULE);
		}
		if (rule->rcv_ifname[0]) {
			rule->rcv_kif = pfi_kif_get(rule->rcv_ifname);
			if (rule->rcv_kif == NULL) {
				error = EINVAL;
			} else
				pfi_kif_ref(rule->rcv_kif, PFI_KIF_REF_RULE);
		}
d1106 6
a1113 9
		TAILQ_FOREACH(pa, &pf_pabuf[0], entries)
			if (pf_tbladdr_setup(ruleset, &pa->addr))
				error = EINVAL;
		TAILQ_FOREACH(pa, &pf_pabuf[1], entries)
			if (pf_tbladdr_setup(ruleset, &pa->addr))
				error = EINVAL;
		TAILQ_FOREACH(pa, &pf_pabuf[2], entries)
			if (pf_tbladdr_setup(ruleset, &pa->addr))
				error = EINVAL;
a1123 8
		pf_mv_pool(&pf_pabuf[0], &rule->nat.list);
		pf_mv_pool(&pf_pabuf[1], &rule->rdr.list);
		pf_mv_pool(&pf_pabuf[2], &rule->route.list);

		if (rule->rt > PF_FASTROUTE &&
		    (TAILQ_FIRST(&rule->route.list) == NULL))
			error = EINVAL;

a1127 3
		rule->nat.cur = TAILQ_FIRST(&rule->nat.list);
		rule->rdr.cur = TAILQ_FIRST(&rule->rdr.list);
		rule->route.cur = TAILQ_FIRST(&rule->route.list);
d1186 3
d1212 1
a1212 2
		    pcr->action == PF_CHANGE_GET_TICKET) &&
		    pcr->pool_ticket != ticket_pabuf) {
a1251 3
			TAILQ_INIT(&newrule->rdr.list);
			TAILQ_INIT(&newrule->nat.list);
			TAILQ_INIT(&newrule->route.list);
d1273 10
a1282 22
			if (newrule->ifname[0]) {
				newrule->kif = pfi_kif_get(newrule->ifname);
				if (newrule->kif == NULL) {
					pool_put(&pf_rule_pl, newrule);
					error = EINVAL;
					break;
				}
				pfi_kif_ref(newrule->kif, PFI_KIF_REF_RULE);
			} else
				newrule->kif = NULL;

			if (newrule->rcv_ifname[0]) {
				newrule->rcv_kif =
				    pfi_kif_get(newrule->rcv_ifname);
				if (newrule->rcv_kif == NULL) {
					error = EINVAL;
				} else {
					pfi_kif_ref(newrule->rcv_kif,
					    PFI_KIF_REF_RULE);
				}
			} else
				newrule->kif = NULL;
d1325 6
a1332 9
			TAILQ_FOREACH(pa, &pf_pabuf[0], entries)
				if (pf_tbladdr_setup(ruleset, &pa->addr))
					error = EINVAL;
			TAILQ_FOREACH(pa, &pf_pabuf[1], entries)
				if (pf_tbladdr_setup(ruleset, &pa->addr))
					error = EINVAL;
			TAILQ_FOREACH(pa, &pf_pabuf[2], entries)
				if (pf_tbladdr_setup(ruleset, &pa->addr))
					error = EINVAL;
a1343 8
			pf_mv_pool(&pf_pabuf[0], &newrule->nat.list);
			pf_mv_pool(&pf_pabuf[1], &newrule->rdr.list);
			pf_mv_pool(&pf_pabuf[2], &newrule->route.list);
			if (newrule->rt > PF_FASTROUTE &&
			    !newrule->anchor &&
			    (TAILQ_FIRST(&newrule->route.list) == NULL))
				error = EINVAL;

a1347 3
			newrule->rdr.cur = TAILQ_FIRST(&newrule->rdr.list);
			newrule->nat.cur = TAILQ_FIRST(&newrule->nat.list);
			newrule->route.cur = TAILQ_FIRST(&newrule->route.list);
a1351 3
		pf_empty_pool(&pf_pabuf[0]);
		pf_empty_pool(&pf_pabuf[1]);
		pf_empty_pool(&pf_pabuf[2]);
a1860 251

	case DIOCBEGINADDRS: {
		struct pfioc_pooladdr	*pp = (struct pfioc_pooladdr *)addr;

		pf_empty_pool(&pf_pabuf[0]);
		pf_empty_pool(&pf_pabuf[1]);
		pf_empty_pool(&pf_pabuf[2]);
		pp->ticket = ++ticket_pabuf;
		break;
	}

	case DIOCADDADDR: {
		struct pfioc_pooladdr	*pp = (struct pfioc_pooladdr *)addr;

		if (pp->which != PF_NAT && pp->which != PF_RDR && pp->which != PF_RT) {
			error = EINVAL;
			break;
		}

		if (pp->ticket != ticket_pabuf) {
			error = EBUSY;
			break;
		}

		switch (pp->af) {
		case 0:
			break;
#ifdef INET
		case AF_INET:
			break;
#endif /* INET */
#ifdef INET6
		case AF_INET6:
			break;
#endif /* INET6 */
		default:
			error = EAFNOSUPPORT;
			goto fail;
		}

		if (pp->addr.addr.type != PF_ADDR_ADDRMASK &&
		    pp->addr.addr.type != PF_ADDR_DYNIFTL &&
		    pp->addr.addr.type != PF_ADDR_TABLE) {
			error = EINVAL;
			break;
		}
		pa = pool_get(&pf_pooladdr_pl, PR_WAITOK|PR_LIMITFAIL);
		if (pa == NULL) {
			error = ENOMEM;
			break;
		}
		bcopy(&pp->addr, pa, sizeof(struct pf_pooladdr));
		if (pa->ifname[0]) {
			pa->kif = pfi_kif_get(pa->ifname);
			if (pa->kif == NULL) {
				pool_put(&pf_pooladdr_pl, pa);
				error = EINVAL;
				break;
			}
			pfi_kif_ref(pa->kif, PFI_KIF_REF_RULE);
		}
		if (pfi_dynaddr_setup(&pa->addr, pp->af)) {
			pfi_dynaddr_remove(&pa->addr);
			pfi_kif_unref(pa->kif, PFI_KIF_REF_RULE);
			pool_put(&pf_pooladdr_pl, pa);
			error = EINVAL;
			break;
		}

		switch (pp->which) {
		case PF_NAT:
			TAILQ_INSERT_TAIL(&pf_pabuf[0], pa, entries);
			break;
		case PF_RDR:	
			TAILQ_INSERT_TAIL(&pf_pabuf[1], pa, entries);
			break;
		case PF_RT:
			TAILQ_INSERT_TAIL(&pf_pabuf[2], pa, entries);
			break;
		}
		break;	
	}

	case DIOCGETADDRS: {
		struct pfioc_pooladdr	*pp = (struct pfioc_pooladdr *)addr;

		if (pp->which != PF_NAT && pp->which != PF_RDR && pp->which != PF_RT) {
			error = EINVAL;
			break;
		}

		pp->nr = 0;
		pool = pf_get_pool(pp->anchor, pp->ticket, pp->r_action,
		    pp->r_num, 0, 1, 0, pp->which);
		if (pool == NULL) {
			error = EBUSY;
			break;
		}
		TAILQ_FOREACH(pa, &pool->list, entries)
			pp->nr++;
		break;
	}

	case DIOCGETADDR: {
		struct pfioc_pooladdr	*pp = (struct pfioc_pooladdr *)addr;
		u_int32_t		 nr = 0;

		if (pp->which != PF_NAT && pp->which != PF_RDR && pp->which != PF_RT) {
			error = EINVAL;
			break;
		}

		pool = pf_get_pool(pp->anchor, pp->ticket, pp->r_action,
		    pp->r_num, 0, 1, 1, pp->which);
		if (pool == NULL) {
			error = EBUSY;
			break;
		}
		pa = TAILQ_FIRST(&pool->list);
		while ((pa != NULL) && (nr < pp->nr)) {
			pa = TAILQ_NEXT(pa, entries);
			nr++;
		}
		if (pa == NULL) {
			error = EBUSY;
			break;
		}
		bcopy(pa, &pp->addr, sizeof(struct pf_pooladdr));
		pf_addr_copyout(&pp->addr.addr);
		break;
	}

	case DIOCCHANGEADDR: {
		struct pfioc_pooladdr	*pca = (struct pfioc_pooladdr *)addr;
		struct pf_pooladdr	*oldpa = NULL, *newpa = NULL;
		struct pf_ruleset	*ruleset;

		if (pca->which != PF_NAT && pca->which != PF_RDR && pca->which != PF_RT) {
			error = EINVAL;
			break;
		}

		if (pca->action < PF_CHANGE_ADD_HEAD ||
		    pca->action > PF_CHANGE_REMOVE) {
			error = EINVAL;
			break;
		}
		if (pca->addr.addr.type != PF_ADDR_ADDRMASK &&
		    pca->addr.addr.type != PF_ADDR_DYNIFTL &&
		    pca->addr.addr.type != PF_ADDR_TABLE) {
			error = EINVAL;
			break;
		}

		ruleset = pf_find_ruleset(pca->anchor);
		if (ruleset == NULL) {
			error = EBUSY;
			break;
		}
		pool = pf_get_pool(pca->anchor, pca->ticket, pca->r_action,
		    pca->r_num, pca->r_last, 1, 1, pca->which);
		if (pool == NULL) {
			error = EBUSY;
			break;
		}
		if (pca->action != PF_CHANGE_REMOVE) {
			newpa = pool_get(&pf_pooladdr_pl,
			    PR_WAITOK|PR_LIMITFAIL);
			if (newpa == NULL) {
				error = ENOMEM;
				break;
			}
			bcopy(&pca->addr, newpa, sizeof(struct pf_pooladdr));

			switch (pca->af) {
			case 0:
				break;
#ifdef INET
			case AF_INET:
				break;
#endif /* INET */
#ifdef INET6
			case AF_INET6:
				break;
#endif /* INET6 */
			default:
				pool_put(&pf_pooladdr_pl, newpa);
				error = EAFNOSUPPORT;
				goto fail;
			}

			if (newpa->ifname[0]) {
				newpa->kif = pfi_kif_get(newpa->ifname);
				if (newpa->kif == NULL) {
					pool_put(&pf_pooladdr_pl, newpa);
					error = EINVAL;
					break;
				}
				pfi_kif_ref(newpa->kif, PFI_KIF_REF_RULE);
			} else
				newpa->kif = NULL;
			if (pfi_dynaddr_setup(&newpa->addr, pca->af) ||
			    pf_tbladdr_setup(ruleset, &newpa->addr)) {
				pfi_dynaddr_remove(&newpa->addr);
				pfi_kif_unref(newpa->kif, PFI_KIF_REF_RULE);
				pool_put(&pf_pooladdr_pl, newpa);
				error = EINVAL;
				break;
			}
		}

		if (pca->action == PF_CHANGE_ADD_HEAD)
			oldpa = TAILQ_FIRST(&pool->list);
		else if (pca->action == PF_CHANGE_ADD_TAIL)
			oldpa = TAILQ_LAST(&pool->list, pf_palist);
		else {
			int	i = 0;

			oldpa = TAILQ_FIRST(&pool->list);
			while ((oldpa != NULL) && (i < pca->nr)) {
				oldpa = TAILQ_NEXT(oldpa, entries);
				i++;
			}
			if (oldpa == NULL) {
				error = EINVAL;
				break;
			}
		}

		if (pca->action == PF_CHANGE_REMOVE) {
			TAILQ_REMOVE(&pool->list, oldpa, entries);
			pfi_dynaddr_remove(&oldpa->addr);
			pf_tbladdr_remove(&oldpa->addr);
			pfi_kif_unref(oldpa->kif, PFI_KIF_REF_RULE);
			pool_put(&pf_pooladdr_pl, oldpa);
		} else {
			if (oldpa == NULL)
				TAILQ_INSERT_TAIL(&pool->list, newpa, entries);
			else if (pca->action == PF_CHANGE_ADD_HEAD ||
			    pca->action == PF_CHANGE_ADD_BEFORE)
				TAILQ_INSERT_BEFORE(oldpa, newpa, entries);
			else
				TAILQ_INSERT_AFTER(&pool->list, oldpa,
				    newpa, entries);
		}

		pool->cur = TAILQ_FIRST(&pool->list);
		PF_ACPY(&pool->counter, &pool->cur->addr.v.a.addr,
		    pca->af);
		break;
	}
@


1.229
log
@fix sticky-address - by pretty much re-implementing it. still following
the original approach using a source tracking node.
the reimplementation i smore flexible than the original one, we now have an
slist of source tracking nodes per state. that is cheap because more than
one entry will be an absolute exception.
ok beck and jsg, also stress tested by Sebastian Benoit <benoit-lists at fb12.de>
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.228 2009/11/24 13:23:55 henning Exp $ */
d369 1
d777 1
d1081 1
d1121 7
d1357 12
@


1.228
log
@kill obsolete natpass
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.227 2009/11/23 16:03:10 henning Exp $ */
d162 2
d2798 2
a2799 2
			state->src_node = NULL;
		RB_FOREACH(n, pf_src_tree, &tree_src_tracking) {
a2800 2
			n->states = 0;
		}
a2801 1
		pf_status.src_nodes = 0;
d2822 1
a2822 1
				if (sn->states != 0) {
d2824 2
a2825 5
					    &tree_id)
						if (s->src_node == sn)
							s->src_node = NULL;
					sn->states = 0;
				}
@


1.227
log
@remove the nat_rule pointer on pf_state and pf_pdesc, obsolete after
the NAT rewrite and ever since then only checked in a couple of plaes
but never set. same for nat_src_node on pf_state.
with this the NAT rewrite made pf over 1000 lines shorter.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.226 2009/11/22 22:34:50 henning Exp $ */
a790 1
	PF_MD5_UPD(rule, natpass);
@


1.226
log
@cleanup after the NAT changes. we used to have multiple rulesets (scrub,
NAT, filter). now we only have one. no need for an array any more. simplifies
the code quite a bit.
in the process fix the abuse of PF_RULESET_* by (surprise, isn't it) the
table code.
written at the filesystem hackathon in stockholm, committed from the
hardware hackathon in portugal. ok gcc and jsing
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.225 2009/11/11 10:31:44 jsg Exp $ */
d2796 1
a2796 1
		RB_FOREACH(state, pf_state_tree_id, &tree_id) {
a2797 2
			state->nat_src_node = NULL;
		}
d2826 1
a2826 1
					    &tree_id) {
a2828 3
						if (s->nat_src_node == sn)
							s->nat_src_node = NULL;
					}
@


1.225
log
@Fix some memory leaks in error cases.
Found by parfait.

ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.224 2009/11/03 17:41:02 claudio Exp $ */
d107 2
a108 2
int			 pf_begin_rules(u_int32_t *, int, const char *);
int			 pf_rollback_rules(u_int32_t, int, char *);
d112 1
a112 1
int			 pf_commit_rules(u_int32_t, int, char *);
a266 1
	int			 rs_num;
a270 3
	rs_num = pf_get_ruleset_number(rule_action);
	if (rs_num >= PF_RULESET_MAX)
		return (NULL);
d272 1
a272 2
		if (check_ticket && ticket !=
		    ruleset->rules[rs_num].active.ticket)
d275 1
a275 1
			rule = TAILQ_LAST(ruleset->rules[rs_num].active.ptr,
d278 1
a278 1
			rule = TAILQ_FIRST(ruleset->rules[rs_num].active.ptr);
d280 1
a280 2
		if (check_ticket && ticket !=
		    ruleset->rules[rs_num].inactive.ticket)
d283 1
a283 1
			rule = TAILQ_LAST(ruleset->rules[rs_num].inactive.ptr,
d286 1
a286 1
			rule = TAILQ_FIRST(ruleset->rules[rs_num].inactive.ptr);
d686 1
a686 1
pf_begin_rules(u_int32_t *ticket, int rs_num, const char *anchor)
d691 1
a691 4
	if (rs_num < 0 || rs_num >= PF_RULESET_MAX)
		return (EINVAL);
	rs = pf_find_or_create_ruleset(anchor);
	if (rs == NULL)
d693 3
a695 3
	while ((rule = TAILQ_FIRST(rs->rules[rs_num].inactive.ptr)) != NULL) {
		pf_rm_rule(rs->rules[rs_num].inactive.ptr, rule);
		rs->rules[rs_num].inactive.rcount--;
d697 2
a698 2
	*ticket = ++rs->rules[rs_num].inactive.ticket;
	rs->rules[rs_num].inactive.open = 1;
d703 1
a703 1
pf_rollback_rules(u_int32_t ticket, int rs_num, char *anchor)
a707 2
	if (rs_num < 0 || rs_num >= PF_RULESET_MAX)
		return (EINVAL);
d709 2
a710 2
	if (rs == NULL || !rs->rules[rs_num].inactive.open ||
	    rs->rules[rs_num].inactive.ticket != ticket)
d712 3
a714 3
	while ((rule = TAILQ_FIRST(rs->rules[rs_num].inactive.ptr)) != NULL) {
		pf_rm_rule(rs->rules[rs_num].inactive.ptr, rule);
		rs->rules[rs_num].inactive.rcount--;
d716 1
a716 1
	rs->rules[rs_num].inactive.open = 0;
d804 1
a804 1
pf_commit_rules(u_int32_t ticket, int rs_num, char *anchor)
a811 2
	if (rs_num < 0 || rs_num >= PF_RULESET_MAX)
		return (EINVAL);
d813 2
a814 2
	if (rs == NULL || !rs->rules[rs_num].inactive.open ||
	    ticket != rs->rules[rs_num].inactive.ticket)
d826 13
a838 17
	old_rules = rs->rules[rs_num].active.ptr;
	old_rcount = rs->rules[rs_num].active.rcount;
	old_array = rs->rules[rs_num].active.ptr_array;

	rs->rules[rs_num].active.ptr =
	    rs->rules[rs_num].inactive.ptr;
	rs->rules[rs_num].active.ptr_array =
	    rs->rules[rs_num].inactive.ptr_array;
	rs->rules[rs_num].active.rcount =
	    rs->rules[rs_num].inactive.rcount;
	rs->rules[rs_num].inactive.ptr = old_rules;
	rs->rules[rs_num].inactive.ptr_array = old_array;
	rs->rules[rs_num].inactive.rcount = old_rcount;

	rs->rules[rs_num].active.ticket =
	    rs->rules[rs_num].inactive.ticket;
	pf_calc_skip_steps(rs->rules[rs_num].active.ptr);
d844 5
a848 5
	if (rs->rules[rs_num].inactive.ptr_array)
		free(rs->rules[rs_num].inactive.ptr_array, M_TEMP);
	rs->rules[rs_num].inactive.ptr_array = NULL;
	rs->rules[rs_num].inactive.rcount = 0;
	rs->rules[rs_num].inactive.open = 0;
a858 1
	int			 rs_cnt;
d862 15
a876 20
	for (rs_cnt = 0; rs_cnt < PF_RULESET_MAX; rs_cnt++) {
		if (rs->rules[rs_cnt].inactive.ptr_array)
			free(rs->rules[rs_cnt].inactive.ptr_array, M_TEMP);
		rs->rules[rs_cnt].inactive.ptr_array = NULL;

		if (rs->rules[rs_cnt].inactive.rcount) {
			rs->rules[rs_cnt].inactive.ptr_array =
			    malloc(sizeof(caddr_t) *
			    rs->rules[rs_cnt].inactive.rcount,
			    M_TEMP, M_NOWAIT);

			if (!rs->rules[rs_cnt].inactive.ptr_array)
				return (ENOMEM);
		}

		TAILQ_FOREACH(rule, rs->rules[rs_cnt].inactive.ptr,
		    entries) {
			pf_hash_rule(&ctx, rule);
			(rs->rules[rs_cnt].inactive.ptr_array)[rule->nr] = rule;
		}
a1048 1
		int			 rs_num;
a1055 5
		rs_num = pf_get_ruleset_number(pr->rule.action);
		if (rs_num >= PF_RULESET_MAX) {
			error = EINVAL;
			break;
		}
d1060 1
a1060 1
		if (pr->ticket != ruleset->rules[rs_num].inactive.ticket) {
d1102 1
a1102 2

		tail = TAILQ_LAST(ruleset->rules[rs_num].inactive.ptr,
d1194 1
a1194 1
		TAILQ_INSERT_TAIL(ruleset->rules[rs_num].inactive.ptr,
d1196 1
a1196 1
		ruleset->rules[rs_num].inactive.rcount++;
a1203 1
		int			 rs_num;
d1211 1
a1211 7
		rs_num = pf_get_ruleset_number(pr->rule.action);
		if (rs_num >= PF_RULESET_MAX) {
			error = EINVAL;
			break;
		}
		tail = TAILQ_LAST(ruleset->rules[rs_num].active.ptr,
		    pf_rulequeue);
d1216 1
a1216 1
		pr->ticket = ruleset->rules[rs_num].active.ticket;
d1224 1
a1224 1
		int			 rs_num, i;
d1232 1
a1232 6
		rs_num = pf_get_ruleset_number(pr->rule.action);
		if (rs_num >= PF_RULESET_MAX) {
			error = EINVAL;
			break;
		}
		if (pr->ticket != ruleset->rules[rs_num].active.ticket) {
d1236 1
a1236 1
		rule = TAILQ_FIRST(ruleset->rules[rs_num].active.ptr);
a1270 1
		int			 rs_num;
a1288 5
		rs_num = pf_get_ruleset_number(pcr->rule.action);
		if (rs_num >= PF_RULESET_MAX) {
			error = EINVAL;
			break;
		}
d1291 1
a1291 1
			pcr->ticket = ++ruleset->rules[rs_num].active.ticket;
d1295 1
a1295 1
			    ruleset->rules[rs_num].active.ticket) {
d1436 1
a1436 2
			oldrule = TAILQ_FIRST(
			    ruleset->rules[rs_num].active.ptr);
d1438 2
a1439 2
			oldrule = TAILQ_LAST(
			    ruleset->rules[rs_num].active.ptr, pf_rulequeue);
d1441 1
a1441 2
			oldrule = TAILQ_FIRST(
			    ruleset->rules[rs_num].active.ptr);
d1453 2
a1454 2
			pf_rm_rule(ruleset->rules[rs_num].active.ptr, oldrule);
			ruleset->rules[rs_num].active.rcount--;
d1458 1
a1458 1
				    ruleset->rules[rs_num].active.ptr,
d1465 1
a1465 1
				    ruleset->rules[rs_num].active.ptr,
d1467 1
a1467 1
			ruleset->rules[rs_num].active.rcount++;
d1471 1
a1471 2
		TAILQ_FOREACH(oldrule,
		    ruleset->rules[rs_num].active.ptr, entries)
d1474 1
a1474 1
		ruleset->rules[rs_num].active.ticket++;
d1476 1
a1476 1
		pf_calc_skip_steps(ruleset->rules[rs_num].active.ptr);
d1786 1
a1786 1
		    ruleset->rules[PF_RULESET_FILTER].active.ptr, entries) {
d2486 1
a2486 1
			switch (ioe->rs_num) {
d2488 1
a2488 1
			case PF_RULESET_ALTQ:
d2502 1
a2502 1
			case PF_RULESET_TABLE:
d2515 1
a2515 1
				    ioe->rs_num, ioe->anchor))) {
d2553 1
a2553 1
			switch (ioe->rs_num) {
d2555 1
a2555 1
			case PF_RULESET_ALTQ:
d2569 1
a2569 1
			case PF_RULESET_TABLE:
d2582 1
a2582 1
				    ioe->rs_num, ioe->anchor))) {
d2616 1
a2616 1
			switch (ioe->rs_num) {
d2618 1
a2618 1
			case PF_RULESET_ALTQ:
d2634 1
a2634 1
			case PF_RULESET_TABLE:
a2644 7
				if (ioe->rs_num < 0 || ioe->rs_num >=
				    PF_RULESET_MAX) {
					free(table, M_TEMP);
					free(ioe, M_TEMP);
					error = EINVAL;
					goto fail;
				}
d2647 2
a2648 2
				    !rs->rules[ioe->rs_num].inactive.open ||
				    rs->rules[ioe->rs_num].inactive.ticket !=
d2679 1
a2679 1
			switch (ioe->rs_num) {
d2681 1
a2681 1
			case PF_RULESET_ALTQ:
d2689 1
a2689 1
			case PF_RULESET_TABLE:
d2702 1
a2702 1
				    ioe->rs_num, ioe->anchor))) {
@


1.224
log
@Use u_int16_t for rdomains for everything. Using various types makes
everything just more complicated. Make sure the structs align nicely.
OK deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.223 2009/11/03 10:59:04 claudio Exp $ */
d2723 2
d2773 2
@


1.223
log
@rtables are stacked on rdomains (it is possible to have multiple routing
tables on top of a rdomain) but until now our code was a crazy mix so that
it was impossible to correctly use rtables in that case. Additionally pf(4)
only knows about rtables and not about rdomains. This is especially bad when
tracking (possibly conflicting) states in various domains.
This diff fixes all or most of these issues. It adds a lookup function to
get the rdomain id based on a rtable id. Makes pf understand rdomains and
allows pf to move packets between rdomains (it is similar to NAT).
Because pf states now track the rdomain id as well it is necessary to modify
the pfsync wire format. So old and new systems will not sync up.
A lot of help by dlg@@, tested by sthen@@, jsg@@ and probably more
OK dlg@@, mpf@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.222 2009/10/28 20:11:01 jsg Exp $ */
d1741 1
a1741 1
		    pnl->rdomain < 0 || pnl->rdomain > RT_TABLEID_MAX)
@


1.222
log
@Add a dedicated pf pool for route options as suggested by henning,
which unbreaks ie route-to after the recent pf changes.

With much help debugging and pointing out of missing bits from claudio@@

ok claudio@@ "looks good" henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.221 2009/10/06 02:31:36 mcbride Exp $ */
d1594 1
a1594 1
			    sk->proto) &&
d1641 1
d1740 2
a1741 1
		    (!pnl->dport || !pnl->sport)))
d1746 1
@


1.221
log
@Replace if (af) tests operating as an af blacklist with stricter switch
statements operating as a whitelist, taking care to allow af 0 (which is
the wildcard value in pf rules)

diff from Vadim Zhukov
ok henning
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.221 2009/10/06 01:46:56 mcbride Exp $ */
d192 1
d302 2
d377 1
d1109 1
d1194 3
d1209 1
d1212 1
a1212 1
		    (TAILQ_FIRST(&rule->rdr.list) == NULL))
d1221 1
d1364 1
d1446 3
d1462 1
d1465 1
a1465 1
			    (TAILQ_FIRST(&newrule->rdr.list) == NULL))
d1474 1
d1481 1
d1997 1
d2005 1
a2005 1
		if (pp->which != PF_NAT && pp->which != PF_RDR) {
d2060 12
a2071 3
		TAILQ_INSERT_TAIL(&pf_pabuf[pp->which == PF_NAT ? 0 : 1], pa,
		    entries);
		break;
d2077 1
a2077 1
		if (pp->which != PF_NAT && pp->which != PF_RDR) {
d2098 1
a2098 1
		if (pp->which != PF_NAT && pp->which != PF_RDR) {
d2128 1
a2128 1
		if (pca->which != PF_NAT && pca->which != PF_RDR) {
@


1.220
log
@the diff theo calls me insanae for:
rewrite of the NAT code, basically. nat and rdr become actions on regular
rules, seperate nat/rdr/binat rules do not exist any more.
match in on $intf rdr-to 1.2.3.4
match out on $intf nat-to 5.6.7.8
the code is capable of doing nat and rdr in any direction, but we prevent
this in pfctl for now, there are implications that need to be documented
better.
the address rewrite happens inline, subsequent rules will see the already
changed addresses. nat / rdr can be applied multiple times as well.
match in on $intf rdr-to 1.2.3.4
match in on $intf to 1.2.3.4 rdr-to 5.6.7.8
help and ok dlg sthen claudio, reyk tested too
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.219 2009/05/31 19:10:51 henning Exp $ */
d1109 6
a1114 4
#ifndef INET
		if (rule->af == AF_INET) {
			pool_put(&pf_rule_pl, rule);
			error = EAFNOSUPPORT;
a1115 1
		}
d1117 5
a1121 2
#ifndef INET6
		if (rule->af == AF_INET6) {
d1124 1
a1124 1
			break;
d1126 1
a1126 1
#endif /* INET6 */
d1357 6
a1362 4
#ifndef INET
			if (newrule->af == AF_INET) {
				pool_put(&pf_rule_pl, newrule);
				error = EAFNOSUPPORT;
a1363 1
			}
d1365 5
a1369 2
#ifndef INET6
			if (newrule->af == AF_INET6) {
d1372 1
a1372 1
				break;
d1374 1
a1374 1
#endif /* INET6 */
d1996 6
a2001 3
#ifndef INET
		if (pp->af == AF_INET) {
			error = EAFNOSUPPORT;
a2002 1
		}
d2004 5
a2008 2
#ifndef INET6
		if (pp->af == AF_INET6) {
d2010 1
a2010 1
			break;
d2012 1
a2012 1
#endif /* INET6 */
d2137 6
a2142 4
#ifndef INET
			if (pca->af == AF_INET) {
				pool_put(&pf_pooladdr_pl, newpa);
				error = EAFNOSUPPORT;
a2143 1
			}
d2145 5
a2149 2
#ifndef INET6
			if (pca->af == AF_INET6) {
d2152 1
a2152 1
				break;
d2154 1
a2154 1
#endif /* INET6 */
@


1.219
log
@make set loginterface, set hostid, set reassemble and set debug
transactional. sanity checked claudio, requested by theo for some time
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.218 2009/04/16 04:40:19 david Exp $ */
d95 1
a95 1
			    u_int8_t, u_int8_t, u_int8_t);
d190 2
a191 1
	TAILQ_INIT(&pf_pabuf);
d262 1
a262 1
    u_int8_t check_ticket)
d299 4
a302 2

	return (&rule->rpool);
d372 2
a373 1
	pf_empty_pool(&rule->rpool.list);
d1103 2
a1104 1
		TAILQ_INIT(&rule->rpool.list);
d1179 4
a1182 1
		TAILQ_FOREACH(pa, &pf_pabuf, entries)
d1195 5
a1199 5
		pf_mv_pool(&pf_pabuf, &rule->rpool.list);
		if (((((rule->action == PF_NAT) || (rule->action == PF_RDR) ||
		    (rule->action == PF_BINAT)) && rule->anchor == NULL) ||
		    (rule->rt > PF_FASTROUTE)) &&
		    (TAILQ_FIRST(&rule->rpool.list) == NULL))
d1206 2
a1207 1
		rule->rpool.cur = TAILQ_FIRST(&rule->rpool.list);
d1348 2
a1349 1
			TAILQ_INIT(&newrule->rpool.list);
d1421 4
a1424 1
			TAILQ_FOREACH(pa, &pf_pabuf, entries)
d1438 5
a1442 7
			pf_mv_pool(&pf_pabuf, &newrule->rpool.list);
			if (((((newrule->action == PF_NAT) ||
			    (newrule->action == PF_RDR) ||
			    (newrule->action == PF_BINAT) ||
			    (newrule->rt > PF_FASTROUTE)) &&
			    !newrule->anchor)) &&
			    (TAILQ_FIRST(&newrule->rpool.list) == NULL))
d1449 2
a1450 1
			newrule->rpool.cur = TAILQ_FIRST(&newrule->rpool.list);
d1455 2
a1456 1
		pf_empty_pool(&pf_pabuf);
d1970 2
a1971 1
		pf_empty_pool(&pf_pabuf);
d1979 5
d2028 3
a2030 1
		TAILQ_INSERT_TAIL(&pf_pabuf, pa, entries);
d2037 5
d2044 1
a2044 1
		    pp->r_num, 0, 1, 0);
d2058 5
d2064 1
a2064 1
		    pp->r_num, 0, 1, 1);
d2088 5
d2111 1
a2111 1
		    pca->r_num, pca->r_last, 1, 1);
@


1.218
log
@Really turn fragment reassembly on by default.  pfctl must handle this
since the DIOCSETREASS ioctl is called on every ruleset load and was
overriding the initial setting in pfattach().  Fix setting of the global
no-df bitmask as well.
ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.217 2009/04/07 12:48:40 henning Exp $ */
d116 1
d124 13
d1669 2
a1670 1
		strlcpy(pf_status.ifname, pi->ifname, IFNAMSIZ);
d1785 2
a1786 1
		pf_status.debug = *level;
d2446 1
d2703 1
d2823 1
a2823 1
			pf_status.hostid = arc4random();
d2825 2
a2826 1
			pf_status.hostid = *hostid;
d2863 2
a2864 1
		pf_status.reass = *reass;
d2879 13
@


1.217
log
@turn fragment reassembly on by default. the is little to no reason to
not do fragment reassembly. discussed with dlg and ryan in basel.
ok ryan dlg sthen jdixon todd deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.216 2009/04/06 12:05:55 henning Exp $ */
a2844 2
		if (!(pf_status.reass & PF_REASS_ENABLED))
			pf_status.reass = 0;
@


1.216
log
@1) scrub rules are completely gone.
2) packet reassembly: only one method remains, full reassembly. crop
and drop-ovl are gone.
.  set reassemble yes|no [no-df]
if no-df is given fragments (and only fragments!) with the df bit set
have it cleared before entering the fragment cache, and thus the
reassembled packet doesn't have df set either. it does NOT touch
non-fragmented packets.
3) regular rules can have scrub options.
.  pass scrub(no-df, min-ttl 64, max-mss 1400, set-tos lowdelay)
.  match scrub(reassemble tcp, random-id)
of course all options are optional. the individual options still do
what they used to do on scrub rules, but everything is stateful now.
4) match rules
"match" is a new action, just like pass and block are, and can be used
like they do. opposed to pass or block, they do NOT change the
pass/block state of a packet. i. e.
.  pass
.  match
passes the packet, and
.  block
.  match
blocks it.
Every time (!) a match rule matches, i. e. not only when it is the
last matching rule, the following actions are set:
-queue assignment. can be overwritten later, the last rule that set a
queue wins. note how this is different from the last matching rule
wins, if the last matching rule has no queue assignments and the
second last matching rule was a match rule with queue assignments,
these assignments are taken.
-rtable assignments. works the same as queue assignments.
-set-tos, min-ttl, max-mss, no-df, random-id, reassemble tcp, all work
like the above
-logging. every matching rule causes the packet to be logged. this
 means a single packet can get logged more than once (think multiple log
 interfaces with different receivers, like pflogd and spamlogd)
.
almost entirely hacked at n2k9 in basel, could not be committed close to
release. this really should have been multiple diffs, but splitting them
now is not feasible any more. input from mcbride and dlg, and frantzen
about the fragment handling.
speedup around 7% for the common case, the more the more scrub rules
were in use.
manpage not up to date, being worked on.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.215 2009/03/09 13:53:10 mcbride Exp $ */
d212 1
@


1.215
log
@Make the DIOCSETIFFLAG, DIOCSETLIMIT, and DIOCSETTIMEOUT ioctls
transactional, closing PRs 4941 and 5910.  Minor flag day, requires rebuild
of userland tools that use struct pfi_kif.

ok henning deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.214 2009/02/16 00:31:25 dlg Exp $ */
d154 2
a857 4
		/* XXX PF_RULESET_SCRUB as well? */
		if (rs_cnt == PF_RULESET_SCRUB)
			continue;

d2837 9
@


1.214
log
@pfsync v5, mostly written at n2k9, but based on work done at n2k8.

WARNING: THIS BREAKS COMPATIBILITY WITH THE PREVIOUS VERSION OF PFSYNC

this is a new variant of the protocol and a large reworking of the
pfsync code to address some performance issues. the single largest
benefit comes from having multiple pfsync messages of different
types handled in a single packet. pfsyncs handling of pf states is
highly optimised now, along with packet parsing and construction.

huggz for beck@@ for testing.
huge thanks to mcbride@@ for his help during development and for
finding all the bugs during the initial tests.
thanks to peter sutton for letting me get credit for this work.

ok beck@@ mcbride@@ "good." deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.213 2009/02/15 21:46:12 mbalmer Exp $ */
d117 1
a117 1
struct pf_rule		 pf_default_rule;
a1714 1
		int		 old;
a1720 1
		old = pf_default_rule.timeout[pt->timeout];
d1723 2
a1724 4
		pf_default_rule.timeout[pt->timeout] = pt->seconds;
		if (pt->timeout == PFTM_INTERVAL && pt->seconds < old)
			wakeup(pf_purge_thread);
		pt->seconds = old;
a1751 1
		int			 old_limit;
d1758 2
a1759 2
		if (pool_sethardlimit(pf_pool_limits[pl->index].pp,
		    pl->limit, NULL, 0) != 0) {
d1763 2
a1764 3
		old_limit = pf_pool_limits[pl->index].limit;
		pf_pool_limits[pl->index].limit = pl->limit;
		pl->limit = old_limit;
d2430 1
d2617 11
d2667 20
@


1.213
log
@Revert previous.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.212 2009/02/15 20:42:33 mbalmer Exp $ */
d1494 1
a1494 1
				s->sync_flags = PFSTATE_NOSYNC;
a1518 5
#if NPFSYNC > 0
				/* send immediate delete of state */
				pfsync_delete_state(s);
				s->sync_flags |= PFSTATE_NOSYNC;
#endif
a1563 5
#if NPFSYNC > 0
				/* send immediate delete of state */
				pfsync_delete_state(s);
				s->sync_flags |= PFSTATE_NOSYNC;
#endif
@


1.212
log
@Fix compilation of kernels that have pf, but not pfsync.
ok dlg, henning, sthen
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.211 2008/11/24 13:22:09 mikeb Exp $ */
a1590 1
#if NPFSYNC > 0
a1591 1
#endif
d1608 1
a1608 1
#if NPFSYNC > 0
a1609 1
#endif
a1633 1
#if NPFSYNC > 0
a1634 1
#endif
@


1.211
log
@Fix splasserts seen in pr 5987 by propagating a flag that discribes
whether we're called from the interrupt context to the functions
performing allocations.

Looked at by mpf@@ and henning@@, tested by mpf@@ and Antti Harri,
the pr originator.

ok tedu
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.210 2008/10/23 22:22:44 deraadt Exp $ */
d1591 1
d1593 1
d1610 1
a1610 1

d1612 1
d1637 1
d1639 1
@


1.210
log
@use the correct idiom for NFOO things which come from "foo.h" files
ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.209 2008/06/29 08:42:15 mcbride Exp $ */
d1167 1
a1167 1
			    rule->overload_tblname)) == NULL)
d1404 1
a1404 1
				    ruleset, newrule->overload_tblname)) ==
@


1.209
log
@Simplify state creation code; merge state import/export code between pfsync
and the state-related pf(4) ioctls, and make functions in state creation and
destruction paths more robust in error conditions.

All values in struct pfsync_state now in network byte order, as with pfsync.

testing by david
ok henning, systat parts ok canacar
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.208 2008/06/22 13:01:33 mcbride Exp $ */
d1492 1
a1492 1
#if NPFSYNC
d1501 1
a1501 1
#if NPFSYNC
@


1.208
log
@Revert 1.203; it's not safe to blindly walk the tailq instead of the rbtree
for picking states to unlink as the tailq may contain unlinked states.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.202 2008/06/10 19:32:13 henning Exp $ */
a112 5
void			 pf_state_export(struct pfsync_state *,
			    struct pf_state *);
void			 pf_state_import(struct pfsync_state *,
			    struct pf_state_key *,
			    struct pf_state_key *, struct pf_state *);
a845 91
void
pf_state_export(struct pfsync_state *sp, struct pf_state *s)
{
	int secs = time_second;
	bzero(sp, sizeof(struct pfsync_state));

	/* copy from state key */
	sp->key[PF_SK_WIRE].addr[0] = s->key[PF_SK_WIRE]->addr[0];
	sp->key[PF_SK_WIRE].addr[1] = s->key[PF_SK_WIRE]->addr[1];
	sp->key[PF_SK_WIRE].port[0] = s->key[PF_SK_WIRE]->port[0];
	sp->key[PF_SK_WIRE].port[1] = s->key[PF_SK_WIRE]->port[1];
	sp->key[PF_SK_STACK].addr[0] = s->key[PF_SK_STACK]->addr[0];
	sp->key[PF_SK_STACK].addr[1] = s->key[PF_SK_STACK]->addr[1];
	sp->key[PF_SK_STACK].port[0] = s->key[PF_SK_STACK]->port[0];
	sp->key[PF_SK_STACK].port[1] = s->key[PF_SK_STACK]->port[1];
	sp->proto = s->key[PF_SK_WIRE]->proto;
	sp->af = s->key[PF_SK_WIRE]->af;
	sp->direction = s->direction;

	/* copy from state */
	memcpy(&sp->id, &s->id, sizeof(sp->id));
	sp->creatorid = s->creatorid;
	strlcpy(sp->ifname, s->kif->pfik_name, sizeof(sp->ifname));
	pf_state_peer_to_pfsync(&s->src, &sp->src);
	pf_state_peer_to_pfsync(&s->dst, &sp->dst);

	sp->rule = s->rule.ptr->nr;
	sp->nat_rule = (s->nat_rule.ptr == NULL) ?  -1 : s->nat_rule.ptr->nr;
	sp->anchor = (s->anchor.ptr == NULL) ?  -1 : s->anchor.ptr->nr;

	pf_state_counter_to_pfsync(s->bytes[0], sp->bytes[0]);
	pf_state_counter_to_pfsync(s->bytes[1], sp->bytes[1]);
	pf_state_counter_to_pfsync(s->packets[0], sp->packets[0]);
	pf_state_counter_to_pfsync(s->packets[1], sp->packets[1]);
	sp->creation = secs - s->creation;
	sp->expire = pf_state_expires(s);
	sp->log = s->log;
	sp->state_flags = s->state_flags;
	sp->timeout = s->timeout;

	if (s->src_node)
		sp->sync_flags |= PFSYNC_FLAG_SRCNODE;
	if (s->nat_src_node)
		sp->sync_flags |= PFSYNC_FLAG_NATSRCNODE;

	if (sp->expire > secs)
		sp->expire -= secs;
	else
		sp->expire = 0;

}

void
pf_state_import(struct pfsync_state *sp, struct pf_state_key *skw,
    struct pf_state_key *sks, struct pf_state *s)
{
	/* copy to state key(s) */
	skw->addr[0] = sp->key[PF_SK_WIRE].addr[0];
	skw->addr[1] = sp->key[PF_SK_WIRE].addr[1];
	skw->port[0] = sp->key[PF_SK_WIRE].port[0];
	skw->port[1] = sp->key[PF_SK_WIRE].port[1];
	skw->proto = sp->proto;
	skw->af = sp->af;
	if (sks != skw) {
		sks->addr[0] = sp->key[PF_SK_STACK].addr[0];
		sks->addr[1] = sp->key[PF_SK_STACK].addr[1];
		sks->port[0] = sp->key[PF_SK_STACK].port[0];
		sks->port[1] = sp->key[PF_SK_STACK].port[1];
		sks->proto = sp->proto;
		sks->af = sp->af;
	}
	/* copy to state */
	memcpy(&s->id, &sp->id, sizeof(sp->id));
	s->creatorid = sp->creatorid;
	pf_state_peer_from_pfsync(&sp->src, &s->src);
	pf_state_peer_from_pfsync(&sp->dst, &s->dst);

	s->direction = sp->direction;
	s->rule.ptr = &pf_default_rule;
	s->nat_rule.ptr = NULL;
	s->anchor.ptr = NULL;
	s->rt_kif = NULL;
	s->creation = time_second;
	s->expire = time_second;
	if (sp->expire > 0)
		s->expire -= pf_default_rule.timeout[sp->timeout] - sp->expire;
	s->pfsync_time = 0;
	s->packets[0] = s->packets[1] = 0;
	s->bytes[0] = s->bytes[1] = 0;
}

a1584 3
		struct pf_state		*s;
		struct pf_state_key	*skw, *sks;
		struct pfi_kif		*kif;
d1591 1
a1591 42
		s = pool_get(&pf_state_pl, PR_WAITOK | PR_LIMITFAIL | PR_ZERO);
		if (s == NULL) {
			error = ENOMEM;
			break;
		}
		if ((skw = pf_alloc_state_key()) == NULL) {
			pool_put(&pf_state_pl, s);
			error = ENOMEM;
			break;
		}
		if ((PF_ANEQ(&sp->key[PF_SK_WIRE].addr[0],
		    &sp->key[PF_SK_STACK].addr[0], sp->af) ||
		    PF_ANEQ(&sp->key[PF_SK_WIRE].addr[1],
		    &sp->key[PF_SK_STACK].addr[1], sp->af) ||
		    sp->key[PF_SK_WIRE].port[0] !=
		    sp->key[PF_SK_STACK].port[0] ||
		    sp->key[PF_SK_WIRE].port[1] !=
		    sp->key[PF_SK_STACK].port[1]) &&
		    (sks = pf_alloc_state_key()) == NULL) {
			pool_put(&pf_state_pl, s);
			pool_put(&pf_state_key_pl, skw);
			error = ENOMEM;
			break;
		} else
			sks = skw;
		pf_state_import(sp, skw, sks, s);
		kif = pfi_kif_get(sp->ifname);
		if (kif == NULL) {
			pool_put(&pf_state_pl, s);
			pool_put(&pf_state_key_pl, skw);
			if (skw != sks)
				pool_put(&pf_state_key_pl, sks);
			error = ENOENT;
			break;
		}
		if (pf_state_insert(kif, skw, sks, s)) {
			pfi_kif_unref(kif, PFI_KIF_REF_NONE);
			pool_put(&pf_state_pl, s);
			error = EEXIST;
			break;
		}
		pf_default_rule.states_cur++;
d1609 1
a1609 1
		pf_state_export(&ps->state, s);
d1634 1
a1634 1
				pf_state_export(pstore, state);
@


1.207
log
@Include "pflog.h" so that we get NPFLOG.

ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.206 2008/06/14 02:22:13 henning Exp $ */
d1583 2
a1584 2
		for (s = TAILQ_FIRST(&state_list); s; s = nexts) {
			nexts = TAILQ_NEXT(s, entry_list);
@


1.206
log
@pool_get()s not in interrupt context should not be PR_NOWAIT, but
PR_WAITOK | PR_LIMITFAIL. from discussion with art. ok ryan claudio thib
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.205 2008/06/11 20:51:34 mcbride Exp $ */
d39 1
@


1.205
log
@Split address setup operations into a separate function. More to come.

ok henning
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.204 2008/06/10 22:39:31 mcbride Exp $ */
d1171 1
a1171 1
		rule = pool_get(&pf_rule_pl, PR_NOWAIT);
d1413 1
a1413 1
			newrule = pool_get(&pf_rule_pl, PR_NOWAIT);
d1689 1
a1689 1
		s = pool_get(&pf_state_pl, PR_NOWAIT | PR_ZERO);
d1987 1
a1987 1
		altq = pool_get(&pf_altq_pl, PR_NOWAIT);
d2127 1
a2127 1
		pa = pool_get(&pf_pooladdr_pl, PR_NOWAIT);
d2221 2
a2222 1
			newpa = pool_get(&pf_pooladdr_pl, PR_NOWAIT);
@


1.204
log
@Simplify code slightly; use PR_ZERO with pool_get() rather than bzero().

ok mpf henning
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.203 2008/06/10 20:14:02 henning Exp $ */
d117 3
d982 19
d1250 1
a1250 3
		if (pfi_dynaddr_setup(&rule->src.addr, rule->af))
			error = EINVAL;
		if (pfi_dynaddr_setup(&rule->dst.addr, rule->af))
d1252 1
a1252 3
		if (pf_tbladdr_setup(ruleset, &rule->src.addr))
			error = EINVAL;
		if (pf_tbladdr_setup(ruleset, &rule->dst.addr))
d1349 2
a1350 6
		pfi_dynaddr_copyout(&pr->rule.src.addr);
		pfi_dynaddr_copyout(&pr->rule.dst.addr);
		pf_tbladdr_copyout(&pr->rule.src.addr);
		pf_tbladdr_copyout(&pr->rule.dst.addr);
		pf_rtlabel_copyout(&pr->rule.src.addr);
		pf_rtlabel_copyout(&pr->rule.dst.addr);
d1487 1
a1487 5
			if (pfi_dynaddr_setup(&newrule->src.addr, newrule->af))
				error = EINVAL;
			if (pfi_dynaddr_setup(&newrule->dst.addr, newrule->af))
				error = EINVAL;
			if (pf_tbladdr_setup(ruleset, &newrule->src.addr))
d1489 1
a1489 1
			if (pf_tbladdr_setup(ruleset, &newrule->dst.addr))
d2188 1
a2188 3
		pfi_dynaddr_copyout(&pp->addr.addr);
		pf_tbladdr_copyout(&pp->addr.addr);
		pf_rtlabel_copyout(&pp->addr.addr);
@


1.203
log
@when walking the entire state table it makes much more sense to walk
the tailq instead of the rb tree. pt out by kjell some time ago, ok ryan
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.202 2008/06/10 19:32:13 henning Exp $ */
d1679 1
a1679 1
		s = pool_get(&pf_state_pl, PR_NOWAIT);
a1683 1
		bzero(s, sizeof(struct pf_state));
@


1.202
log
@save somespace in the state by collapsing two 8 bit ints used as booleans
into one 8 bit flags field.
shrinks the state structure by 4 bytes on 32bit archs
ryan ok
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.201 2008/06/10 04:24:17 henning Exp $ */
d1572 2
a1573 2
		for (s = RB_MIN(pf_state_tree_id, &tree_id); s; s = nexts) {
			nexts = RB_NEXT(pf_state_tree_id, &tree_id, s);
@


1.201
log
@implement a sloppy tcpstate tracker which does not look at sequence
numbers at all. scary consequences; only tobe used in very specific
situations where you don't see all packets of a connection, e. g.
asymmetric routing. ok ryan reyk theo
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.200 2008/05/30 14:22:48 henning Exp $ */
d884 1
a884 2
	sp->allow_opts = s->allow_opts;
	sp->sloppy = s->sloppy;
@


1.200
log
@trivial KNF before we go further
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.199 2008/05/29 01:00:53 mcbride Exp $ */
d885 1
@


1.199
log
@Second half of PF state table rearrangement.
- Mechanical change: Use arrays for state key pointers in pf_state, and
  addr/port in pf_state_key, to allow the use of indexes.
- Fix NAT, pfsync, pfctl, and tcpdump to handle the new state structures.
  In struct pfsync_state, both state keys are included even when identical.
- Also fix some bugs discovered in the existing code during testing.
  (in particular, "block return" for TCP packets was not returning an RST)

ok henning beck deraadt
tested by otto dlg beck laurent

Special thanks to users Manuel Pata and Emilio Perea who did enough testing
to actually find some bugs.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.197 2008/05/18 11:54:04 mcbride Exp $ */
d153 1
a153 1
	pool_init(&pf_state_item_pl, sizeof(struct pf_state_item), 0, 0, 0, 
d848 1
a848 1
pf_state_export(struct pfsync_state *sp, struct pf_state *s) 
d901 1
a901 1
   struct pf_state_key *sks, struct pf_state *s) 
@


1.198
log
@rewrite the state table logic.
complete the split off of the layer 3/4 adressing information from the extra
information in the actual state. a state key holds a list of states, and a
state points to two state keys - they're only different in the NAT case.
More specificially, it deprecates the (often difficult to understand)
concept of lan, ext, and gwy addresses, replacing them with WIRE and
STACK side address tuples.  (af, proto, saddr, daddr, sport, dport).
Concept first brought up some years ago on a ferry ride in bc by ryan and
me, I spent some time over the last year getting closer, and finally
got it completed in japan with ryan. dlg also took part, helped a lot,
and saved us 8 bytes.
This commit removes support for any kind of NAT as well as pfsync.
It also paves the road for some code simplification and some very cool
future stuff.
ok ryan beck, tested by many
@
text
@d115 1
a852 1
/* XXX_RYAN_NAT */
d854 10
a863 8
	sp->lan.addr = s->key_wire->addr2;
	sp->lan.port = s->key_wire->port2;
	sp->gwy.addr = s->key_wire->addr2;
	sp->gwy.port = s->key_wire->port2;
	sp->ext.addr = s->key_wire->addr1;
	sp->ext.port = s->key_wire->port1;
	sp->proto = s->key_wire->proto;
	sp->af = s->key_wire->af;
d900 2
a901 2
pf_state_import(struct pfsync_state *sp, struct pf_state_key *sk,
    struct pf_state *s)
d903 15
a917 11
	/* copy to state key */
#ifdef XXX_RYAN_HENNING_PFSYNC_FIXED
	sk->lan.addr = sp->lan.addr;
	sk->lan.port = sp->lan.port;
	sk->gwy.addr = sp->gwy.addr;
	sk->gwy.port = sp->gwy.port;
	sk->ext.addr = sp->ext.addr;
	sk->ext.port = sp->ext.port;
#endif
	sk->proto = sp->proto;
	sk->af = sp->af;
d1618 1
a1618 1
			sk = s->key_wire;
d1621 4
a1624 4
				srcaddr = &sk->addr2;
				dstaddr = &sk->addr1;
				srcport = sk->port2;
				dstport = sk->port1;
d1626 4
a1629 4
				srcaddr = &sk->addr1;
				dstaddr = &sk->addr2;
				srcport = sk->port2;
				dstport = sk->port1;
d1671 1
a1671 1
		struct pf_state_key	*sk;
d1685 1
a1685 1
		if ((sk = pf_alloc_state_key()) == NULL) {
d1690 16
a1705 2
		pf_state_import(sp, sk, s);
/* RYAN NAT */	pf_attach_state(sk, s, 0, PF_SK_BOTH);
d1709 3
a1711 1
			pool_put(&pf_state_key_pl, sk);
d1715 1
a1715 1
		if (pf_state_insert(kif, sk, s)) {
d1816 1
d1818 3
a1820 2
		key.af = pnl->af;
		key.proto = pnl->proto;
d1830 9
a1838 19
			/*
			 * userland gives us source and dest of connection,
			 * reverse the lookup so we ask for what happens with
			 * the return traffic, enabling us to find it in the
			 * state tree.
			 */
			if (direction == PF_IN) {
				PF_ACPY(&key.addr1, &pnl->daddr, pnl->af);
				key.port1 = pnl->dport;
				PF_ACPY(&key.addr2, &pnl->saddr, pnl->af);
				key.port2 = pnl->sport;
				state = pf_find_state_all(&key, PF_IN, &m);
			} else {
				PF_ACPY(&key.addr2, &pnl->daddr, pnl->af);
				key.port2 = pnl->dport;
				PF_ACPY(&key.addr1, &pnl->saddr, pnl->af);
				key.port1 = pnl->sport;
				state = pf_find_state_all(&key, PF_OUT, &m);
			}
d1842 5
a1846 16
				sk = state->key_wire; /* XXX which side? */
				if (direction == PF_IN) {
					PF_ACPY(&pnl->rsaddr, &sk->addr1,
					    sk->af);
					pnl->rsport = sk->port1;
					PF_ACPY(&pnl->rdaddr, &pnl->daddr,
					    pnl->af);
					pnl->rdport = pnl->dport;
				} else {
					PF_ACPY(&pnl->rdaddr, &sk->addr2,
					    sk->af);
					pnl->rdport = sk->port2;
					PF_ACPY(&pnl->rsaddr, &pnl->saddr,
					    pnl->af);
					pnl->rsport = pnl->sport;
				}
@


1.197
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.196 2008/05/09 13:59:31 mpf Exp $ */
d113 1
a113 1
			    struct pf_state_key *, struct pf_state *);
d152 2
d847 1
a847 2
pf_state_export(struct pfsync_state *sp, struct pf_state_key *sk,
    struct pf_state *s)
d852 1
d854 9
a862 9
	sp->lan.addr = sk->lan.addr;
	sp->lan.port = sk->lan.port;
	sp->gwy.addr = sk->gwy.addr;
	sp->gwy.port = sk->gwy.port;
	sp->ext.addr = sk->ext.addr;
	sp->ext.port = sk->ext.port;
	sp->proto = sk->proto;
	sp->af = sk->af;
	sp->direction = sk->direction;
d902 1
d909 1
a911 2
	sk->direction = sp->direction;

d918 1
d1589 2
a1590 1
		struct pf_state_host	*src, *dst;
d1612 1
a1612 1
			sk = s->state_key;
d1614 5
a1618 3
			if (sk->direction == PF_OUT) {
				src = &sk->lan;
				dst = &sk->ext;
d1620 4
a1623 2
				src = &sk->ext;
				dst = &sk->lan;
d1631 1
a1631 1
			    &src->addr, sk->af) &&
d1635 1
a1635 1
			    &dst->addr, sk->af) &&
d1639 1
a1639 1
			    src->port)) &&
d1643 1
a1643 1
			    dst->port)) &&
d1679 1
a1679 1
		if ((sk = pf_alloc_state_key(s)) == NULL) {
d1685 1
d1693 1
a1693 1
		if (pf_insert_state(kif, s)) {
d1717 1
a1717 1
		pf_state_export(&ps->state, s->state_key, s);
d1742 1
a1742 3

				pf_state_export(pstore,
				    state->state_key, state);
d1813 4
a1816 4
				PF_ACPY(&key.ext.addr, &pnl->daddr, pnl->af);
				key.ext.port = pnl->dport;
				PF_ACPY(&key.gwy.addr, &pnl->saddr, pnl->af);
				key.gwy.port = pnl->sport;
d1819 4
a1822 4
				PF_ACPY(&key.lan.addr, &pnl->daddr, pnl->af);
				key.lan.port = pnl->dport;
				PF_ACPY(&key.ext.addr, &pnl->saddr, pnl->af);
				key.ext.port = pnl->sport;
d1828 1
a1828 1
				sk = state->state_key;
d1830 1
a1830 1
					PF_ACPY(&pnl->rsaddr, &sk->lan.addr,
d1832 1
a1832 1
					pnl->rsport = sk->lan.port;
d1837 1
a1837 1
					PF_ACPY(&pnl->rdaddr, &sk->gwy.addr,
d1839 1
a1839 1
					pnl->rdport = sk->gwy.port;
@


1.196
log
@Add support to kill states by rule label or state id.
Fix printing of the state id in pfctl -ss -vv.
Remove the psnk_af hack to return the number of killed states.
OK markus, beck. "I like it" henning, deraadt.
Manpage help from jmc.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.195 2008/05/06 03:45:22 mpf Exp $ */
d150 1
a150 1
	pool_init(&pf_state_key_pl, sizeof(struct pf_state_key), 0, 0, 0, 
d846 1
a846 1
   struct pf_state *s) 
d897 1
a897 1
   struct pf_state *s) 
d1070 2
a1071 1
			if (((struct pfioc_rule *)addr)->action == PF_GET_CLR_CNTR)
d1655 1
a1655 1
		struct pfsync_state 	*sp = &ps->state;
d2871 2
a2872 2
		struct pfioc_src_node_kill *psnk = \
			(struct pfioc_src_node_kill *) addr;
d2876 8
a2883 8
        		if (PF_MATCHA(psnk->psnk_src.neg, \
				      &psnk->psnk_src.addr.v.a.addr, \
				      &psnk->psnk_src.addr.v.a.mask, \
				      &sn->addr, sn->af) &&
			    PF_MATCHA(psnk->psnk_dst.neg, \
				      &psnk->psnk_dst.addr.v.a.addr, \
				      &psnk->psnk_dst.addr.v.a.mask, \
				      &sn->raddr, sn->af)) {
d2886 1
a2886 1
					RB_FOREACH(s, pf_state_tree_id, 
@


1.195
log
@Add a counter to record how many states have been created by a rule.
It shows up in pfctl verbose mode and in the 7th field of the labels
output.  Also remove the label printing for scrub rules, as they
do not support labels.
OK dhartmei@@ (on an earlier version), henning@@, mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.194 2008/05/06 03:24:25 weingart Exp $ */
d1560 1
a1560 1
		int			 killed = 0;
d1575 1
a1575 1
		psk->psk_af = killed;
d1587 16
a1602 1
		int			 killed = 0;
d1635 2
d1648 1
a1648 1
		psk->psk_af = killed;
d2872 1
a2872 1
		int			killed = 0;
d2902 1
a2902 1
		psnk->psnk_af = killed;
@


1.194
log
@Prevent possible overflow of int variable on large memory machines.

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.193 2007/12/02 12:08:04 pascoe Exp $ */
d312 1
a312 1
		if (rule->states <= 0) {
d328 1
a328 1
	if (rule->states > 0 || rule->src_nodes > 0 ||
d1151 1
a1151 1
		rule->states = 0;
d1338 1
d1399 1
a1399 1
			newrule->states = 0;
d1672 1
a1672 1
		pf_default_rule.states++;
@


1.193
log
@DIOC{GET,ADD}STATE incorrectly use a user provided pointer without using
copyin/out.  Change the API so that the state is included in the ioctl
argument, so the ioctl wrappers take care of copying memory as appropriate.

Also change the DIOCGETSTATE API to be more useful.  Instead of getting
an arbitrarily "numbered" state (using numbering that can change between
calls), instead search based on id and creatorid.  If you want to monitor
only a particular state, you can now use the bulk functions first to find
the appropriate id/creatorid and then fetch it directly from then on.

ok dlg@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.192 2007/12/02 12:00:20 pascoe Exp $ */
d163 1
a163 1
	if (ptoa(physmem) <= 100*1024*1024)
@


1.192
log
@When pf_insert_state state succeeds, increase the state count on the
default rule.

When pf_insert_state fails, it's because a matching state already exists.
Return a better error code to the user in this case.

ok henning@@ dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.191 2007/12/02 11:56:29 dhartmei Exp $ */
d1636 1
a1636 1
		struct pfsync_state 	*sp = (struct pfsync_state *)ps->state;
d1678 1
a1678 1
		u_int32_t		 nr;
d1680 4
a1683 6
		nr = 0;
		RB_FOREACH(s, pf_state_tree_id, &tree_id) {
			if (nr >= ps->nr)
				break;
			nr++;
		}
d1685 1
a1685 1
			error = EBUSY;
d1689 1
a1689 2
		pf_state_export((struct pfsync_state *)ps->state,
		    s->state_key, s);
@


1.191
log
@initialize altq->altq_disc to NULL, from Max Laier
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.190 2007/12/02 11:53:06 pascoe Exp $ */
d1668 2
a1669 1
			error = ENOMEM;
d1671 1
@


1.190
log
@Don't put state key if pf_insert_state fails.  pf_detach_state would have
put it for us already.

Also, fix cut-n-paste error in previous commit.

ok dlg@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.189 2007/12/02 11:42:05 pascoe Exp $ */
d1967 1
@


1.189
log
@Don't leak state if key allocation fails during add.

ok dlg@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.188 2007/12/02 11:39:45 pascoe Exp $ */
d1653 1
a1653 1
			pool_put(pf_state_pl, s);
a1667 1
			pool_put(&pf_state_key_pl, sk);
@


1.188
log
@Set expiry timestamp when importing a state, otherwise it expires on the
next expiry run.

ok dlg@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.187 2007/12/02 11:36:39 pascoe Exp $ */
d1653 1
@


1.187
log
@DIOCADDSTATE would always dereference a NULL pointer during this copy
and what it was copying would get overwritten anyway.  Remove the copy
and avoid a panic.

DIOCGETSTATE would incorrectly dereference a pointer to a pointer,
causing another panic.  Fix this.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.186 2007/09/27 22:24:05 mpf Exp $ */
d921 3
@


1.186
log
@Add loginterface support for groups.
Using a group sums up the statistics of all members.
Modify pfctl(1) slightly to allow a groupname "all",
which gives us an overall pf(4) statistic.

OK henning@@, markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.185 2007/09/15 16:43:51 henning Exp $ */
a912 1
	strlcpy(sp->ifname, s->kif->pfik_name, sizeof(sp->ifname));
d1686 1
a1686 1
		pf_state_export((struct pfsync_state *)&ps->state,
@


1.185
log
@malloc sweep:
-remove useless casts
-MALLOC/FREE -> malloc/free
-use M_ZERO where appropriate instead of seperate bzero
feedback & ok krw, hshoexer
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.184 2007/09/01 15:14:44 martin Exp $ */
d1736 1
a1736 1
		pfi_fill_oldstatus(s);
a1746 4
		if (ifunit(pi->ifname) == NULL) {
			error = EINVAL;
			break;
		}
d1757 1
a1757 1
			pfi_clr_istats(pf_status.ifname);
@


1.184
log
@replace the machine dependant bytes-to-clicks macro by the MI ptoa()
version for i386

more architectures and ctob() replacement is being worked on

prodded by and ok miod
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.183 2007/08/30 13:07:06 henning Exp $ */
d382 1
a382 2
	tag = (struct pf_tagname *)malloc(sizeof(struct pf_tagname),
	    M_TEMP, M_NOWAIT);
a384 1
	bzero(tag, sizeof(struct pf_tagname));
d2548 2
a2549 4
		ioe = (struct pfioc_trans_e *)malloc(sizeof(*ioe),
		    M_TEMP, M_WAITOK);
		table = (struct pfr_table *)malloc(sizeof(*table),
		    M_TEMP, M_WAITOK);
d2615 2
a2616 4
		ioe = (struct pfioc_trans_e *)malloc(sizeof(*ioe),
		    M_TEMP, M_WAITOK);
		table = (struct pfr_table *)malloc(sizeof(*table),
		    M_TEMP, M_WAITOK);
d2677 2
a2678 4
		ioe = (struct pfioc_trans_e *)malloc(sizeof(*ioe),
		    M_TEMP, M_WAITOK);
		table = (struct pfr_table *)malloc(sizeof(*table),
		    M_TEMP, M_WAITOK);
@


1.183
log
@mechanic change:
there is a 1:1 mapping between direction and the tree the states get
attached to. there is no need to have anything outside the state insertion/
deletion/lookup routinbes know about these internals. so just pass the
direction to the lookup functions and let them pick the right tree.
ok dhartmei markus
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.182 2007/06/24 11:17:13 mcbride Exp $ */
d163 1
a163 1
	if (ctob(physmem) <= 100*1024*1024)
@


1.182
log
@Save some bytes and make code more readable by removing junk union and
unused ifname (this information is in struct pf_state_sync now).

Also a bit of KNF on the pf_state struct.

ok mpf@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.181 2007/06/21 19:31:49 henning Exp $ */
d1796 1
a1796 1
				state = pf_find_state_all(&key, PF_EXT_GWY, &m);
d1802 1
a1802 1
				state = pf_find_state_all(&key, PF_LAN_EXT, &m);
@


1.181
log
@force logif to zero if no logging is asked for
check the logif when changing a rule
from max laier, ok ryan
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.180 2007/06/07 13:32:06 henning Exp $ */
d867 1
a867 1
	strlcpy(sp->ifname, s->u.s.kif->pfik_name, sizeof(sp->ifname));
d915 1
a915 1
	strlcpy(sp->ifname, s->u.s.kif->pfik_name, sizeof(sp->ifname));
d1565 1
a1565 1
			    s->u.s.kif->pfik_name)) {
d1620 1
a1620 1
			    s->u.s.kif->pfik_name))) {
d1726 1
a1726 1
			state = TAILQ_NEXT(state, u.s.entry_list);
@


1.180
log
@PR 5502 From: Marc Huber <Marc.Huber@@web.de>
        pfioctl()'s DIOCKILLSTATES triggers panic due to wrong test
        variable in for() loop.
well analyzed and fixed, excellent PR, applied verbatim, thanks!
(this was fallout from the state - state key split)
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.179 2007/06/01 18:44:23 henning Exp $ */
d1210 2
d1453 6
@


1.179
log
@factor out duplicated code to allocate state key and cross-reference it
with a state entry into a new pf_alloc_state_key() function and use it
everywhere. makes upcoming changes way easier and is cleaner anyway.
conceptually agreed by ryan, but he's on the road now ;(
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.178 2007/05/31 18:48:05 mcbride Exp $ */
d1580 1
a1580 1
		for (s = RB_MIN(pf_state_tree_id, &tree_id); sk;
@


1.178
log
@Move the state id and creatorid (used mainly by pfsync) into struct pf_state.

ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.177 2007/05/31 04:11:42 mcbride Exp $ */
a900 5
	bzero(sk, sizeof(struct pf_state_key));
	bzero(s, sizeof(struct pf_state));
	sk->state = s;
	s->state_key = sk;

d1643 2
a1644 2
		sk = pool_get(&pf_state_key_pl, PR_NOWAIT);
		if (sk == NULL) {
@


1.177
log
@First step of rearranging pf's state table internals...

- Split pf_state into pf_state (used for tracking connection information),
  and pf_state_key (used for searching the state table)

- Use pfsync_state in the ioctl for userland access to the state
  table. This will sheild userland somewhat from future changes.

ok henning@@ toby@@ pyr@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.176 2007/05/29 00:17:32 thib Exp $ */
a853 2
	memcpy(&sp->id, &sk->id, sizeof(sp->id));
	sp->creatorid = sk->creatorid;
d865 2
a906 2
	memcpy(&sk->id, &sp->id, sizeof(sp->id));
	sk->creatorid = sp->creatorid;
d918 2
d1554 1
a1554 1
		struct pf_state_key	*sk, *nextsk;
d1558 2
a1559 3
		for (sk = RB_MIN(pf_state_tree_id, &tree_id); sk;
		    sk = nextsk) {
			nextsk = RB_NEXT(pf_state_tree_id, &tree_id, sk);
d1562 1
a1562 1
			    sk->state->u.s.kif->pfik_name)) {
d1565 1
a1565 1
				sk->state->sync_flags = PFSTATE_NOSYNC;
d1567 1
a1567 1
				pf_unlink_state(sk->state);
d1579 2
a1580 1
		struct pf_state_key	*sk, *nextsk;
d1585 4
a1588 3
		for (sk = RB_MIN(pf_state_tree_id, &tree_id); sk;
		    sk = nextsk) {
			nextsk = RB_NEXT(pf_state_tree_id, &tree_id, sk);
d1617 1
a1617 1
			    sk->state->u.s.kif->pfik_name))) {
d1620 2
a1621 2
				pfsync_delete_state(sk->state);
				sk->state->sync_flags |= PFSTATE_NOSYNC;
d1623 1
a1623 1
				pf_unlink_state(sk->state);
d1672 1
a1672 1
		struct pf_state_key	*sk;
d1676 1
a1676 1
		RB_FOREACH(sk, pf_state_tree_id, &tree_id) {
d1681 1
a1681 1
		if (sk == NULL) {
d1687 1
a1687 1
		    sk, sk->state);
d2841 1
a2841 1
		struct pf_state_key	*state_key;
d2843 3
a2845 3
		RB_FOREACH(state_key, pf_state_tree_id, &tree_id) {
			state_key->state->src_node = NULL;
			state_key->state->nat_src_node = NULL;
a2858 1
		struct pf_state_key	*sk;
d2874 1
a2874 1
					RB_FOREACH(sk, pf_state_tree_id, 
a2875 1
						s = sk->state;
@


1.176
log
@Add a name argument to the RWLOCK_INITIALIZER macro.
Pick reasonble names for the locks involved..

ok tedu@@, art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.175 2007/02/26 22:47:43 deraadt Exp $ */
d112 4
d150 2
d846 88
d1554 1
a1554 1
		struct pf_state		*state, *nexts;
d1558 3
a1560 3
		for (state = RB_MIN(pf_state_tree_id, &tree_id); state;
		    state = nexts) {
			nexts = RB_NEXT(pf_state_tree_id, &tree_id, state);
d1563 1
a1563 1
			    state->u.s.kif->pfik_name)) {
d1566 1
a1566 1
				state->sync_flags = PFSTATE_NOSYNC;
d1568 1
a1568 1
				pf_unlink_state(state);
d1580 1
a1580 1
		struct pf_state		*state, *nexts;
d1585 7
a1591 7
		for (state = RB_MIN(pf_state_tree_id, &tree_id); state;
		    state = nexts) {
			nexts = RB_NEXT(pf_state_tree_id, &tree_id, state);

			if (state->direction == PF_OUT) {
				src = &state->lan;
				dst = &state->ext;
d1593 2
a1594 2
				src = &state->ext;
				dst = &state->lan;
d1596 1
a1596 1
			if ((!psk->psk_af || state->af == psk->psk_af)
d1598 1
a1598 1
			    state->proto) &&
d1602 1
a1602 1
			    &src->addr, state->af) &&
d1606 1
a1606 1
			    &dst->addr, state->af) &&
d1616 1
a1616 1
			    state->u.s.kif->pfik_name))) {
d1619 2
a1620 2
				pfsync_delete_state(state);
				state->sync_flags |= PFSTATE_NOSYNC;
d1622 1
a1622 1
				pf_unlink_state(state);
d1632 3
a1634 1
		struct pf_state		*state;
d1637 2
a1638 2
		if (ps->state.timeout >= PFTM_MAX &&
		    ps->state.timeout != PFTM_UNTIL_PACKET) {
d1642 7
a1648 2
		state = pool_get(&pf_state_pl, PR_NOWAIT);
		if (state == NULL) {
d1652 2
a1653 1
		kif = pfi_kif_get(ps->state.u.ifname);
d1655 2
a1656 1
			pool_put(&pf_state_pl, state);
d1660 1
a1660 12
		bcopy(&ps->state, state, sizeof(struct pf_state));
		bzero(&state->u, sizeof(state->u));
		state->rule.ptr = &pf_default_rule;
		state->nat_rule.ptr = NULL;
		state->anchor.ptr = NULL;
		state->rt_kif = NULL;
		state->creation = time_second;
		state->pfsync_time = 0;
		state->packets[0] = state->packets[1] = 0;
		state->bytes[0] = state->bytes[1] = 0;

		if (pf_insert_state(kif, state)) {
d1662 2
a1663 1
			pool_put(&pf_state_pl, state);
d1671 1
a1671 1
		struct pf_state		*state;
a1672 1
		int			 secs;
d1675 1
a1675 1
		RB_FOREACH(state, pf_state_tree_id, &tree_id) {
d1680 1
a1680 1
		if (state == NULL) {
d1684 3
a1686 15
		secs = time_second;
		bcopy(state, &ps->state, sizeof(ps->state));
		strlcpy(ps->state.u.ifname, state->u.s.kif->pfik_name,
		    sizeof(ps->state.u.ifname));
		ps->state.rule.nr = state->rule.ptr->nr;
		ps->state.nat_rule.nr = (state->nat_rule.ptr == NULL) ?
		    -1 : state->nat_rule.ptr->nr;
		ps->state.anchor.nr = (state->anchor.ptr == NULL) ?
		    -1 : state->anchor.ptr->nr;
		ps->state.creation = secs - ps->state.creation;
		ps->state.expire = pf_state_expires(state);
		if (ps->state.expire > secs)
			ps->state.expire -= secs;
		else
			ps->state.expire = 0;
d1693 1
a1693 1
		struct pf_state		*p, *pstore;
a1694 1
		int			 space = ps->ps_len;
d1696 1
a1696 1
		if (space == 0) {
d1698 1
a1698 1
			ps->ps_len = sizeof(struct pf_state) * nr;
a1708 2
				int	secs = time_second;

d1712 2
a1713 15
				bcopy(state, pstore, sizeof(*pstore));
				strlcpy(pstore->u.ifname,
				    state->u.s.kif->pfik_name,
				    sizeof(pstore->u.ifname));
				pstore->rule.nr = state->rule.ptr->nr;
				pstore->nat_rule.nr = (state->nat_rule.ptr ==
				    NULL) ? -1 : state->nat_rule.ptr->nr;
				pstore->anchor.nr = (state->anchor.ptr ==
				    NULL) ? -1 : state->anchor.ptr->nr;
				pstore->creation = secs - pstore->creation;
				pstore->expire = pf_state_expires(state);
				if (pstore->expire > secs)
					pstore->expire -= secs;
				else
					pstore->expire = 0;
d1725 1
a1725 1
		ps->ps_len = sizeof(struct pf_state) * nr;
d1765 1
d1767 1
a1767 1
		struct pf_state_cmp	 key;
d1803 1
d1805 3
a1807 3
					PF_ACPY(&pnl->rsaddr, &state->lan.addr,
					    state->af);
					pnl->rsport = state->lan.port;
d1812 3
a1814 3
					PF_ACPY(&pnl->rdaddr, &state->gwy.addr,
					    state->af);
					pnl->rdport = state->gwy.port;
d2840 1
a2840 1
		struct pf_state		*state;
d2842 3
a2844 3
		RB_FOREACH(state, pf_state_tree_id, &tree_id) {
			state->src_node = NULL;
			state->nat_src_node = NULL;
d2858 1
d2874 1
a2874 1
					RB_FOREACH(s, pf_state_tree_id, 
d2876 1
@


1.175
log
@because sparc has variable pagesize, ctob() varies between machines, and we
need uvm/uvm_extern.h to get at uvmexp.  oops.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.174 2007/02/23 21:31:51 deraadt Exp $ */
d114 1
a114 1
struct rwlock		 pf_consistency_lock = RWLOCK_INITIALIZER;
@


1.174
log
@if machine has more than 100MB of physmem, default the max table entries
to 200,000 instead of the conservative 100,000; ok dhartmei beck
tested by ckuethe
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.173 2007/02/09 11:20:39 henning Exp $ */
d55 1
@


1.173
log
@allow counters to be reset with DIOCGETRULES.
this allows an atomic read and reset counters, instead of read, reset in a
later ioctl and lose everything in between.
use the previously unused of pr->action. When it is set to PF_GET_CLR_CNTR,
the ioctl requires write permissions and counters are reset after they have
been copied out to userland.
obsoletes DIOCCLRRULECTRS, which only works for the main ruleset, but not
within anchors (yeah, that's how it all started)
ok dhartmei, mcbride and theo agree as well
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.172 2006/11/20 14:25:11 mcbride Exp $ */
d155 4
@


1.172
log
@ioctl to explicitly remove source tracking nodes,
diff from Berk D. Demir <bdd@@mindcast.org>

ok henning dhartmei
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.171 2006/10/27 13:56:51 mcbride Exp $ */
a937 1
		case DIOCGETRULE:
d975 4
d1237 6
d1823 1
@


1.171
log
@Split ruleset manipulation functions out into pf_ruleset.c to allow them to
be imported into pfctl. This is a precursor to separating ruleset parsing
from loading in pfctl, and tons of good things will come from it.

2 minor changes aside from cut-n-paste and #define portability magic:

- instead of defining the global pf_main_ruleset, define pf_main_anchor
  (which contains the pf_main_ruleset)

- allow pf_find_or_create_ruleset() to return the pf_main_ruleset if it's
  passed an empty anchor name.

ok henning dhartmei
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.170 2006/10/25 11:26:47 henning Exp $ */
d2771 39
@


1.170
log
@add a "u_int8_t logif" to struct pfrule to select to which pflog interface
logs go. ok mcbride
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.169 2006/08/30 11:31:02 djm Exp $ */
a93 7
int			 pf_get_ruleset_number(u_int8_t);
void			 pf_init_ruleset(struct pf_ruleset *);
int			 pf_anchor_setup(struct pf_rule *,
			    const struct pf_ruleset *, const char *);
int			 pf_anchor_copyout(const struct pf_ruleset *,
			    const struct pf_rule *, struct pfioc_rule *);
void			 pf_anchor_remove(struct pf_rule *);
a269 307
}

int
pf_get_ruleset_number(u_int8_t action)
{
	switch (action) {
	case PF_SCRUB:
	case PF_NOSCRUB:
		return (PF_RULESET_SCRUB);
		break;
	case PF_PASS:
	case PF_DROP:
		return (PF_RULESET_FILTER);
		break;
	case PF_NAT:
	case PF_NONAT:
		return (PF_RULESET_NAT);
		break;
	case PF_BINAT:
	case PF_NOBINAT:
		return (PF_RULESET_BINAT);
		break;
	case PF_RDR:
	case PF_NORDR:
		return (PF_RULESET_RDR);
		break;
	default:
		return (PF_RULESET_MAX);
		break;
	}
}

void
pf_init_ruleset(struct pf_ruleset *ruleset)
{
	int	i;

	memset(ruleset, 0, sizeof(struct pf_ruleset));
	for (i = 0; i < PF_RULESET_MAX; i++) {
		TAILQ_INIT(&ruleset->rules[i].queues[0]);
		TAILQ_INIT(&ruleset->rules[i].queues[1]);
		ruleset->rules[i].active.ptr = &ruleset->rules[i].queues[0];
		ruleset->rules[i].inactive.ptr = &ruleset->rules[i].queues[1];
	}
}

struct pf_anchor *
pf_find_anchor(const char *path)
{
	struct pf_anchor	*key, *found;

	key = (struct pf_anchor *)malloc(sizeof(*key), M_TEMP, M_WAITOK);
	memset(key, 0, sizeof(*key));
	strlcpy(key->path, path, sizeof(key->path));
	found = RB_FIND(pf_anchor_global, &pf_anchors, key);
	free(key, M_TEMP);
	return (found);
}

struct pf_ruleset *
pf_find_ruleset(const char *path)
{
	struct pf_anchor	*anchor;

	while (*path == '/')
		path++;
	if (!*path)
		return (&pf_main_ruleset);
	anchor = pf_find_anchor(path);
	if (anchor == NULL)
		return (NULL);
	else
		return (&anchor->ruleset);
}

struct pf_ruleset *
pf_find_or_create_ruleset(const char *path)
{
	char			*p, *q, *r;
	struct pf_ruleset	*ruleset;
	struct pf_anchor	*anchor, *dup, *parent = NULL;

	while (*path == '/')
		path++;
	ruleset = pf_find_ruleset(path);
	if (ruleset != NULL)
		return (ruleset);
	p = (char *)malloc(MAXPATHLEN, M_TEMP, M_WAITOK);
	bzero(p, MAXPATHLEN);
	strlcpy(p, path, MAXPATHLEN);
	while (parent == NULL && (q = strrchr(p, '/')) != NULL) {
		*q = 0;
		if ((ruleset = pf_find_ruleset(p)) != NULL) {
			parent = ruleset->anchor;
			break;
		}
	}
	if (q == NULL)
		q = p;
	else
		q++;
	strlcpy(p, path, MAXPATHLEN);
	if (!*q) {
		free(p, M_TEMP);
		return (NULL);
	}
	while ((r = strchr(q, '/')) != NULL || *q) {
		if (r != NULL)
			*r = 0;
		if (!*q || strlen(q) >= PF_ANCHOR_NAME_SIZE ||
		    (parent != NULL && strlen(parent->path) >=
		    MAXPATHLEN - PF_ANCHOR_NAME_SIZE - 1)) {
			free(p, M_TEMP);
			return (NULL);
		}
		anchor = (struct pf_anchor *)malloc(sizeof(*anchor), M_TEMP,
		    M_NOWAIT);
		if (anchor == NULL) {
			free(p, M_TEMP);
			return (NULL);
		}
		memset(anchor, 0, sizeof(*anchor));
		RB_INIT(&anchor->children);
		strlcpy(anchor->name, q, sizeof(anchor->name));
		if (parent != NULL) {
			strlcpy(anchor->path, parent->path,
			    sizeof(anchor->path));
			strlcat(anchor->path, "/", sizeof(anchor->path));
		}
		strlcat(anchor->path, anchor->name, sizeof(anchor->path));
		if ((dup = RB_INSERT(pf_anchor_global, &pf_anchors, anchor)) !=
		    NULL) {
			printf("pf_find_or_create_ruleset: RB_INSERT1 "
			    "'%s' '%s' collides with '%s' '%s'\n",
			    anchor->path, anchor->name, dup->path, dup->name);
			free(anchor, M_TEMP);
			free(p, M_TEMP);
			return (NULL);
		}
		if (parent != NULL) {
			anchor->parent = parent;
			if ((dup = RB_INSERT(pf_anchor_node, &parent->children,
			    anchor)) != NULL) {
				printf("pf_find_or_create_ruleset: "
				    "RB_INSERT2 '%s' '%s' collides with "
				    "'%s' '%s'\n", anchor->path, anchor->name,
				    dup->path, dup->name);
				RB_REMOVE(pf_anchor_global, &pf_anchors,
				    anchor);
				free(anchor, M_TEMP);
				free(p, M_TEMP);
				return (NULL);
			}
		}
		pf_init_ruleset(&anchor->ruleset);
		anchor->ruleset.anchor = anchor;
		parent = anchor;
		if (r != NULL)
			q = r + 1;
		else
			*q = 0;
	}
	free(p, M_TEMP);
	return (&anchor->ruleset);
}

void
pf_remove_if_empty_ruleset(struct pf_ruleset *ruleset)
{
	struct pf_anchor	*parent;
	int			 i;

	while (ruleset != NULL) {
		if (ruleset == &pf_main_ruleset || ruleset->anchor == NULL ||
		    !RB_EMPTY(&ruleset->anchor->children) ||
		    ruleset->anchor->refcnt > 0 || ruleset->tables > 0 ||
		    ruleset->topen)
			return;
		for (i = 0; i < PF_RULESET_MAX; ++i)
			if (!TAILQ_EMPTY(ruleset->rules[i].active.ptr) ||
			    !TAILQ_EMPTY(ruleset->rules[i].inactive.ptr) ||
			    ruleset->rules[i].inactive.open)
				return;
		RB_REMOVE(pf_anchor_global, &pf_anchors, ruleset->anchor);
		if ((parent = ruleset->anchor->parent) != NULL)
			RB_REMOVE(pf_anchor_node, &parent->children,
			    ruleset->anchor);
		free(ruleset->anchor, M_TEMP);
		if (parent == NULL)
			return;
		ruleset = &parent->ruleset;
	}
}

int
pf_anchor_setup(struct pf_rule *r, const struct pf_ruleset *s,
    const char *name)
{
	char			*p, *path;
	struct pf_ruleset	*ruleset;

	r->anchor = NULL;
	r->anchor_relative = 0;
	r->anchor_wildcard = 0;
	if (!name[0])
		return (0);
	path = (char *)malloc(MAXPATHLEN, M_TEMP, M_WAITOK);
	bzero(path, MAXPATHLEN);
	if (name[0] == '/')
		strlcpy(path, name + 1, MAXPATHLEN);
	else {
		/* relative path */
		r->anchor_relative = 1;
		if (s->anchor == NULL || !s->anchor->path[0])
			path[0] = 0;
		else
			strlcpy(path, s->anchor->path, MAXPATHLEN);
		while (name[0] == '.' && name[1] == '.' && name[2] == '/') {
			if (!path[0]) {
				printf("pf_anchor_setup: .. beyond root\n");
				free(path, M_TEMP);
				return (1);
			}
			if ((p = strrchr(path, '/')) != NULL)
				*p = 0;
			else
				path[0] = 0;
			r->anchor_relative++;
			name += 3;
		}
		if (path[0])
			strlcat(path, "/", MAXPATHLEN);
		strlcat(path, name, MAXPATHLEN);
	}
	if ((p = strrchr(path, '/')) != NULL && !strcmp(p, "/*")) {
		r->anchor_wildcard = 1;
		*p = 0;
	}
	ruleset = pf_find_or_create_ruleset(path);
	free(path, M_TEMP);
	if (ruleset == NULL || ruleset->anchor == NULL) {
		printf("pf_anchor_setup: ruleset\n");
		return (1);
	}
	r->anchor = ruleset->anchor;
	r->anchor->refcnt++;
	return (0);
}

int
pf_anchor_copyout(const struct pf_ruleset *rs, const struct pf_rule *r,
    struct pfioc_rule *pr)
{
	pr->anchor_call[0] = 0;
	if (r->anchor == NULL)
		return (0);
	if (!r->anchor_relative) {
		strlcpy(pr->anchor_call, "/", sizeof(pr->anchor_call));
		strlcat(pr->anchor_call, r->anchor->path,
		    sizeof(pr->anchor_call));
	} else {
		char	*a, *p;
		int	 i;

		a = (char *)malloc(MAXPATHLEN, M_TEMP, M_WAITOK);
		bzero(a, MAXPATHLEN);
		if (rs->anchor == NULL)
			a[0] = 0;
		else
			strlcpy(a, rs->anchor->path, MAXPATHLEN);
		for (i = 1; i < r->anchor_relative; ++i) {
			if ((p = strrchr(a, '/')) == NULL)
				p = a;
			*p = 0;
			strlcat(pr->anchor_call, "../",
			    sizeof(pr->anchor_call));
		}
		if (strncmp(a, r->anchor->path, strlen(a))) {
			printf("pf_anchor_copyout: '%s' '%s'\n", a,
			    r->anchor->path);
			free(a, M_TEMP);
			return (1);
		}
		if (strlen(r->anchor->path) > strlen(a))
			strlcat(pr->anchor_call, r->anchor->path + (a[0] ?
			    strlen(a) + 1 : 0), sizeof(pr->anchor_call));
		free(a, M_TEMP);
	}
	if (r->anchor_wildcard)
		strlcat(pr->anchor_call, pr->anchor_call[0] ? "/*" : "*",
		    sizeof(pr->anchor_call));
	return (0);
}

void
pf_anchor_remove(struct pf_rule *r)
{
	if (r->anchor == NULL)
		return;
	if (r->anchor->refcnt <= 0) {
		printf("pf_anchor_remove: broken refcount\n");
		r->anchor = NULL;
		return;
	}
	if (!--r->anchor->refcnt)
		pf_remove_if_empty_ruleset(&r->anchor->ruleset);
	r->anchor = NULL;
@


1.169
log
@allow DIOCNATLOOK to look up NAT states for protocols without port
numbers, reported by Raja Subramanian; ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.168 2006/07/21 01:21:17 dhartmei Exp $ */
d75 4
d1426 4
@


1.168
log
@fix a bug in the input sanity check of DIOCCHANGERULE (not used by pfctl,
but third-party tools). a rule must have a non-empty replacement address
list when it's a translation rule but not an anchor call (i.e. "nat ... ->"
needs a replacement address, but "nat-anchor ..." doesn't). the check
confused "rule is an anchor call" with "rule is defined within an anchor".
report from Michal Mertl, Max Laier.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.167 2006/07/06 13:25:40 henning Exp $ */
d2003 3
a2005 1
		    !pnl->dport || !pnl->sport)
@


1.167
log
@allow rules to point to an alternate routing table, and tag packets
matching that rule so that the forwarding code later can use the
alternate routing table fo lookups (not implemented yet).
the tagging is "sticky", every matching rule modifies, just like the
regular "tag". ok claudio hshoexer, hacked at r2k6
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.166 2006/05/28 02:45:45 mcbride Exp $ */
d1686 1
a1686 1
			    !pcr->anchor[0])) &&
@


1.166
log
@Enable adaptive timeouts by default, with adaptive.start of 60% of the
state limit and adaptive.end of 120% of the state limit.
Explicitly setting the adaptive timeouts will override the default,
and it can be disabled by setting both adaptive.start and adaptive.end to 0.

ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.165 2006/03/04 22:40:16 brad Exp $ */
d173 1
d1397 3
d1625 4
@


1.165
log
@With the exception of two other small uncommited diffs this moves
the remainder of the network stack from splimp to splnet.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.164 2006/01/06 00:41:21 dhartmei Exp $ */
d193 2
@


1.164
log
@DIOCNATLOOK was forgotten in the second access control switch. it's a
read-only operation (looking up one state entry), so allow it when /dev/pf
is opened read-only (allows squid to work read-only). from Andrey Matveev.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.163 2006/01/06 00:37:27 dhartmei Exp $ */
d923 1
a923 1
		s = splimp();
d953 1
a953 1
		s = splimp();
@


1.163
log
@for DIOCCLRSTATUS (pfctl -Fi), reset 'Enabled for x' time, too. simplifies
computations of change rates. unfortunately, I don't remember who suggested
this.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.162 2006/01/05 02:23:39 deraadt Exp $ */
d1258 1
@


1.162
log
@bzero after malloc; ok dhartmei
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.161 2005/12/10 14:41:07 krw Exp $ */
d1974 1
@


1.161
log
@C99 section 6.8.6.4 says "A return statement with an expression shall
not appear in a function whose return type is void." Lint agrees.

ok (and C99 spec info) cloder@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.160 2005/10/27 12:34:40 mcbride Exp $ */
d358 1
d477 1
d535 1
@


1.160
log
@Basic support for attaching states from pfsync to the correct rules.
Applies only to rules in the main ruleset (not anchors) if the ruleset
checksum matches. Necessary to fix the following for pfsync'd states:
	- per-rule limits on number of states
	- altq
	- rule-based settings such as timeouts

More work to do re: nat rules, src-nodes, etc.

NOTE: This is modifies the pfsync header and version number.
Tools which process pfsync packets must be recompiled, and firewalls with
different versions will not sync.

ok mpf@@ henning@@ dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.159 2005/09/28 01:46:32 pascoe Exp $ */
d733 1
a733 1
	return (tag2tagname(&pf_tags, tagid, p));
d751 1
a751 1
	return (tag_unref(&pf_tags, tag));
d795 1
a795 1
	return (tag2tagname(&pf_qids, (u_int16_t)qid, p));
d801 1
a801 1
	return (tag_unref(&pf_qids, (u_int16_t)qid));
@


1.159
log
@Improve the safety of pf IOCTLs, taking into account that some paths can sleep.

- Introduces a rw_lock in pfioctl so that we can have concurrent readers
  but only one process performing updates at a time;

- Separates state expiry into "unlink" and "free" parts; anyone can unlink
  a state/src node from the RB trees at any time, but a state can only be
  freed whilst the write lock is held;

- Converts state_updates into list state_list containing all states,
  regardless of whether they are "linked" or "unlinked";

- Introduces a new PFTM_UNLINKED state that is used on the "unlinked" states
  to signal that they can be freed;

- Converts pf_purge_expired_state to an "unlink" state routine, which only
  unlinks the state from the RB trees.  Freeing the state/src nodes is left
  to the purge thread, which runs whilst holding a write lock, such that all
  "next" references remain valid;

- Converts pfsync_bulk_update and DIOCGETSTATES to walk state_list rather
  than the RB trees;

- Converts the purge thread to use the new state_list and perform a partial
  purge every second, with the target rate a full state table walk every
  PFTM_INTERVAL seconds.

seen by mcbride, henning, dhartmei pre-3.8, but too intrusive for then
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.158 2005/09/05 14:51:08 dhartmei Exp $ */
d110 1
a110 1
void			 pf_calc_chksum(struct pf_ruleset *);
d970 1
a970 1
	while ((rule = TAILQ_FIRST(rs->rules[rs_num].inactive.ptr)) != NULL)
d972 2
d991 1
a991 1
	while ((rule = TAILQ_FIRST(rs->rules[rs_num].inactive.ptr)) != NULL)
d993 2
d1019 1
a1019 1
	switch(pfr->addr.type) {
d1086 1
a1086 1
	struct pf_rule		*rule;
d1088 2
a1089 1
	int			 s;
d1098 7
d1108 3
d1113 4
d1118 3
a1124 3
	/* Calculate checksum for the main ruleset */
	if (rs == &pf_main_ruleset)
		pf_calc_chksum(rs);
d1129 4
d1139 2
a1140 2
void
pf_calc_chksum(struct pf_ruleset *rs)
d1153 16
a1168 2
		TAILQ_FOREACH(rule, rs->rules[rs_cnt].active.ptr,
		    entries)
d1170 2
d1176 1
d1454 1
d1706 1
a1706 1
		if (pcr->action == PF_CHANGE_REMOVE)
d1708 2
a1709 1
		else {
d1721 1
d1858 1
a1858 1
		int 			 secs;
@


1.158
log
@in DIOCCHANGERULE, properly initialize table, if used in NAT rule.
from Boris Polevoy <vapcom at mail dot ru>, ok mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.157 2005/08/18 10:32:56 pascoe Exp $ */
d54 1
d116 1
d167 1
a167 1
	TAILQ_INIT(&state_updates);
d1234 2
a1235 1
			    PFR_FLAG_DUMMY)
d1237 1
d1243 5
d1695 1
a1695 1
		struct pf_state		*state;
d1699 4
a1702 1
		RB_FOREACH(state, pf_state_tree_id, &tree_id) {
a1704 1
				state->timeout = PFTM_PURGE;
d1709 1
a1712 1
		pf_purge_expired_states();
d1721 1
a1721 1
		struct pf_state		*state;
d1726 4
a1729 1
		RB_FOREACH(state, pf_state_tree_id, &tree_id) {
d1758 6
a1763 1
				state->timeout = PFTM_PURGE;
a1766 1
		pf_purge_expired_states();
a1848 1
		struct pfi_kif		*kif;
d1853 1
a1853 2
			TAILQ_FOREACH(kif, &pfi_statehead, pfik_w_states)
				nr += kif->pfik_states;
d1861 4
a1864 3
		TAILQ_FOREACH(kif, &pfi_statehead, pfik_w_states)
			RB_FOREACH(state, pf_state_tree_ext_gwy,
			    &kif->pfik_ext_gwy) {
d1871 2
a1872 1
				strlcpy(pstore->u.ifname, kif->pfik_name,
d1893 3
d3015 1
a3015 1
		pf_purge_expired_src_nodes();
d3066 4
@


1.157
log
@Malloc temporary buffers in pfioctl rather than having several large
pf_state buffers on the stack.

ok henning mcbride
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.156 2005/08/18 10:28:14 pascoe Exp $ */
d1603 3
@


1.157.2.1
log
@MFC:
Fix by deraadt@@

bzero after malloc

ok tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.157 2005/08/18 10:32:56 pascoe Exp $ */
a355 1
	bzero(p, MAXPATHLEN);
a473 1
	bzero(path, MAXPATHLEN);
a530 1
		bzero(a, MAXPATHLEN);
@


1.156
log
@Rearrange pf_state and pfi_kif so that the parts of the structure needed
to search for a particular entry in the RB trees are at the start of the
structure.

This permits us to place a much smaller structure on the stack in the
interrupt paths that match packets against state entries.

ok mcbride
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.155 2005/08/12 04:15:38 pascoe Exp $ */
d1827 1
a1827 1
		struct pf_state		*p, pstore;
d1839 2
d1850 5
a1854 5
				bcopy(state, &pstore, sizeof(pstore));
				strlcpy(pstore.u.ifname, kif->pfik_name,
				    sizeof(pstore.u.ifname));
				pstore.rule.nr = state->rule.ptr->nr;
				pstore.nat_rule.nr = (state->nat_rule.ptr ==
d1856 1
a1856 1
				pstore.anchor.nr = (state->anchor.ptr ==
d1858 4
a1861 4
				pstore.creation = secs - pstore.creation;
				pstore.expire = pf_state_expires(state);
				if (pstore.expire > secs)
					pstore.expire -= secs;
d1863 4
a1866 3
					pstore.expire = 0;
				error = copyout(&pstore, p, sizeof(*p));
				if (error)
d1868 1
d1873 2
d2927 1
a2927 2
		struct pf_src_node	*n;
		struct pf_src_node *p, pstore;
d2938 2
d2947 1
a2947 1
			bcopy(n, &pstore, sizeof(pstore));
d2949 4
a2952 4
				pstore.rule.nr = n->rule.ptr->nr;
			pstore.creation = secs - pstore.creation;
			if (pstore.expire > secs)
				pstore.expire -= secs;
d2954 1
a2954 1
				pstore.expire = 0;
d2959 1
a2959 1
				pstore.conn_rate.count = 0;
d2961 1
a2961 1
				pstore.conn_rate.count -=
d2965 3
a2967 2
			error = copyout(&pstore, p, sizeof(*p));
			if (error)
d2969 1
d2974 2
@


1.155
log
@Fill out interface name and state creation time correctly in
DIOCGETSTATE.

ok dhartmei mcbride
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.154 2005/08/07 11:54:02 pascoe Exp $ */
d1906 1
a1906 1
		struct pf_state		 key;
@


1.154
log
@Do not blindly reset the state count to zero after a clear, as we may not
have purged all states in the case when an interface name was specified.
pf_purge_expired_states should decrease the count as appropriate.

ok dhartmei
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.153 2005/08/07 11:37:33 dhartmei Exp $ */
d1794 1
d1806 4
a1809 1
		bcopy(state, &ps->state, sizeof(struct pf_state));
d1815 1
d1817 2
a1818 2
		if (ps->state.expire > time_second)
			ps->state.expire -= time_second;
@


1.153
log
@verify ticket in DIOCADDADDR, from Boris Polevoy, ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.152 2005/08/05 09:03:19 dhartmei Exp $ */
a1698 1
		pf_status.states = 0;
@


1.152
log
@make three functions non-static (namespace is no issue, they might get
inlined), ok art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.151 2005/08/04 20:33:45 dhartmei Exp $ */
d2198 4
@


1.151
log
@instead of static locals, malloc/free. the goal is to reduce stack usage,
but statics are dangerous in case of concurrency. ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.150 2005/08/02 12:40:42 pascoe Exp $ */
d126 3
a128 3
static u_int16_t	 tagname2tag(struct pf_tags *, char *);
static void		 tag2tagname(struct pf_tags *, u_int16_t, char *);
static void		 tag_unref(struct pf_tags *, u_int16_t);
d645 1
a645 1
static	u_int16_t
d690 1
a690 1
static	void
d702 1
a702 1
static	void
@


1.150
log
@Instead of copying a table structure so we can mask off a bit before
"validating" it, pass the bits to be ignored down to the validating
function in its allowedflags argument.  Saves a 1kB+ stack allocation.

ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.149 2005/08/01 05:39:27 pascoe Exp $ */
d317 1
a317 1
	static struct pf_anchor	 key;
d319 6
a324 3
	memset(&key, 0, sizeof(key));
	strlcpy(key.path, path, sizeof(key.path));
	return (RB_FIND(pf_anchor_global, &pf_anchors, &key));
d346 1
a346 2
	static char		 p[MAXPATHLEN];
	char			*q, *r;
d355 2
a356 1
	strlcpy(p, path, sizeof(p));
d368 3
a370 2
	strlcpy(p, path, sizeof(p));
	if (!*q)
d372 1
d378 2
a379 1
		    MAXPATHLEN - PF_ANCHOR_NAME_SIZE - 1))
d381 1
d384 2
a385 1
		if (anchor == NULL)
d387 1
d403 1
d417 1
d429 1
d465 1
a465 1
	static char		*p, path[MAXPATHLEN];
d473 1
d475 1
a475 1
		strlcpy(path, name + 1, sizeof(path));
d482 1
a482 1
			strlcpy(path, s->anchor->path, sizeof(path));
d486 1
d497 2
a498 2
			strlcat(path, "/", sizeof(path));
		strlcat(path, name, sizeof(path));
d505 1
d527 2
a528 2
		static char a[MAXPATHLEN], *p;
		int i;
d530 1
d534 1
a534 1
			strlcpy(a, rs->anchor->path, sizeof(a));
d545 1
d551 1
d2664 4
a2667 5
		struct pfioc_trans		*io = (struct pfioc_trans *)
						    addr;
		static struct pfioc_trans_e	 ioe;
		static struct pfr_table		 table;
		int				 i;
d2669 1
a2669 1
		if (io->esize != sizeof(ioe)) {
d2673 4
d2678 3
a2680 1
			if (copyin(io->array+i, &ioe, sizeof(ioe))) {
d2684 1
a2684 1
			switch (ioe.rs_num) {
d2687 3
a2689 1
				if (ioe.anchor[0]) {
d2693 3
a2695 1
				if ((error = pf_begin_altq(&ioe.ticket)))
d2697 1
d2701 7
a2707 5
				bzero(&table, sizeof(table));
				strlcpy(table.pfrt_anchor, ioe.anchor,
				    sizeof(table.pfrt_anchor));
				if ((error = pfr_ina_begin(&table,
				    &ioe.ticket, NULL, 0)))
d2709 1
d2712 4
a2715 2
				if ((error = pf_begin_rules(&ioe.ticket,
				    ioe.rs_num, ioe.anchor)))
d2717 1
d2720 3
a2722 1
			if (copyout(&ioe, io->array+i, sizeof(io->array[i]))) {
d2727 2
d2733 4
a2736 5
		struct pfioc_trans		*io = (struct pfioc_trans *)
						    addr;
		static struct pfioc_trans_e	 ioe;
		static struct pfr_table		 table;
		int				 i;
d2738 1
a2738 1
		if (io->esize != sizeof(ioe)) {
d2742 4
d2747 3
a2749 1
			if (copyin(io->array+i, &ioe, sizeof(ioe))) {
d2753 1
a2753 1
			switch (ioe.rs_num) {
d2756 3
a2758 1
				if (ioe.anchor[0]) {
d2762 3
a2764 1
				if ((error = pf_rollback_altq(ioe.ticket)))
d2766 1
d2770 7
a2776 5
				bzero(&table, sizeof(table));
				strlcpy(table.pfrt_anchor, ioe.anchor,
				    sizeof(table.pfrt_anchor));
				if ((error = pfr_ina_rollback(&table,
				    ioe.ticket, NULL, 0)))
d2778 1
d2781 4
a2784 2
				if ((error = pf_rollback_rules(ioe.ticket,
				    ioe.rs_num, ioe.anchor)))
d2786 1
d2790 2
d2796 5
a2800 6
		struct pfioc_trans		*io = (struct pfioc_trans *)
						    addr;
		static struct pfioc_trans_e	 ioe;
		static struct pfr_table		 table;
		struct pf_ruleset		*rs;
		int				 i;
d2802 1
a2802 1
		if (io->esize != sizeof(ioe)) {
d2806 4
d2812 3
a2814 1
			if (copyin(io->array+i, &ioe, sizeof(ioe))) {
d2818 1
a2818 1
			switch (ioe.rs_num) {
d2821 3
a2823 1
				if (ioe.anchor[0]) {
d2827 1
a2827 1
				if (!altqs_inactive_open || ioe.ticket !=
d2829 2
d2837 2
a2838 2
				rs = pf_find_ruleset(ioe.anchor);
				if (rs == NULL || !rs->topen || ioe.ticket !=
d2840 2
d2847 1
a2847 1
				if (ioe.rs_num < 0 || ioe.rs_num >=
d2849 2
d2854 1
a2854 1
				rs = pf_find_ruleset(ioe.anchor);
d2856 5
a2860 3
				    !rs->rules[ioe.rs_num].inactive.open ||
				    rs->rules[ioe.rs_num].inactive.ticket !=
				    ioe.ticket) {
d2869 3
a2871 1
			if (copyin(io->array+i, &ioe, sizeof(ioe))) {
d2875 1
a2875 1
			switch (ioe.rs_num) {
d2878 3
a2880 1
				if ((error = pf_commit_altq(ioe.ticket)))
d2882 1
d2886 7
a2892 5
				bzero(&table, sizeof(table));
				strlcpy(table.pfrt_anchor, ioe.anchor,
				    sizeof(table.pfrt_anchor));
				if ((error = pfr_ina_commit(&table, ioe.ticket,
				    NULL, NULL, 0)))
d2894 1
d2897 4
a2900 2
				if ((error = pf_commit_rules(ioe.ticket,
				    ioe.rs_num, ioe.anchor)))
d2902 1
d2906 2
@


1.149
log
@Use a string directly rather than making a copy, save on stack space.
Use a static buffer for another large variable, pending further analysis.

prodded deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.148 2005/07/31 05:20:57 pascoe Exp $ */
d2566 1
a2566 1
		    PFR_FLAG_USERIOCTL);
@


1.148
log
@Perform pf state/rule/table expiry in a kernel thread instead of running
it out of a timeout handler.

This means we will have process context, required when using the oldnointr
pool allocator.

Addresses pr4186, pr4273.

ok dhartmei@@ henning@@ tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.147 2005/07/26 05:21:27 pascoe Exp $ */
d512 1
a512 1
		char a[MAXPATHLEN], b[MAXPATHLEN], *p;
a518 1
		strlcpy(b, r->anchor->path, sizeof(b));
d526 3
a528 2
		if (strncmp(a, b, strlen(a))) {
			printf("pf_anchor_copyout: '%s' '%s'\n", a, b);
d531 3
a533 3
		if (strlen(b) > strlen(a))
			strlcat(pr->anchor_call, b + (a[0] ? strlen(a) + 1 : 0),
			    sizeof(pr->anchor_call));
@


1.147
log
@Add missing newline to error message.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.146 2005/07/11 14:14:14 dhartmei Exp $ */
d53 1
d84 1
a113 2
extern struct timeout	 pf_expire_to;

a191 3
	timeout_set(&pf_expire_to, pf_purge_timeout, &pf_expire_to);
	timeout_add(&pf_expire_to, timeout[PFTM_INTERVAL] * hz);

d198 10
d1949 2
d1952 2
@


1.146
log
@add missing {} around TAILQ_FOREACH block, found by David Hill
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.145 2005/06/30 20:52:20 sturm Exp $ */
d540 1
a540 1
		printf("pf_anchor_remove: broken refcount");
@


1.145
log
@in order for pfvar.h not to conflict with openssl's crypto.h, use
PF_MD5_DIGEST_LENGTH instead of including crypto/md5.h

ok markus@@, henning@@, mpf@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.144 2005/06/13 20:17:25 henning Exp $ */
d2001 1
a2001 1
		    ruleset->rules[PF_RULESET_FILTER].active.ptr, entries)
d2005 1
@


1.144
log
@make the packet and byte counters on rules and src nodes per direction,
matches the counters on states now. also fix the counting on scrub rules
where we previously did not handle the byte counters at all.
extend pfctl -sl output to include the new seperate in/out counters
hacked on the ferry from Earls Cove to Saltery Bay
ok ryan
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.143 2005/05/27 21:41:03 mpf Exp $ */
d66 1
d1095 1
a1095 1
	u_int8_t		 digest[MD5_DIGEST_LENGTH];
@


1.143
log
@Calculate an MD5 checksum over the main pf ruleset.
This is the basis for further pfsync improvements,
to ensure that pf rules are in sync with the master.

"get it in" mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.142 2005/05/27 17:22:41 dhartmei Exp $ */
d1375 2
a1376 1
		rule->evaluations = rule->packets = rule->bytes = 0;
d1602 3
a1604 2
			newrule->evaluations = newrule->packets = 0;
			newrule->bytes = 0;
d2001 3
a2003 2
			rule->evaluations = rule->packets =
			    rule->bytes = 0;
@


1.142
log
@log two pairs of uid/pid through pflog: the uid/pid of the process that
inserted the rule which causes the logging. secondly, the uid/pid of the
process in case the logged packet is delivered to/from a local socket.
a lookup of the local socket can be forced for logged packets with a new
option, 'log (user)'. make tcpdump print the additional information when
-e and -v is used. note: this changes the pflog header struct, rebuild all
dependancies. ok bob@@, henning@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.141 2005/05/21 21:03:57 henning Exp $ */
d106 3
d967 83
d1075 4
d1086 23
@


1.141
log
@clean up and rework the interface absraction code big time, rip out multiple
useless layers of indirection and make the code way cleaner overall.
this is just the start, more to come...
worked very hard on by Ryan and me in Montreal last week, on the airplane to
vancouver and yesterday here in calgary. it hurt.
ok ryan theo
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.140 2005/05/10 13:15:15 joel Exp $ */
d51 1
d1163 2
d1395 2
@


1.140
log
@In DIOCKILLSTATES: take into account the direction of the state when
matching source and destination addresses/ports.

ok henning@@ dhartmei@@ mpf@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.139 2005/03/03 07:13:39 dhartmei Exp $ */
d563 1
a563 1
		pfi_detach_rule(empty_pool_pa->kif);
d609 1
a609 1
	pfi_detach_rule(rule->kif);
a1041 1
		case DIOCICLRISTATS:
d1190 1
a1190 1
			rule->kif = pfi_attach_rule(rule->ifname);
d1196 1
d1411 1
a1411 1
				newrule->kif = pfi_attach_rule(newrule->ifname);
d1417 1
d1620 1
a1620 1
		kif = pfi_lookup_create(ps->state.u.ifname);
d1638 1
a1638 1
			pfi_maybe_destroy(kif);
d1749 1
a1749 2
			pfi_clr_istats(pf_status.ifname, NULL,
			    PFI_FLAG_INSTANCE);
d2071 1
a2071 1
			pa->kif = pfi_attach_rule(pa->ifname);
d2077 1
d2081 1
a2081 1
			pfi_detach_rule(pa->kif);
d2181 1
a2181 1
				newpa->kif = pfi_attach_rule(newpa->ifname);
d2187 1
d2193 1
a2193 1
				pfi_detach_rule(newpa->kif);
d2222 1
a2222 1
			pfi_detach_rule(oldpa->kif);
d2776 1
a2776 1
		if (io->pfiio_esize != sizeof(struct pfi_if)) {
d2781 1
a2781 9
		    &io->pfiio_size, io->pfiio_flags);
		break;
	}

	case DIOCICLRISTATS: {
		struct pfioc_iface *io = (struct pfioc_iface *)addr;

		error = pfi_clr_istats(io->pfiio_name, &io->pfiio_nzero,
		    io->pfiio_flags);
@


1.139
log
@when tagging, apply the same tag to all packets matching a state entry
(not just to the initial packet). note: kernel/userland abi change
(rebuild pfctl). ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.138 2005/01/05 18:11:55 mcbride Exp $ */
d1562 1
d1567 7
d1580 1
a1580 1
			    &state->lan.addr, state->af) &&
d1584 1
a1584 1
			    &state->ext.addr, state->af) &&
d1588 1
a1588 1
			    state->lan.port)) &&
d1592 1
a1592 1
			    state->ext.port)) &&
@


1.139.2.1
log
@MFC:
Fix by pascoe@@

Perform pf state/rule/table expiry in a kernel thread instead of running
it out of a timeout handler.

This means we will have process context, required when using the oldnointr
pool allocator.

Addresses pr4186, pr4273.

ok dhartmei@@ deraadt@@ pascoe@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.139 2005/03/03 07:13:39 dhartmei Exp $ */
a51 1
#include <sys/kthread.h>
a80 1
void			 pf_thread_create(void *);
d107 2
d187 3
a195 10

	/* require process context to purge states, so perform in a thread */
	kthread_create_deferred(pf_thread_create, NULL);
}

void
pf_thread_create(void *v)
{
	if (kthread_create(pf_purge_thread, NULL, NULL, "pfpurge"))
		panic("pfpurge thread");
a1812 2
		if (pt->timeout == PFTM_INTERVAL && pt->seconds == 0)
			pt->seconds = 1;
a1813 2
		if (pt->timeout == PFTM_INTERVAL && pt->seconds < old)
			wakeup(pf_purge_thread);
@


1.139.2.2
log
@MFC:
Fix by deraadt@@

bzero after malloc

ok tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.139.2.1 2005/10/07 19:56:15 brad Exp $ */
a347 1
	bzero(p, MAXPATHLEN);
a455 1
	bzero(path, MAXPATHLEN);
a509 1
		bzero(a, MAXPATHLEN);
@


1.138
log
@- Use defines from pfvar.h for timeouts
- instead of erroring on an attempt to set hostid to 0, just set it
  with arc4random()

ok henning@@ dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.137 2004/12/22 17:17:55 dhartmei Exp $ */
d702 12
@


1.137
log
@Introduce 'set skip on <ifspec>' to support a list of interfaces where no
packet filtering should occur (like loopback, for instance).
Code from Max Laier, with minor improvements based on feedback from
deraadt@@. ok mcbride@@, henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.136 2004/12/10 22:13:26 henning Exp $ */
d168 18
a185 18
	timeout[PFTM_TCP_FIRST_PACKET] = 120;		/* First TCP packet */
	timeout[PFTM_TCP_OPENING] = 30;			/* No response yet */
	timeout[PFTM_TCP_ESTABLISHED] = 24*60*60;	/* Established */
	timeout[PFTM_TCP_CLOSING] = 15 * 60;		/* Half closed */
	timeout[PFTM_TCP_FIN_WAIT] = 45;		/* Got both FINs */
	timeout[PFTM_TCP_CLOSED] = 90;			/* Got a RST */
	timeout[PFTM_UDP_FIRST_PACKET] = 60;		/* First UDP packet */
	timeout[PFTM_UDP_SINGLE] = 30;			/* Unidirectional */
	timeout[PFTM_UDP_MULTIPLE] = 60;		/* Bidirectional */
	timeout[PFTM_ICMP_FIRST_PACKET] = 20;		/* First ICMP packet */
	timeout[PFTM_ICMP_ERROR_REPLY] = 10;		/* Got error response */
	timeout[PFTM_OTHER_FIRST_PACKET] = 60;		/* First packet */
	timeout[PFTM_OTHER_SINGLE] = 30;		/* Unidirectional */
	timeout[PFTM_OTHER_MULTIPLE] = 60;		/* Bidirectional */
	timeout[PFTM_FRAG] = 30;			/* Fragment expire */
	timeout[PFTM_INTERVAL] = 10;			/* Expire interval */
	timeout[PFTM_SRC_NODE] = 0;			/* Source tracking */
	timeout[PFTM_TS_DIFF] = 30;			/* Allowed TS diff */
d2740 4
a2743 5
		if (*hostid == 0) {
			error = EINVAL;
			goto fail;
		}
		pf_status.hostid = *hostid;
@


1.136
log
@allow pf to filter on route labels
pass in from route dtag keep state queue reallyslow
tested by Gabriel Kihlman <gk@@stacken.kth.se> and
Michael Knudsen <e@@molioner.dk> and ryan
ok ryan
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.135 2004/12/07 18:02:04 mcbride Exp $ */
d1031 2
d2769 14
@


1.135
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.134 2004/12/05 10:46:26 dhartmei Exp $ */
d124 3
d599 2
d710 31
d1207 3
d1315 2
a1427 1

d1430 3
d2104 1
@


1.134
log
@after attaching an overload table, set its active flag. otherwise, the
table is not visible/accessible when the rule is the only reference
(you don't HAVE to reference the table elsewhere).
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.133 2004/12/04 07:49:48 mcbride Exp $ */
d2654 1
a2654 1
                        
d2657 4
a2660 4
        		if (diff >= n->conn_rate.seconds)
                		pstore.conn_rate.count = 0;
        		else    
                		pstore.conn_rate.count -=
d2662 1
a2662 1
                    		    n->conn_rate.seconds;
@


1.133
log
@Add kernel code to keep track of tcp connections which have completed
the 3-way handshake. Allow limits on both total connections and connection
rate, put offenders in a table which can be used in the ruleset, and optionally
kill existing states. Rate tracking code from dhartmei@@.

Adds a second pool for table entries using the default allocator, which
allows entries to be added at splsoftnet().

ok deraadt@@ dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.132 2004/12/01 23:22:43 dhartmei Exp $ */
d1185 8
a1192 4
		if (rule->overload_tblname[0] &&
		    (rule->overload_tbl = pfr_attach_table(ruleset,
		    rule->overload_tblname)) == NULL)
			error = EINVAL;
d1401 9
a1409 4
			if (newrule->overload_tblname[0] &&
			    (newrule->overload_tbl = pfr_attach_table(ruleset,
			    newrule->overload_tblname)) == NULL)
				error = EINVAL;
@


1.132
log
@replace finer-grained spl locking in pfioctl() with a single broad lock
around the entire body. this resolves the (misleading) panics in
pf_tag_packet() during heavy ioctl operations (like when using authpf)
that occur because softclock can interrupt ioctl on i386 since SMP.
patch from camield@@. ok mcbride@@, henning@@ and (presumably ;) bob@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.131 2004/09/21 16:59:12 aaron Exp $ */
d578 2
d601 2
d1185 5
d1397 5
d2632 1
a2632 1
			int	secs = time_second;
d2645 10
@


1.131
log
@Implement "no scrub" to allow exclusion of specific traffic from scrub rules.
First match wins, just like "no {binat,nat,rdr}".  henning@@, dhartmei@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.130 2004/09/09 22:08:42 dhartmei Exp $ */
d1046 1
a1215 1
		s = splsoftnet();
a1222 1
		splx(s);
a1246 1
		s = splsoftnet();
a1251 1
			splx(s);
a1256 1
			splx(s);
a1268 1
		splx(s);
a1406 2
		s = splsoftnet();

a1421 1
				splx(s);
a1451 1
		splx(s);
a1459 1
		s = splsoftnet();
a1476 1
		splx(s);
a1484 1
		s = splsoftnet();
a1511 1
		splx(s);
a1530 1
		s = splsoftnet();
a1534 1
			splx(s);
a1552 1
		splx(s);
a1561 1
		s = splsoftnet();
a1568 1
			splx(s);
a1576 1
		splx(s);
a1593 1
			s = splsoftnet();
a1595 1
			splx(s);
d1597 1
a1597 1
			return (0);
a1599 1
		s = splsoftnet();
d1624 1
a1624 2
				if (error) {
					splx(s);
a1625 1
				}
a1629 1
		splx(s);
a1679 2
			s = splsoftnet();

a1718 1
			splx(s);
a1790 1
		s = splsoftnet();
a1794 1
		splx(s);
a1802 1
		s = splsoftnet();
a1811 1
		splx(s);
a1819 1
		s = splsoftnet();
a1828 1
		splx(s);
a1882 1
		s = splsoftnet();
a1885 1
		splx(s);
a1898 1
		s = splsoftnet();
a1905 1
			splx(s);
a1908 1
		splx(s);
a1928 1
		s = splsoftnet();
a1935 1
			splx(s);
a1938 1
		splx(s);
a2004 1
		s = splsoftnet();
a2008 1
			splx(s);
a2012 1
		splx(s);
a2019 1
		s = splsoftnet();
a2023 1
			splx(s);
a2032 1
			splx(s);
a2037 1
		splx(s);
a2108 2
		s = splsoftnet();

a2122 1
				splx(s);
a2146 1
		splx(s);
a2409 1
		s = splsoftnet();
a2410 1
		splx(s);
a2415 1
		s = splsoftnet();
a2416 1
		splx(s);
a2609 1
			s = splsoftnet();
a2611 1
			splx(s);
d2613 1
a2613 1
			return (0);
a2615 1
		s = splsoftnet();
d2632 1
a2632 2
			if (error) {
				splx(s);
a2633 1
			}
a2637 1
		splx(s);
a2644 1
		s = splsoftnet();
a2654 1
		splx(s);
a2669 1
		s = splsoftnet();
a2670 1
		splx(s);
d2698 1
a2698 1

@


1.130
log
@Copy out anchors with relative paths and wildcards correctly,
from jaredy@@, ok henning@@, mcbride@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.129 2004/07/22 23:21:10 msf Exp $ */
d260 1
@


1.130.2.1
log
@MFC:
Fix by dhartmei@@

replace finer-grained spl locking in pfioctl() with a single broad lock
around the entire body. this resolves the (misleading) panics in
pf_tag_packet() during heavy ioctl operations (like when using authpf)
that occur because softclock can interrupt ioctl on i386 since SMP.
patch from camield@@.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.130 2004/09/09 22:08:42 dhartmei Exp $ */
a1044 1
	s = splsoftnet();
d1214 1
d1222 1
d1247 1
d1253 1
d1259 1
d1272 1
d1411 2
d1428 1
d1459 1
d1468 1
d1486 1
d1495 1
d1523 1
d1543 1
d1548 1
d1567 1
d1577 1
d1585 1
d1594 1
d1612 1
d1615 1
d1617 1
a1617 1
			break;
d1620 1
d1645 2
a1646 1
				if (error)
d1648 1
d1653 1
d1704 2
d1745 1
d1818 1
d1823 1
d1832 1
d1842 1
d1851 1
d1861 1
d1916 1
d1920 1
d1934 1
d1942 1
d1946 1
d1967 1
d1975 1
d1979 1
d2046 1
d2051 1
d2056 1
d2064 1
d2069 1
d2079 1
d2085 1
d2157 2
d2173 1
d2198 1
d2462 1
d2464 1
d2470 1
d2472 1
d2666 1
d2669 1
d2671 1
a2671 1
			break;
d2674 1
d2691 2
a2692 1
			if (error)
d2694 1
d2699 1
d2707 1
d2718 1
d2734 1
d2736 1
d2764 1
a2764 1
	splx(s);
@


1.129
log
@Add missing check for NULL in DIOCCHANGERULE. This prevents a crash in
certain rare cases.

ok mcbride@@ dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.128 2004/07/05 00:15:20 henning Exp $ */
d515 3
a517 2
		strlcat(pr->anchor_call, b + (a[0] ? strlen(a) + 1 : 0),
		    sizeof(pr->anchor_call));
d520 2
a521 1
		strlcat(pr->anchor_call, "/*", sizeof(pr->anchor_call));
@


1.128
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.127 2004/06/21 23:50:36 tholo Exp $ */
d1423 2
a1424 1
				pf_rm_rule(NULL, newrule);
@


1.127
log
@First step towards more sane time handling in the kernel -- this changes
things such that code that only need a second-resolution uptime or wall
time, and used to get that from time.tv_secs or mono_time.tv_secs now get
this from separate time_t globals time_second and time_uptime.

ok art@@ niklas@@ nordin@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.126 2004/06/14 20:53:27 cedric Exp $ */
d2478 1
a2478 1
		int			 	 i;
@


1.126
log
@Remove DIOCBEGINRULES, DIOCCOMMITRULES, DIOCBEGINALTQS, DIOCCOMMITALTQS,
DIOCRINABEGIN, DIOCRINACOMMIT ioctls.
Use DIOCXBEGIN/DIOCXCOMMIT/DIOCXROLLBACK instead.
ok beck@@ dhartmei@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.125 2004/06/10 14:22:54 dhartmei Exp $ */
d1050 1
a1050 1
			pf_status.since = time.tv_sec;
d1052 1
a1052 1
				pf_status.stateid = time.tv_sec;
d1064 1
a1064 1
			pf_status.since = time.tv_sec;
d1554 1
a1554 1
		state->creation = time.tv_sec;
d1593 2
a1594 2
		if (ps->state.expire > time.tv_sec)
			ps->state.expire -= time.tv_sec;
d1622 1
a1622 1
				int	secs = time.tv_sec;
d2674 1
a2674 1
			int	secs = time.tv_sec;
@


1.125
log
@rename struct pf_rule_addr member 'not' to 'neg', as 'not' is a reserved
keyword in C++. ok henning@@, cedric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.124 2004/05/31 20:35:46 dhartmei Exp $ */
a1068 9
	case DIOCBEGINRULES: {
		struct pfioc_rule	*pr = (struct pfioc_rule *)addr;

		pr->anchor[sizeof(pr->anchor) - 1] = 0;
		error = pf_begin_rules(&pr->ticket, pf_get_ruleset_number(
		    pr->rule.action), pr->anchor);
		break;
	}

a1194 9
	case DIOCCOMMITRULES: {
		struct pfioc_rule	*pr = (struct pfioc_rule *)addr;

		pr->anchor[sizeof(pr->anchor) - 1] = 0;
		error = pf_commit_rules(pr->ticket, pf_get_ruleset_number(
		    pr->rule.action), pr->anchor);
		break;
	}

a1862 7
	case DIOCBEGINALTQS: {
		u_int32_t	*ticket = (u_int32_t *)addr;

		error = pf_begin_altq(ticket);
		break;
	}

a1907 7
	case DIOCCOMMITALTQS: {
		u_int32_t		ticket = *(u_int32_t *)addr;

		error = pf_commit_altq(ticket);
		break;
	}

a2439 25
		    PFR_FLAG_USERIOCTL);
		break;
	}

	case DIOCRINABEGIN: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != 0) {
			error = ENODEV;
			break;
		}
		error = pfr_ina_begin(&io->pfrio_table, &io->pfrio_ticket,
		    &io->pfrio_ndel, io->pfrio_flags | PFR_FLAG_USERIOCTL);
		break;
	}

	case DIOCRINACOMMIT: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != 0) {
			error = ENODEV;
			break;
		}
		error = pfr_ina_commit(&io->pfrio_table, io->pfrio_ticket,
		    &io->pfrio_nadd, &io->pfrio_nchange, io->pfrio_flags |
@


1.124
log
@thinko, reported by Fernando Braga
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.123 2004/05/21 23:10:47 dhartmei Exp $ */
d1515 1
a1515 1
			    PF_MATCHA(psk->psk_src.not,
d1519 1
a1519 1
			    PF_MATCHA(psk->psk_dst.not,
@


1.123
log
@Use '/' instead of ':' as separator for anchor path components. Note that
the parser now needs quotes around paths containing separators.
ok mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.122 2004/05/21 08:03:29 dhartmei Exp $ */
d1188 1
a1188 1
		    (rule->action == PF_BINAT)) && !pr->anchor[0]) ||
@


1.122
log
@copy out relative anchor paths correctly
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.121 2004/05/19 17:50:52 dhartmei Exp $ */
d313 1
a313 1
	while (*path == ':')
d332 1
a332 1
	while (*path == ':')
d338 1
a338 1
	while (parent == NULL && (q = strrchr(p, ':')) != NULL) {
d352 1
a352 1
	while ((r = strchr(q, ':')) != NULL || *q) {
d369 1
a369 1
			strlcat(anchor->path, ":", sizeof(anchor->path));
d445 1
a445 1
	if (name[0] == ':')
d454 1
a454 1
		while (name[0] == '.' && name[1] == '.' && name[2] == ':') {
d459 1
a459 1
			if ((p = strrchr(path, ':')) != NULL)
d467 1
a467 1
			strlcat(path, ":", sizeof(path));
d470 1
a470 1
	if ((p = strrchr(path, ':')) != NULL && !strcmp(p, ":*")) {
d492 1
a492 1
		strlcpy(pr->anchor_call, ":", sizeof(pr->anchor_call));
d505 1
a505 1
			if ((p = strrchr(a, ':')) == NULL)
d508 1
a508 1
			strlcat(pr->anchor_call, "..:",
d519 1
a519 1
		strlcat(pr->anchor_call, ":*", sizeof(pr->anchor_call));
@


1.121
log
@Allow recursive anchors (anchors within anchors, up to 64
levels deep). More work required, but this is already
functional. authpf users will need to adjust their anchor
calls, but this will change again soon. ok beck@@, cedric@@,
henning@@, mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.120 2004/05/18 10:35:22 dhartmei Exp $ */
d89 2
d449 1
d484 39
d1273 4
a1276 10
		if (rule->anchor == NULL)
			pr->anchor_call[0] = 0;
		else {
			/* XXX relative paths */
			strlcpy(pr->anchor_call, ":", sizeof(pr->anchor_call));
			strlcat(pr->anchor_call, rule->anchor->path,
			    sizeof(pr->anchor_call));
			if (rule->anchor_wildcard)
				strlcat(pr->anchor_call, ":*",
				    sizeof(pr->anchor_call));
@


1.120
log
@In DIOCCHANGERULE, move ticket increment above code that might free
the ruleset and invalidate the pointer. ok cedric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.119 2004/05/05 23:16:03 frantzen Exp $ */
d83 2
a84 2
struct pf_pool		*pf_get_pool(char *, char *, u_int32_t,
			    u_int8_t, u_int32_t, u_int8_t, u_int8_t, u_int8_t);
d87 2
a88 3
struct pf_anchor	*pf_find_or_create_anchor(char[PF_ANCHOR_NAME_SIZE]);
void			 pf_remove_if_empty_anchor(struct pf_anchor *);
int			 pf_anchor_setup(struct pf_ruleset *, struct pf_rule *);
d101 3
a103 3
int			 pf_begin_rules(u_int32_t *, int, char *, char *);
int			 pf_rollback_rules(u_int32_t, int, char *, char *);
int			 pf_commit_rules(u_int32_t, int, char *, char *);
d148 1
a148 1
	TAILQ_INIT(&pf_anchors);
d210 3
a212 3
pf_get_pool(char *anchorname, char *rulesetname, u_int32_t ticket,
    u_int8_t rule_action, u_int32_t rule_number, u_int8_t r_last,
    u_int8_t active, u_int8_t check_ticket)
d218 1
a218 1
	ruleset = pf_find_ruleset(anchorname, rulesetname);
d297 1
a297 1
pf_find_anchor(const char *anchorname)
d299 1
a299 2
	struct pf_anchor	*anchor;
	int			 n = -1;
d301 3
a303 7
	anchor = TAILQ_FIRST(&pf_anchors);
	while (anchor != NULL && (n = strcmp(anchor->name, anchorname)) < 0)
		anchor = TAILQ_NEXT(anchor, entries);
	if (n == 0)
		return (anchor);
	else
		return (NULL);
d307 1
a307 1
pf_find_ruleset(char *anchorname, char *rulesetname)
a309 1
	struct pf_ruleset	*ruleset;
d311 3
a313 1
	if (!anchorname[0] && !rulesetname[0])
d315 1
a315 5
	if (!anchorname[0] || !rulesetname[0])
		return (NULL);
	anchorname[PF_ANCHOR_NAME_SIZE-1] = 0;
	rulesetname[PF_RULESET_NAME_SIZE-1] = 0;
	anchor = pf_find_anchor(anchorname);
a317 5
	ruleset = TAILQ_FIRST(&anchor->rulesets);
	while (ruleset != NULL && strcmp(ruleset->name, rulesetname) < 0)
		ruleset = TAILQ_NEXT(ruleset, entries);
	if (ruleset != NULL && !strcmp(ruleset->name, rulesetname))
		return (ruleset);
d319 1
a319 1
		return (NULL);
d323 1
a323 2
pf_find_or_create_ruleset(char anchorname[PF_ANCHOR_NAME_SIZE],
    char rulesetname[PF_RULESET_NAME_SIZE])
d325 4
a328 2
	struct pf_anchor	*anchor;
	struct pf_ruleset	*ruleset, *r;
d330 19
a348 7
	if (!anchorname[0] && !rulesetname[0])
		return (&pf_main_ruleset);
	if (!anchorname[0] || !rulesetname[0])
		return (NULL);
	rulesetname[PF_RULESET_NAME_SIZE-1] = 0;
	anchor = pf_find_or_create_anchor(anchorname);
	if (anchor == NULL)
d350 1
a350 11
	r = TAILQ_FIRST(&anchor->rulesets);
	while (r != NULL && strcmp(r->name, rulesetname) < 0)
		r = TAILQ_NEXT(r, entries);
	if (r != NULL && !strcmp(r->name, rulesetname))
		return (r);
	ruleset = (struct pf_ruleset *)malloc(sizeof(struct pf_ruleset),
	    M_TEMP, M_NOWAIT);
	if (ruleset != NULL) {
		pf_init_ruleset(ruleset);
		bcopy(rulesetname, ruleset->name, sizeof(ruleset->name));
		ruleset->anchor = anchor;
d352 7
a358 23
			TAILQ_INSERT_BEFORE(r, ruleset, entries);
		else
			TAILQ_INSERT_TAIL(&anchor->rulesets, ruleset, entries);
	}
	return (ruleset);
}

struct pf_anchor *
pf_find_or_create_anchor(char anchorname[PF_ANCHOR_NAME_SIZE])
{
	struct pf_anchor	*anchor, *a;

	if (!anchorname[0])
		return (NULL);
	anchorname[PF_ANCHOR_NAME_SIZE-1] = 0;
	a = TAILQ_FIRST(&pf_anchors);
	while (a != NULL && strcmp(a->name, anchorname) < 0)
		a = TAILQ_NEXT(a, entries);
	if (a != NULL && !strcmp(a->name, anchorname))
		anchor = a;
	else {
		anchor = (struct pf_anchor *)malloc(sizeof(struct pf_anchor),
		    M_TEMP, M_NOWAIT);
d361 36
a396 5
		memset(anchor, 0, sizeof(struct pf_anchor));
		bcopy(anchorname, anchor->name, sizeof(anchor->name));
		TAILQ_INIT(&anchor->rulesets);
		if (a != NULL)
			TAILQ_INSERT_BEFORE(a, anchor, entries);
d398 1
a398 1
			TAILQ_INSERT_TAIL(&pf_anchors, anchor, entries);
d400 1
a400 1
	return (anchor);
d406 1
a406 1
	struct pf_anchor	*anchor;
d409 17
a425 7
	if (ruleset == NULL || ruleset->anchor == NULL || ruleset->tables > 0 ||
	    ruleset->topen)
		return;
	for (i = 0; i < PF_RULESET_MAX; ++i)
		if (!TAILQ_EMPTY(ruleset->rules[i].active.ptr) ||
		    !TAILQ_EMPTY(ruleset->rules[i].inactive.ptr) ||
		    ruleset->rules[i].inactive.open)
d427 1
a427 16

	anchor = ruleset->anchor;
	TAILQ_REMOVE(&anchor->rulesets, ruleset, entries);
	free(ruleset, M_TEMP);

	pf_remove_if_empty_anchor(anchor);
}

void
pf_remove_if_empty_anchor(struct pf_anchor *anchor)
{
	if (anchor->refcnt > 0)
		return;
	if (TAILQ_EMPTY(&anchor->rulesets)) {
		TAILQ_REMOVE(&pf_anchors, anchor, entries);
		free(anchor, M_TEMP);
d432 2
a433 1
pf_anchor_setup(struct pf_ruleset *rs, struct pf_rule *r)
d435 3
d439 38
a476 7
	if (rs != &pf_main_ruleset && *r->anchorname)
		return (1);	/* anchors are not recursive */
	if (!*r->anchorname)
		return (0);	/* no anchor, nothing to do */
	r->anchor = pf_find_or_create_anchor(r->anchorname);
	if (r->anchor == NULL)
		return (1);	/* memory? */
d492 1
a492 1
		pf_remove_if_empty_anchor(r->anchor);
d831 1
a831 1
pf_begin_rules(u_int32_t *ticket, int rs_num, char *anchor, char *ruleset)
d838 1
a838 1
	rs = pf_find_or_create_ruleset(anchor, ruleset);
d849 1
a849 1
pf_rollback_rules(u_int32_t ticket, int rs_num, char *anchor, char *ruleset)
d856 1
a856 1
	rs = pf_find_ruleset(anchor, ruleset);
d867 1
a867 1
pf_commit_rules(u_int32_t ticket, int rs_num, char *anchor, char *ruleset)
d876 1
a876 1
	rs = pf_find_ruleset(anchor, ruleset);
a927 2
		case DIOCGETANCHORS:
		case DIOCGETANCHOR:
a972 2
		case DIOCGETANCHORS:
		case DIOCGETANCHOR:
d1030 1
d1032 1
a1032 1
		    pr->rule.action), pr->anchor, pr->ruleset);
d1043 2
a1044 1
		ruleset = pf_find_ruleset(pr->anchor, pr->ruleset);
a1053 4
		if (pr->rule.anchorname[0] && ruleset != &pf_main_ruleset) {
			error = EINVAL;
			break;
		}
d1138 1
a1138 1
		if (pf_anchor_setup(ruleset, rule))
d1146 1
a1146 1
		    (rule->action == PF_BINAT)) && !rule->anchorname[0]) ||
d1165 1
d1167 1
a1167 1
		    pr->rule.action), pr->anchor, pr->ruleset);
d1177 2
a1178 1
		ruleset = pf_find_ruleset(pr->anchor, pr->ruleset);
d1206 2
a1207 1
		ruleset = pf_find_ruleset(pr->anchor, pr->ruleset);
d1231 11
d1275 1
a1275 1
		ruleset = pf_find_ruleset(pcr->anchor, pcr->ruleset);
d1369 1
a1369 1
			if (pf_anchor_setup(ruleset, newrule))
d1377 1
a1377 1
			    !newrule->anchorname[0])) &&
d2040 2
a2041 2
		pool = pf_get_pool(pp->anchor, pp->ruleset, pp->ticket,
		    pp->r_action, pp->r_num, 0, 1, 0);
d2058 2
a2059 2
		pool = pf_get_pool(pp->anchor, pp->ruleset, pp->ticket,
		    pp->r_action, pp->r_num, 0, 1, 1);
d2099 1
a2099 1
		ruleset = pf_find_ruleset(pca->anchor, pca->ruleset);
d2104 2
a2105 2
		pool = pf_get_pool(pca->anchor, pca->ruleset, pca->ticket,
		    pca->r_action, pca->r_num, pca->r_last, 1, 1);
a2194 27
	case DIOCGETANCHORS: {
		struct pfioc_anchor	*pa = (struct pfioc_anchor *)addr;
		struct pf_anchor	*anchor;

		pa->nr = 0;
		TAILQ_FOREACH(anchor, &pf_anchors, entries)
			pa->nr++;
		break;
	}

	case DIOCGETANCHOR: {
		struct pfioc_anchor	*pa = (struct pfioc_anchor *)addr;
		struct pf_anchor	*anchor;
		u_int32_t		 nr = 0;

		anchor = TAILQ_FIRST(&pf_anchors);
		while (anchor != NULL && nr < pa->nr) {
			anchor = TAILQ_NEXT(anchor, entries);
			nr++;
		}
		if (anchor == NULL)
			error = EBUSY;
		else
			bcopy(anchor->name, pa->name, sizeof(pa->name));
		break;
	}

d2197 1
a2198 1
		struct pf_ruleset	*ruleset;
d2200 2
a2201 2
		pr->anchor[PF_ANCHOR_NAME_SIZE-1] = 0;
		if ((anchor = pf_find_anchor(pr->anchor)) == NULL) {
d2206 10
a2215 2
		TAILQ_FOREACH(ruleset, &anchor->rulesets, entries)
			pr->nr++;
d2221 1
a2222 1
		struct pf_ruleset	*ruleset;
d2225 2
a2226 1
		if ((anchor = pf_find_anchor(pr->anchor)) == NULL) {
d2230 17
a2246 4
		ruleset = TAILQ_FIRST(&anchor->rulesets);
		while (ruleset != NULL && nr < pr->nr) {
			ruleset = TAILQ_NEXT(ruleset, entries);
			nr++;
d2248 1
a2248 1
		if (ruleset == NULL)
a2249 2
		else
			bcopy(ruleset->name, pr->name, sizeof(pr->name));
d2495 5
a2499 4
		struct pfioc_trans	*io = (struct pfioc_trans *)addr;
		struct pfioc_trans_e	 ioe;
		struct pfr_table	 table;
		int			 i;
d2513 1
a2513 1
				if (ioe.anchor[0] || ioe.ruleset[0]) {
a2524 2
				strlcpy(table.pfrt_ruleset, ioe.ruleset,
				    sizeof(table.pfrt_ruleset));
d2531 1
a2531 1
				    ioe.rs_num, ioe.anchor, ioe.ruleset)))
d2544 5
a2548 4
		struct pfioc_trans	*io = (struct pfioc_trans *)addr;
		struct pfioc_trans_e	 ioe;
		struct pfr_table	 table;
		int			 i;
d2562 1
a2562 1
				if (ioe.anchor[0] || ioe.ruleset[0]) {
a2573 2
				strlcpy(table.pfrt_ruleset, ioe.ruleset,
				    sizeof(table.pfrt_ruleset));
d2580 1
a2580 1
				    ioe.rs_num, ioe.anchor, ioe.ruleset)))
d2589 6
a2594 5
		struct pfioc_trans	*io = (struct pfioc_trans *)addr;
		struct pfioc_trans_e	 ioe;
		struct pfr_table	 table;
		struct pf_ruleset	*rs;
		int			 i;
d2609 1
a2609 1
				if (ioe.anchor[0] || ioe.ruleset[0]) {
d2621 1
a2621 1
				rs = pf_find_ruleset(ioe.anchor, ioe.ruleset);
d2634 1
a2634 1
				rs = pf_find_ruleset(ioe.anchor, ioe.ruleset);
a2661 2
				strlcpy(table.pfrt_ruleset, ioe.ruleset,
				    sizeof(table.pfrt_ruleset));
d2668 1
a2668 1
				    ioe.rs_num, ioe.anchor, ioe.ruleset)))
@


1.119
log
@Use RFC1323 PAWS timestamps as a logical extension to the conventional TCP
sequence numbers by taking advantage of the maximum 1KHz clock as an upperbound
on the timestamp.  Typically gains 10 to 18 bits of additional security against
blind data insertion attacks.  More if the TS Echo wasn't optional :-(
Enabled with:  scrub on !lo0 all reassemble tcp
ok dhartmei@@.  documentation help from jmc@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.118 2004/05/03 07:51:59 kjc Exp $ */
d1391 2
a1395 1
		ruleset->rules[rs_num].active.ticket++;
@


1.118
log
@fix a stupid mistake in my previous commit.
"if (error == 0)" should be "if (error != 0)".
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.117 2004/04/28 02:43:09 pb Exp $ */
d181 1
@


1.117
log
@Dont step into INET6 code, just because af != AF_INET
Also comment #endif properly while being here

ok mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.116 2004/04/27 02:56:20 kjc Exp $ */
d709 1
a709 1
			if (error == 0) {
@


1.116
log
@make separate functions to enable/disable altq, and call them when we
reload rules.
this fixes an altq problem that, if you reload pf rules not containing
queues while running altq, the interface shaper is not properly removed.

make pf_altq_running local to pf_ioctl.c since it is no longer used in
altq_subr.c.

ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.115 2004/04/26 02:01:47 mcbride Exp $ */
d1306 1
a1306 1
#endif
@


1.115
log
@The rule_number parameter for pf_get_pool() needs to be 32 bits, not 8 -
this fixes corruption of the address pools with large rulesets.

This is a candidate for -stable.

Reported by Zbigniew Kossowski <zk@@openbsd.com.pl>, hours of braintwisting
debugging by pb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.114 2004/04/26 00:12:28 cedric Exp $ */
d99 2
d109 3
d707 3
a709 1
			if (error) {
d721 2
d738 55
a1764 2
		struct ifnet		*ifp;
		struct tb_profile	 tb;
d1770 1
a1770 12
				if ((ifp = ifunit(altq->ifname)) == NULL) {
					error = EINVAL;
					break;
				}
				if (ifp->if_snd.altq_type != ALTQT_NONE)
					error = altq_enable(&ifp->if_snd);
				if (error != 0)
					break;
				/* set tokenbucket regulator */
				tb.rate = altq->ifbandwidth;
				tb.depth = altq->tbrsize;
				error = tbr_set(&ifp->if_snd, &tb);
d1776 1
a1776 1
			pfaltq_running = 1;
a1783 3
		struct ifnet		*ifp;
		struct tb_profile	 tb;
		int			 err;
d1789 2
a1790 2
				if ((ifp = ifunit(altq->ifname)) == NULL) {
					error = EINVAL;
a1791 11
				}
				if (ifp->if_snd.altq_type != ALTQT_NONE) {
					err = altq_disable(&ifp->if_snd);
					if (err != 0 && error == 0)
						error = err;
				}
				/* clear tokenbucket regulator */
				tb.rate = 0;
				err = tbr_set(&ifp->if_snd, &tb);
				if (err != 0 && error == 0)
					error = err;
d1795 1
a1795 1
			pfaltq_running = 0;
@


1.114
log
@anchor refcounting. ok dhartmei@@ mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.113 2004/04/09 19:30:41 frantzen Exp $ */
d84 1
a84 1
			    u_int8_t, u_int8_t, u_int8_t, u_int8_t, u_int8_t);
d206 1
a206 1
    u_int8_t rule_action, u_int8_t rule_number, u_int8_t r_last,
@


1.113
log
@move some of the non-interrupt pools from the small kmem_map to the much
larger kernel map
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.112 2004/03/22 04:54:18 mcbride Exp $ */
d87 5
d334 1
a334 1
	struct pf_anchor	*anchor, *a;
d341 30
a371 1
	rulesetname[PF_RULESET_NAME_SIZE-1] = 0;
d390 1
a390 17
	r = TAILQ_FIRST(&anchor->rulesets);
	while (r != NULL && strcmp(r->name, rulesetname) < 0)
		r = TAILQ_NEXT(r, entries);
	if (r != NULL && !strcmp(r->name, rulesetname))
		return (r);
	ruleset = (struct pf_ruleset *)malloc(sizeof(struct pf_ruleset),
	    M_TEMP, M_NOWAIT);
	if (ruleset != NULL) {
		pf_init_ruleset(ruleset);
		bcopy(rulesetname, ruleset->name, sizeof(ruleset->name));
		ruleset->anchor = anchor;
		if (r != NULL)
			TAILQ_INSERT_BEFORE(r, ruleset, entries);
		else
			TAILQ_INSERT_TAIL(&anchor->rulesets, ruleset, entries);
	}
	return (ruleset);
d412 8
a422 1
		pf_update_anchor_rules();
d426 30
d516 1
a796 1
	pf_update_anchor_rules();
d1045 2
d1262 2
a1327 1
		pf_update_anchor_rules();
@


1.112
log
@Support for best effort bulk transfers of states when pfsync syncif is
configured.  This this allows pfsync+carp clusters to come up gracefully
without killing active connections. pfsync now prevents carp from
preempting to become master until the state table has sync'd.

ABI change, any application which use struct pf_state must be recompiled.

Reminded about this by Christian Gut. Thanks to beck@@ cedric@@ and dhartmei@@
for testing and comments.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.111 2004/03/18 23:24:02 cedric Exp $ */
d128 1
a128 1
	    NULL);
d130 1
a130 1
	    "pfpooladdrpl", NULL);
@


1.112.2.1
log
@MFC:
Fix by mcbride@@

The rule_number parameter for pf_get_pool() needs to be 32 bits, not 8 -
this fixes corruption of the address pools with large rulesets.

Reported by Zbigniew Kossowski <zk@@openbsd.com.pl>, hours of braintwisting
debugging by pb@@

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.112 2004/03/22 04:54:18 mcbride Exp $ */
d84 1
a84 1
			    u_int8_t, u_int32_t, u_int8_t, u_int8_t, u_int8_t);
d201 1
a201 1
    u_int8_t rule_action, u_int32_t rule_number, u_int8_t r_last,
@


1.112.2.2
log
@MFC:
Fix by msf@@

Add missing check for NULL in DIOCCHANGERULE. This prevents a crash in
certain rare cases.

ok mcbride@@ dhartmei@@ millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.112.2.1 2004/04/30 21:43:30 brad Exp $ */
d1239 1
a1239 2
				if (newrule != NULL)
					pf_rm_rule(NULL, newrule);
@


1.111
log
@state->rule.ptr shall not be NULL. from Jon Coller. ok dhartmei@@ mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.110 2004/03/15 10:59:07 henning Exp $ */
d146 1
a180 1
	pf_status.stateid = 1;	/* might want 0 for something special */
d859 4
d1371 1
@


1.110
log
@plug memory leak in error path
missing break; in error case
from patrick latifi, cedric ok
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.109 2004/03/09 21:44:41 mcbride Exp $ */
d1362 1
a1362 1
		state->rule.ptr = NULL;
@


1.109
log
@KNF, ok cedric@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.108 2004/02/20 19:22:03 mcbride Exp $ */
d1355 1
d1358 1
@


1.108
log
@Make pfsync deal with clearing states bound to a group or interface (eg
pfctl -i fxp0 -Fs). Also don't send out individual state deletions if we're
sending a clear message, move pfsync_clear_states() inside splnet, and fix
if_pfsync.h includes in  pf.c and pf_ioctl.c.

ok cedric@@ dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.107 2004/02/19 21:29:51 cedric Exp $ */
d105 1
a105 1
    				pf_qids = TAILQ_HEAD_INITIALIZER(pf_qids);
d111 1
a111 1
static void		 tag2tagname(struct pf_tags *,  u_int16_t, char *);
d511 1
a511 1
tag2tagname(struct pf_tags *head,  u_int16_t tagid, char *p)
d1176 1
a1176 1
					    pf_qname2qid(newrule->pqname))  == 0)
@


1.107
log
@Makes pfctl -Fs and pfctl -w works with the optional -i specifier.
Kernel/Userland Sync needed. ok dhartmei@@ jmc@@ markus@@ mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.106 2004/02/19 07:41:45 kjc Exp $ */
d38 2
d66 2
d69 1
d1282 4
a1290 1
		splx(s);
d1293 1
a1293 2
		if (!psk->psk_ifname[0])
			pfsync_clear_states(pf_status.hostid);
d1295 1
@


1.106
log
@the 2nd round of the qid assignment change.
make the semantics in line with the tag assignment, which simplifies
the id management in pf.

ok, henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.105 2004/02/13 19:32:49 mpf Exp $ */
d1268 3
a1270 1
		struct pf_state	*state;
d1273 7
a1279 2
		RB_FOREACH(state, pf_state_tree_id, &tree_id)
			state->timeout = PFTM_PURGE;
d1283 1
d1285 2
a1286 1
		pfsync_clear_states(pf_status.hostid);
d1316 3
a1318 1
			    state->ext.port))) {
@


1.105
log
@Do an explicit pf_update_anchor_rules() after an anchor gets removed.
In some situations not all anchor rules got updated properly,
so they still refered to already freed anchors.

OK dhartmei@@ mcbride@@ cedric@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.104 2004/02/10 22:42:57 dhartmei Exp $ */
d99 9
a107 1
TAILQ_HEAD(pf_tags, pf_tagname)	pf_tags = TAILQ_HEAD_INITIALIZER(pf_tags);
d444 5
d460 2
a461 2
u_int16_t
pf_tagname2tag(char *tagname)
d466 1
a466 1
	TAILQ_FOREACH(tag, &pf_tags, entries)
d479 2
a480 2
	if (!TAILQ_EMPTY(&pf_tags))
		for (p = TAILQ_FIRST(&pf_tags); p != NULL &&
d500 1
a500 1
		TAILQ_INSERT_TAIL(&pf_tags, tag, entries);
d505 2
a506 2
void
pf_tag2tagname(u_int16_t tagid, char *p)
d510 1
a510 1
	TAILQ_FOREACH(tag, &pf_tags, entries)
d517 2
a518 2
void
pf_tag_unref(u_int16_t tag)
d525 1
a525 1
	for (p = TAILQ_FIRST(&pf_tags); p != NULL; p = next) {
d529 1
a529 1
				TAILQ_REMOVE(&pf_tags, p, entries);
d537 18
d556 18
d586 2
a587 1
		}
d611 2
a612 1
		}
a623 2
	struct pf_anchor	*anchor;
	struct pf_ruleset	*ruleset;
d659 2
a660 1
		}
a664 10
	/* update queue IDs */
	pf_rule_set_qid(
	    pf_main_ruleset.rules[PF_RULESET_FILTER].active.ptr);
	TAILQ_FOREACH(anchor, &pf_anchors, entries) {
		TAILQ_FOREACH(ruleset, &anchor->rulesets, entries) {
			pf_rule_set_qid(
			    ruleset->rules[PF_RULESET_FILTER].active.ptr
			    );
		}
	}
a720 6
#ifdef ALTQ
	/* set queue IDs */
	if (rs_num == PF_RULESET_FILTER)
		pf_rule_set_qid(rs->rules[rs_num].inactive.ptr);
#endif

d951 13
d1166 8
a1173 5
				newrule->qid = pf_qname_to_qid(newrule->qname);
				if (newrule->pqname[0] != 0)
					newrule->pqid =
					    pf_qname_to_qid(newrule->pqname);
				else
d1707 5
@


1.104
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.103 2004/02/10 18:49:10 henning Exp $ */
d384 1
@


1.103
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.102 2004/02/09 13:27:50 cedric Exp $ */
d670 1
a670 1
	struct pf_rulequeue     *old_rules;
@


1.102
log
@Repair "set loginterface". Don't flush stats on pfctl -e. pf_status.since
is the time of last "pf -e" or "pf -d". ok dhartmei@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.101 2004/02/04 10:43:18 mcbride Exp $ */
d368 2
a369 1
	if (ruleset == NULL || ruleset->anchor == NULL || ruleset->tables > 0 ||	    ruleset->topen)
d2295 1
a2295 1
			switch(ioe.rs_num) {
d2345 1
a2345 1
			switch(ioe.rs_num) {
@


1.101
log
@Fix a number of bugs with setting pool limits which I introduced with
source-tracking. Found by Pyun YongHyeon.
Also add support to pfctl to set the src-nodes pool limit.

"Luckily" some of the bugs cancel each other out; update kernel before
pfctl.

ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.100 2004/01/05 13:33:11 cedric Exp $ */
a815 6
			u_int64_t stateid = pf_status.stateid;
			u_int32_t states = pf_status.states;
			u_int32_t debug = pf_status.debug;
			u_int32_t hostid = pf_status.hostid;
			u_int32_t src_nodes = pf_status.src_nodes;
			bzero(&pf_status, sizeof(struct pf_status));
a816 5
			pf_status.states = states;
			pf_status.debug = debug;
			pf_status.stateid = stateid;
			pf_status.hostid = hostid;
			pf_status.states = src_nodes;
d827 1
d1419 2
a1420 1
			pfi_clr_istats(pf_status.ifname, NULL, 0);
@


1.100
log
@Repair my merging error, simplify DIOCCLRSTATUS code. ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.99 2004/01/05 12:54:47 cedric Exp $ */
d122 2
a123 2
	pool_sethardlimit(&pf_state_pl, pf_pool_limits[PF_LIMIT_STATES].limit,
	    NULL, 0);
d1535 2
a1536 1
		if (pl->index < 0 || pl->index >= PF_LIMIT_MAX) {
a1546 2
		if (pl->index == PF_LIMIT_SRC_NODES)
			pf_default_rule.max_src_nodes = pl->limit;
@


1.99
log
@Repair merge errors. Thanks Pyun YongHyeon, Sorry Henning :)
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.98 2003/12/31 22:14:42 deraadt Exp $ */
d1425 3
a1427 12
		u_int32_t	running = pf_status.running;
		u_int32_t	states = pf_status.states;
		u_int32_t	src_nodes = pf_status.src_nodes;
		u_int32_t	since = pf_status.since;
		u_int32_t	debug = pf_status.debug;

		bzero(&pf_status, sizeof(struct pf_status));
		pf_status.running = running;
		pf_status.states = states;
		pf_status.src_nodes = src_nodes;
		pf_status.since = since;
		pf_status.debug = debug;
@


1.98
log
@spacing.  note this, cedric
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.97 2003/12/31 11:18:25 cedric Exp $ */
d5 1
d1234 1
d1236 1
@


1.97
log
@Many improvements to the handling of interfaces in PF.

1) PF should do the right thing when unplugging/replugging or cloning/
destroying NICs.

2) Rules can be loaded in the kernel for not-yet-existing devices
(USB, PCMCIA, Cardbus). For example, it is valid to write:
"pass in on kue0" before kue USB is plugged in.

3) It is possible to write rules that apply to group of interfaces
(drivers), like "pass in on ppp all"

4) There is a new ":peer" modifier that completes the ":broadcast"
and ":network" modifiers.

5) There is a new ":0" modifier that will filter out interface aliases.
Can also be applied to DNS names to restore original PF behaviour.

6) The dynamic interface syntax (foo) has been vastly improved, and
now support multiple addresses, v4 and v6 addresses, and all userland
modifiers, like "pass in from (fxp0:network)"

7) Scrub rules now support the !if syntax.

8) States can be bound to the specific interface that created them or
to  a group of interfaces for example:

- pass all keep state (if-bound)
- pass all keep state (group-bound)
- pass all keep state (floating)

9) The default value when only keep state is given can be selected by
using the "set state-policy" statement.

10) "pfctl -ss" will now print the interface scope of the state.

This diff change the pf_state structure slighltly, so you should
recompile your userland tools (pfctl, authpf, pflogd, tcpdump...)

Tested on i386, sparc, sparc64 by Ryan
Tested on macppc, sparc64 by Daniel

ok deraadt@@ mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.92 2003/12/15 09:10:26 henning Exp $ */
d1303 1
a1303 1
		
@


1.96
log
@pasto in pf_status.src_nodes backup, from 'kirash'
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.95 2003/12/19 16:12:43 henning Exp $ */
a4 1
 * Copyright (c) 2002,2003 Henning Brauer
a108 2
	pool_init(&pf_addr_pl, sizeof(struct pf_addr_dyn), 0, 0, 0, "pfaddrpl",
	    &pool_allocator_nointr);
d118 1
a123 2
	RB_INIT(&tree_lan_ext);
	RB_INIT(&tree_ext_gwy);
d312 2
a313 1
pf_find_or_create_ruleset(char *anchorname, char *rulesetname)
d404 1
d439 1
d750 2
d753 8
d790 1
d792 13
d826 1
a826 1
			pf_status.src_nodes = src_nodes;
a827 3
			if (status_ifp != NULL)
				strlcpy(pf_status.ifname,
				    status_ifp->if_xname, IFNAMSIZ);
d889 1
a889 1
		rule->ifp = NULL;
d916 2
a917 2
			rule->ifp = ifunit(rule->ifname);
			if (rule->ifp == NULL) {
d1114 2
a1115 2
				newrule->ifp = ifunit(newrule->ifname);
				if (newrule->ifp == NULL) {
d1121 1
a1121 1
				newrule->ifp = NULL;
d1228 1
a1228 1
		RB_FOREACH(state, pf_state_tree_ext_gwy, &tree_ext_gwy)
a1232 1
#if NPFSYNC
a1233 1
#endif
d1243 4
a1246 3
		RB_FOREACH(state, pf_state_tree_ext_gwy, &tree_ext_gwy) {
			if ((!psk->psk_af || state->af == psk->psk_af) &&
			    (!psk->psk_proto || psk->psk_proto == state->proto) &&
d1249 2
a1250 2
			    &psk->psk_src.addr.v.a.mask, &state->lan.addr,
			    state->af) &&
d1253 2
a1254 2
			    &psk->psk_dst.addr.v.a.mask, &state->ext.addr,
			    state->af) &&
d1276 1
d1289 5
d1295 1
d1299 1
a1299 1
		state->rt_ifp = NULL;
d1303 3
a1305 1
		if (pf_insert_state(state)) {
d1320 1
a1320 1
		RB_FOREACH(state, pf_state_tree_ext_gwy, &tree_ext_gwy) {
d1349 1
d1355 2
a1356 2
			RB_FOREACH(state, pf_state_tree_ext_gwy, &tree_ext_gwy)
				nr++;
d1364 4
a1367 2
		RB_FOREACH(state, pf_state_tree_ext_gwy, &tree_ext_gwy) {
			int	secs = time.tv_sec;
d1369 2
a1370 2
			if ((nr + 1) * sizeof(*p) > (unsigned)ps->ps_len)
				break;
d1372 21
a1392 16
			bcopy(state, &pstore, sizeof(pstore));
			pstore.rule.nr = state->rule.ptr->nr;
			pstore.nat_rule.nr = (state->nat_rule.ptr == NULL) ?
			    -1 : state->nat_rule.ptr->nr;
			pstore.anchor.nr = (state->anchor.ptr == NULL) ?
			    -1 : state->anchor.ptr->nr;
			pstore.creation = secs - pstore.creation;
			pstore.expire = pf_state_expires(state);
			if (pstore.expire > secs)
				pstore.expire -= secs;
			else
				pstore.expire = 0;
			error = copyout(&pstore, p, sizeof(*p));
			if (error) {
				splx(s);
				goto fail;
a1393 3
			p++;
			nr++;
		}
d1402 1
a1407 1
		struct ifnet	*ifp;
a1409 1
			status_ifp = NULL;
d1413 1
a1413 1
		if ((ifp = ifunit(pi->ifname)) == NULL) {
d1416 3
a1418 4
		} else if (ifp == status_ifp)
			break;
		status_ifp = ifp;
		/* fallthrough into DIOCCLRSTATUS */
a1421 1
		u_int64_t	stateid = pf_status.stateid;
a1426 1
		u_int32_t	hostid = pf_status.hostid;
d1434 2
a1435 5
		pf_status.hostid = hostid;
		pf_status.stateid = stateid;
		if (status_ifp != NULL)
			strlcpy(pf_status.ifname,
			    status_ifp->if_xname, IFNAMSIZ);
d1443 1
a1443 1
		int			 direction = pnl->direction;
d1467 1
a1467 1
				state = pf_find_state(&key, PF_EXT_GWY);
d1473 1
a1473 1
				state = pf_find_state(&key, PF_LAN_EXT);
d1475 3
a1477 1
			if (state != NULL) {
d1811 2
a1812 2
			pa->ifp = ifunit(pa->ifname);
			if (pa->ifp == NULL) {
d1820 1
d1926 2
a1927 2
				newpa->ifp = ifunit(newpa->ifname);
				if (newpa->ifp == NULL) {
d1933 1
a1933 1
				newpa->ifp = NULL;
d1937 1
d1969 1
d2062 1
a2062 1
		    io->pfrio_flags);
d2074 1
a2074 1
		    &io->pfrio_nadd, io->pfrio_flags);
d2086 1
a2086 1
		    &io->pfrio_ndel, io->pfrio_flags);
d2098 1
a2098 1
		    &io->pfrio_size, io->pfrio_flags);
d2110 1
a2110 1
		    &io->pfrio_size, io->pfrio_flags);
d2122 1
a2122 1
		    &io->pfrio_nzero, io->pfrio_flags);
d2135 1
a2135 1
		    &io->pfrio_ndel, io->pfrio_flags);
d2147 1
a2147 1
		    io->pfrio_flags);
d2159 2
a2160 1
		    io->pfrio_size, &io->pfrio_nadd, io->pfrio_flags);
d2172 2
a2173 1
		    io->pfrio_size, &io->pfrio_ndel, io->pfrio_flags);
d2186 2
a2187 1
		    &io->pfrio_ndel, &io->pfrio_nchange, io->pfrio_flags);
d2199 1
a2199 1
		    &io->pfrio_size, io->pfrio_flags);
d2211 1
a2211 1
		    &io->pfrio_size, io->pfrio_flags);
d2223 2
a2224 1
		    io->pfrio_size, &io->pfrio_nzero, io->pfrio_flags);
d2236 2
a2237 1
		    io->pfrio_size, &io->pfrio_nmatch, io->pfrio_flags);
d2249 1
a2249 1
		    &io->pfrio_ndel, io->pfrio_flags);
d2261 2
a2262 1
		    &io->pfrio_nadd, &io->pfrio_nchange, io->pfrio_flags);
d2275 1
a2275 1
		    io->pfrio_ticket, io->pfrio_flags);
d2530 1
a2530 1
		RB_FOREACH(state, pf_state_tree_lan_ext, &tree_lan_ext) {
d2560 20
@


1.95
log
@i wrote much of these, assert my copyright
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.94 2003/12/18 20:55:20 mcbride Exp $ */
d803 1
a803 1
			pf_status.states = src_nodes;
@


1.94
log
@Save pf_status.hostid and pf_status.stateid in the DIOCCLRSTATUS
ioctl.

Pointed out by dhartmei@@

ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.93 2003/12/18 20:52:19 mcbride Exp $ */
d5 1
@


1.93
log
@Unbreak compile with no pfsync(4) device.

patch from Max Laier
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.92 2003/12/15 09:10:26 henning Exp $ */
d1390 1
d1396 1
d1404 2
@


1.92
log
@ryan left a few for me ;-)
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.91 2003/12/15 07:28:25 mcbride Exp $ */
d1212 1
d1214 1
@


1.91
log
@Fix whitespace screwups before henning wakes up.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.90 2003/12/15 07:11:30 mcbride Exp $ */
d169 1
a169 1
	pf_status.stateid = 1; 	/* might want 0 for something special */
@


1.90
log
@Add initial support for pf state synchronization over the network.
Implemented as an in-kernel multicast IP protocol.

Turn it on like this:

# ifconfig pfsync0 up syncif fxp0

There is not yet any authentication on this protocol, so the syncif
must be on a trusted network. ie, a crossover cable between the two
firewalls.

NOTABLE CHANGES:
- A new index based on a unique (creatorid, stateid) tuple has been
  added to the state tree.
- Updates now appear on the pfsync(4) interface; multiple updates may
  be compressed into a single update.
- Applications which use bpf on pfsync(4) will need modification;
  packets on pfsync no longer contains regular pf_state structs,
  but pfsync_state structs which contain no pointers.

Much more to come.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.89 2003/12/15 00:02:04 mcbride Exp $ */
d1517 1
a1517 1
		if (pl->index == PF_LIMIT_SRC_NODES) 
@


1.89
log
@Add support to track stateful connections by source ip. This allows us
to:
- Ensure that clients get a consistent IP mapping with load-balanced
  translation/routing rules
- Limit the number of simultaneous connections a client can make
- Limit the number of clients which can connect through a rule

ok dhartmei@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.88 2003/12/12 20:05:45 cedric Exp $ */
d61 1
d63 1
d166 4
d791 1
d794 1
d800 2
d1212 1
d2497 11
@


1.88
log
@Move PF interface code to new net/pf_if.c
Expect improvements in this area soon.
ok dhartmei@@ mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.87 2003/11/02 01:33:56 mcbride Exp $ */
d109 2
d125 1
d156 1
d162 1
d422 3
a424 1
	if (rule->states > 0 || rule->entries.tqe_prev != NULL)
d742 2
d773 1
d787 1
d792 1
d862 1
d1379 1
d1386 1
d1506 2
a2223 6
	case DIOCOSFPFLUSH:
		s = splsoftnet();
		pf_osfp_flush();
		splx(s);
		break;

d2424 70
@


1.87
log
@Don't zero the debug level when we enable pf.

ok henning@@ dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.86 2003/10/25 20:27:07 mcbride Exp $ */
d393 1
a393 1
		pf_dynaddr_remove(&empty_pool_pa->addr);
d421 2
a422 2
	pf_dynaddr_remove(&rule->src.addr);
	pf_dynaddr_remove(&rule->dst.addr);
d889 1
a889 1
		if (pf_dynaddr_setup(&rule->src.addr, rule->af))
d891 1
a891 1
		if (pf_dynaddr_setup(&rule->dst.addr, rule->af))
d985 2
a986 2
		pf_dynaddr_copyout(&pr->rule.src.addr);
		pf_dynaddr_copyout(&pr->rule.dst.addr);
d1101 1
a1101 1
			if (pf_dynaddr_setup(&newrule->src.addr, newrule->af))
d1103 1
a1103 1
			if (pf_dynaddr_setup(&newrule->dst.addr, newrule->af))
d1755 2
a1756 2
		if (pf_dynaddr_setup(&pa->addr, pp->af)) {
			pf_dynaddr_remove(&pa->addr);
d1806 1
a1806 1
		pf_dynaddr_copyout(&pp->addr.addr);
d1870 1
a1870 1
			if (pf_dynaddr_setup(&newpa->addr, pca->af) ||
d1872 1
a1872 1
				pf_dynaddr_remove(&newpa->addr);
d1902 1
a1902 1
			pf_dynaddr_remove(&oldpa->addr);
@


1.86
log
@Build state search indexes directly on pf_state instead of pf_tree_node.
This saves more than 30% memory on state entries, and simplifies the state
insertion and removal code as well.

NOTE: This changes the pf API; userland tools must be updated to match.

ok henning@@ dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.85 2003/10/19 06:50:07 mcbride Exp $ */
d776 1
d780 1
@


1.85
log
@Add missing "#ifdef ALTQ"'s in the ioctl transacions code.
Allows non-ALTQ kernel compile.

Pointed out by tedu@@

ok itojun@@, "works here" tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.84 2003/10/08 15:06:08 henning Exp $ */
a104 2
	pool_init(&pf_tree_pl, sizeof(struct pf_tree_node), 0, 0, 0, "pftrpl",
	    NULL);
d1179 1
a1179 1
		struct pf_tree_node	*n;
d1182 2
a1183 2
		RB_FOREACH(n, pf_state_tree, &tree_ext_gwy)
			n->state->timeout = PFTM_PURGE;
d1191 1
a1191 2
		struct pf_tree_node	*n;
		struct pf_state		*st;
d1196 3
a1198 4
		RB_FOREACH(n, pf_state_tree, &tree_ext_gwy) {
			st = n->state;
			if ((!psk->psk_af || st->af == psk->psk_af) &&
			    (!psk->psk_proto || psk->psk_proto == st->proto) &&
d1201 2
a1202 2
			    &psk->psk_src.addr.v.a.mask, &st->lan.addr,
			    st->af) &&
d1205 2
a1206 2
			    &psk->psk_dst.addr.v.a.mask, &st->ext.addr,
			    st->af) &&
d1210 1
a1210 1
			    st->lan.port)) &&
d1214 2
a1215 2
			    st->ext.port))) {
				st->timeout = PFTM_PURGE;
d1258 1
a1258 1
		struct pf_tree_node	*n;
d1263 1
a1263 1
		RB_FOREACH(n, pf_state_tree, &tree_ext_gwy) {
d1268 1
a1268 1
		if (n == NULL) {
d1273 6
a1278 6
		bcopy(n->state, &ps->state, sizeof(struct pf_state));
		ps->state.rule.nr = n->state->rule.ptr->nr;
		ps->state.nat_rule.nr = (n->state->nat_rule.ptr == NULL) ?
		    -1 : n->state->nat_rule.ptr->nr;
		ps->state.anchor.nr = (n->state->anchor.ptr == NULL) ?
		    -1 : n->state->anchor.ptr->nr;
d1280 1
a1280 1
		ps->state.expire = pf_state_expires(n->state);
d1290 1
a1290 1
		struct pf_tree_node	*n;
d1297 1
a1297 1
			RB_FOREACH(n, pf_state_tree, &tree_ext_gwy)
d1306 1
a1306 1
		RB_FOREACH(n, pf_state_tree, &tree_ext_gwy) {
d1312 6
a1317 6
			bcopy(n->state, &pstore, sizeof(pstore));
			pstore.rule.nr = n->state->rule.ptr->nr;
			pstore.nat_rule.nr = (n->state->nat_rule.ptr == NULL) ?
			    -1 : n->state->nat_rule.ptr->nr;
			pstore.anchor.nr = (n->state->anchor.ptr == NULL) ?
			    -1 : n->state->anchor.ptr->nr;
d1319 1
a1319 1
			pstore.expire = pf_state_expires(n->state);
d1380 2
a1381 2
		struct pf_state		*st;
		struct pf_tree_node	 key;
a1386 10
		/*
		 * userland gives us source and dest of connection, reverse
		 * the lookup so we ask for what happens with the return
		 * traffic, enabling us to find it in the state tree.
		 */
		PF_ACPY(&key.addr[1], &pnl->saddr, pnl->af);
		key.port[1] = pnl->sport;
		PF_ACPY(&key.addr[0], &pnl->daddr, pnl->af);
		key.port[0] = pnl->dport;

d1394 21
a1414 5
			if (direction == PF_IN)
				st = pf_find_state(&tree_ext_gwy, &key);
			else
				st = pf_find_state(&tree_lan_ext, &key);
			if (st != NULL) {
d1416 3
a1418 3
					PF_ACPY(&pnl->rsaddr, &st->lan.addr,
					    st->af);
					pnl->rsport = st->lan.port;
d1423 3
a1425 3
					PF_ACPY(&pnl->rdaddr, &st->gwy.addr,
					    st->af);
					pnl->rdport = st->gwy.port;
@


1.84
log
@obviously i'm on drugs, revert
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.83 2003/10/08 14:44:35 henning Exp $ */
d82 1
d86 1
d510 1
d512 1
a512 1
pf_begin_altq(u_int32_t *ticket) 
d555 1
a555 1
pf_commit_altq(u_int32_t ticket) 
d614 1
d2241 1
d2250 1
d2291 1
d2300 1
d2339 1
d2351 1
d2360 1
a2360 1
			default:	
d2384 1
d2389 1
@


1.83
log
@missing DIOCX* in the securelevel > 1 case
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.82 2003/09/26 21:44:08 cedric Exp $ */
a732 3
		case DIOCXBEGIN:
		case DIOCXROLLBACK:
		case DIOCXCOMMIT:
@


1.82
log
@Rearchitecture of the userland/kernel IOCTL interface for transactions.
This brings us close to 100% atomicity for a "pfctl -f pf.conf" command.
(some splxxx work remain in the kernel). Basically, improvements are:

   - Anchors/Rulesets cannot disappear unexpectedly anymore.
   - No more leftover in the kernel if "pfctl -f" fail.
   - Commit is now done in a single atomic IOCTL.

WARNING: The kernel code is fully backward compatible, but the new
pfctl/authpf userland utilities will only run on a new kernel.

The following ioctls are deprecated (i.e. will be deleted sooner or
later, depending on how many 3rd party utilities use them and how soon
they can be upgraded):

   - DIOCBEGINRULES
   - DIOCCOMMITRULES
   - DIOCBEGINALTQS
   - DIOCCOMMITALTQS
   - DIOCRINABEGIN
   - DIOCRINADEFINE

They are replaced by the following ioctls (yes, PF(4) will follow)
which operate on a vector of rulesets:

   - DIOCXBEGIN
   - DIOCXCOMMIT
   - DIOCXROLLBACK

Ok dhartmei@@ mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.81 2003/08/22 21:50:34 david Exp $ */
d733 3
@


1.81
log
@pf spelling police
ok dhartmei@@ jmc@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.80 2003/08/21 19:12:08 frantzen Exp $ */
d82 6
d362 2
a363 1
		    !TAILQ_EMPTY(ruleset->rules[i].inactive.ptr))
d509 181
a795 3
		struct pf_ruleset	*ruleset;
		struct pf_rule		*rule;
		int			 rs_num;
d797 2
a798 14
		ruleset = pf_find_or_create_ruleset(pr->anchor, pr->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		rs_num = pf_get_ruleset_number(pr->rule.action);
		if (rs_num >= PF_RULESET_MAX) {
			error = EINVAL;
			break;
		}
		while ((rule =
		    TAILQ_FIRST(ruleset->rules[rs_num].inactive.ptr)) != NULL)
			pf_rm_rule(ruleset->rules[rs_num].inactive.ptr, rule);
		pr->ticket = ++ruleset->rules[rs_num].inactive.ticket;
a916 25
		struct pf_ruleset	*ruleset;
		struct pf_rulequeue	*old_rules;
		struct pf_rule		*rule;
		int			 rs_num;

		ruleset = pf_find_ruleset(pr->anchor, pr->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		rs_num = pf_get_ruleset_number(pr->rule.action);
		if (rs_num >= PF_RULESET_MAX) {
			error = EINVAL;
			break;
		}
		if (pr->ticket != ruleset->rules[rs_num].inactive.ticket) {
			error = EBUSY;
			break;
		}

#ifdef ALTQ
		/* set queue IDs */
		if (rs_num == PF_RULESET_FILTER)
			pf_rule_set_qid(ruleset->rules[rs_num].inactive.ptr);
#endif
d918 2
a919 16
		/* Swap rules, keep the old. */
		s = splsoftnet();
		old_rules = ruleset->rules[rs_num].active.ptr;
		ruleset->rules[rs_num].active.ptr =
		    ruleset->rules[rs_num].inactive.ptr;
		ruleset->rules[rs_num].inactive.ptr = old_rules;
		ruleset->rules[rs_num].active.ticket =
		    ruleset->rules[rs_num].inactive.ticket;
		pf_calc_skip_steps(ruleset->rules[rs_num].active.ptr);

		/* Purge the old rule list. */
		while ((rule = TAILQ_FIRST(old_rules)) != NULL)
			pf_rm_rule(old_rules, rule);
		pf_remove_if_empty_ruleset(ruleset);
		pf_update_anchor_rules();
		splx(s);
a1574 1
		struct pf_altq	*altq;
d1576 1
a1576 10
		/* Purge the old altq list */
		while ((altq = TAILQ_FIRST(pf_altqs_inactive)) != NULL) {
			TAILQ_REMOVE(pf_altqs_inactive, altq, entries);
			if (altq->qname[0] == 0) {
				/* detach and destroy the discipline */
				error = altq_remove(altq);
			}
			pool_put(&pf_altq_pl, altq);
		}
		*ticket = ++ticket_altqs_inactive;
d1621 1
a1621 46
		u_int32_t		*ticket = (u_int32_t *)addr;
		struct pf_altqqueue	*old_altqs;
		struct pf_altq		*altq;
		struct pf_anchor	*anchor;
		struct pf_ruleset	*ruleset;
		int			 err;

		if (*ticket != ticket_altqs_inactive) {
			error = EBUSY;
			break;
		}

		/* Swap altqs, keep the old. */
		s = splsoftnet();
		old_altqs = pf_altqs_active;
		pf_altqs_active = pf_altqs_inactive;
		pf_altqs_inactive = old_altqs;
		ticket_altqs_active = ticket_altqs_inactive;

		/* Attach new disciplines */
		TAILQ_FOREACH(altq, pf_altqs_active, entries) {
			if (altq->qname[0] == 0) {
				/* attach the discipline */
				error = altq_pfattach(altq);
				if (error) {
					splx(s);
					goto fail;
				}
			}
		}

		/* Purge the old altq list */
		while ((altq = TAILQ_FIRST(pf_altqs_inactive)) != NULL) {
			TAILQ_REMOVE(pf_altqs_inactive, altq, entries);
			if (altq->qname[0] == 0) {
				/* detach and destroy the discipline */
				err = altq_pfdetach(altq);
				if (err != 0 && error == 0)
					error = err;
				err = altq_remove(altq);
				if (err != 0 && error == 0)
					error = err;
			}
			pool_put(&pf_altq_pl, altq);
		}
		splx(s);
d1623 1
a1623 10
		/* update queue IDs */
		pf_rule_set_qid(
		    pf_main_ruleset.rules[PF_RULESET_FILTER].active.ptr);
		TAILQ_FOREACH(anchor, &pf_anchors, entries) {
			TAILQ_FOREACH(ruleset, &anchor->rulesets, entries) {
				pf_rule_set_qid(
				    ruleset->rules[PF_RULESET_FILTER].active.ptr
				    );
			}
		}
d2218 177
@


1.81.2.1
log
@MFC:
Fix by dhartmei@@

Fix a problem related to empty anchor rulesets, which could cause
a kernel panic.

ok deraadt@@ dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.81 2003/08/22 21:50:34 david Exp $ */
a365 1
		pf_update_anchor_rules();
@


1.81.2.2
log
@MFC:
Fix by mcbride@@

The rule_number parameter for pf_get_pool() needs to be 32 bits, not 8 -
this fixes corruption of the address pools with large rulesets.

Reported by Zbigniew Kossowski <zk@@openbsd.com.pl>, hours of braintwisting
debugging by pb@@

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.81.2.1 2004/03/28 01:34:15 brad Exp $ */
d76 1
a76 1
			    u_int8_t, u_int32_t, u_int8_t, u_int8_t, u_int8_t);
d173 1
a173 1
    u_int8_t rule_action, u_int32_t rule_number, u_int8_t r_last,
@


1.81.2.3
log
@MFC:
Fix by msf@@

Add missing check for NULL in DIOCCHANGERULE. This prevents a crash in
certain rare cases.

ok mcbride@@ dhartmei@@ millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.81.2.2 2004/04/30 23:28:58 brad Exp $ */
d1006 1
a1006 2
				if (newrule != NULL)
					pf_rm_rule(NULL, newrule);
@


1.80
log
@Add Michal Zalewski's p0f v2 style passive OS fingerprinting to PF.
Exposes the source IP's operating system to the filter language.
Interesting policy decisions are now enforceable:
.	block proto tcp from any os SCO
.	block proto tcp from any os Windows to any port smtp
.	rdr ... from any os "Windows 98" to port WWW -> 127.0.0.1 port 8001
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.79 2003/08/11 20:15:45 dhartmei Exp $ */
d1254 1
a1254 1
		 * userland gives us source and dest of connetion, reverse
@


1.79
log
@Fix DIOCCHANGEADDR, use the supplied ticket instead of 0.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.78 2003/08/09 14:56:48 cedric Exp $ */
d110 1
d544 1
d573 1
d2126 22
@


1.78
log
@This patch remove the restriction that tables cannot be used in routing or
redirection rules...

The advantage of using tables in redirection/routing rules is not efficiency,
in fact it will run slower than straight address pools. However, this brings
a lot of flexibility to PF, allowing simple scripts/daemons to add/remove
addresses from redirection/routing pools easily.

This implementation support all table features, including cidr blocks and
negated addresses. So specifying { 10.0.0.0/29 !10.0.0.0 !10.0.0.7 } will
correctly round-robin between the six addresses: .1, .2, .3, .4, .5, .6.

Tables can also be combined with simple addresses, so the following rule
will work as expected: "nat on foo0 -> { 1.1.1.1 <bar> }"

ok henning@@ mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.77 2003/07/31 22:25:54 cedric Exp $ */
d1753 1
a1753 1
		pool = pf_get_pool(pca->anchor, pca->ruleset, 0,
@


1.77
log
@Make table tickets per-ruleset instead of global.
Make table tickets u_int32_t for consistency with other parts of PF.
Ok dhartmei@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.76 2003/07/19 13:08:58 cedric Exp $ */
d386 1
d630 1
d717 3
d1655 2
a1656 1
		    pp->addr.addr.type != PF_ADDR_DYNIFTL) {
d1726 1
d1734 1
d1742 2
a1743 1
		    pca->addr.addr.type != PF_ADDR_DYNIFTL) {
d1748 5
d1789 2
a1790 1
			if (pf_dynaddr_setup(&newpa->addr, pca->af)) {
d1822 1
@


1.76
log
@Simplify struct pf_pooladdr to include struct pf_addr_wrap directly
instead of indirectly trough struct pf_rule_addr.

Ryan McBride says:
If I'm not mistaken, the code _used_ to use the ports in pf_rule_addr as
well. The code was changed to fix some of the bugs with port ranges, but
it was too late in the release cycle to make kernel API changes, so the
structure was left as is.

Needless to say: KERNEL/USERLAND SYNC REQUIRED.

ok henning@@ mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.75 2003/06/30 19:09:25 henning Exp $ */
d351 1
a351 1
	if (ruleset == NULL || ruleset->anchor == NULL || ruleset->tables > 0)
d2080 2
a2081 2
		error = pfr_ina_begin(&io->pfrio_ticket, &io->pfrio_ndel,
		    io->pfrio_flags);
d2092 2
a2093 2
		error = pfr_ina_commit(io->pfrio_ticket, &io->pfrio_nadd,
		    &io->pfrio_nchange, io->pfrio_flags);
@


1.75
log
@change that queue ID allocator so it always has the queues sorted by ID.
that allows us to get rid of the "tagid" global which stored the highest
tag ID in use.
when allocating a new ID scan the list for a free slot and only use
highest + 1 on failure instead of using highest + 1 from the beginning
scanning for a dup afterwards. this prevents ID space fragmentation better.

as a result this allows us do get rid of the pf_tag_purge() function
completely and let pf_tag_unref() remove an entry once the reference
counter reaches zero by itself.
after all it makes for easier code and is about 50% faster.

idea came up during a discussion on icb earlier today between cedric and
myself, which itself was particulary inspired by Darren Reed questioning the
need for pf_tag_purge on tech-net@@netbsd.

ok dhartmei@@ cedric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.74 2003/06/30 17:45:01 dhartmei Exp $ */
d385 1
a385 1
		pf_dynaddr_remove(&empty_pool_pa->addr.addr);
d1649 2
a1650 2
		if (pp->addr.addr.addr.type != PF_ADDR_ADDRMASK &&
		    pp->addr.addr.addr.type != PF_ADDR_DYNIFTL) {
d1668 2
a1669 2
		if (pf_dynaddr_setup(&pa->addr.addr, pp->af)) {
			pf_dynaddr_remove(&pa->addr.addr);
d1719 1
a1719 1
		pf_dynaddr_copyout(&pp->addr.addr.addr);
d1733 2
a1734 2
		if (pca->addr.addr.addr.type != PF_ADDR_ADDRMASK &&
		    pca->addr.addr.addr.type != PF_ADDR_DYNIFTL) {
d1775 2
a1776 2
			if (pf_dynaddr_setup(&newpa->addr.addr, pca->af)) {
				pf_dynaddr_remove(&newpa->addr.addr);
d1806 1
a1806 1
			pf_dynaddr_remove(&oldpa->addr.addr);
d1820 1
a1820 1
		PF_ACPY(&pool->counter, &pool->cur->addr.addr.v.a.addr,
@


1.74
log
@reset interface statistics when loginterface is changed, closes pr3332,
from Jason Ackley, ok henning@@, cedric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.73 2003/06/30 10:50:16 henning Exp $ */
a87 1
static u_int16_t	 tagid = 0;
d425 2
a426 2
	struct pf_tagname	*tag, *p;
	int			 wrapped = 0;
d433 7
d441 7
a447 12
	if (++tagid > TAGID_MAX)	/* > 50000 reserved for special use */
		tagid = wrapped = 1;
	for (p = TAILQ_FIRST(&pf_tags); p != NULL; p = TAILQ_NEXT(p, entries))
		if (p->tag == tagid) {
			if (++tagid > TAGID_MAX) {
				if (wrapped)
					return (0);
				else
					tagid = wrapped = 1;
			}
			p = TAILQ_FIRST(&pf_tags);
		}
d449 1
d456 1
a456 1
	tag->tag = tagid;
d458 6
a463 1
	TAILQ_INSERT_TAIL(&pf_tags, tag, entries);
d482 1
a482 1
	struct pf_tagname	*p;
d484 9
a492 5
	if (tag > 0)
		TAILQ_FOREACH(p, &pf_tags, entries)
			if (tag == p->tag) {
				p->ref--;
				return;
d494 1
a494 14
}

void
pf_tag_purge(void)
{
	struct pf_tagname	*p, *next;

	for (p = TAILQ_LAST(&pf_tags, pf_tags); p != NULL; p = next) {
		next = TAILQ_PREV(p, pf_tags, entries);
		if (p->ref == 0) {
			if (p->tag == tagid)
				tagid--;
			TAILQ_REMOVE(&pf_tags, p, entries);
			free(p, M_TEMP);
a776 1
		pf_tag_purge();
@


1.73
log
@move prototype for pf_tag_purge() to pfvar.h
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.72 2003/06/27 14:38:02 henning Exp $ */
d1198 6
d1211 9
a1219 15
		} else
			if ((ifp = ifunit(pi->ifname)) == NULL)
				error = EINVAL;
			else {
				status_ifp = ifp;
				strlcpy(pf_status.ifname, ifp->if_xname,
				    IFNAMSIZ);
			}
		break;
	}

	case DIOCGETSTATUS: {
		struct pf_status *s = (struct pf_status *)addr;
		bcopy(&pf_status, s, sizeof(struct pf_status));
		break;
@


1.72
log
@do pf_tagname2tag() in DIOCCHANGERULE as well.

noticed by and ok cedric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.71 2003/06/27 11:38:23 henning Exp $ */
a81 1
void			 pf_tag_purge(void);
@


1.71
log
@move down pf_tag_unref() calls in pf_rm_rule() to after the check wetehr there
are still states for the given rule existant.
based on a very nice analysis from cedric@@, that is so completely right that
I have nothing to add:

in pf_rm_rule(), the pf_tag_unref() calls are done *before*
the if (rule->states > 0 || rule->entries.tqe_prev != NULL) test.

That mean that the two pf_tag_unref() calls could occur *twice*
for a given rule: first when the rule is removed from the ruleset
and (if the rule was kept around because of a state) a second
time when the state refcount drops to zero and the rule gets
really deleted. Unless I'm mistaken, that breaks the refcounting.

...and cedric was not mistaken.
and, as daniel pointed out:
The breakage this causes is so subtle, I doubt anyone noticed it before, if it
did occur.

consensus on this between cedric, dhartmei and myself
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.70 2003/06/23 02:33:39 cedric Exp $ */
d948 9
@


1.70
log
@Don't remove anchor too early in table code, it makes PF use freed memory.
This might just be a temporary fix, we're still looking for a better one.
ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.69 2003/06/21 09:07:01 djm Exp $ */
d410 2
a413 2
	if (rule->states > 0 || rule->entries.tqe_prev != NULL)
		return;
@


1.69
log
@count packets and bidirectionally on state entries, allowing for fine-grained
traffic reporting w/ pfsync; ok dhartmei@@

Note: ABI change (new fields in struct pf_state), requires a rebuild of
pfctl and tcpdump.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.68 2003/06/08 09:41:08 cedric Exp $ */
d397 9
d416 4
a419 2
	pf_tbladdr_remove(&rule->src.addr);
	pf_tbladdr_remove(&rule->dst.addr);
@


1.68
log
@A table in an anchor creates a real anchor: pfctl -sA works.
The following two pfctl functions work with an "-a" option:
  - pfctl [-a foo[:bar]] -sT
  - pfctl [-a foo[:bar]] -FT
ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.67 2003/06/03 12:34:04 henning Exp $ */
d1088 2
a1089 2
		state->packets = 0;
		state->bytes = 0;
@


1.67
log
@move some prototypes to pfvar.h. needed soon.
pf_tagname2tag, pf_tag2tagname, pf_tag_unref, pf_tag_packet
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.66 2003/06/03 12:30:33 henning Exp $ */
a78 4
struct pf_anchor	*pf_find_anchor(const char *);
struct pf_ruleset	*pf_find_ruleset(char *, char *);
struct pf_ruleset	*pf_find_or_create_ruleset(char *, char *);
void			 pf_remove_if_empty_ruleset(struct pf_ruleset *);
d353 1
a353 1
	if (ruleset == NULL || ruleset->anchor == NULL)
d1882 2
a1883 1
		error = pfr_clr_tables(&io->pfrio_ndel, io->pfrio_flags);
d1918 2
a1919 2
		error = pfr_get_tables(io->pfrio_buffer, &io->pfrio_size,
		    io->pfrio_flags);
d1930 2
a1931 2
		error = pfr_get_tstats(io->pfrio_buffer, &io->pfrio_size,
		    io->pfrio_flags);
@


1.66
log
@provide pf_tag2tagname which is the reverse of pf_tagname2tag. needed soon.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.65 2003/05/14 01:39:51 frantzen Exp $ */
a85 3
u_int16_t		 pf_tagname2tag(char *);
void			 pf_tag2tagname(u_int16_t, char *);
void			 pf_tag_unref(u_int16_t);
@


1.65
log
@fix use after free race when purging the new PF tags
ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.64 2003/05/13 17:45:24 henning Exp $ */
d87 1
d455 12
@


1.64
log
@add support for tagging packets with arbitary tags and filtering based on
those tags later on.

ok dhartmei@@ pb@@ mcbride@@ frantzen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.63 2003/05/12 17:43:29 mcbride Exp $ */
d472 1
a472 1
	struct pf_tagname	*p;
d474 2
a475 1
	TAILQ_FOREACH_REVERSE(p, &pf_tags, entries, pf_tagnames)
d482 1
@


1.63
log
@Correctness nit. Initialise state search trees properly.

ok henning@@ frantzen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.62 2003/05/12 01:25:31 dhartmei Exp $ */
d86 3
d94 4
d407 2
d419 64
d682 7
d761 1
@


1.62
log
@Adaptive timeout value scaling. Allows to reduce timeout values as the
number of state table entries grows, so entries time out faster before
the table fills up. Works both globally and per-rule. ok frantzen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.61 2003/05/12 00:02:32 henning Exp $ */
d115 2
@


1.61
log
@missing include
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.60 2003/04/30 12:30:27 cedric Exp $ */
d932 1
a932 1
			n->state->expire = 0;
d966 1
a966 1
				st->expire = 0;
d980 5
a996 1
		state->expire += state->creation;
a1010 1
		int			 secs;
d1031 4
a1034 3
		secs = time.tv_sec;
		ps->state.creation = secs - ps->state.creation;
		if (ps->state.expire <= (unsigned)secs)
a1035 2
		else
			ps->state.expire -= secs;
d1070 4
a1073 1
			if (pstore.expire <= (unsigned)secs)
a1074 2
			else
				pstore.expire -= secs;
@


1.60
log
@Allow tables to be loaded into anchors.
Most pfctl table commands (excluding 'show' and 'flush') support the "-a"
modifier.
ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.59 2003/04/27 16:02:07 cedric Exp $ */
d48 1
@


1.59
log
@Update the pfioc_table IOCTL structure.
Prepare for anchors, improve robustness.
WARNING: need to sync kernel/userland.
ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.58 2003/04/11 14:40:57 henning Exp $ */
d612 1
a612 1
		if (pf_tbladdr_setup(&rule->src.addr))
d614 1
a614 1
		if (pf_tbladdr_setup(&rule->dst.addr))
d851 1
a851 1
			if (pf_tbladdr_setup(&newrule->src.addr))
d853 1
a853 1
			if (pf_tbladdr_setup(&newrule->dst.addr))
@


1.58
log
@set/update the queue IDs on filter rules (qid and pqid) on
-DIOCCHANGERULE (just the affected rule)
-DIOCCOMMITRULES (all filter rules that get committed - one anchor or main rs)
-DIOCCOMMITALTQS (all filter rules, main set plus all anchors)

This fixes a whole bunch of issues.
previously, this was done in userland at load time. This worked fine for the
usual case, full ruleset load. It did not work inside anchors, as the queue
name <-> queue ID mapping is unknown there. Also, if the queue definitions
were changed without reloading the rules too (pfctl -A), the queue IDs on
the rules were not updated.
The three ioctls mentioned above are all entry points where the mapping is
touched.

helpful discussion with dhartmei@@ and cedric@@ helped verifying my approach
for this fix was right.

ok dhartmei@@ cedric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.57 2003/04/09 15:32:59 cedric Exp $ */
d1783 4
d1794 4
d1806 4
d1818 4
d1830 4
d1842 4
d1854 4
d1867 4
d1879 4
d1891 4
d1903 4
d1916 4
d1928 4
d1940 4
d1952 4
d1964 4
d1976 4
d1988 4
@


1.57
log
@Change pf_state structure to point to both a rule and the anchor,
so states created by rules in anchors correctly use rule options like
routing and (soon) queues...
Rule number bumped to 32 bit value.
USERLAND NEED TO BE RECOMPILED.
ok dhartmei@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.56 2003/04/07 13:44:22 dhartmei Exp $ */
d657 6
d834 11
d1381 2
d1424 11
@


1.56
log
@Catch and refuse rules with invalid ICMP types (> 40), ok cedric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.55 2003/04/05 20:24:58 cedric Exp $ */
d395 1
d970 2
a971 1
		state->nat_rule = NULL;
d1004 5
a1008 4
		if (n->state->rule.ptr->entries.tqe_prev == NULL)
			ps->state.rule.nr = -1;
		else
			ps->state.rule.nr = n->state->rule.ptr->nr;
d1044 5
a1048 4
			if (n->state->rule.ptr->entries.tqe_prev == NULL)
				pstore.rule.nr = -1;
			else
				pstore.rule.nr = n->state->rule.ptr->nr;
@


1.55
log
@Stick pf_default_rule everytime a packet pass because of the
implicit "pass all" first rule match and remove all "r == NULL"
tests which are now useless.
ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.52 2003/04/03 13:17:24 cedric Exp $ */
d58 1
d552 4
d783 4
@


1.54
log
@Replace the timeout variables by the content of the timeout
field of a new pf_default_rule structure.
ok dhartmei@@
@
text
@d993 1
a993 1
		if (n->state->rule.ptr == NULL)
d1032 1
a1032 1
			if (n->state->rule.ptr == NULL)
@


1.53
log
@Back out my last change, which was incorrect or incomplete.
States can still be created without a rule for people who have only
NAT rules, for example.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.51 2003/03/31 13:15:27 cedric Exp $ */
d87 2
d94 2
d121 23
d145 1
a145 1
	timeout_add(&pf_expire_to, pftm_interval * hz);
d1157 2
a1158 2
		old = *pftm_timeouts[pt->timeout];
		*pftm_timeouts[pt->timeout] = pt->seconds;
d1170 1
a1170 1
		pt->seconds = *pftm_timeouts[pt->timeout];
@


1.52
log
@Remove (state->rule.ptr != NULL) tests: this is always true now.
ok dhartmei@@
@
text
@d966 1
a966 1
		if (n->state->rule.ptr->entries.tqe_prev == NULL)
d1005 1
a1005 1
			if (n->state->rule.ptr->entries.tqe_prev == NULL)
@


1.51
log
@Only delete rule structure when no state refer to it.
Fix a bunch of issues.
Removal of unneeded (r != null) tests coming soon...
ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.50 2003/03/11 13:26:09 dhartmei Exp $ */
d966 1
a966 1
		if (n->state->rule.ptr == NULL)
d1005 1
a1005 1
			if (n->state->rule.ptr == NULL)
@


1.50
log
@Missing break, unintentional fall-through. Found by Kimmo Ms.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.49 2003/01/20 20:29:52 cedric Exp $ */
a82 1
void			 pf_rm_rule(struct pf_rulequeue *, struct pf_rule *);
d364 6
a374 2
	if (rulequeue != NULL)
		TAILQ_REMOVE(rulequeue, rule, entries);
d541 3
a606 1
		struct pf_tree_node	*n;
a625 11
		/*
		 * Rules are about to get freed, clear rule pointers in states
		 */
		if (rs_num == PF_RULESET_FILTER) {
			if (ruleset == &pf_main_ruleset)
				RB_FOREACH(n, pf_state_tree, &tree_ext_gwy)
					n->state->rule.ptr = NULL;
		} else if ((rs_num == PF_RULESET_NAT) ||
		    (rs_num == PF_RULESET_BINAT) || (rs_num == PF_RULESET_RDR))
			RB_FOREACH(n, pf_state_tree, &tree_ext_gwy)
				n->state->nat_rule = NULL;
d764 3
d842 1
a842 9
		if (pcr->action == PF_CHANGE_REMOVE) {
			struct pf_tree_node	*n;

			RB_FOREACH(n, pf_state_tree, &tree_ext_gwy) {
				if (n->state->rule.ptr == oldrule)
					n->state->rule.ptr = NULL;
				if (n->state->nat_rule == oldrule)
					n->state->nat_rule = NULL;
			}
d844 1
a844 1
		} else {
@


1.50.2.1
log
@MFC:
Fix by dhartmei@@

Fix DIOCCHANGEADDR, use the supplied ticket instead of 0.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.50 2003/03/11 13:26:09 dhartmei Exp $ */
d1569 1
a1569 1
		pool = pf_get_pool(pca->anchor, pca->ruleset, pca->ticket,
@


1.50.2.2
log
@MFC:
Fix by dhartmei@@

Fix a problem related to empty anchor rulesets, which could cause
a kernel panic.

ok deraadt@@ dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.50.2.1 2003/08/12 02:23:47 brad Exp $ */
a335 1
		pf_update_anchor_rules();
@


1.50.4.1
log
@Sync the SMP branch to -current. This includes moving to ELF.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.50 2003/03/11 13:26:09 dhartmei Exp $ */
a47 1
#include <sys/malloc.h>
a57 1
#include <netinet/ip_icmp.h>
d83 1
a87 2
struct pf_rule		 pf_default_rule;

a92 2
	u_int32_t *timeout = pf_default_rule.timeout;

a109 2
	RB_INIT(&tree_lan_ext);
	RB_INIT(&tree_ext_gwy);
a117 23
	/* default rule should never be garbage collected */
	pf_default_rule.entries.tqe_prev = &pf_default_rule.entries.tqe_next;
	pf_default_rule.action = PF_PASS;
	pf_default_rule.nr = -1;

	/* initialize default timeouts */
	timeout[PFTM_TCP_FIRST_PACKET] = 120;		/* First TCP packet */
	timeout[PFTM_TCP_OPENING] = 30;			/* No response yet */
	timeout[PFTM_TCP_ESTABLISHED] = 24*60*60;	/* Established */
	timeout[PFTM_TCP_CLOSING] = 15 * 60;		/* Half closed */
	timeout[PFTM_TCP_FIN_WAIT] = 45;		/* Got both FINs */
	timeout[PFTM_TCP_CLOSED] = 90;			/* Got a RST */
	timeout[PFTM_UDP_FIRST_PACKET] = 60;		/* First UDP packet */
	timeout[PFTM_UDP_SINGLE] = 30;			/* Unidirectional */
	timeout[PFTM_UDP_MULTIPLE] = 60;		/* Bidirectional */
	timeout[PFTM_ICMP_FIRST_PACKET] = 20;		/* First ICMP packet */
	timeout[PFTM_ICMP_ERROR_REPLY] = 10;		/* Got error response */
	timeout[PFTM_OTHER_FIRST_PACKET] = 60;		/* First packet */
	timeout[PFTM_OTHER_SINGLE] = 30;		/* Unidirectional */
	timeout[PFTM_OTHER_MULTIPLE] = 60;		/* Bidirectional */
	timeout[PFTM_FRAG] = 30;			/* Fragment expire */
	timeout[PFTM_INTERVAL] = 10;			/* Expire interval */

d119 1
a119 1
	timeout_add(&pf_expire_to, timeout[PFTM_INTERVAL] * hz);
a364 7
	if (rulequeue != NULL) {
		TAILQ_REMOVE(rulequeue, rule, entries);
		rule->entries.tqe_prev = NULL;
		rule->nr = -1;
	}
	if (rule->states > 0 || rule->entries.tqe_prev != NULL)
		return;
d370 2
a520 4
		if (pr->rule.return_icmp >> 8 > ICMP_MAXTYPE) {
			error = EINVAL;
			break;
		}
a537 3
		/* initialize refcounting */
		rule->states = 0;
		rule->entries.tqe_prev = NULL;
d573 1
a573 1
		if (pf_tbladdr_setup(ruleset, &rule->src.addr))
d575 1
a575 1
		if (pf_tbladdr_setup(ruleset, &rule->dst.addr))
d601 1
a618 6
#ifdef ALTQ
		/* set queue IDs */
		if (rs_num == PF_RULESET_FILTER)
			pf_rule_set_qid(ruleset->rules[rs_num].inactive.ptr);
#endif

d621 11
a759 4
			if (pcr->rule.return_icmp >> 8 > ICMP_MAXTYPE) {
				error = EINVAL;
				break;
			}
a769 3
			/* initialize refcounting */
			newrule->states = 0;
			newrule->entries.tqe_prev = NULL;
a793 11
#ifdef ALTQ
			/* set queue IDs */
			if (newrule->qname[0] != 0) {
				newrule->qid = pf_qname_to_qid(newrule->qname);
				if (newrule->pqname[0] != 0)
					newrule->pqid =
					    pf_qname_to_qid(newrule->pqname);
				else
					newrule->pqid = newrule->qid;
			}
#endif
d800 1
a800 1
			if (pf_tbladdr_setup(ruleset, &newrule->src.addr))
d802 1
a802 1
			if (pf_tbladdr_setup(ruleset, &newrule->dst.addr))
d845 9
a853 1
		if (pcr->action == PF_CHANGE_REMOVE)
d855 1
a855 1
		else {
d888 1
a888 1
			n->state->timeout = PFTM_PURGE;
d922 1
a922 1
				st->timeout = PFTM_PURGE;
a935 5
		if (ps->state.timeout >= PFTM_MAX &&
		    ps->state.timeout != PFTM_UNTIL_PACKET) {
			error = EINVAL;
			break;
		}
d944 1
a944 2
		state->nat_rule.ptr = NULL;
		state->anchor.ptr = NULL;
d947 1
d962 1
d977 4
a980 5
		ps->state.rule.nr = n->state->rule.ptr->nr;
		ps->state.nat_rule.nr = (n->state->nat_rule.ptr == NULL) ?
		    -1 : n->state->nat_rule.ptr->nr;
		ps->state.anchor.nr = (n->state->anchor.ptr == NULL) ?
		    -1 : n->state->anchor.ptr->nr;
d982 4
a985 3
		ps->state.expire = pf_state_expires(n->state);
		if (ps->state.expire > time.tv_sec)
			ps->state.expire -= time.tv_sec;
d987 1
a987 1
			ps->state.expire = 0;
d1016 4
a1019 5
			pstore.rule.nr = n->state->rule.ptr->nr;
			pstore.nat_rule.nr = (n->state->nat_rule.ptr == NULL) ?
			    -1 : n->state->nat_rule.ptr->nr;
			pstore.anchor.nr = (n->state->anchor.ptr == NULL) ?
			    -1 : n->state->anchor.ptr->nr;
d1021 3
a1023 2
			pstore.expire = pf_state_expires(n->state);
			if (pstore.expire > secs)
a1024 2
			else
				pstore.expire = 0;
d1141 2
a1142 2
		old = pf_default_rule.timeout[pt->timeout];
		pf_default_rule.timeout[pt->timeout] = pt->seconds;
d1154 1
a1154 1
		pt->seconds = pf_default_rule.timeout[pt->timeout];
a1334 2
		struct pf_anchor	*anchor;
		struct pf_ruleset	*ruleset;
a1375 11

		/* update queue IDs */
		pf_rule_set_qid(
		    pf_main_ruleset.rules[PF_RULESET_FILTER].active.ptr);
		TAILQ_FOREACH(anchor, &pf_anchors, entries) {
			TAILQ_FOREACH(ruleset, &anchor->rulesets, entries) {
				pf_rule_set_qid(
				    ruleset->rules[PF_RULESET_FILTER].active.ptr
				    );
			}
		}
a1723 4
		if (io->pfrio_esize != 0) {
			error = ENODEV;
			break;
		}
a1730 4
		if (io->pfrio_esize != sizeof(struct pfr_table)) {
			error = ENODEV;
			break;
		}
a1738 4
		if (io->pfrio_esize != sizeof(struct pfr_table)) {
			error = ENODEV;
			break;
		}
a1746 4
		if (io->pfrio_esize != sizeof(struct pfr_table)) {
			error = ENODEV;
			break;
		}
a1754 4
		if (io->pfrio_esize != sizeof(struct pfr_tstats)) {
			error = ENODEV;
			break;
		}
a1762 4
		if (io->pfrio_esize != sizeof(struct pfr_table)) {
			error = ENODEV;
			break;
		}
a1770 4
		if (io->pfrio_esize != sizeof(struct pfr_table)) {
			error = ENODEV;
			break;
		}
a1779 4
		if (io->pfrio_esize != 0) {
			error = ENODEV;
			break;
		}
a1787 4
		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
a1795 4
		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
a1803 4
		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
a1812 4
		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
a1820 4
		if (io->pfrio_esize != sizeof(struct pfr_astats)) {
			error = ENODEV;
			break;
		}
a1828 4
		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
a1836 4
		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
a1844 4
		if (io->pfrio_esize != 0) {
			error = ENODEV;
			break;
		}
a1852 4
		if (io->pfrio_esize != 0) {
			error = ENODEV;
			break;
		}
a1860 4
		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
@


1.50.4.2
log
@merge the trunk so we will get the genfs and locking fixes
@
text
@d1 1
a1 1
/*	$OpenBSD$ */
a85 3
u_int16_t		 pf_tagname2tag(char *);
void			 pf_tag_unref(u_int16_t);
void			 pf_tag_purge(void);
a90 4
#define	TAGID_MAX	 50000
static u_int16_t	 tagid = 0;
TAILQ_HEAD(pf_tags, pf_tagname)	pf_tags = TAILQ_HEAD_INITIALIZER(pf_tags);

a399 2
	pf_tag_unref(rule->tag);
	pf_tag_unref(rule->match_tag);
a409 66
u_int16_t
pf_tagname2tag(char *tagname)
{
	struct pf_tagname	*tag, *p;
	int			 wrapped = 0;

	TAILQ_FOREACH(tag, &pf_tags, entries)
		if (strcmp(tagname, tag->name) == 0) {
			tag->ref++;
			return (tag->tag);
		}
	/* new entry */
	if (++tagid > TAGID_MAX)	/* > 50000 reserved for special use */
		tagid = wrapped = 1;
	for (p = TAILQ_FIRST(&pf_tags); p != NULL; p = TAILQ_NEXT(p, entries))
		if (p->tag == tagid) {
			if (++tagid > TAGID_MAX) {
				if (wrapped)
					return (0);
				else
					tagid = wrapped = 1;
			}
			p = TAILQ_FIRST(&pf_tags);
		}

	tag = (struct pf_tagname *)malloc(sizeof(struct pf_tagname),
	    M_TEMP, M_NOWAIT);
	if (tag == NULL)
		return (0);
	bzero(tag, sizeof(struct pf_tagname));
	strlcpy(tag->name, tagname, sizeof(tag->name));
	tag->tag = tagid;
	tag->ref++;
	TAILQ_INSERT_TAIL(&pf_tags, tag, entries);
	return (tag->tag);
}

void
pf_tag_unref(u_int16_t tag)
{
	struct pf_tagname	*p;

	if (tag > 0)
		TAILQ_FOREACH(p, &pf_tags, entries)
			if (tag == p->tag) {
				p->ref--;
				return;
			}
}

void
pf_tag_purge(void)
{
	struct pf_tagname	*p, *next;

	for (p = TAILQ_LAST(&pf_tags, pf_tags); p != NULL; p = next) {
		next = TAILQ_PREV(p, pf_tags, entries);
		if (p->ref == 0) {
			if (p->tag == tagid)
				tagid--;
			TAILQ_REMOVE(&pf_tags, p, entries);
			free(p, M_TEMP);
		}
	}
}

a608 7
		if (rule->tagname[0])
			if ((rule->tag = pf_tagname2tag(rule->tagname)) == 0)
				error = EBUSY;
		if (rule->match_tagname[0])
			if ((rule->match_tag =
			    pf_tagname2tag(rule->match_tagname)) == 0)
				error = EBUSY;
a680 1
		pf_tag_purge();
@


1.50.4.3
log
@Sync SMP branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.50.4.2 2003/05/16 00:29:44 niklas Exp $ */
d86 2
a453 12
}

void
pf_tag2tagname(u_int16_t tagid, char *p)
{
	struct pf_tagname	*tag;

	TAILQ_FOREACH(tag, &pf_tags, entries)
		if (tag->tag == tagid) {
			strlcpy(p, tag->name, PF_TAG_NAME_SIZE);
			return;
		}
@


1.50.4.4
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD$ */
a4 1
 * Copyright (c) 2002,2003 Henning Brauer
a60 1
#include <dev/rndvar.h>
a61 1
#include <net/if_pfsync.h>
d79 4
d86 1
a86 8
#ifdef ALTQ
int			 pf_begin_altq(u_int32_t *);
int			 pf_rollback_altq(u_int32_t);
int			 pf_commit_altq(u_int32_t);
#endif /* ALTQ */
int			 pf_begin_rules(u_int32_t *, int, char *, char *);
int			 pf_rollback_rules(u_int32_t, int, char *, char *);
int			 pf_commit_rules(u_int32_t, int, char *, char *);
d93 1
d103 2
d107 2
a108 2
	pool_init(&pf_src_tree_pl, sizeof(struct pf_src_node), 0, 0, 0,
	    "pfsrctrpl", NULL);
a115 2
	pfi_initialize();
	pf_osfp_initialize();
d120 2
a121 1
	RB_INIT(&tree_src_tracking);
a151 1
	timeout[PFTM_SRC_NODE] = 0;			/* Source tracking */
a156 1
	bzero(&pf_status, sizeof(pf_status));
a157 4

	/* XXX do our best to avoid a conflict */
	pf_status.hostid = arc4random();
	pf_status.stateid = 1;	/* might want 0 for something special */
d303 1
a303 2
pf_find_or_create_ruleset(char anchorname[PF_ANCHOR_NAME_SIZE],
    char rulesetname[PF_RULESET_NAME_SIZE])
d357 1
a357 1
	if (ruleset == NULL || ruleset->anchor == NULL || ruleset->tables > 0 ||	    ruleset->topen)
d361 1
a361 2
		    !TAILQ_EMPTY(ruleset->rules[i].inactive.ptr) ||
		    ruleset->rules[i].inactive.open)
d391 1
a391 3
		pfi_dynaddr_remove(&empty_pool_pa->addr);
		pf_tbladdr_remove(&empty_pool_pa->addr);
		pfi_detach_rule(empty_pool_pa->kif);
a400 9
		if (rule->states <= 0) {
			/*
			 * XXX - we need to remove the table *before* detaching
			 * the rule to make sure the table code does not delete
			 * the anchor under our feet.
			 */
			pf_tbladdr_remove(&rule->src.addr);
			pf_tbladdr_remove(&rule->dst.addr);
		}
a404 4

	if (rule->states > 0 || rule->src_nodes > 0 ||
	    rule->entries.tqe_prev != NULL)
		return;
d407 6
a412 7
	pfi_dynaddr_remove(&rule->src.addr);
	pfi_dynaddr_remove(&rule->dst.addr);
	if (rulequeue == NULL) {
		pf_tbladdr_remove(&rule->src.addr);
		pf_tbladdr_remove(&rule->dst.addr);
	}
	pfi_detach_rule(rule->kif);
d420 2
a421 2
	struct pf_tagname	*tag, *p = NULL;
	u_int16_t		 new_tagid = 1;
a427 7

	/*
	 * to avoid fragmentation, we do a linear search from the beginning
	 * and take the first free slot we find. if there is none or the list
	 * is empty, append a new entry at the end.
	 */

d429 12
a440 4
	if (!TAILQ_EMPTY(&pf_tags))
		for (p = TAILQ_FIRST(&pf_tags); p != NULL &&
		    p->tag == new_tagid; p = TAILQ_NEXT(p, entries))
			new_tagid = p->tag + 1;
a441 4
	if (new_tagid > TAGID_MAX)
		return (0);

	/* allocate and fill new struct pf_tagname */
d448 1
a448 1
	tag->tag = new_tagid;
d450 1
a450 6

	if (p != NULL)	/* insert new entry before p */
		TAILQ_INSERT_BEFORE(p, tag, entries);
	else	/* either list empty or no free slot in between */
		TAILQ_INSERT_TAIL(&pf_tags, tag, entries);

d469 1
a469 4
	struct pf_tagname	*p, *next;

	if (tag == 0)
		return;
d471 5
a475 6
	for (p = TAILQ_FIRST(&pf_tags); p != NULL; p = next) {
		next = TAILQ_NEXT(p, entries);
		if (tag == p->tag) {
			if (--p->ref == 0) {
				TAILQ_REMOVE(&pf_tags, p, entries);
				free(p, M_TEMP);
a476 3
			break;
		}
	}
d479 2
a480 3
#ifdef ALTQ
int
pf_begin_altq(u_int32_t *ticket)
d482 1
a482 24
	struct pf_altq	*altq;
	int		 error = 0;

	/* Purge the old altq list */
	while ((altq = TAILQ_FIRST(pf_altqs_inactive)) != NULL) {
		TAILQ_REMOVE(pf_altqs_inactive, altq, entries);
		if (altq->qname[0] == 0) {
			/* detach and destroy the discipline */
			error = altq_remove(altq);
		}
		pool_put(&pf_altq_pl, altq);
	}
	if (error)
		return (error);
	*ticket = ++ticket_altqs_inactive;
	altqs_inactive_open = 1;
	return (0);
}

int
pf_rollback_altq(u_int32_t ticket)
{
	struct pf_altq	*altq;
	int		 error = 0;
d484 7
a490 8
	if (!altqs_inactive_open || ticket != ticket_altqs_inactive)
		return (0);
	/* Purge the old altq list */
	while ((altq = TAILQ_FIRST(pf_altqs_inactive)) != NULL) {
		TAILQ_REMOVE(pf_altqs_inactive, altq, entries);
		if (altq->qname[0] == 0) {
			/* detach and destroy the discipline */
			error = altq_remove(altq);
a491 1
		pool_put(&pf_altq_pl, altq);
a492 141
	altqs_inactive_open = 0;
	return (error);
}

int
pf_commit_altq(u_int32_t ticket)
{
	struct pf_altqqueue	*old_altqs;
	struct pf_altq		*altq;
	struct pf_anchor	*anchor;
	struct pf_ruleset	*ruleset;
	int			 s, err, error = 0;

	if (!altqs_inactive_open || ticket != ticket_altqs_inactive)
		return (EBUSY);

	/* swap altqs, keep the old. */
	s = splsoftnet();
	old_altqs = pf_altqs_active;
	pf_altqs_active = pf_altqs_inactive;
	pf_altqs_inactive = old_altqs;
	ticket_altqs_active = ticket_altqs_inactive;

	/* Attach new disciplines */
	TAILQ_FOREACH(altq, pf_altqs_active, entries) {
		if (altq->qname[0] == 0) {
			/* attach the discipline */
			error = altq_pfattach(altq);
			if (error) {
				splx(s);
				return (error);
			}
		}
	}

	/* Purge the old altq list */
	while ((altq = TAILQ_FIRST(pf_altqs_inactive)) != NULL) {
		TAILQ_REMOVE(pf_altqs_inactive, altq, entries);
		if (altq->qname[0] == 0) {
			/* detach and destroy the discipline */
			err = altq_pfdetach(altq);
			if (err != 0 && error == 0)
				error = err;
			err = altq_remove(altq);
			if (err != 0 && error == 0)
				error = err;
		}
		pool_put(&pf_altq_pl, altq);
	}
	splx(s);

	/* update queue IDs */
	pf_rule_set_qid(
	    pf_main_ruleset.rules[PF_RULESET_FILTER].active.ptr);
	TAILQ_FOREACH(anchor, &pf_anchors, entries) {
		TAILQ_FOREACH(ruleset, &anchor->rulesets, entries) {
			pf_rule_set_qid(
			    ruleset->rules[PF_RULESET_FILTER].active.ptr
			    );
		}
	}
	altqs_inactive_open = 0;
	return (error);
}
#endif /* ALTQ */

int
pf_begin_rules(u_int32_t *ticket, int rs_num, char *anchor, char *ruleset)
{
	struct pf_ruleset	*rs;
	struct pf_rule		*rule;

	if (rs_num < 0 || rs_num >= PF_RULESET_MAX)
		return (EINVAL);
	rs = pf_find_or_create_ruleset(anchor, ruleset);
	if (rs == NULL)
		return (EINVAL);
	while ((rule = TAILQ_FIRST(rs->rules[rs_num].inactive.ptr)) != NULL)
		pf_rm_rule(rs->rules[rs_num].inactive.ptr, rule);
	*ticket = ++rs->rules[rs_num].inactive.ticket;
	rs->rules[rs_num].inactive.open = 1;
	return (0);
}

int
pf_rollback_rules(u_int32_t ticket, int rs_num, char *anchor, char *ruleset)
{
	struct pf_ruleset	*rs;
	struct pf_rule		*rule;

	if (rs_num < 0 || rs_num >= PF_RULESET_MAX)
		return (EINVAL);
	rs = pf_find_ruleset(anchor, ruleset);
	if (rs == NULL || !rs->rules[rs_num].inactive.open ||
	    rs->rules[rs_num].inactive.ticket != ticket)
		return (0);
	while ((rule = TAILQ_FIRST(rs->rules[rs_num].inactive.ptr)) != NULL)
		pf_rm_rule(rs->rules[rs_num].inactive.ptr, rule);
	rs->rules[rs_num].inactive.open = 0;
	return (0);
}

int
pf_commit_rules(u_int32_t ticket, int rs_num, char *anchor, char *ruleset)
{
	struct pf_ruleset	*rs;
	struct pf_rule		*rule;
	struct pf_rulequeue     *old_rules;
	int			 s;

	if (rs_num < 0 || rs_num >= PF_RULESET_MAX)
		return (EINVAL);
	rs = pf_find_ruleset(anchor, ruleset);
	if (rs == NULL || !rs->rules[rs_num].inactive.open ||
	    ticket != rs->rules[rs_num].inactive.ticket)
		return (EBUSY);

#ifdef ALTQ
	/* set queue IDs */
	if (rs_num == PF_RULESET_FILTER)
		pf_rule_set_qid(rs->rules[rs_num].inactive.ptr);
#endif

	/* Swap rules, keep the old. */
	s = splsoftnet();
	old_rules = rs->rules[rs_num].active.ptr;
	rs->rules[rs_num].active.ptr =
	    rs->rules[rs_num].inactive.ptr;
	rs->rules[rs_num].inactive.ptr = old_rules;
	rs->rules[rs_num].active.ticket =
	    rs->rules[rs_num].inactive.ticket;
	pf_calc_skip_steps(rs->rules[rs_num].active.ptr);

	/* Purge the old rule list. */
	while ((rule = TAILQ_FIRST(old_rules)) != NULL)
		pf_rm_rule(old_rules, rule);
	rs->rules[rs_num].inactive.open = 0;
	pf_remove_if_empty_ruleset(rs);
	pf_update_anchor_rules();
	splx(s);
	return (0);
d538 1
a538 14
		case DIOCOSFPGET:
		case DIOCGETSRCNODES:
		case DIOCCLRSRCNODES:
		case DIOCIGETIFACES:
		case DIOCICLRISTATS:
			break;
		case DIOCRCLRTABLES:
		case DIOCRADDTABLES:
		case DIOCRDELTABLES:
		case DIOCRSETTFLAGS:
			if (((struct pfioc_table *)addr)->pfrio_flags &
			    PFR_FLAG_DUMMY)
				break; /* dummy operation ok */
			return (EPERM);
d566 1
a566 17
		case DIOCOSFPGET:
		case DIOCGETSRCNODES:
		case DIOCIGETIFACES:
			break;
		case DIOCRCLRTABLES:
		case DIOCRADDTABLES:
		case DIOCRDELTABLES:
		case DIOCRCLRTSTATS:
		case DIOCRCLRADDRS:
		case DIOCRADDADDRS:
		case DIOCRDELADDRS:
		case DIOCRSETADDRS:
		case DIOCRSETTFLAGS:
			if (((struct pfioc_table *)addr)->pfrio_flags &
			    PFR_FLAG_DUMMY)
				break; /* dummy operation ok */
			return (EACCES);
a576 1
			u_int64_t stateid = pf_status.stateid;
a577 3
			u_int32_t debug = pf_status.debug;
			u_int32_t hostid = pf_status.hostid;
			u_int32_t src_nodes = pf_status.src_nodes;
a580 4
			pf_status.debug = debug;
			pf_status.stateid = stateid;
			pf_status.hostid = hostid;
			pf_status.states = src_nodes;
d582 3
d600 3
d604 14
a617 2
		error = pf_begin_rules(&pr->ticket, pf_get_ruleset_number(
		    pr->rule.action), pr->anchor, pr->ruleset);
a624 1
		struct pf_pooladdr	*pa;
d660 1
a660 1
		rule->kif = NULL;
a663 1
		rule->src_nodes = 0;
d686 2
a687 2
			rule->kif = pfi_attach_rule(rule->ifname);
			if (rule->kif == NULL) {
d703 1
a703 1
		if (pfi_dynaddr_setup(&rule->src.addr, rule->af))
d705 1
a705 1
		if (pfi_dynaddr_setup(&rule->dst.addr, rule->af))
a710 3
		TAILQ_FOREACH(pa, &pf_pabuf, entries)
			if (pf_tbladdr_setup(ruleset, &pa->addr))
				error = EINVAL;
d732 35
d768 7
a774 2
		error = pf_commit_rules(pr->ticket, pf_get_ruleset_number(
		    pr->rule.action), pr->anchor, pr->ruleset);
d836 2
a837 2
		pfi_dynaddr_copyout(&pr->rule.src.addr);
		pfi_dynaddr_copyout(&pr->rule.dst.addr);
d921 2
a922 2
				newrule->kif = pfi_attach_rule(newrule->ifname);
				if (newrule->kif == NULL) {
d928 1
a928 1
				newrule->kif = NULL;
a940 9
			if (newrule->tagname[0])
				if ((newrule->tag =
				    pf_tagname2tag(newrule->tagname)) == 0)
					error = EBUSY;
			if (newrule->match_tagname[0])
				if ((newrule->match_tag = pf_tagname2tag(
				    newrule->match_tagname)) == 0)
					error = EBUSY;

d943 1
a943 1
			if (pfi_dynaddr_setup(&newrule->src.addr, newrule->af))
d945 1
a945 1
			if (pfi_dynaddr_setup(&newrule->dst.addr, newrule->af))
d1023 1
a1023 1
		struct pf_state	*state;
d1026 2
a1027 2
		RB_FOREACH(state, pf_state_tree_id, &tree_id)
			state->timeout = PFTM_PURGE;
a1030 3
#if NPFSYNC
		pfsync_clear_states(pf_status.hostid);
#endif
d1035 2
a1036 1
		struct pf_state		*state;
d1041 4
a1044 4
		RB_FOREACH(state, pf_state_tree_id, &tree_id) {
			if ((!psk->psk_af || state->af == psk->psk_af)
			    && (!psk->psk_proto || psk->psk_proto ==
			    state->proto) &&
d1047 2
a1048 2
			    &psk->psk_src.addr.v.a.mask,
			    &state->lan.addr, state->af) &&
d1051 2
a1052 2
			    &psk->psk_dst.addr.v.a.mask,
			    &state->ext.addr, state->af) &&
d1056 1
a1056 1
			    state->lan.port)) &&
d1060 2
a1061 2
			    state->ext.port))) {
				state->timeout = PFTM_PURGE;
a1073 1
		struct pfi_kif		*kif;
a1085 5
		kif = pfi_lookup_create(ps->state.u.ifname);
		if (kif == NULL) {
			error = ENOENT;
			splx(s);
		}
a1086 1
		bzero(&state->u, sizeof(state->u));
d1090 1
a1090 1
		state->rt_kif = NULL;
d1092 3
a1094 5
		state->packets[0] = state->packets[1] = 0;
		state->bytes[0] = state->bytes[1] = 0;

		if (pf_insert_state(kif, state)) {
			pfi_maybe_destroy(kif);
d1104 1
a1104 1
		struct pf_state		*state;
d1109 1
a1109 1
		RB_FOREACH(state, pf_state_tree_id, &tree_id) {
d1114 1
a1114 1
		if (state == NULL) {
d1119 6
a1124 6
		bcopy(state, &ps->state, sizeof(struct pf_state));
		ps->state.rule.nr = state->rule.ptr->nr;
		ps->state.nat_rule.nr = (state->nat_rule.ptr == NULL) ?
		    -1 : state->nat_rule.ptr->nr;
		ps->state.anchor.nr = (state->anchor.ptr == NULL) ?
		    -1 : state->anchor.ptr->nr;
d1126 1
a1126 1
		ps->state.expire = pf_state_expires(state);
d1136 1
a1136 1
		struct pf_state		*state;
a1137 1
		struct pfi_kif		*kif;
d1143 2
a1144 2
			TAILQ_FOREACH(kif, &pfi_statehead, pfik_w_states)
				nr += kif->pfik_states;
d1152 2
a1153 4
		TAILQ_FOREACH(kif, &pfi_statehead, pfik_w_states)
			RB_FOREACH(state, pf_state_tree_ext_gwy,
			    &kif->pfik_ext_gwy) {
				int	secs = time.tv_sec;
d1155 2
a1156 2
				if ((nr+1) * sizeof(*p) > (unsigned)ps->ps_len)
					break;
d1158 16
a1173 21
				bcopy(state, &pstore, sizeof(pstore));
				strlcpy(pstore.u.ifname, kif->pfik_name,
				    sizeof(pstore.u.ifname));
				pstore.rule.nr = state->rule.ptr->nr;
				pstore.nat_rule.nr = (state->nat_rule.ptr ==
				    NULL) ? -1 : state->nat_rule.ptr->nr;
				pstore.anchor.nr = (state->anchor.ptr ==
				    NULL) ? -1 : state->anchor.ptr->nr;
				pstore.creation = secs - pstore.creation;
				pstore.expire = pf_state_expires(state);
				if (pstore.expire > secs)
					pstore.expire -= secs;
				else
					pstore.expire = 0;
				error = copyout(&pstore, p, sizeof(*p));
				if (error) {
					splx(s);
					goto fail;
				}
				p++;
				nr++;
d1175 3
a1182 7
	case DIOCGETSTATUS: {
		struct pf_status *s = (struct pf_status *)addr;
		bcopy(&pf_status, s, sizeof(struct pf_status));
		pfi_fill_oldstatus(s);
		break;
	}

d1185 1
d1188 1
d1190 14
a1203 7
			break;
		}
		if (ifunit(pi->ifname) == NULL) {
			error = EINVAL;
			break;
		}
		strlcpy(pf_status.ifname, pi->ifname, IFNAMSIZ);
d1208 13
a1220 5
		bzero(pf_status.counters, sizeof(pf_status.counters));
		bzero(pf_status.fcounters, sizeof(pf_status.fcounters));
		bzero(pf_status.scounters, sizeof(pf_status.scounters));
		if (*pf_status.ifname)
			pfi_clr_istats(pf_status.ifname, NULL, 0);
d1226 3
a1228 3
		struct pf_state		*state;
		struct pf_state		 key;
		int			 m = 0, direction = pnl->direction;
d1233 10
d1250 5
a1254 23

			/*
			 * userland gives us source and dest of connection,
			 * reverse the lookup so we ask for what happens with
			 * the return traffic, enabling us to find it in the
			 * state tree.
			 */
			if (direction == PF_IN) {
				PF_ACPY(&key.ext.addr, &pnl->daddr, pnl->af);
				key.ext.port = pnl->dport;
				PF_ACPY(&key.gwy.addr, &pnl->saddr, pnl->af);
				key.gwy.port = pnl->sport;
				state = pf_find_state_all(&key, PF_EXT_GWY, &m);
			} else {
				PF_ACPY(&key.lan.addr, &pnl->daddr, pnl->af);
				key.lan.port = pnl->dport;
				PF_ACPY(&key.ext.addr, &pnl->saddr, pnl->af);
				key.ext.port = pnl->sport;
				state = pf_find_state_all(&key, PF_LAN_EXT, &m);
			}
			if (m > 1)
				error = E2BIG;	/* more than one state */
			else if (state != NULL) {
d1256 3
a1258 3
					PF_ACPY(&pnl->rsaddr, &state->lan.addr,
					    state->af);
					pnl->rsport = state->lan.port;
d1263 3
a1265 3
					PF_ACPY(&pnl->rdaddr, &state->gwy.addr,
					    state->af);
					pnl->rdport = state->gwy.port;
a1328 2
		if (pl->index == PF_LIMIT_SRC_NODES)
			pf_default_rule.max_src_nodes = pl->limit;
d1421 1
d1423 10
a1432 1
		error = pf_begin_altq(ticket);
d1477 46
a1522 1
		u_int32_t		ticket = *(u_int32_t *)addr;
d1524 10
a1533 1
		error = pf_commit_altq(ticket);
d1637 2
a1638 3
		if (pp->addr.addr.type != PF_ADDR_ADDRMASK &&
		    pp->addr.addr.type != PF_ADDR_DYNIFTL &&
		    pp->addr.addr.type != PF_ADDR_TABLE) {
d1649 2
a1650 2
			pa->kif = pfi_attach_rule(pa->ifname);
			if (pa->kif == NULL) {
d1656 2
a1657 3
		if (pfi_dynaddr_setup(&pa->addr, pp->af)) {
			pfi_dynaddr_remove(&pa->addr);
			pfi_detach_rule(pa->kif);
d1707 1
a1707 2
		pfi_dynaddr_copyout(&pp->addr.addr);
		pf_tbladdr_copyout(&pp->addr.addr);
a1714 1
		struct pf_ruleset	*ruleset;
d1721 2
a1722 3
		if (pca->addr.addr.type != PF_ADDR_ADDRMASK &&
		    pca->addr.addr.type != PF_ADDR_DYNIFTL &&
		    pca->addr.addr.type != PF_ADDR_TABLE) {
d1727 1
a1727 6
		ruleset = pf_find_ruleset(pca->anchor, pca->ruleset);
		if (ruleset == NULL) {
			error = EBUSY;
			break;
		}
		pool = pf_get_pool(pca->anchor, pca->ruleset, pca->ticket,
d1755 2
a1756 2
				newpa->kif = pfi_attach_rule(newpa->ifname);
				if (newpa->kif == NULL) {
d1762 3
a1764 5
				newpa->kif = NULL;
			if (pfi_dynaddr_setup(&newpa->addr, pca->af) ||
			    pf_tbladdr_setup(ruleset, &newpa->addr)) {
				pfi_dynaddr_remove(&newpa->addr);
				pfi_detach_rule(newpa->kif);
d1794 1
a1794 3
			pfi_dynaddr_remove(&oldpa->addr);
			pf_tbladdr_remove(&oldpa->addr);
			pfi_detach_rule(oldpa->kif);
d1808 1
a1808 1
		PF_ACPY(&pool->counter, &pool->cur->addr.v.a.addr,
d1886 1
a1886 2
		error = pfr_clr_tables(&io->pfrio_table, &io->pfrio_ndel,
		    io->pfrio_flags | PFR_FLAG_USERIOCTL);
d1898 1
a1898 1
		    &io->pfrio_nadd, io->pfrio_flags | PFR_FLAG_USERIOCTL);
d1910 1
a1910 1
		    &io->pfrio_ndel, io->pfrio_flags | PFR_FLAG_USERIOCTL);
d1921 2
a1922 2
		error = pfr_get_tables(&io->pfrio_table, io->pfrio_buffer,
		    &io->pfrio_size, io->pfrio_flags | PFR_FLAG_USERIOCTL);
d1933 2
a1934 2
		error = pfr_get_tstats(&io->pfrio_table, io->pfrio_buffer,
		    &io->pfrio_size, io->pfrio_flags | PFR_FLAG_USERIOCTL);
d1946 1
a1946 1
		    &io->pfrio_nzero, io->pfrio_flags | PFR_FLAG_USERIOCTL);
d1959 1
a1959 1
		    &io->pfrio_ndel, io->pfrio_flags | PFR_FLAG_USERIOCTL);
d1971 1
a1971 1
		    io->pfrio_flags | PFR_FLAG_USERIOCTL);
d1983 1
a1983 2
		    io->pfrio_size, &io->pfrio_nadd, io->pfrio_flags |
		    PFR_FLAG_USERIOCTL);
d1995 1
a1995 2
		    io->pfrio_size, &io->pfrio_ndel, io->pfrio_flags |
		    PFR_FLAG_USERIOCTL);
d2008 1
a2008 2
		    &io->pfrio_ndel, &io->pfrio_nchange, io->pfrio_flags |
		    PFR_FLAG_USERIOCTL);
d2020 1
a2020 1
		    &io->pfrio_size, io->pfrio_flags | PFR_FLAG_USERIOCTL);
d2032 1
a2032 1
		    &io->pfrio_size, io->pfrio_flags | PFR_FLAG_USERIOCTL);
d2044 1
a2044 2
		    io->pfrio_size, &io->pfrio_nzero, io->pfrio_flags |
		    PFR_FLAG_USERIOCTL);
d2056 1
a2056 2
		    io->pfrio_size, &io->pfrio_nmatch, io->pfrio_flags |
		    PFR_FLAG_USERIOCTL);
d2067 2
a2068 2
		error = pfr_ina_begin(&io->pfrio_table, &io->pfrio_ticket,
		    &io->pfrio_ndel, io->pfrio_flags | PFR_FLAG_USERIOCTL);
d2079 2
a2080 3
		error = pfr_ina_commit(&io->pfrio_table, io->pfrio_ticket,
		    &io->pfrio_nadd, &io->pfrio_nchange, io->pfrio_flags |
		    PFR_FLAG_USERIOCTL);
d2093 1
a2093 303
		    io->pfrio_ticket, io->pfrio_flags | PFR_FLAG_USERIOCTL);
		break;
	}

	case DIOCOSFPADD: {
		struct pf_osfp_ioctl *io = (struct pf_osfp_ioctl *)addr;
		s = splsoftnet();
		error = pf_osfp_add(io);
		splx(s);
		break;
	}

	case DIOCOSFPGET: {
		struct pf_osfp_ioctl *io = (struct pf_osfp_ioctl *)addr;
		s = splsoftnet();
		error = pf_osfp_get(io);
		splx(s);
		break;
	}

	case DIOCXBEGIN: {
		struct pfioc_trans	*io = (struct pfioc_trans *)addr;
		struct pfioc_trans_e	 ioe;
		struct pfr_table	 table;
		int			 i;

		if (io->esize != sizeof(ioe)) {
			error = ENODEV;
			goto fail;
		}
		for (i = 0; i < io->size; i++) {
			if (copyin(io->array+i, &ioe, sizeof(ioe))) {
				error = EFAULT;
				goto fail;
			}
			switch(ioe.rs_num) {
#ifdef ALTQ
			case PF_RULESET_ALTQ:
				if (ioe.anchor[0] || ioe.ruleset[0]) {
					error = EINVAL;
					goto fail;
				}
				if ((error = pf_begin_altq(&ioe.ticket)))
					goto fail;
				break;
#endif /* ALTQ */
			case PF_RULESET_TABLE:
				bzero(&table, sizeof(table));
				strlcpy(table.pfrt_anchor, ioe.anchor,
				    sizeof(table.pfrt_anchor));
				strlcpy(table.pfrt_ruleset, ioe.ruleset,
				    sizeof(table.pfrt_ruleset));
				if ((error = pfr_ina_begin(&table,
				    &ioe.ticket, NULL, 0)))
					goto fail;
				break;
			default:
				if ((error = pf_begin_rules(&ioe.ticket,
				    ioe.rs_num, ioe.anchor, ioe.ruleset)))
					goto fail;
				break;
			}
			if (copyout(&ioe, io->array+i, sizeof(io->array[i]))) {
				error = EFAULT;
				goto fail;
			}
		}
		break;
	}

	case DIOCXROLLBACK: {
		struct pfioc_trans	*io = (struct pfioc_trans *)addr;
		struct pfioc_trans_e	 ioe;
		struct pfr_table	 table;
		int			 i;

		if (io->esize != sizeof(ioe)) {
			error = ENODEV;
			goto fail;
		}
		for (i = 0; i < io->size; i++) {
			if (copyin(io->array+i, &ioe, sizeof(ioe))) {
				error = EFAULT;
				goto fail;
			}
			switch(ioe.rs_num) {
#ifdef ALTQ
			case PF_RULESET_ALTQ:
				if (ioe.anchor[0] || ioe.ruleset[0]) {
					error = EINVAL;
					goto fail;
				}
				if ((error = pf_rollback_altq(ioe.ticket)))
					goto fail; /* really bad */
				break;
#endif /* ALTQ */
			case PF_RULESET_TABLE:
				bzero(&table, sizeof(table));
				strlcpy(table.pfrt_anchor, ioe.anchor,
				    sizeof(table.pfrt_anchor));
				strlcpy(table.pfrt_ruleset, ioe.ruleset,
				    sizeof(table.pfrt_ruleset));
				if ((error = pfr_ina_rollback(&table,
				    ioe.ticket, NULL, 0)))
					goto fail; /* really bad */
				break;
			default:
				if ((error = pf_rollback_rules(ioe.ticket,
				    ioe.rs_num, ioe.anchor, ioe.ruleset)))
					goto fail; /* really bad */
				break;
			}
		}
		break;
	}

	case DIOCXCOMMIT: {
		struct pfioc_trans	*io = (struct pfioc_trans *)addr;
		struct pfioc_trans_e	 ioe;
		struct pfr_table	 table;
		struct pf_ruleset	*rs;
		int			 i;

		if (io->esize != sizeof(ioe)) {
			error = ENODEV;
			goto fail;
		}
		/* first makes sure everything will succeed */
		for (i = 0; i < io->size; i++) {
			if (copyin(io->array+i, &ioe, sizeof(ioe))) {
				error = EFAULT;
				goto fail;
			}
			switch (ioe.rs_num) {
#ifdef ALTQ
			case PF_RULESET_ALTQ:
				if (ioe.anchor[0] || ioe.ruleset[0]) {
					error = EINVAL;
					goto fail;
				}
				if (!altqs_inactive_open || ioe.ticket !=
				    ticket_altqs_inactive) {
					error = EBUSY;
					goto fail;
				}
				break;
#endif /* ALTQ */
			case PF_RULESET_TABLE:
				rs = pf_find_ruleset(ioe.anchor, ioe.ruleset);
				if (rs == NULL || !rs->topen || ioe.ticket !=
				     rs->tticket) {
					error = EBUSY;
					goto fail;
				}
				break;
			default:
				if (ioe.rs_num < 0 || ioe.rs_num >=
				    PF_RULESET_MAX) {
					error = EINVAL;
					goto fail;
				}
				rs = pf_find_ruleset(ioe.anchor, ioe.ruleset);
				if (rs == NULL ||
				    !rs->rules[ioe.rs_num].inactive.open ||
				    rs->rules[ioe.rs_num].inactive.ticket !=
				    ioe.ticket) {
					error = EBUSY;
					goto fail;
				}
				break;
			}
		}
		/* now do the commit - no errors should happen here */
		for (i = 0; i < io->size; i++) {
			if (copyin(io->array+i, &ioe, sizeof(ioe))) {
				error = EFAULT;
				goto fail;
			}
			switch (ioe.rs_num) {
#ifdef ALTQ
			case PF_RULESET_ALTQ:
				if ((error = pf_commit_altq(ioe.ticket)))
					goto fail; /* really bad */
				break;
#endif /* ALTQ */
			case PF_RULESET_TABLE:
				bzero(&table, sizeof(table));
				strlcpy(table.pfrt_anchor, ioe.anchor,
				    sizeof(table.pfrt_anchor));
				strlcpy(table.pfrt_ruleset, ioe.ruleset,
				    sizeof(table.pfrt_ruleset));
				if ((error = pfr_ina_commit(&table, ioe.ticket,
				    NULL, NULL, 0)))
					goto fail; /* really bad */
				break;
			default:
				if ((error = pf_commit_rules(ioe.ticket,
				    ioe.rs_num, ioe.anchor, ioe.ruleset)))
					goto fail; /* really bad */
				break;
			}
		}
		break;
	}

	case DIOCGETSRCNODES: {
		struct pfioc_src_nodes	*psn = (struct pfioc_src_nodes *)addr;
		struct pf_src_node	*n;
		struct pf_src_node *p, pstore;
		u_int32_t		 nr = 0;
		int			 space = psn->psn_len;

		if (space == 0) {
			s = splsoftnet();
			RB_FOREACH(n, pf_src_tree, &tree_src_tracking)
				nr++;
			splx(s);
			psn->psn_len = sizeof(struct pf_src_node) * nr;
			return (0);
		}

		s = splsoftnet();
		p = psn->psn_src_nodes;
		RB_FOREACH(n, pf_src_tree, &tree_src_tracking) {
			int	secs = time.tv_sec;

			if ((nr + 1) * sizeof(*p) > (unsigned)psn->psn_len)
				break;

			bcopy(n, &pstore, sizeof(pstore));
			if (n->rule.ptr != NULL)
				pstore.rule.nr = n->rule.ptr->nr;
			pstore.creation = secs - pstore.creation;
			if (pstore.expire > secs)
				pstore.expire -= secs;
			else
				pstore.expire = 0;
			error = copyout(&pstore, p, sizeof(*p));
			if (error) {
				splx(s);
				goto fail;
			}
			p++;
			nr++;
		}
		psn->psn_len = sizeof(struct pf_src_node) * nr;
		splx(s);
		break;
	}

	case DIOCCLRSRCNODES: {
		struct pf_src_node	*n;
		struct pf_state		*state;

		s = splsoftnet();
		RB_FOREACH(state, pf_state_tree_id, &tree_id) {
			state->src_node = NULL;
			state->nat_src_node = NULL;
		}
		RB_FOREACH(n, pf_src_tree, &tree_src_tracking) {
			n->expire = 1;
			n->states = 0;
		}
		pf_purge_expired_src_nodes();
		pf_status.src_nodes = 0;
		splx(s);
		break;
	}

	case DIOCSETHOSTID: {
		u_int32_t	*hostid = (u_int32_t *)addr;

		if (*hostid == 0) {
			error = EINVAL;
			goto fail;
		}
		pf_status.hostid = *hostid;
		break;
	}

	case DIOCOSFPFLUSH:
		s = splsoftnet();
		pf_osfp_flush();
		splx(s);
		break;

	case DIOCIGETIFACES: {
		struct pfioc_iface *io = (struct pfioc_iface *)addr;

		if (io->pfiio_esize != sizeof(struct pfi_if)) {
			error = ENODEV;
			break;
		}
		error = pfi_get_ifaces(io->pfiio_name, io->pfiio_buffer,
		    &io->pfiio_size, io->pfiio_flags);
		break;
	}

	case DIOCICLRISTATS: {
		struct pfioc_iface *io = (struct pfioc_iface *)addr;

		error = pfi_clr_istats(io->pfiio_name, &io->pfiio_nzero,
		    io->pfiio_flags);
@


1.50.4.5
log
@Merge with the trunk
@
text
@a37 2
#include "pfsync.h"

a63 2

#if NPFSYNC > 0
a64 1
#endif /* NPFSYNC > 0 */
d78 2
a79 2
struct pf_pool		*pf_get_pool(char *, u_int32_t, u_int8_t, u_int32_t,
			    u_int8_t, u_int8_t, u_int8_t);
a81 6
int			 pf_anchor_setup(struct pf_rule *,
			    const struct pf_ruleset *, const char *);
int			 pf_anchor_copyout(const struct pf_ruleset *,
			    const struct pf_rule *, struct pfioc_rule *);
void			 pf_anchor_remove(struct pf_rule *);

a88 2
int			 pf_enable_altq(struct pf_altq *);
int			 pf_disable_altq(struct pf_altq *);
d90 3
a92 3
int			 pf_begin_rules(u_int32_t *, int, const char *);
int			 pf_rollback_rules(u_int32_t, int, char *);
int			 pf_commit_rules(u_int32_t, int, char *);
a96 3
#ifdef ALTQ
static int		 pf_altq_running;
#endif
d99 1
a99 9
TAILQ_HEAD(pf_tags, pf_tagname)	pf_tags = TAILQ_HEAD_INITIALIZER(pf_tags),
				pf_qids = TAILQ_HEAD_INITIALIZER(pf_qids);

#if (PF_QNAME_SIZE != PF_TAG_NAME_SIZE)
#error PF_QNAME_SIZE must be equal to PF_TAG_NAME_SIZE
#endif
static u_int16_t	 tagname2tag(struct pf_tags *, char *);
static void		 tag2tagname(struct pf_tags *, u_int16_t, char *);
static void		 tag_unref(struct pf_tags *, u_int16_t);
d115 1
a115 1
	    &pool_allocator_nointr);
d117 1
a117 1
	    "pfpooladdrpl", &pool_allocator_nointr);
d122 2
a123 2
	pool_sethardlimit(pf_pool_limits[PF_LIMIT_STATES].pp,
	    pf_pool_limits[PF_LIMIT_STATES].limit, NULL, 0);
d126 1
a126 1
	RB_INIT(&pf_anchors);
a132 1
	TAILQ_INIT(&state_updates);
a156 1
	timeout[PFTM_TS_DIFF] = 30;			/* Allowed TS diff */
d167 1
d187 3
a189 3
pf_get_pool(char *anchor, u_int32_t ticket, u_int8_t rule_action,
    u_int32_t rule_number, u_int8_t r_last, u_int8_t active,
    u_int8_t check_ticket)
d195 1
a195 1
	ruleset = pf_find_ruleset(anchor);
d274 1
a274 1
pf_find_anchor(const char *path)
d276 2
a277 1
	static struct pf_anchor	 key;
d279 7
a285 3
	memset(&key, 0, sizeof(key));
	strlcpy(key.path, path, sizeof(key.path));
	return (RB_FIND(pf_anchor_global, &pf_anchors, &key));
d289 1
a289 1
pf_find_ruleset(const char *path)
d292 1
d294 1
a294 3
	while (*path == '/')
		path++;
	if (!*path)
d296 5
a300 1
	anchor = pf_find_anchor(path);
d303 5
d309 1
a309 1
		return (&anchor->ruleset);
d313 2
a314 1
pf_find_or_create_ruleset(const char *path)
d316 2
a317 4
	static char		 p[MAXPATHLEN];
	char			*q, *r;
	struct pf_ruleset	*ruleset;
	struct pf_anchor	*anchor, *dup, *parent = NULL;
d319 3
a321 19
	while (*path == '/')
		path++;
	ruleset = pf_find_ruleset(path);
	if (ruleset != NULL)
		return (ruleset);
	strlcpy(p, path, sizeof(p));
	while (parent == NULL && (q = strrchr(p, '/')) != NULL) {
		*q = 0;
		if ((ruleset = pf_find_ruleset(p)) != NULL) {
			parent = ruleset->anchor;
			break;
		}
	}
	if (q == NULL)
		q = p;
	else
		q++;
	strlcpy(p, path, sizeof(p));
	if (!*q)
d323 10
a332 9
	while ((r = strchr(q, '/')) != NULL || *q) {
		if (r != NULL)
			*r = 0;
		if (!*q || strlen(q) >= PF_ANCHOR_NAME_SIZE ||
		    (parent != NULL && strlen(parent->path) >=
		    MAXPATHLEN - PF_ANCHOR_NAME_SIZE - 1))
			return (NULL);
		anchor = (struct pf_anchor *)malloc(sizeof(*anchor), M_TEMP,
		    M_NOWAIT);
d335 19
a353 34
		memset(anchor, 0, sizeof(*anchor));
		RB_INIT(&anchor->children);
		strlcpy(anchor->name, q, sizeof(anchor->name));
		if (parent != NULL) {
			strlcpy(anchor->path, parent->path,
			    sizeof(anchor->path));
			strlcat(anchor->path, "/", sizeof(anchor->path));
		}
		strlcat(anchor->path, anchor->name, sizeof(anchor->path));
		if ((dup = RB_INSERT(pf_anchor_global, &pf_anchors, anchor)) !=
		    NULL) {
			printf("pf_find_or_create_ruleset: RB_INSERT1 "
			    "'%s' '%s' collides with '%s' '%s'\n",
			    anchor->path, anchor->name, dup->path, dup->name);
			free(anchor, M_TEMP);
			return (NULL);
		}
		if (parent != NULL) {
			anchor->parent = parent;
			if ((dup = RB_INSERT(pf_anchor_node, &parent->children,
			    anchor)) != NULL) {
				printf("pf_find_or_create_ruleset: "
				    "RB_INSERT2 '%s' '%s' collides with "
				    "'%s' '%s'\n", anchor->path, anchor->name,
				    dup->path, dup->name);
				RB_REMOVE(pf_anchor_global, &pf_anchors,
				    anchor);
				free(anchor, M_TEMP);
				return (NULL);
			}
		}
		pf_init_ruleset(&anchor->ruleset);
		anchor->ruleset.anchor = anchor;
		parent = anchor;
d355 1
a355 1
			q = r + 1;
d357 1
a357 1
			*q = 0;
d359 1
a359 1
	return (&anchor->ruleset);
d365 1
a365 1
	struct pf_anchor	*parent;
d368 6
a373 17
	while (ruleset != NULL) {
		if (ruleset == &pf_main_ruleset || ruleset->anchor == NULL ||
		    !RB_EMPTY(&ruleset->anchor->children) ||
		    ruleset->anchor->refcnt > 0 || ruleset->tables > 0 ||
		    ruleset->topen)
			return;
		for (i = 0; i < PF_RULESET_MAX; ++i)
			if (!TAILQ_EMPTY(ruleset->rules[i].active.ptr) ||
			    !TAILQ_EMPTY(ruleset->rules[i].inactive.ptr) ||
			    ruleset->rules[i].inactive.open)
				return;
		RB_REMOVE(pf_anchor_global, &pf_anchors, ruleset->anchor);
		if ((parent = ruleset->anchor->parent) != NULL)
			RB_REMOVE(pf_anchor_node, &parent->children,
			    ruleset->anchor);
		free(ruleset->anchor, M_TEMP);
		if (parent == NULL)
a374 3
		ruleset = &parent->ruleset;
	}
}
d376 7
a382 45
int
pf_anchor_setup(struct pf_rule *r, const struct pf_ruleset *s,
    const char *name)
{
	static char		*p, path[MAXPATHLEN];
	struct pf_ruleset	*ruleset;

	r->anchor = NULL;
	r->anchor_relative = 0;
	r->anchor_wildcard = 0;
	if (!name[0])
		return (0);
	if (name[0] == '/')
		strlcpy(path, name + 1, sizeof(path));
	else {
		/* relative path */
		r->anchor_relative = 1;
		if (s->anchor == NULL || !s->anchor->path[0])
			path[0] = 0;
		else
			strlcpy(path, s->anchor->path, sizeof(path));
		while (name[0] == '.' && name[1] == '.' && name[2] == '/') {
			if (!path[0]) {
				printf("pf_anchor_setup: .. beyond root\n");
				return (1);
			}
			if ((p = strrchr(path, '/')) != NULL)
				*p = 0;
			else
				path[0] = 0;
			r->anchor_relative++;
			name += 3;
		}
		if (path[0])
			strlcat(path, "/", sizeof(path));
		strlcat(path, name, sizeof(path));
	}
	if ((p = strrchr(path, '/')) != NULL && !strcmp(p, "/*")) {
		r->anchor_wildcard = 1;
		*p = 0;
	}
	ruleset = pf_find_or_create_ruleset(path);
	if (ruleset == NULL || ruleset->anchor == NULL) {
		printf("pf_anchor_setup: ruleset\n");
		return (1);
a383 57
	r->anchor = ruleset->anchor;
	r->anchor->refcnt++;
	return (0);
}

int
pf_anchor_copyout(const struct pf_ruleset *rs, const struct pf_rule *r,
    struct pfioc_rule *pr)
{
	pr->anchor_call[0] = 0;
	if (r->anchor == NULL)
		return (0);
	if (!r->anchor_relative) {
		strlcpy(pr->anchor_call, "/", sizeof(pr->anchor_call));
		strlcat(pr->anchor_call, r->anchor->path,
		    sizeof(pr->anchor_call));
	} else {
		char a[MAXPATHLEN], b[MAXPATHLEN], *p;
		int i;

		if (rs->anchor == NULL)
			a[0] = 0;
		else
			strlcpy(a, rs->anchor->path, sizeof(a));
		strlcpy(b, r->anchor->path, sizeof(b));
		for (i = 1; i < r->anchor_relative; ++i) {
			if ((p = strrchr(a, '/')) == NULL)
				p = a;
			*p = 0;
			strlcat(pr->anchor_call, "../",
			    sizeof(pr->anchor_call));
		}
		if (strncmp(a, b, strlen(a))) {
			printf("pf_anchor_copyout: '%s' '%s'\n", a, b);
			return (1);
		}
		strlcat(pr->anchor_call, b + (a[0] ? strlen(a) + 1 : 0),
		    sizeof(pr->anchor_call));
	}
	if (r->anchor_wildcard)
		strlcat(pr->anchor_call, "/*", sizeof(pr->anchor_call));
	return (0);
}

void
pf_anchor_remove(struct pf_rule *r)
{
	if (r->anchor == NULL)
		return;
	if (r->anchor->refcnt <= 0) {
		printf("pf_anchor_remove: broken refcount");
		r->anchor = NULL;
		return;
	}
	if (!--r->anchor->refcnt)
		pf_remove_if_empty_ruleset(&r->anchor->ruleset);
	r->anchor = NULL;
a433 5
#ifdef ALTQ
	if (rule->pqid != rule->qid)
		pf_qid_unref(rule->pqid);
	pf_qid_unref(rule->qid);
#endif
a440 1
	pf_anchor_remove(rule);
d445 2
a446 2
static	u_int16_t
tagname2tag(struct pf_tags *head, char *tagname)
d451 1
a451 1
	TAILQ_FOREACH(tag, head, entries)
d464 2
a465 2
	if (!TAILQ_EMPTY(head))
		for (p = TAILQ_FIRST(head); p != NULL &&
d485 1
a485 1
		TAILQ_INSERT_TAIL(head, tag, entries);
d490 2
a491 2
static	void
tag2tagname(struct pf_tags *head, u_int16_t tagid, char *p)
d495 1
a495 1
	TAILQ_FOREACH(tag, head, entries)
d502 2
a503 2
static	void
tag_unref(struct pf_tags *head, u_int16_t tag)
d510 1
a510 1
	for (p = TAILQ_FIRST(head); p != NULL; p = next) {
d514 1
a514 1
				TAILQ_REMOVE(head, p, entries);
a521 18
u_int16_t
pf_tagname2tag(char *tagname)
{
	return (tagname2tag(&pf_tags, tagname));
}

void
pf_tag2tagname(u_int16_t tagid, char *p)
{
	return (tag2tagname(&pf_tags, tagid, p));
}

void
pf_tag_unref(u_int16_t tag)
{
	return (tag_unref(&pf_tags, tag));
}

a522 18
u_int32_t
pf_qname2qid(char *qname)
{
	return ((u_int32_t)tagname2tag(&pf_qids, qname));
}

void
pf_qid2qname(u_int32_t qid, char *p)
{
	return (tag2tagname(&pf_qids, (u_int16_t)qid, p));
}

void
pf_qid_unref(u_int32_t qid)
{
	return (tag_unref(&pf_qids, (u_int16_t)qid));
}

d535 1
a535 2
		} else
			pf_qid_unref(altq->qid);
d559 1
a559 2
		} else
			pf_qid_unref(altq->qid);
d571 2
d590 1
a590 3
			if (error == 0 && pf_altq_running)
				error = pf_enable_altq(altq);
			if (error != 0) {
a601 2
			if (pf_altq_running)
				error = pf_disable_altq(altq);
d608 1
a608 2
		} else
			pf_qid_unref(altq->qid);
d613 10
a625 55

int
pf_enable_altq(struct pf_altq *altq)
{
	struct ifnet		*ifp;
	struct tb_profile	 tb;
	int			 s, error = 0;

	if ((ifp = ifunit(altq->ifname)) == NULL)
		return (EINVAL);

	if (ifp->if_snd.altq_type != ALTQT_NONE)
		error = altq_enable(&ifp->if_snd);

	/* set tokenbucket regulator */
	if (error == 0 && ifp != NULL && ALTQ_IS_ENABLED(&ifp->if_snd)) {
		tb.rate = altq->ifbandwidth;
		tb.depth = altq->tbrsize;
		s = splimp();
		error = tbr_set(&ifp->if_snd, &tb);
		splx(s);
	}

	return (error);
}

int
pf_disable_altq(struct pf_altq *altq)
{
	struct ifnet		*ifp;
	struct tb_profile	 tb;
	int			 s, error;

	if ((ifp = ifunit(altq->ifname)) == NULL)
		return (EINVAL);

	/*
	 * when the discipline is no longer referenced, it was overridden
	 * by a new one.  if so, just return.
	 */
	if (altq->altq_disc != ifp->if_snd.altq_disc)
		return (0);

	error = altq_disable(&ifp->if_snd);

	if (error == 0) {
		/* clear tokenbucket regulator */
		tb.rate = 0;
		s = splimp();
		error = tbr_set(&ifp->if_snd, &tb);
		splx(s);
	}

	return (error);
}
d629 1
a629 1
pf_begin_rules(u_int32_t *ticket, int rs_num, const char *anchor)
d636 1
a636 1
	rs = pf_find_or_create_ruleset(anchor);
d647 1
a647 1
pf_rollback_rules(u_int32_t ticket, int rs_num, char *anchor)
d654 1
a654 1
	rs = pf_find_ruleset(anchor);
d665 1
a665 1
pf_commit_rules(u_int32_t ticket, int rs_num, char *anchor)
d669 1
a669 1
	struct pf_rulequeue	*old_rules;
d674 1
a674 1
	rs = pf_find_ruleset(anchor);
d679 6
d700 1
d733 2
d780 2
d816 6
d823 5
a828 4
			if (pf_status.stateid == 0) {
				pf_status.stateid = time.tv_sec;
				pf_status.stateid = pf_status.stateid << 32;
			}
a837 1
			pf_status.since = time.tv_sec;
a844 1
		pr->anchor[sizeof(pr->anchor) - 1] = 0;
d846 1
a846 1
		    pr->rule.action), pr->anchor);
d857 1
a857 2
		pr->anchor[sizeof(pr->anchor) - 1] = 0;
		ruleset = pf_find_ruleset(pr->anchor);
d867 4
a924 13
#ifdef ALTQ
		/* set queue IDs */
		if (rule->qname[0] != 0) {
			if ((rule->qid = pf_qname2qid(rule->qname)) == 0)
				error = EBUSY;
			else if (rule->pqname[0] != 0) {
				if ((rule->pqid =
				    pf_qname2qid(rule->pqname)) == 0)
					error = EBUSY;
			} else
				rule->pqid = rule->qid;
		}
#endif
a941 2
		if (pf_anchor_setup(rule, ruleset, pr->anchor_call))
			error = EINVAL;
d948 1
a948 1
		    (rule->action == PF_BINAT)) && rule->anchor == NULL) ||
a966 1
		pr->anchor[sizeof(pr->anchor) - 1] = 0;
d968 1
a968 1
		    pr->rule.action), pr->anchor);
d978 1
a978 2
		pr->anchor[sizeof(pr->anchor) - 1] = 0;
		ruleset = pf_find_ruleset(pr->anchor);
d1006 1
a1006 2
		pr->anchor[sizeof(pr->anchor) - 1] = 0;
		ruleset = pf_find_ruleset(pr->anchor);
a1029 5
		if (pf_anchor_copyout(ruleset, rule, pr)) {
			error = EBUSY;
			splx(s);
			break;
		}
d1063 1
a1063 1
		ruleset = pf_find_ruleset(pcr->anchor);
d1127 5
a1131 8
				if ((newrule->qid =
				    pf_qname2qid(newrule->qname)) == 0)
					error = EBUSY;
				else if (newrule->pqname[0] != 0) {
					if ((newrule->pqid =
					    pf_qname2qid(newrule->pqname)) == 0)
						error = EBUSY;
				} else
d1134 1
a1134 1
#endif /* ALTQ */
a1153 2
			if (pf_anchor_setup(newrule, ruleset, pcr->anchor_call))
				error = EINVAL;
d1160 1
a1160 1
			    !pcr->anchor[0])) &&
a1215 2
		ruleset->rules[rs_num].active.ticket++;

d1218 1
d1220 1
d1226 1
a1226 3
		struct pf_state		*state;
		struct pfioc_state_kill *psk = (struct pfioc_state_kill *)addr;
		int			 killed = 0;
d1229 2
a1230 11
		RB_FOREACH(state, pf_state_tree_id, &tree_id) {
			if (!psk->psk_ifname[0] || !strcmp(psk->psk_ifname,
			    state->u.s.kif->pfik_name)) {
				state->timeout = PFTM_PURGE;
#if NPFSYNC
				/* don't send out individual delete messages */
				state->sync_flags = PFSTATE_NOSYNC;
#endif
				killed++;
			}
		}
d1233 1
a1233 1
		psk->psk_af = killed;
d1235 1
a1235 1
		pfsync_clear_states(pf_status.hostid, psk->psk_ifname);
a1236 1
		splx(s);
d1265 1
a1265 3
			    state->ext.port)) &&
			    (!psk->psk_ifname[0] || !strcmp(psk->psk_ifname,
			    state->u.s.kif->pfik_name))) {
a1293 1
			pool_put(&pf_state_pl, state);
a1295 1
			break;
d1299 1
a1299 1
		state->rule.ptr = &pf_default_rule;
a1303 1
		state->pfsync_time = 0;
d1429 1
a1429 2
			pfi_clr_istats(pf_status.ifname, NULL,
			    PFI_FLAG_INSTANCE);
d1535 1
a1535 2
		if (pl->index < 0 || pl->index >= PF_LIMIT_MAX ||
		    pf_pool_limits[pl->index].pp == NULL) {
d1546 2
d1575 2
d1582 12
a1593 1
				error = pf_enable_altq(altq);
d1599 1
a1599 1
			pf_altq_running = 1;
d1607 3
d1615 2
a1616 2
				error = pf_disable_altq(altq);
				if (error != 0)
d1618 11
d1632 1
a1632 1
			pf_altq_running = 0;
a1664 5
			if ((altq->qid = pf_qname2qid(altq->qname)) == 0) {
				error = EBUSY;
				pool_put(&pf_altq_pl, altq);
				break;
			}
d1828 2
a1829 2
		pool = pf_get_pool(pp->anchor, pp->ticket, pp->r_action,
		    pp->r_num, 0, 1, 0);
d1846 2
a1847 2
		pool = pf_get_pool(pp->anchor, pp->ticket, pp->r_action,
		    pp->r_num, 0, 1, 1);
d1887 1
a1887 1
		ruleset = pf_find_ruleset(pca->anchor);
d1892 2
a1893 2
		pool = pf_get_pool(pca->anchor, pca->ticket, pca->r_action,
		    pca->r_num, pca->r_last, 1, 1);
d1983 27
d2012 1
a2013 1
		struct pf_anchor	*anchor;
d2015 2
a2016 2
		pr->path[sizeof(pr->path) - 1] = 0;
		if ((ruleset = pf_find_ruleset(pr->path)) == NULL) {
d2021 2
a2022 10
		if (ruleset->anchor == NULL) {
			/* XXX kludge for pf_main_ruleset */
			RB_FOREACH(anchor, pf_anchor_global, &pf_anchors)
				if (anchor->parent == NULL)
					pr->nr++;
		} else {
			RB_FOREACH(anchor, pf_anchor_node,
			    &ruleset->anchor->children)
				pr->nr++;
		}
d2028 1
a2029 1
		struct pf_anchor	*anchor;
d2032 1
a2032 2
		pr->path[sizeof(pr->path) - 1] = 0;
		if ((ruleset = pf_find_ruleset(pr->path)) == NULL) {
d2036 4
a2039 17
		pr->name[0] = 0;
		if (ruleset->anchor == NULL) {
			/* XXX kludge for pf_main_ruleset */
			RB_FOREACH(anchor, pf_anchor_global, &pf_anchors)
				if (anchor->parent == NULL && nr++ == pr->nr) {
					strlcpy(pr->name, anchor->name,
					    sizeof(pr->name));
					break;
				}
		} else {
			RB_FOREACH(anchor, pf_anchor_node,
			    &ruleset->anchor->children)
				if (nr++ == pr->nr) {
					strlcpy(pr->name, anchor->name,
					    sizeof(pr->name));
					break;
				}
d2041 1
a2041 1
		if (!pr->name[0])
d2043 2
d2290 4
a2293 5
		struct pfioc_trans		*io = (struct pfioc_trans *)
						    addr;
		static struct pfioc_trans_e	 ioe;
		static struct pfr_table		 table;
		int			 	 i;
d2304 1
a2304 1
			switch (ioe.rs_num) {
d2307 1
a2307 1
				if (ioe.anchor[0]) {
d2319 2
d2327 1
a2327 1
				    ioe.rs_num, ioe.anchor)))
d2340 4
a2343 5
		struct pfioc_trans		*io = (struct pfioc_trans *)
						    addr;
		static struct pfioc_trans_e	 ioe;
		static struct pfr_table		 table;
		int				 i;
d2354 1
a2354 1
			switch (ioe.rs_num) {
d2357 1
a2357 1
				if (ioe.anchor[0]) {
d2369 2
d2377 1
a2377 1
				    ioe.rs_num, ioe.anchor)))
d2386 5
a2390 6
		struct pfioc_trans		*io = (struct pfioc_trans *)
						    addr;
		static struct pfioc_trans_e	 ioe;
		static struct pfr_table		 table;
		struct pf_ruleset		*rs;
		int				 i;
d2405 1
a2405 1
				if (ioe.anchor[0]) {
d2417 1
a2417 1
				rs = pf_find_ruleset(ioe.anchor);
d2430 1
a2430 1
				rs = pf_find_ruleset(ioe.anchor);
d2458 2
d2466 1
a2466 1
				    ioe.rs_num, ioe.anchor)))
@


1.50.4.6
log
@sync to HEAD
@
text
@d1515 1
a1515 1
			    PF_MATCHA(psk->psk_src.neg,
d1519 1
a1519 1
			    PF_MATCHA(psk->psk_dst.neg,
@


1.49
log
@It's difficult to create a table by changing its flags.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.48 2003/01/09 18:36:48 henning Exp $ */
d955 1
@


1.48
log
@minor KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.47 2003/01/09 15:58:35 dhartmei Exp $ */
d1772 1
a1772 1
		    &io->pfrio_nadd, io->pfrio_flags);
@


1.47
log
@(whitespace) KNF, re-fold -w 80
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.46 2003/01/09 10:40:44 cedric Exp $ */
d180 1
a180 1
		return(NULL);
d220 1
a220 1
	for(i = 0; i < PF_RULESET_MAX; i++) {
@


1.46
log
@Add support for active/inactive tablesets in the kernel.
Add table definition/initialisation construct in pfctl parser.
Add and fix documentation for pf.4 and pf.conf.5.
Tested on i386 and sparc64 by myself, macppc by Daniel.
ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.45 2003/01/07 00:21:07 dhartmei Exp $ */
d827 2
a828 1
			oldrule = TAILQ_FIRST(ruleset->rules[rs_num].active.ptr);
d830 2
a831 2
			oldrule = TAILQ_LAST(ruleset->rules[rs_num].active.ptr,
			    pf_rulequeue);
d833 2
a834 1
			oldrule = TAILQ_FIRST(ruleset->rules[rs_num].active.ptr);
d906 8
a913 4
			    PF_MATCHA(psk->psk_src.not, &psk->psk_src.addr.v.a.addr,
			    &psk->psk_src.addr.v.a.mask, &st->lan.addr, st->af) &&
			    PF_MATCHA(psk->psk_dst.not, &psk->psk_dst.addr.v.a.addr,
			    &psk->psk_dst.addr.v.a.mask, &st->ext.addr, st->af) &&
d1109 1
a1109 1
				if (direction  == PF_IN) {
d1649 2
a1650 1
		PF_ACPY(&pool->counter, &pool->cur->addr.addr.v.a.addr, pca->af);
@


1.45
log
@Remove table name hashing (pass the name in each ioctl instead), and
introduce reference counting for tables, they are now automatically
created and deleted through referencing rules. Diff partly from cedric@@.
ok mcbride@@, henning@@, cedric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.44 2003/01/06 14:19:40 cedric Exp $ */
d709 2
d1760 9
d1831 25
@


1.44
log
@Move initialisation of radix table globals in pfr_initialize()
ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.43 2003/01/05 22:14:23 dhartmei Exp $ */
d367 2
a417 2
		case DIOCRWRAPTABLE:
		case DIOCRUNWRTABLE:
a445 2
		case DIOCRWRAPTABLE:
		case DIOCRUNWRTABLE:
d573 4
d798 4
d1470 5
d1554 5
a1819 17
		break;
	}

	case DIOCRWRAPTABLE: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		error = pfr_wrap_table(&io->pfrio_table, io->pfrio_buffer,
		    io->pfrio_exists ? &io->pfrio_exists : NULL,
		    io->pfrio_flags);
		break;
	}

	case DIOCRUNWRTABLE: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		error = pfr_unwrap_table(&io->pfrio_table, io->pfrio_buffer,
		    io->pfrio_flags);
@


1.43
log
@Move ifname from pf_addr to pf_addr_wrap, prepare pf_addr_wrap for table
name. ok henning@@, mcbride@@, cedric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.42 2003/01/04 00:33:49 dhartmei Exp $ */
d105 1
a105 4
	pool_init(&pfr_ktable_pl, sizeof(struct pfr_ktable), 0, 0, 0,
	    "pfr_ktable", NULL);
	pool_init(&pfr_kentry_pl, sizeof(struct pfr_kentry), 0, 0, 0,
	    "pfr_kentry", NULL);
@


1.42
log
@Remove unused pf_add_addr(), ok mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.41 2003/01/03 10:39:09 cedric Exp $ */
d899 4
a902 4
			    PF_MATCHA(psk->psk_src.not, &psk->psk_src.addr.addr,
			    &psk->psk_src.addr.mask, &st->lan.addr, st->af) &&
			    PF_MATCHA(psk->psk_dst.not, &psk->psk_dst.addr.addr,
			    &psk->psk_dst.addr.mask, &st->ext.addr, st->af) &&
d1628 1
a1628 1
		PF_ACPY(&pool->counter, &pool->cur->addr.addr.addr, pca->af);
@


1.41
log
@1) pfr_insert_kentries() cannot return ENOMEM anymore -> make it void.
2) add new PFR_FLAG_REPLACE for use by pfr_tst_addrs().
3) add new pfrio_nmatch alias to pfioc_table, set by pfr_tst_addrs().
Tested on i386, sparc64
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.40 2003/01/02 11:34:59 mcbride Exp $ */
a74 2
int			 pf_add_addr(struct pf_pool *, struct pf_pooladdr *,
			    u_int8_t);
a186 33

int
pf_add_addr(struct pf_pool *pool, struct pf_pooladdr *addr, u_int8_t af)
{
	struct pf_pooladdr	*pa;

	pa = pool_get(&pf_pooladdr_pl, PR_NOWAIT);
	if (pa == NULL) {
		return (ENOMEM);
	}
	bcopy(addr, pa, sizeof(struct pf_pooladdr));
	if (pa->ifname[0]) {
		pa->ifp = ifunit((char *)&pa->ifname);
		if (pa->ifp == NULL) {
			pool_put(&pf_pooladdr_pl, pa);
			return (EINVAL);
		}
	} else
		pa->ifp = NULL;
	if (pf_dynaddr_setup(&pa->addr.addr, af)) {
		pf_dynaddr_remove(&pa->addr.addr);
		pool_put(&pf_pooladdr_pl, pa);
		return (EBUSY);
	}
	if (TAILQ_EMPTY(&pool->list)) {
		pool->cur = pa;
		PF_ACPY(&pool->counter, &pa->addr.addr.addr, af);
	}
	TAILQ_INSERT_TAIL(&pool->list, pa, entries);

	return (0);
}

@


1.40
log
@Require a direction to be specified for rules which do routing.

ok dhartmei@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.39 2003/01/01 16:07:01 henning Exp $ */
d1841 1
a1841 1
		    io->pfrio_size, io->pfrio_flags);
@


1.39
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.38 2003/01/01 03:53:22 dhartmei Exp $ */
d607 2
d828 2
@


1.38
log
@Fix breakage from PF_RULESET_MAX increase, regress tests match again.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.37 2002/12/31 19:18:41 mcbride Exp $ */
d159 1
a159 1
	if (rs_num >= PF_RULESET_MAX) 
@


1.37
log
@Split scrub rules out from the filter rules in the kernel.
Precursor to removing rule.action from skip steps.

Also a couple of other small fixes:
- s/PF_RULESET_RULE/PF_RULESET_FILTER/
- replacement of 4 with PF_RULESET_MAX in pfvar.h struct ruleset {
- error handling in ioctl of an invalid value in rule.action
- counting evaluations and matching packets for scrub rules

ok henning@@ dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.36 2002/12/31 00:00:44 dhartmei Exp $ */
d81 1
a81 1
struct pf_ruleset	*pf_find_or_create_ruleset(char *, char *, int);
d306 1
a306 1
pf_find_or_create_ruleset(char *anchorname, char *rulesetname, int rs_num)
d358 1
d360 1
a360 9
	if (ruleset == NULL || ruleset->anchor == NULL ||
	    !TAILQ_EMPTY(ruleset->rules[0].active.ptr) ||
	    !TAILQ_EMPTY(ruleset->rules[0].inactive.ptr) ||
	    !TAILQ_EMPTY(ruleset->rules[1].active.ptr) ||
	    !TAILQ_EMPTY(ruleset->rules[1].inactive.ptr) ||
	    !TAILQ_EMPTY(ruleset->rules[2].active.ptr) ||
	    !TAILQ_EMPTY(ruleset->rules[2].inactive.ptr) ||
	    !TAILQ_EMPTY(ruleset->rules[3].active.ptr) ||
	    !TAILQ_EMPTY(ruleset->rules[3].inactive.ptr))
d362 4
d524 1
a524 2
		ruleset = pf_find_or_create_ruleset(pr->anchor,
		    pr->ruleset, rs_num);
@


1.36
log
@Use a default state table limit of 10000 entries. This is safe for all
normal configurations, and sufficient for many. You can always increase
it, if you need more concurrent states and have enough memory (65000 for
64MB RAM, for instance). Suggested earlier by henning@@. ok mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.35 2002/12/30 02:24:35 henning Exp $ */
d159 2
d227 3
d232 1
a232 3
	case PF_SCRUB:
	default:
		return (PF_RULESET_RULE);
d246 3
d534 4
d557 4
d648 4
d662 1
a662 1
		if (rs_num == PF_RULESET_RULE) {
d666 2
a667 1
		} else
d699 4
d727 4
d782 4
d1224 1
a1224 1
		    ruleset->rules[PF_RULESET_RULE].active.ptr, entries)
@


1.35
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.34 2002/12/29 20:07:34 cedric Exp $ */
d111 3
@


1.34
log
@Add support for radix tables for source and destination of PF rules.
ok dhartmei@@, mcbride@@, henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.33 2002/12/27 21:45:14 mcbride Exp $ */
d804 1
a804 1
		 	    (newrule->action == PF_BINAT) || 
@


1.33
log
@Bugfix and better error handling:
- set rpool.cur in DIOCCHANGERULE
- check to make sure rpool.list is not empty if we're doing translation
  or routing other than fastroute

ok dhartmei@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.32 2002/12/27 15:20:30 dhartmei Exp $ */
d107 4
d437 13
d473 7
d1696 129
@


1.32
log
@Initialize rt_ifp in newly allocated pf_state objects to NULL.
Solves the crashes in pf_route() with -current.
Reports from Michael Lucas and Bjorn Runaker.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.31 2002/12/23 13:15:18 mcbride Exp $ */
d574 8
a585 1
		pf_mv_pool(&pf_pabuf, &rule->rpool.list);
d776 10
d790 1
a790 1
			pf_mv_pool(&pf_pabuf, &newrule->rpool.list);
@


1.31
log
@Change from array to single pf_pabuf (no longer need multiple buffers as
we don't need the second list of addresses for DIOCCHANGE* operations)

Also get rid of a bug where DIOCBEGINADDRS clears pabuf[1] when pabuf[0]
is the one being used.

ok henning@@ dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.30 2002/12/19 16:25:51 dhartmei Exp $ */
d894 1
@


1.30
log
@Clear pf_state.nat_rule pointers when non-main nat rules are removed.
Unlike with filter rules, nat rules inside anchors might be pointed to.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.29 2002/12/18 19:40:41 dhartmei Exp $ */
d112 1
a112 2
	TAILQ_INIT(&pf_pabuf[0]);
	TAILQ_INIT(&pf_pabuf[1]);
d578 1
a578 1
		pf_mv_pool(&pf_pabuf[0], &rule->rpool.list);
d773 1
a773 1
			pf_mv_pool(&pf_pabuf[0], &newrule->rpool.list);
d777 1
a777 1
		pf_empty_pool(&pf_pabuf[0]);
d1406 1
a1406 1
		pf_empty_pool(&pf_pabuf[1]);
d1446 1
a1446 1
		TAILQ_INSERT_TAIL(&pf_pabuf[0], pa, entries);
@


1.29
log
@Store translation rule pointer in state entries, so pfctl -vsn can print
evaluation, packet, byte and state entry counters similar to -vsr. Helps
verify whether/how often translation rules are evaluated/matched.
ok frantzen@@, henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.28 2002/12/18 18:25:14 henning Exp $ */
d611 2
a612 2
		if (ruleset == &pf_main_ruleset) {
			if (rs_num == PF_RULESET_RULE)
d615 3
a617 4
			else
				RB_FOREACH(n, pf_state_tree, &tree_ext_gwy)
					n->state->nat_rule = NULL;
		}
d802 5
a806 7
			if (ruleset == &pf_main_ruleset) {
				RB_FOREACH(n, pf_state_tree, &tree_ext_gwy) {
					if (n->state->rule.ptr == oldrule)
						n->state->rule.ptr = NULL;
					if (n->state->nat_rule == oldrule)
						n->state->nat_rule = NULL;
				}
@


1.28
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.27 2002/12/18 16:28:40 dhartmei Exp $ */
d612 6
a617 2
			RB_FOREACH(n, pf_state_tree, &tree_ext_gwy)
				n->state->rule.ptr = NULL;
d804 1
a804 1
				RB_FOREACH(n, pf_state_tree, &tree_ext_gwy)
d807 3
d897 1
@


1.27
log
@Pass skip step values through ioctl interface, pfctl -vvsr shows them,
main purpose is making them regress-testable.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.26 2002/12/17 12:30:13 mcbride Exp $ */
d145 4
a148 3
	struct pf_ruleset *ruleset;
	struct pf_rule *rule;
	int rs_num;
d185 1
a185 1
	struct pf_pooladdr *pa;
d243 1
a243 1
	int i;
d257 2
a258 2
	struct pf_anchor *anchor;
	int n = -1;
d272 2
a273 2
	struct pf_anchor *anchor;
	struct pf_ruleset *ruleset;
d296 2
a297 2
	struct pf_anchor *anchor, *a;
	struct pf_ruleset *ruleset, *r;
d345 1
a345 1
	struct pf_anchor *anchor;
d371 1
a371 1
	struct pf_pooladdr *mv_pool_pa;
d382 1
a382 1
	struct pf_pooladdr *empty_pool_pa;
d405 4
a408 4
	int error = 0;
	struct pf_pooladdr *pa = NULL;
	struct pf_pool *pool = NULL;
	int s;
d490 4
a493 4
		struct pfioc_rule *pr = (struct pfioc_rule *)addr;
		struct pf_ruleset *ruleset;
		struct pf_rule *rule;
		int rs_num;
d510 4
a513 4
		struct pfioc_rule *pr = (struct pfioc_rule *)addr;
		struct pf_ruleset *ruleset;
		struct pf_rule *rule, *tail;
		int rs_num;
d588 6
a593 6
		struct pfioc_rule *pr = (struct pfioc_rule *)addr;
		struct pf_ruleset *ruleset;
		struct pf_rulequeue *old_rules;
		struct pf_rule *rule;
		struct pf_tree_node *n;
		int rs_num;
d633 4
a636 4
		struct pfioc_rule *pr = (struct pfioc_rule *)addr;
		struct pf_ruleset *ruleset;
		struct pf_rule *tail;
		int rs_num;
d657 4
a660 4
		struct pfioc_rule *pr = (struct pfioc_rule *)addr;
		struct pf_ruleset *ruleset;
		struct pf_rule *rule;
		int rs_num, i;
d695 5
a699 5
		struct pfioc_rule *pcr = (struct pfioc_rule *)addr;
		struct pf_ruleset *ruleset;
		struct pf_rule *oldrule = NULL, *newrule = NULL;
		u_int32_t nr = 0;
		int rs_num;
d797 1
a797 1
			struct pf_tree_node *n;
d834 1
a834 1
		struct pf_tree_node *n;
d846 4
a849 5
		struct pf_tree_node *n;
		struct pf_state *st;
		struct pfioc_state_kill *psk =
		    (struct pfioc_state_kill *)addr;
		int killed = 0;
d879 2
a880 2
		struct pfioc_state *ps = (struct pfioc_state *)addr;
		struct pf_state *state;
d902 4
a905 4
		struct pfioc_state *ps = (struct pfioc_state *)addr;
		struct pf_tree_node *n;
		u_int32_t nr;
		int secs;
d935 5
a939 5
		struct pfioc_states *ps = (struct pfioc_states *)addr;
		struct pf_tree_node *n;
		struct pf_state *p, pstore;
		u_int32_t nr = 0;
		int space = ps->ps_len;
d953 1
a953 1
			int secs = time.tv_sec;
d982 2
a983 2
		struct pfioc_if *pi = (struct pfioc_if *)addr;
		struct ifnet *ifp;
d1006 4
a1009 4
		u_int32_t running = pf_status.running;
		u_int32_t states = pf_status.states;
		u_int32_t since = pf_status.since;
		u_int32_t debug = pf_status.debug;
d1023 4
a1026 4
		struct pfioc_natlook *pnl = (struct pfioc_natlook *)addr;
		struct pf_state *st;
		struct pf_tree_node key;
		int direction = pnl->direction;
d1076 2
a1077 2
		struct pfioc_tm *pt = (struct pfioc_tm *)addr;
		int old;
d1091 1
a1091 1
		struct pfioc_tm *pt = (struct pfioc_tm *)addr;
d1102 1
a1102 1
		struct pfioc_limit *pl = (struct pfioc_limit *)addr;
d1113 2
a1114 2
		struct pfioc_limit *pl = (struct pfioc_limit *)addr;
		int old_limit;
d1132 2
a1133 1
		u_int32_t *level = (u_int32_t *)addr;
d1139 2
a1140 2
		struct pf_ruleset *ruleset = &pf_main_ruleset;
		struct pf_rule *rule;
d1153 3
a1155 3
		struct pf_altq *altq;
		struct ifnet *ifp;
		struct tb_profile tb;
d1185 4
a1188 4
		struct pf_altq *altq;
		struct ifnet *ifp;
		struct tb_profile tb;
		int err;
d1218 2
a1219 2
		u_int32_t *ticket = (u_int32_t *)addr;
		struct pf_altq *altq;
a1223 1

a1227 1

a1229 1

d1235 2
a1236 2
		struct pfioc_altq *pa = (struct pfioc_altq *)addr;
		struct pf_altq *altq, *a;
d1255 2
a1256 2
				if (strncmp(a->ifname, altq->ifname, IFNAMSIZ)
				    == 0 && a->qname[0] == 0) {
a1263 1

a1269 1

d1275 4
a1278 4
		u_int32_t *ticket = (u_int32_t *)addr;
		struct pf_altqqueue *old_altqs;
		struct pf_altq *altq;
		int err;
a1306 1

a1315 1

d1323 2
a1324 2
		struct pfioc_altq *pa = (struct pfioc_altq *)addr;
		struct pf_altq *altq;
d1336 3
a1338 3
		struct pfioc_altq *pa = (struct pfioc_altq *)addr;
		struct pf_altq *altq;
		u_int32_t nr;
d1367 4
a1370 4
		struct pfioc_qstats *pq = (struct pfioc_qstats *)addr;
		struct pf_altq *altq;
		u_int32_t nr;
		int nbytes;
d1400 1
a1400 1
		struct pfioc_pooladdr *pp = (struct pfioc_pooladdr *)addr;
d1408 1
a1408 1
		struct pfioc_pooladdr *pp = (struct pfioc_pooladdr *)addr;
a1442 1

d1447 1
a1447 1
		struct pfioc_pooladdr *pp = (struct pfioc_pooladdr *)addr;
d1465 2
a1466 2
		struct pfioc_pooladdr *pp = (struct pfioc_pooladdr *)addr;
		u_int32_t nr = 0;
d1493 2
a1494 2
		struct pfioc_pooladdr *pca = (struct pfioc_pooladdr *)addr;
		struct pf_pooladdr *oldpa = NULL, *newpa = NULL;
d1553 2
a1554 1
			int i = 0;
a1583 1

d1589 2
a1590 2
		struct pfioc_anchor *pa = (struct pfioc_anchor *)addr;
		struct pf_anchor *anchor;
d1599 3
a1601 3
		struct pfioc_anchor *pa = (struct pfioc_anchor *)addr;
		struct pf_anchor *anchor;
		u_int32_t nr = 0;
d1616 3
a1618 3
		struct pfioc_ruleset *pr = (struct pfioc_ruleset *)addr;
		struct pf_anchor *anchor;
		struct pf_ruleset *ruleset;
d1632 4
a1635 4
		struct pfioc_ruleset *pr = (struct pfioc_ruleset *)addr;
		struct pf_anchor *anchor;
		struct pf_ruleset *ruleset;
		u_int32_t nr = 0;
@


1.26
log
@Merge pf_nat/pf_binat/pf_rdr structs into pf_rule. Simplifies code, allows
skip steps on translation rules.

Also:
- Require a ticket for DIOCCHANGERULE operations to prevent races.
- Remove pf_compare_* functions from pf_ioctl.c. DIOCCHANGE* operations
  use a rule number, and comparisons happen in userland.

Testing and fixes from dhartmei@@ and frantzen@@

ok dhartmei@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.25 2002/12/13 21:48:30 henning Exp $ */
d659 1
a659 1
		int rs_num;
d683 6
@


1.25
log
@add pqueue and pqid to pf_rule.
this allows for a second queue on pf_rule.
assign packets with tos 0x10 (lowdelay) to this one.
if the second queue isn't specified set pqid = qid

idea dhartmei@@
ok dhartmei@@ frantzen@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.24 2002/12/12 20:24:20 aaron Exp $ */
d74 1
a74 1
			    u_int8_t, u_int8_t, u_int8_t, u_int8_t);
d77 1
a77 12
int			 pf_compare_addr_wrap(struct pf_addr_wrap *,
			    struct pf_addr_wrap *, sa_family_t);
int			 pf_compare_pool(struct pf_pool *, struct pf_pool *,
			    sa_family_t);
int			 pf_compare_rules(struct pf_rule *,
			    struct pf_rule *);
int			 pf_compare_nats(struct pf_nat *, struct pf_nat *);
int			 pf_compare_binats(struct pf_binat *,
			    struct pf_binat *);
int			 pf_compare_pooladdrs(struct pf_pooladdr *,
			    struct pf_pooladdr *, sa_family_t);
int			 pf_compare_rdrs(struct pf_rdr *, struct pf_rdr *);
d81 1
a81 1
struct pf_ruleset	*pf_find_or_create_ruleset(char *, char *);
a85 3
void			 pf_rm_nat(struct pf_natqueue *, struct pf_nat *);
void			 pf_rm_binat(struct pf_binatqueue *, struct pf_binat *);
void			 pf_rm_rdr(struct pf_rdrqueue *, struct pf_rdr *);
d99 1
a99 5
	pool_init(&pf_nat_pl, sizeof(struct pf_nat), 0, 0, 0, "pfnatpl",
	    &pool_allocator_nointr);
	pool_init(&pf_binat_pl, sizeof(struct pf_binat), 0, 0, 0, "pfbinatpl",
	    &pool_allocator_nointr);
	pool_init(&pf_rdr_pl, sizeof(struct pf_rdr), 0, 0, 0, "pfrdrpl",
a102 2
	pool_init(&pf_addr_pl, sizeof(struct pf_addr_dyn), 0, 0, 0, "pfaddr",
	    NULL);
d142 2
a143 1
    u_int8_t r_id, u_int8_t r_num, u_int8_t active, u_int8_t check_ticket)
d147 1
a147 4
	struct pf_nat *nat;
	struct pf_rdr *rdr;
	u_int32_t nr = 0;

d151 26
a176 60
	switch (r_id & PF_POOL_IDMASK) {
	case PF_POOL_RULE_RT:
		if (active) {
			if (check_ticket && ticket !=
			    ruleset->rules.active.ticket)
				break;
			if (r_id & PF_POOL_LAST)
				rule = TAILQ_LAST(ruleset->rules.active.ptr,
				    pf_rulequeue);
			else
				rule = TAILQ_FIRST(ruleset->rules.active.ptr);
		} else {
			if (check_ticket && ticket !=
			    ruleset->rules.inactive.ticket)
				break;
			if (r_id & PF_POOL_LAST)
				rule = TAILQ_LAST(ruleset->rules.inactive.ptr,
				    pf_rulequeue);
			else
				rule = TAILQ_FIRST(ruleset->rules.inactive.ptr);
		}
		if (!(r_id & PF_POOL_LAST)) {
			while ((rule != NULL) && (rule->nr < r_num))
				rule = TAILQ_NEXT(rule, entries);
		}
		if (rule == NULL)
			break;
		return(&rule->rt_pool);
		break;

	case PF_POOL_NAT_R:
		if (active) {
			if (check_ticket && ticket !=
			    ruleset->nats.active.ticket)
				break;
			if (r_id & PF_POOL_LAST)
				nat = TAILQ_LAST(ruleset->nats.active.ptr,
				    pf_natqueue);
			else
				nat = TAILQ_FIRST(ruleset->nats.active.ptr);
		} else {
			if (check_ticket && ticket !=
			    ruleset->nats.inactive.ticket)
				break;
			if (r_id & PF_POOL_LAST)
				nat = TAILQ_LAST(ruleset->nats.inactive.ptr,
				    pf_natqueue);
			else
				nat = TAILQ_FIRST(ruleset->nats.inactive.ptr);
		}
		if (!(r_id & PF_POOL_LAST)) {
			while ((nat != NULL) && (nr < r_num)) {
				nat = TAILQ_NEXT(nat, entries);
				nr++;
			}
		}
		if (nat == NULL)
			break;
		return(&nat->rpool);
		break;
d178 1
a178 32
	case PF_POOL_RDR_R:
		if (active) {
			if (check_ticket && ticket !=
			    ruleset->rdrs.active.ticket)
				break;
			if (r_id & PF_POOL_LAST)
				rdr = TAILQ_LAST(ruleset->rdrs.active.ptr,
				    pf_rdrqueue);
			else
				rdr = TAILQ_FIRST(ruleset->rdrs.active.ptr);
		} else {
			if (check_ticket && ticket !=
			    ruleset->rdrs.inactive.ticket)
				break;
			if (r_id & PF_POOL_LAST)
				rdr = TAILQ_LAST(ruleset->rdrs.inactive.ptr,
				    pf_rdrqueue);
			else
				rdr = TAILQ_FIRST(ruleset->rdrs.inactive.ptr);
		}
		if (!(r_id & PF_POOL_LAST)) {
			while ((rdr != NULL) && (nr < r_num)) {
				rdr = TAILQ_NEXT(rdr, entries);
				nr++;
			}
		}
		if (rdr == NULL)
			break;
		return(&rdr->rpool);
		break;
	}
	return (NULL);
d199 2
a200 2
	if (pf_dynaddr_setup(&pa->addr, af)) {
		pf_dynaddr_remove(&pa->addr);
d206 1
a206 1
		PF_ACPY(&pool->counter, &pa->addr.addr, af);
a212 17
int
pf_compare_addr_wrap(struct pf_addr_wrap *a, struct pf_addr_wrap *b,
    sa_family_t af)
{
	if (a->addr_dyn != NULL && b->addr_dyn != NULL) {
		if (strcmp(a->addr_dyn->ifname, b->addr_dyn->ifname))
			return (1);
	} else {
		if (a->addr_dyn != NULL || b->addr_dyn != NULL)
			return (1);
		if (PF_ANEQ(&a->addr, &b->addr, af))
			return (1);
	}
	if (PF_ANEQ(&a->mask, &b->mask, af))
		return (1);
	return (0);
}
d215 1
a215 1
pf_compare_pool(struct pf_pool *a, struct pf_pool *b, sa_family_t af)
d217 19
a235 17
	struct pf_pooladdr *pa_a, *pa_b;

	if (a->key.key32[0] != b->key.key32[0] ||
	    a->key.key32[1] != b->key.key32[1] ||
	    a->key.key32[2] != b->key.key32[2] ||
	    a->key.key32[3] != b->key.key32[3] ||
	    a->opts != b->opts)
		return(1);
	pa_a = TAILQ_FIRST(&a->list);
	pa_b = TAILQ_FIRST(&b->list);
	while (pa_a != NULL && pa_b != NULL) {
		if (pf_compare_addr_wrap(&pa_a->addr, &pa_b->addr, af))
			return (1);
		if (strcmp(pa_a->ifname, pa_b->ifname))
			return (1);
		pa_a = TAILQ_NEXT(pa_a, entries);
		pa_b = TAILQ_NEXT(pa_b, entries);
a236 132
	return (0);
}

int
pf_compare_rules(struct pf_rule *a, struct pf_rule *b)
{
	if (a->return_icmp != b->return_icmp ||
	    a->return_icmp6 != b->return_icmp6 ||
	    a->action != b->action ||
	    a->direction != b->direction ||
	    a->log != b->log ||
	    a->quick != b->quick ||
	    a->keep_state != b->keep_state ||
	    a->af != b->af ||
	    a->proto != b->proto ||
	    a->type != b->type ||
	    a->code != b->code ||
	    a->flags != b->flags ||
	    a->flagset != b->flagset ||
	    a->rule_flag != b->rule_flag ||
	    a->min_ttl != b->min_ttl ||
	    a->tos != b->tos ||
	    a->allow_opts != b->allow_opts ||
	    a->ifnot != b->ifnot)
		return (1);
	if (pf_compare_addr_wrap(&a->src.addr, &b->src.addr, a->af))
		return (1);
	if (a->src.port[0] != b->src.port[0] ||
	    a->src.port[1] != b->src.port[1] ||
	    a->src.not != b->src.not ||
	    a->src.port_op != b->src.port_op)
		return (1);
	if (pf_compare_addr_wrap(&a->dst.addr, &b->dst.addr, a->af))
		return (1);
	if (a->dst.port[0] != b->dst.port[0] ||
	    a->dst.port[1] != b->dst.port[1] ||
	    a->dst.not != b->dst.not ||
	    a->dst.port_op != b->dst.port_op)
		return (1);
	if (pf_compare_pool(&a->rt_pool, &b->rt_pool, a->af))
		return (1);
	if (strcmp(a->ifname, b->ifname) ||
	    strcmp(a->anchorname, b->anchorname) ||
	    strcmp(a->label, b->label))
		return (1);
	return (0);
}

int
pf_compare_nats(struct pf_nat *a, struct pf_nat *b)
{
	if (a->proto != b->proto ||
	    a->af != b->af ||
	    a->ifnot != b->ifnot ||
	    a->no != b->no)
		return (1);
	if (pf_compare_addr_wrap(&a->src.addr, &b->src.addr, a->af))
		return (1);
	if (a->src.port[0] != b->src.port[0] ||
	    a->src.port[1] != b->src.port[1] ||
	    a->src.not != b->src.not ||
	    a->src.port_op != b->src.port_op)
		return (1);
	if (pf_compare_addr_wrap(&a->dst.addr, &b->dst.addr, a->af))
		return (1);
	if (a->dst.port[0] != b->dst.port[0] ||
	    a->dst.port[1] != b->dst.port[1] ||
	    a->dst.not != b->dst.not ||
	    a->dst.port_op != b->dst.port_op)
		return (1);
	if (pf_compare_pool(&a->rpool, &b->rpool, a->af))
		return (1);
	if (strcmp(a->ifname, b->ifname))
		return (1);
	return (0);
}

int
pf_compare_binats(struct pf_binat *a, struct pf_binat *b)
{
	if (a->proto != b->proto ||
	    a->dnot != b->dnot ||
	    a->af != b->af ||
	    a->no != b->no)
		return (1);
	if (pf_compare_addr_wrap(&a->saddr, &b->saddr, a->af))
		return (1);
	if (PF_ANEQ(&a->saddr.mask, &b->saddr.mask, a->af))
		return (1);
	if (pf_compare_addr_wrap(&a->daddr, &b->daddr, a->af))
		return (1);
	if (PF_ANEQ(&a->daddr.mask, &b->daddr.mask, a->af))
		return (1);
	if (strcmp(a->ifname, b->ifname))
		return (1);
	return (0);
}

int
pf_compare_rdrs(struct pf_rdr *a, struct pf_rdr *b)
{
	if (a->dport != b->dport ||
	    a->dport2 != b->dport2 ||
	    a->rport != b->rport ||
	    a->proto != b->proto ||
	    a->af != b->af ||
	    a->snot != b->snot ||
	    a->dnot != b->dnot ||
	    a->ifnot != b->ifnot ||
	    a->opts != b->opts ||
	    a->no != b->no)
		return (1);
	if (pf_compare_addr_wrap(&a->saddr, &b->saddr, a->af))
		return (1);
	if (pf_compare_addr_wrap(&a->daddr, &b->daddr, a->af))
		return (1);
	if (pf_compare_pool(&a->rpool, &b->rpool, a->af))
		return (1);
	if (strcmp(a->ifname, b->ifname))
		return (1);
	return (0);
}

int
pf_compare_pooladdrs(struct pf_pooladdr *a, struct pf_pooladdr *b,
    sa_family_t af)
{
	if (pf_compare_addr_wrap(&a->addr, &b->addr, af))
		return (1);
	if (strcmp(a->ifname, b->ifname))
		return (1);
	return (0);
d242 2
d245 6
a250 16
	TAILQ_INIT(&ruleset->rules.queues[0]);
	TAILQ_INIT(&ruleset->rules.queues[1]);
	ruleset->rules.active.ptr = &ruleset->rules.queues[0];
	ruleset->rules.inactive.ptr = &ruleset->rules.queues[1];
	TAILQ_INIT(&ruleset->nats.queues[0]);
	TAILQ_INIT(&ruleset->nats.queues[1]);
	ruleset->nats.active.ptr = &ruleset->nats.queues[0];
	ruleset->nats.inactive.ptr = &ruleset->nats.queues[1];
	TAILQ_INIT(&ruleset->rdrs.queues[0]);
	TAILQ_INIT(&ruleset->rdrs.queues[1]);
	ruleset->rdrs.active.ptr = &ruleset->rdrs.queues[0];
	ruleset->rdrs.inactive.ptr = &ruleset->rdrs.queues[1];
	TAILQ_INIT(&ruleset->binats.queues[0]);
	TAILQ_INIT(&ruleset->binats.queues[1]);
	ruleset->binats.active.ptr = &ruleset->binats.queues[0];
	ruleset->binats.inactive.ptr = &ruleset->binats.queues[1];
d293 1
a293 1
pf_find_or_create_ruleset(char *anchorname, char *rulesetname)
d347 8
a354 8
	    !TAILQ_EMPTY(ruleset->rules.active.ptr) ||
	    !TAILQ_EMPTY(ruleset->rules.inactive.ptr) ||
	    !TAILQ_EMPTY(ruleset->nats.active.ptr) ||
	    !TAILQ_EMPTY(ruleset->nats.inactive.ptr) ||
	    !TAILQ_EMPTY(ruleset->rdrs.active.ptr) ||
	    !TAILQ_EMPTY(ruleset->rdrs.inactive.ptr) ||
	    !TAILQ_EMPTY(ruleset->binats.active.ptr) ||
	    !TAILQ_EMPTY(ruleset->binats.inactive.ptr))
d384 1
a384 1
		pf_dynaddr_remove(&empty_pool_pa->addr);
d395 1
a395 1
	pf_empty_pool(&rule->rt_pool.list);
d401 7
a407 858
void
pf_rm_nat(struct pf_natqueue *natqueue, struct pf_nat *nat)
{
	pf_dynaddr_remove(&nat->src.addr);
	pf_dynaddr_remove(&nat->dst.addr);
	pf_empty_pool(&nat->rpool.list);
	if (natqueue != NULL)
		TAILQ_REMOVE(natqueue, nat, entries);
	pool_put(&pf_nat_pl, nat);
}

void
pf_rm_binat(struct pf_binatqueue *binatqueue, struct pf_binat *binat)
{
	pf_dynaddr_remove(&binat->saddr);
	pf_dynaddr_remove(&binat->daddr);
	pf_dynaddr_remove(&binat->raddr);
	if (binatqueue != NULL)
		TAILQ_REMOVE(binatqueue, binat, entries);
	pool_put(&pf_binat_pl, binat);
}

void
pf_rm_rdr(struct pf_rdrqueue *rdrqueue, struct pf_rdr *rdr)
{
	pf_dynaddr_remove(&rdr->saddr);
	pf_dynaddr_remove(&rdr->daddr);
	pf_empty_pool(&rdr->rpool.list);
	if (rdrqueue != NULL)
		TAILQ_REMOVE(rdrqueue, rdr, entries);
	pool_put(&pf_rdr_pl, rdr);
}

int
pfioctl(dev_t dev, u_long cmd, caddr_t addr, int flags, struct proc *p)
{
	int error = 0;
	struct pf_pooladdr *pa = NULL;
	struct pf_pool *pool = NULL;
	int s;

	/* XXX keep in sync with switch() below */
	if (securelevel > 1)
		switch (cmd) {
		case DIOCGETRULES:
		case DIOCGETRULE:
		case DIOCGETNATS:
		case DIOCGETNAT:
		case DIOCGETBINATS:
		case DIOCGETBINAT:
		case DIOCGETRDRS:
		case DIOCGETRDR:
		case DIOCGETADDRS:
		case DIOCGETADDR:
		case DIOCGETSTATE:
		case DIOCSETSTATUSIF:
		case DIOCGETSTATUS:
		case DIOCCLRSTATUS:
		case DIOCNATLOOK:
		case DIOCSETDEBUG:
		case DIOCGETSTATES:
		case DIOCGETTIMEOUT:
		case DIOCCLRRULECTRS:
		case DIOCGETLIMIT:
		case DIOCGETALTQS:
		case DIOCGETALTQ:
		case DIOCGETQSTATS:
		case DIOCGETANCHORS:
		case DIOCGETANCHOR:
		case DIOCGETRULESETS:
		case DIOCGETRULESET:
			break;
		default:
			return (EPERM);
		}

	if (!(flags & FWRITE))
		switch (cmd) {
		case DIOCGETRULES:
		case DIOCGETRULE:
		case DIOCGETNATS:
		case DIOCGETNAT:
		case DIOCGETRDRS:
		case DIOCGETRDR:
		case DIOCGETADDRS:
		case DIOCGETADDR:
		case DIOCGETSTATE:
		case DIOCGETSTATUS:
		case DIOCGETSTATES:
		case DIOCGETTIMEOUT:
		case DIOCGETBINATS:
		case DIOCGETBINAT:
		case DIOCGETLIMIT:
		case DIOCGETALTQS:
		case DIOCGETALTQ:
		case DIOCGETQSTATS:
		case DIOCGETANCHORS:
		case DIOCGETANCHOR:
		case DIOCGETRULESETS:
		case DIOCGETRULESET:
			break;
		default:
			return (EACCES);
		}

	switch (cmd) {

	case DIOCSTART:
		if (pf_status.running)
			error = EEXIST;
		else {
			u_int32_t states = pf_status.states;
			bzero(&pf_status, sizeof(struct pf_status));
			pf_status.running = 1;
			pf_status.states = states;
			pf_status.since = time.tv_sec;
			if (status_ifp != NULL)
				strlcpy(pf_status.ifname,
				    status_ifp->if_xname, IFNAMSIZ);
			DPFPRINTF(PF_DEBUG_MISC, ("pf: started\n"));
		}
		break;

	case DIOCSTOP:
		if (!pf_status.running)
			error = ENOENT;
		else {
			pf_status.running = 0;
			DPFPRINTF(PF_DEBUG_MISC, ("pf: stopped\n"));
		}
		break;

	case DIOCBEGINRULES: {
		struct pfioc_rule *pr = (struct pfioc_rule *)addr;
		struct pf_ruleset *ruleset;
		struct pf_rule *rule;

		ruleset = pf_find_or_create_ruleset(pr->anchor, pr->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		while ((rule = TAILQ_FIRST(ruleset->rules.inactive.ptr)) !=
		    NULL)
			pf_rm_rule(ruleset->rules.inactive.ptr, rule);
		pr->ticket = ++ruleset->rules.inactive.ticket;
		break;
	}

	case DIOCADDRULE: {
		struct pfioc_rule *pr = (struct pfioc_rule *)addr;
		struct pf_ruleset *ruleset;
		struct pf_rule *rule, *tail;

		ruleset = pf_find_ruleset(pr->anchor, pr->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		if (pr->rule.anchorname[0] && ruleset != &pf_main_ruleset) {
			error = EINVAL;
			break;
		}
		if (pr->ticket != ruleset->rules.inactive.ticket) {
			error = EBUSY;
			break;
		}
		if (pr->pool_ticket != ticket_pabuf) {
			error = EBUSY;
			break;
		}
		rule = pool_get(&pf_rule_pl, PR_NOWAIT);
		if (rule == NULL) {
			error = ENOMEM;
			break;
		}
		bcopy(&pr->rule, rule, sizeof(struct pf_rule));
		rule->anchor = NULL;
		rule->ifp = NULL;
		TAILQ_INIT(&rule->rt_pool.list);
#ifndef INET
		if (rule->af == AF_INET) {
			pool_put(&pf_rule_pl, rule);
			error = EAFNOSUPPORT;
			break;
		}
#endif /* INET */
#ifndef INET6
		if (rule->af == AF_INET6) {
			pool_put(&pf_rule_pl, rule);
			error = EAFNOSUPPORT;
			break;
		}
#endif /* INET6 */
		tail = TAILQ_LAST(ruleset->rules.inactive.ptr, pf_rulequeue);
		if (tail)
			rule->nr = tail->nr + 1;
		else
			rule->nr = 0;
		if (rule->ifname[0]) {
			rule->ifp = ifunit(rule->ifname);
			if (rule->ifp == NULL) {
				pool_put(&pf_rule_pl, rule);
				error = EINVAL;
				break;
			}
		}
#ifdef ALTQ
		if (rule->qid && !rule->pqid)
			rule->pqid = rule->qid;
#endif /* ALTQ */

		if (pf_dynaddr_setup(&rule->src.addr, rule->af))
			error = EINVAL;
		if (pf_dynaddr_setup(&rule->dst.addr, rule->af))
			error = EINVAL;
		if (error) {
			pf_rm_rule(NULL, rule);
			break;
		}
		pf_mv_pool(&pf_pabuf[0], &rule->rt_pool.list);
		rule->rt_pool.cur = TAILQ_FIRST(&rule->rt_pool.list);
		rule->evaluations = rule->packets = rule->bytes = 0;
		TAILQ_INSERT_TAIL(ruleset->rules.inactive.ptr, rule, entries);
		break;
	}

	case DIOCCOMMITRULES: {
		struct pfioc_rule *pr = (struct pfioc_rule *)addr;
		struct pf_ruleset *ruleset;
		struct pf_rulequeue *old_rules;
		struct pf_rule *rule;
		struct pf_tree_node *n;

		ruleset = pf_find_ruleset(pr->anchor, pr->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		if (pr->ticket != ruleset->rules.inactive.ticket) {
			error = EBUSY;
			break;
		}

		/* Swap rules, keep the old. */
		s = splsoftnet();
		/*
		 * Rules are about to get freed, clear rule pointers in states
		 */
		if (ruleset == &pf_main_ruleset) {
			RB_FOREACH(n, pf_state_tree, &tree_ext_gwy)
				n->state->rule.ptr = NULL;
		}
		old_rules = ruleset->rules.active.ptr;
		ruleset->rules.active.ptr = ruleset->rules.inactive.ptr;
		ruleset->rules.inactive.ptr = old_rules;
		ruleset->rules.active.ticket = ruleset->rules.inactive.ticket;
		pf_calc_skip_steps(ruleset->rules.active.ptr);

		/* Purge the old rule list. */
		while ((rule = TAILQ_FIRST(old_rules)) != NULL)
			pf_rm_rule(old_rules, rule);
		pf_remove_if_empty_ruleset(ruleset);
		pf_update_anchor_rules();
		splx(s);
		break;
	}

	case DIOCGETRULES: {
		struct pfioc_rule *pr = (struct pfioc_rule *)addr;
		struct pf_ruleset *ruleset;
		struct pf_rule *tail;

		ruleset = pf_find_ruleset(pr->anchor, pr->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		s = splsoftnet();
		tail = TAILQ_LAST(ruleset->rules.active.ptr, pf_rulequeue);
		if (tail)
			pr->nr = tail->nr + 1;
		else
			pr->nr = 0;
		pr->ticket = ruleset->rules.active.ticket;
		splx(s);
		break;
	}

	case DIOCGETRULE: {
		struct pfioc_rule *pr = (struct pfioc_rule *)addr;
		struct pf_ruleset *ruleset;
		struct pf_rule *rule;

		ruleset = pf_find_ruleset(pr->anchor, pr->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		if (pr->ticket != ruleset->rules.active.ticket) {
			error = EBUSY;
			break;
		}
		s = splsoftnet();
		rule = TAILQ_FIRST(ruleset->rules.active.ptr);
		while ((rule != NULL) && (rule->nr != pr->nr))
			rule = TAILQ_NEXT(rule, entries);
		if (rule == NULL) {
			error = EBUSY;
			splx(s);
			break;
		}
		bcopy(rule, &pr->rule, sizeof(struct pf_rule));
		pf_dynaddr_copyout(&pr->rule.src.addr);
		pf_dynaddr_copyout(&pr->rule.dst.addr);
		splx(s);
		break;
	}

	case DIOCCHANGERULE: {
		struct pfioc_changerule *pcr = (struct pfioc_changerule *)addr;
		struct pf_ruleset *ruleset;
		struct pf_rule *oldrule = NULL, *newrule = NULL;
		u_int32_t nr = 0;

		if (pcr->pool_ticket != ticket_pabuf) {
			error = EBUSY;
			break;
		}

		if (pcr->action < PF_CHANGE_ADD_HEAD ||
		    pcr->action > PF_CHANGE_REMOVE) {
			error = EINVAL;
			break;
		}
		ruleset = pf_find_ruleset(pcr->anchor, pcr->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}

		if (pcr->action != PF_CHANGE_REMOVE) {
			newrule = pool_get(&pf_rule_pl, PR_NOWAIT);
			if (newrule == NULL) {
				error = ENOMEM;
				break;
			}
			bcopy(&pcr->newrule, newrule, sizeof(struct pf_rule));
			TAILQ_INIT(&newrule->rt_pool.list);
#ifndef INET
			if (newrule->af == AF_INET) {
				pool_put(&pf_rule_pl, newrule);
				error = EAFNOSUPPORT;
				break;
			}
#endif /* INET */
#ifndef INET6
			if (newrule->af == AF_INET6) {
				pool_put(&pf_rule_pl, newrule);
				error = EAFNOSUPPORT;
				break;
			}
#endif /* INET6 */
			if (newrule->ifname[0]) {
				newrule->ifp = ifunit(newrule->ifname);
				if (newrule->ifp == NULL) {
					pool_put(&pf_rule_pl, newrule);
					error = EINVAL;
					break;
				}
			} else
				newrule->ifp = NULL;

			if (pf_dynaddr_setup(&newrule->src.addr, newrule->af))
				error = EINVAL;
			if (pf_dynaddr_setup(&newrule->dst.addr, newrule->af))
				error = EINVAL;
			if (error) {
				pf_rm_rule(NULL, newrule);
				break;
			}
			pf_mv_pool(&pf_pabuf[0], &newrule->rt_pool.list);
			newrule->evaluations = newrule->packets = 0;
			newrule->bytes = 0;
		}
		pf_empty_pool(&pf_pabuf[0]);

		s = splsoftnet();

		if (pcr->action == PF_CHANGE_ADD_HEAD)
			oldrule = TAILQ_FIRST(ruleset->rules.active.ptr);
		else if (pcr->action == PF_CHANGE_ADD_TAIL)
			oldrule = TAILQ_LAST(ruleset->rules.active.ptr,
			    pf_rulequeue);
		else {
			pf_mv_pool(&pf_pabuf[0], &pcr->oldrule.rt_pool.list);
			oldrule = TAILQ_FIRST(ruleset->rules.active.ptr);
			while ((oldrule != NULL) && pf_compare_rules(oldrule,
			    &pcr->oldrule))
				oldrule = TAILQ_NEXT(oldrule, entries);
			pf_empty_pool(&pcr->oldrule.rt_pool.list);
			if (oldrule == NULL) {
				pf_rm_rule(NULL, newrule);
				error = EINVAL;
				splx(s);
				break;
			}
		}

		if (pcr->action == PF_CHANGE_REMOVE) {
			struct pf_tree_node *n;

			if (ruleset == &pf_main_ruleset) {
				RB_FOREACH(n, pf_state_tree, &tree_ext_gwy)
					if (n->state->rule.ptr == oldrule)
						n->state->rule.ptr = NULL;
			}
			pf_rm_rule(NULL, oldrule);
		} else {
			if (oldrule == NULL)
				TAILQ_INSERT_TAIL(ruleset->rules.active.ptr,
				    newrule, entries);
			else if (pcr->action == PF_CHANGE_ADD_HEAD ||
			    pcr->action == PF_CHANGE_ADD_BEFORE)
				TAILQ_INSERT_BEFORE(oldrule, newrule, entries);
			else
				TAILQ_INSERT_AFTER(ruleset->rules.active.ptr,
				    oldrule, newrule, entries);
		}

		TAILQ_FOREACH(oldrule, ruleset->rules.active.ptr, entries)
			oldrule->nr = nr++;

		pf_calc_skip_steps(ruleset->rules.active.ptr);
		pf_remove_if_empty_ruleset(ruleset);
		pf_update_anchor_rules();

		ruleset->rules.active.ticket++;
		splx(s);
		break;
	}

	case DIOCBEGINNATS: {
		struct pfioc_nat *pn = (struct pfioc_nat *)addr;
		struct pf_ruleset *ruleset;
		struct pf_nat *nat;

		ruleset = pf_find_or_create_ruleset(pn->anchor, pn->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		while ((nat = TAILQ_FIRST(ruleset->nats.inactive.ptr)) !=
		    NULL)
			pf_rm_nat(ruleset->nats.inactive.ptr, nat);
		pn->ticket = ++ruleset->nats.inactive.ticket;
		break;
	}

	case DIOCADDNAT: {
		struct pfioc_nat *pn = (struct pfioc_nat *)addr;
		struct pf_ruleset *ruleset;
		struct pf_nat *nat;

		ruleset = pf_find_ruleset(pn->anchor, pn->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		if (pn->nat.anchorname[0] && ruleset != &pf_main_ruleset) {
			error = EINVAL;
			break;
		}
		if (pn->ticket != ruleset->nats.inactive.ticket) {
			error = EBUSY;
			break;
		}
		if (pn->pool_ticket != ticket_pabuf) {
			error = EBUSY;
			break;
		}
		nat = pool_get(&pf_nat_pl, PR_NOWAIT);
		if (nat == NULL) {
			error = ENOMEM;
			break;
		}
		bcopy(&pn->nat, nat, sizeof(struct pf_nat));
		nat->anchor = NULL;
		nat->ifp = NULL;
		TAILQ_INIT(&nat->rpool.list);
#ifndef INET
		if (nat->af == AF_INET) {
			pool_put(&pf_nat_pl, nat);
			error = EAFNOSUPPORT;
			break;
		}
#endif /* INET */
#ifndef INET6
		if (nat->af == AF_INET6) {
			pool_put(&pf_nat_pl, nat);
			error = EAFNOSUPPORT;
			break;
		}
#endif /* INET6 */
		if (nat->ifname[0]) {
			nat->ifp = ifunit(nat->ifname);
			if (nat->ifp == NULL) {
				pool_put(&pf_nat_pl, nat);
				error = EINVAL;
				break;
			}
		}

		if (pf_dynaddr_setup(&nat->src.addr, nat->af))
			error = EINVAL;
		if (pf_dynaddr_setup(&nat->dst.addr, nat->af))
			error = EINVAL;
		if (error) {
			pf_rm_nat(NULL, nat);
			break;
		}
		pf_mv_pool(&pf_pabuf[0], &nat->rpool.list);
		nat->rpool.cur = TAILQ_FIRST(&nat->rpool.list);
		TAILQ_INSERT_TAIL(ruleset->nats.inactive.ptr, nat, entries);
		break;
	}

	case DIOCCOMMITNATS: {
		struct pfioc_nat *pn = (struct pfioc_nat *)addr;
		struct pf_ruleset *ruleset;
		struct pf_natqueue *old_nats;
		struct pf_nat *nat;

		ruleset = pf_find_ruleset(pn->anchor, pn->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		if (pn->ticket != ruleset->nats.inactive.ticket) {
			error = EBUSY;
			break;
		}

		/* Swap nats, keep the old. */
		s = splsoftnet();
		old_nats = ruleset->nats.active.ptr;
		ruleset->nats.active.ptr = ruleset->nats.inactive.ptr;
		ruleset->nats.inactive.ptr = old_nats;
		ruleset->nats.active.ticket = ruleset->nats.inactive.ticket;

		/* Purge the old nat list */
		while ((nat = TAILQ_FIRST(old_nats)) != NULL)
			pf_rm_nat(old_nats, nat);
		pf_remove_if_empty_ruleset(ruleset);
		pf_update_anchor_rules();
		splx(s);
		break;
	}

	case DIOCGETNATS: {
		struct pfioc_nat *pn = (struct pfioc_nat *)addr;
		struct pf_ruleset *ruleset;
		struct pf_nat *nat;

		ruleset = pf_find_ruleset(pn->anchor, pn->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		pn->nr = 0;
		s = splsoftnet();
		TAILQ_FOREACH(nat, ruleset->nats.active.ptr, entries)
			pn->nr++;
		pn->ticket = ruleset->nats.active.ticket;
		splx(s);
		break;
	}

	case DIOCGETNAT: {
		struct pfioc_nat *pn = (struct pfioc_nat *)addr;
		struct pf_ruleset *ruleset;
		struct pf_nat *nat;
		u_int32_t nr;

		ruleset = pf_find_ruleset(pn->anchor, pn->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		if (pn->ticket != ruleset->nats.active.ticket) {
			error = EBUSY;
			break;
		}
		nr = 0;
		s = splsoftnet();
		nat = TAILQ_FIRST(ruleset->nats.active.ptr);
		while ((nat != NULL) && (nr < pn->nr)) {
			nat = TAILQ_NEXT(nat, entries);
			nr++;
		}
		if (nat == NULL) {
			error = EBUSY;
			splx(s);
			break;
		}
		bcopy(nat, &pn->nat, sizeof(struct pf_nat));
		pf_dynaddr_copyout(&pn->nat.src.addr);
		pf_dynaddr_copyout(&pn->nat.dst.addr);
		splx(s);
		break;
	}

	case DIOCCHANGENAT: {
		struct pfioc_changenat *pcn = (struct pfioc_changenat *)addr;
		struct pf_ruleset *ruleset;
		struct pf_nat *oldnat = NULL, *newnat = NULL;

		if (pcn->pool_ticket != ticket_pabuf) {
			error = EBUSY;
			break;
		}

		if (pcn->action < PF_CHANGE_ADD_HEAD ||
		    pcn->action > PF_CHANGE_REMOVE) {
			error = EINVAL;
			break;
		}
		ruleset = pf_find_ruleset(pcn->anchor, pcn->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}

		if (pcn->action != PF_CHANGE_REMOVE) {
			newnat = pool_get(&pf_nat_pl, PR_NOWAIT);
			if (newnat == NULL) {
				error = ENOMEM;
				break;
			}
			bcopy(&pcn->newnat, newnat, sizeof(struct pf_nat));
			TAILQ_INIT(&newnat->rpool.list);
#ifndef INET
			if (newnat->af == AF_INET) {
				pool_put(&pf_nat_pl, newnat);
				error = EAFNOSUPPORT;
				break;
			}
#endif /* INET */
#ifndef INET6
			if (newnat->af == AF_INET6) {
				pool_put(&pf_nat_pl, newnat);
				error = EAFNOSUPPORT;
				break;
			}
#endif /* INET6 */
			if (newnat->ifname[0]) {
				newnat->ifp = ifunit(newnat->ifname);
				if (newnat->ifp == NULL) {
					pool_put(&pf_nat_pl, newnat);
					error = EINVAL;
					break;
				}
			} else
				newnat->ifp = NULL;

			if (pf_dynaddr_setup(&newnat->src.addr, newnat->af))
				error = EINVAL;
			if (pf_dynaddr_setup(&newnat->dst.addr, newnat->af))
				error = EINVAL;
			if (error) {
				pf_rm_nat(NULL, newnat);
				break;
			}
			pf_mv_pool(&pf_pabuf[0], &newnat->rpool.list);
		}
		pf_empty_pool(&pf_pabuf[0]);

		s = splsoftnet();

		if (pcn->action == PF_CHANGE_ADD_HEAD)
			oldnat = TAILQ_FIRST(ruleset->nats.active.ptr);
		else if (pcn->action == PF_CHANGE_ADD_TAIL)
			oldnat = TAILQ_LAST(ruleset->nats.active.ptr,
			    pf_natqueue);
		else {
			pf_mv_pool(&pf_pabuf[1], &pcn->oldnat.rpool.list);
			oldnat = TAILQ_FIRST(ruleset->nats.active.ptr);
			while ((oldnat != NULL) && pf_compare_nats(oldnat,
			    &pcn->oldnat))
				oldnat = TAILQ_NEXT(oldnat, entries);
			pf_empty_pool(&pcn->oldnat.rpool.list);
			if (oldnat == NULL) {
				pf_rm_nat(NULL, newnat);
				error = EINVAL;
				splx(s);
				break;
			}
		}

		if (pcn->action == PF_CHANGE_REMOVE)
			pf_rm_nat(ruleset->nats.active.ptr, oldnat);
		else {
			if (oldnat == NULL)
				TAILQ_INSERT_TAIL(ruleset->nats.active.ptr,
				    newnat, entries);
			else if (pcn->action == PF_CHANGE_ADD_HEAD ||
			    pcn->action == PF_CHANGE_ADD_BEFORE)
				TAILQ_INSERT_BEFORE(oldnat, newnat, entries);
			else
				TAILQ_INSERT_AFTER(ruleset->nats.active.ptr,
				    oldnat, newnat, entries);
		}

		pf_remove_if_empty_ruleset(ruleset);
		pf_update_anchor_rules();

		ruleset->nats.active.ticket++;
		splx(s);
		break;
	}

	case DIOCBEGINBINATS: {
		struct pfioc_binat *pb = (struct pfioc_binat *)addr;
		struct pf_ruleset *ruleset;
		struct pf_binat *binat;

		ruleset = pf_find_or_create_ruleset(pb->anchor, pb->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		while ((binat = TAILQ_FIRST(ruleset->binats.inactive.ptr)) !=
		    NULL)
			pf_rm_binat(ruleset->binats.inactive.ptr, binat);
		pb->ticket = ++ruleset->binats.inactive.ticket;
		break;
	}

	case DIOCADDBINAT: {
		struct pfioc_binat *pb = (struct pfioc_binat *)addr;
		struct pf_ruleset *ruleset;
		struct pf_binat *binat;

		ruleset = pf_find_ruleset(pb->anchor, pb->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		if (pb->binat.anchorname[0] && ruleset != &pf_main_ruleset) {
			error = EINVAL;
			break;
		}
		if (pb->ticket != ruleset->binats.inactive.ticket) {
			error = EBUSY;
			break;
		}
		binat = pool_get(&pf_binat_pl, PR_NOWAIT);
		if (binat == NULL) {
			error = ENOMEM;
			break;
		}
		bcopy(&pb->binat, binat, sizeof(struct pf_binat));
		binat->anchor = NULL;
		binat->ifp = NULL;
#ifndef INET
		if (binat->af == AF_INET) {
			pool_put(&pf_binat_pl, binat);
			error = EAFNOSUPPORT;
			break;
		}
#endif /* INET */
#ifndef INET6
		if (binat->af == AF_INET6) {
			pool_put(&pf_binat_pl, binat);
			error = EAFNOSUPPORT;
			break;
		}
#endif /* INET6 */
		if (binat->ifname[0]) {
			binat->ifp = ifunit(binat->ifname);
			if (binat->ifp == NULL) {
				pool_put(&pf_binat_pl, binat);
				error = EINVAL;
				break;
			}
		}

		if (pf_dynaddr_setup(&binat->saddr, binat->af))
			error = EINVAL;
		if (pf_dynaddr_setup(&binat->daddr, binat->af))
			error = EINVAL;
		if (pf_dynaddr_setup(&binat->raddr, binat->af))
			error = EINVAL;
		if (error) {
			pf_rm_binat(NULL, binat);
			break;
		}
		TAILQ_INSERT_TAIL(ruleset->binats.inactive.ptr, binat,
		    entries);
		break;
	}

	case DIOCCOMMITBINATS: {
		struct pfioc_binat *pb = (struct pfioc_binat *)addr;
		struct pf_ruleset *ruleset;
		struct pf_binatqueue *old_binats;
		struct pf_binat *binat;

		ruleset = pf_find_ruleset(pb->anchor, pb->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		if (pb->ticket != ruleset->binats.inactive.ticket) {
			error = EBUSY;
			break;
		}

		/* Swap binats, keep the old. */
		s = splsoftnet();
		old_binats = ruleset->binats.active.ptr;
		ruleset->binats.active.ptr = ruleset->binats.inactive.ptr;
		ruleset->binats.inactive.ptr = old_binats;
		ruleset->binats.active.ticket = ruleset->binats.inactive.ticket;

		/* Purge the old binat list */
		while ((binat = TAILQ_FIRST(old_binats)) != NULL)
			pf_rm_binat(old_binats, binat);
		pf_remove_if_empty_ruleset(ruleset);
		pf_update_anchor_rules();
		splx(s);
		break;
	}

	case DIOCGETBINATS: {
		struct pfioc_binat *pb = (struct pfioc_binat *)addr;
		struct pf_ruleset *ruleset;
		struct pf_binat *binat;

		ruleset = pf_find_ruleset(pb->anchor, pb->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		pb->nr = 0;
		s = splsoftnet();
		TAILQ_FOREACH(binat, ruleset->binats.active.ptr, entries)
			pb->nr++;
		pb->ticket = ruleset->binats.active.ticket;
		splx(s);
		break;
	}

	case DIOCGETBINAT: {
		struct pfioc_binat *pb = (struct pfioc_binat *)addr;
		struct pf_ruleset *ruleset;
		struct pf_binat *binat;
		u_int32_t nr;
d409 24
a432 19
		ruleset = pf_find_or_create_ruleset(pb->anchor, pb->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		if (pb->ticket != ruleset->binats.active.ticket) {
			error = EBUSY;
			break;
		}
		nr = 0;
		s = splsoftnet();
		binat = TAILQ_FIRST(ruleset->binats.active.ptr);
		while ((binat != NULL) && (nr < pb->nr)) {
			binat = TAILQ_NEXT(binat, entries);
			nr++;
		}
		if (binat == NULL) {
			error = EBUSY;
			splx(s);
d434 2
a436 7
		bcopy(binat, &pb->binat, sizeof(struct pf_binat));
		pf_dynaddr_copyout(&pb->binat.saddr);
		pf_dynaddr_copyout(&pb->binat.daddr);
		pf_dynaddr_copyout(&pb->binat.raddr);
		splx(s);
		break;
	}
d438 18
a455 14
	case DIOCCHANGEBINAT: {
		struct pfioc_changebinat *pcn =
		    (struct pfioc_changebinat *)addr;
		struct pf_ruleset *ruleset;
		struct pf_binat *oldbinat = NULL, *newbinat = NULL;

		if (pcn->action < PF_CHANGE_ADD_HEAD ||
		    pcn->action > PF_CHANGE_REMOVE) {
			error = EINVAL;
			break;
		}
		ruleset = pf_find_ruleset(pcn->anchor, pcn->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
d457 2
d461 1
a461 42
		if (pcn->action != PF_CHANGE_REMOVE) {
			newbinat = pool_get(&pf_binat_pl, PR_NOWAIT);
			if (newbinat == NULL) {
				error = ENOMEM;
				break;
			}
			bcopy(&pcn->newbinat, newbinat,
				sizeof(struct pf_binat));
#ifndef INET
			if (newbinat->af == AF_INET) {
				pool_put(&pf_binat_pl, newbinat);
				error = EAFNOSUPPORT;
				break;
			}
#endif /* INET */
#ifndef INET6
			if (newbinat->af == AF_INET6) {
				pool_put(&pf_binat_pl, newbinat);
				error = EAFNOSUPPORT;
				break;
			}
#endif /* INET6 */
			if (newbinat->ifname[0]) {
				newbinat->ifp = ifunit(newbinat->ifname);
				if (newbinat->ifp == NULL) {
					pool_put(&pf_binat_pl, newbinat);
					error = EINVAL;
					break;
				}
			} else
				newbinat->ifp = NULL;
			if (pf_dynaddr_setup(&newbinat->saddr, newbinat->af))
				error = EINVAL;
			if (pf_dynaddr_setup(&newbinat->daddr, newbinat->af))
				error = EINVAL;
			if (pf_dynaddr_setup(&newbinat->raddr, newbinat->af))
				error = EINVAL;
			if (error) {
				pf_rm_binat(NULL, newbinat);
				break;
			}
		}
d463 3
a465 7
		s = splsoftnet();

		if (pcn->action == PF_CHANGE_ADD_HEAD)
			oldbinat = TAILQ_FIRST(ruleset->binats.active.ptr);
		else if (pcn->action == PF_CHANGE_ADD_TAIL)
			oldbinat = TAILQ_LAST(ruleset->binats.active.ptr,
			    pf_binatqueue);
d467 9
a475 10
			oldbinat = TAILQ_FIRST(ruleset->binats.active.ptr);
			while ((oldbinat != NULL) && pf_compare_binats(oldbinat,
			    &pcn->oldbinat))
				oldbinat = TAILQ_NEXT(oldbinat, entries);
			if (oldbinat == NULL) {
				pf_rm_binat(NULL, newbinat);
				error = EINVAL;
				splx(s);
				break;
			}
d477 1
d479 3
a481 2
		if (pcn->action == PF_CHANGE_REMOVE)
			pf_rm_binat(ruleset->binats.active.ptr, oldbinat);
d483 2
a484 10
			if (oldbinat == NULL)
				TAILQ_INSERT_TAIL(ruleset->binats.active.ptr,
				    newbinat, entries);
			else if (pcn->action == PF_CHANGE_ADD_HEAD ||
			    pcn->action == PF_CHANGE_ADD_BEFORE)
				TAILQ_INSERT_BEFORE(oldbinat, newbinat,
				    entries);
			else
				TAILQ_INSERT_AFTER(ruleset->binats.active.ptr,
				    oldbinat, newbinat, entries);
a485 6

		pf_remove_if_empty_ruleset(ruleset);
		pf_update_anchor_rules();

		ruleset->binats.active.ticket++;
		splx(s);
a486 1
	}
d488 2
a489 2
	case DIOCBEGINRDRS: {
		struct pfioc_rdr *pr = (struct pfioc_rdr *)addr;
d491 2
a492 1
		struct pf_rdr *rdr;
d494 2
a495 1
		ruleset = pf_find_or_create_ruleset(pr->anchor, pr->ruleset);
d500 5
a504 4
		while ((rdr = TAILQ_FIRST(ruleset->rdrs.inactive.ptr)) !=
		    NULL)
			pf_rm_rdr(ruleset->rdrs.inactive.ptr, rdr);
		pr->ticket = ++ruleset->rdrs.inactive.ticket;
d508 2
a509 2
	case DIOCADDRDR: {
		struct pfioc_rdr *pr = (struct pfioc_rdr *)addr;
d511 2
a512 1
		struct pf_rdr *rdr;
d519 2
a520 1
		if (pr->rdr.anchorname[0] && ruleset != &pf_main_ruleset) {
d524 1
a524 1
		if (pr->ticket != ruleset->rdrs.inactive.ticket) {
d532 2
a533 2
		rdr = pool_get(&pf_rdr_pl, PR_NOWAIT);
		if (rdr == NULL) {
d537 4
a540 4
		bcopy(&pr->rdr, rdr, sizeof(struct pf_rdr));
		rdr->anchor = NULL;
		rdr->ifp = NULL;
		TAILQ_INIT(&rdr->rpool.list);
d542 2
a543 2
		if (rdr->af == AF_INET) {
			pool_put(&pf_rdr_pl, rdr);
d549 2
a550 2
		if (rdr->af == AF_INET6) {
			pool_put(&pf_rdr_pl, rdr);
d555 10
a564 4
		if (rdr->ifname[0]) {
			rdr->ifp = ifunit(rdr->ifname);
			if (rdr->ifp == NULL) {
				pool_put(&pf_rdr_pl, rdr);
d570 1
a570 1
		if (pf_dynaddr_setup(&rdr->saddr, rdr->af))
d572 1
a572 1
		if (pf_dynaddr_setup(&rdr->daddr, rdr->af))
d575 1
a575 1
			pf_rm_rdr(NULL, rdr);
d578 5
a582 3
		pf_mv_pool(&pf_pabuf[0], &rdr->rpool.list);
		rdr->rpool.cur = TAILQ_FIRST(&rdr->rpool.list);
		TAILQ_INSERT_TAIL(ruleset->rdrs.inactive.ptr, rdr, entries);
d586 2
a587 2
	case DIOCCOMMITRDRS: {
		struct pfioc_rdr *pr = (struct pfioc_rdr *)addr;
d589 4
a592 2
		struct pf_rdrqueue *old_rdrs;
		struct pf_rdr *rdr;
d599 2
a600 1
		if (pr->ticket != ruleset->rdrs.inactive.ticket) {
d605 1
a605 1
		/* Swap rdrs, keep the old. */
d607 18
a624 8
		old_rdrs = ruleset->rdrs.active.ptr;
		ruleset->rdrs.active.ptr = ruleset->rdrs.inactive.ptr;
		ruleset->rdrs.inactive.ptr = old_rdrs;
		ruleset->rdrs.active.ticket = ruleset->rdrs.inactive.ticket;

		/* Purge the old rdr list */
		while ((rdr = TAILQ_FIRST(old_rdrs)) != NULL)
			pf_rm_rdr(old_rdrs, rdr);
d631 2
a632 2
	case DIOCGETRDRS: {
		struct pfioc_rdr *pr = (struct pfioc_rdr *)addr;
d634 2
a635 1
		struct pf_rdr *rdr;
d642 1
a642 1
		pr->nr = 0;
d644 7
a650 3
		TAILQ_FOREACH(rdr, ruleset->rdrs.active.ptr, entries)
			pr->nr++;
		pr->ticket = ruleset->rdrs.active.ticket;
d655 2
a656 2
	case DIOCGETRDR: {
		struct pfioc_rdr *pr = (struct pfioc_rdr *)addr;
d658 2
a659 2
		struct pf_rdr *rdr;
		u_int32_t nr;
d666 2
a667 1
		if (pr->ticket != ruleset->rdrs.active.ticket) {
a670 1
		nr = 0;
d672 4
a675 6
		rdr = TAILQ_FIRST(ruleset->rdrs.active.ptr);
		while ((rdr != NULL) && (nr < pr->nr)) {
			rdr = TAILQ_NEXT(rdr, entries);
			nr++;
		}
		if (rdr == NULL) {
d680 3
a682 3
		bcopy(rdr, &pr->rdr, sizeof(struct pf_rdr));
		pf_dynaddr_copyout(&pr->rdr.saddr);
		pf_dynaddr_copyout(&pr->rdr.daddr);
d687 2
a688 2
	case DIOCCHANGERDR: {
		struct pfioc_changerdr *pcn = (struct pfioc_changerdr *)addr;
d690 3
a692 1
		struct pf_rdr *oldrdr = NULL, *newrdr = NULL;
d694 3
a696 1
		if (pcn->pool_ticket != ticket_pabuf) {
d701 2
a702 2
		if (pcn->action < PF_CHANGE_ADD_HEAD ||
		    pcn->action > PF_CHANGE_REMOVE) {
d706 1
a706 1
		ruleset = pf_find_ruleset(pcn->anchor, pcn->ruleset);
d711 12
d724 3
a726 3
		if (pcn->action != PF_CHANGE_REMOVE) {
			newrdr = pool_get(&pf_rdr_pl, PR_NOWAIT);
			if (newrdr == NULL) {
d730 2
a731 2
			bcopy(&pcn->newrdr, newrdr, sizeof(struct pf_rdr));
			TAILQ_INIT(&newrdr->rpool.list);
d733 2
a734 2
			if (newrdr->af == AF_INET) {
				pool_put(&pf_rdr_pl, newrdr);
d740 2
a741 2
			if (newrdr->af == AF_INET6) {
				pool_put(&pf_rdr_pl, newrdr);
d746 4
a749 4
			if (newrdr->ifname[0]) {
				newrdr->ifp = ifunit(newrdr->ifname);
				if (newrdr->ifp == NULL) {
					pool_put(&pf_rdr_pl, newrdr);
d754 1
a754 1
				newrdr->ifp = NULL;
d756 1
a756 1
			if (pf_dynaddr_setup(&newrdr->saddr, newrdr->af))
d758 1
a758 1
			if (pf_dynaddr_setup(&newrdr->daddr, newrdr->af))
d761 1
a761 1
				pf_rm_rdr(NULL, newrdr);
d764 3
a766 1
			pf_mv_pool(&pf_pabuf[0], &newrdr->rpool.list);
d772 5
a776 5
		if (pcn->action == PF_CHANGE_ADD_HEAD)
			oldrdr = TAILQ_FIRST(ruleset->rdrs.active.ptr);
		else if (pcn->action == PF_CHANGE_ADD_TAIL)
			oldrdr = TAILQ_LAST(ruleset->rdrs.active.ptr,
			    pf_rdrqueue);
d778 5
a782 8
			pf_mv_pool(&pf_pabuf[1], &pcn->oldrdr.rpool.list);
			oldrdr = TAILQ_FIRST(ruleset->rdrs.active.ptr);
			while ((oldrdr != NULL) && pf_compare_rdrs(oldrdr,
			    &pcn->oldrdr))
				oldrdr = TAILQ_NEXT(oldrdr, entries);
			pf_empty_pool(&pcn->oldrdr.rpool.list);
			if (oldrdr == NULL) {
				pf_rm_rdr(NULL, newrdr);
d789 17
a805 9
		if (pcn->action == PF_CHANGE_REMOVE)
			pf_rm_rdr(ruleset->rdrs.active.ptr, oldrdr);
		else {
			if (oldrdr == NULL)
				TAILQ_INSERT_TAIL(ruleset->rdrs.active.ptr,
				    newrdr, entries);
			else if (pcn->action == PF_CHANGE_ADD_HEAD ||
			    pcn->action == PF_CHANGE_ADD_BEFORE)
				TAILQ_INSERT_BEFORE(oldrdr, newrdr, entries);
d807 3
a809 2
				TAILQ_INSERT_AFTER(ruleset->rdrs.active.ptr,
				    oldrdr, newrdr, entries);
d812 6
d821 1
a821 1
		ruleset->rdrs.active.ticket++;
d1136 2
a1137 1
		TAILQ_FOREACH(rule, ruleset->rules.active.ptr, entries)
a1402 1
		pf_mv_pool(&pf_pabuf[0], &pf_pabuf[1]);
d1436 2
a1437 2
		if (pf_dynaddr_setup(&pa->addr, pp->af)) {
			pf_dynaddr_remove(&pa->addr);
d1453 1
a1453 1
		    pp->r_id, pp->r_num, 1, 0);
d1471 1
a1471 1
		    pp->r_id, pp->r_num, 1, 1);
d1488 1
a1488 1
		pf_dynaddr_copyout(&pp->addr.addr);
d1494 1
a1494 1
		struct pfioc_changeaddr *pca = (struct pfioc_changeaddr *)addr;
d1504 1
a1504 1
		    pca->r_id, pca->r_num, 1, 0);
d1515 1
a1515 1
			bcopy(&pca->newaddr, newpa, sizeof(struct pf_pooladdr));
d1539 2
a1540 2
			if (pf_dynaddr_setup(&newpa->addr, pca->af)) {
				pf_dynaddr_remove(&newpa->addr);
d1554 1
d1556 1
a1556 2
			while ((oldpa != NULL) && pf_compare_pooladdrs(oldpa,
			    &pca->oldaddr, pca->af))
d1558 2
d1569 1
a1569 1
			pf_dynaddr_remove(&oldpa->addr);
d1583 1
a1583 1
		PF_ACPY(&pool->counter, &pool->cur->addr.addr, pca->af);
@


1.24
log
@Pastos in pf_compare_pool(); dhartmei@@, mcbride@@ ok.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.23 2002/12/06 00:47:32 dhartmei Exp $ */
d850 4
@


1.23
log
@Introduce anchors and named rule sets, allowing to load additional rule
sets with pfctl and evaluate them from the main rule set using a new type
of rule (which will support conditional evaluation soon). Makes
maintenance of sub-rulesets simpler for pfctl and daemons.

Idea and ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.22 2002/12/01 19:56:38 henning Exp $ */
d324 3
a326 3
	    a->key.key32[0] != b->key.key32[0] ||
	    a->key.key32[0] != b->key.key32[0] ||
	    a->key.key32[0] != b->key.key32[0] ||
@


1.22
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.21 2002/12/01 19:54:32 mcbride Exp $ */
d73 2
a74 2
struct pf_pool		*pf_get_pool(u_int32_t, u_int8_t, u_int8_t,
			    u_int8_t, u_int8_t);
d89 5
d128 2
a129 8
	TAILQ_INIT(&pf_rules[0]);
	TAILQ_INIT(&pf_rules[1]);
	TAILQ_INIT(&pf_nats[0]);
	TAILQ_INIT(&pf_nats[1]);
	TAILQ_INIT(&pf_binats[0]);
	TAILQ_INIT(&pf_binats[1]);
	TAILQ_INIT(&pf_rdrs[0]);
	TAILQ_INIT(&pf_rdrs[1]);
a133 8
	pf_rules_active = &pf_rules[0];
	pf_rules_inactive = &pf_rules[1];
	pf_nats_active = &pf_nats[0];
	pf_nats_inactive = &pf_nats[1];
	pf_binats_active = &pf_binats[0];
	pf_binats_inactive = &pf_binats[1];
	pf_rdrs_active = &pf_rdrs[0];
	pf_rdrs_inactive = &pf_rdrs[1];
d161 2
a162 2
pf_get_pool(u_int32_t ticket, u_int8_t r_id, u_int8_t r_num, u_int8_t active,
    u_int8_t check_ticket)
d164 1
d170 3
d176 2
a177 1
			if (check_ticket && ticket != ticket_rules_active)
d180 1
a180 1
				rule = TAILQ_LAST(pf_rules_active,
d183 1
a183 1
				rule = TAILQ_FIRST(pf_rules_active);
d185 2
a186 1
			if (check_ticket && ticket != ticket_rules_inactive)
d189 1
a189 1
				rule = TAILQ_LAST(pf_rules_inactive,
d192 1
a192 1
				rule = TAILQ_FIRST(pf_rules_inactive);
d205 2
a206 1
			if (check_ticket && ticket != ticket_nats_active)
d209 2
a210 1
				nat = TAILQ_LAST(pf_nats_active, pf_natqueue);
d212 1
a212 1
				nat = TAILQ_FIRST(pf_nats_active);
d214 2
a215 1
			if (check_ticket && ticket != ticket_nats_inactive)
d218 2
a219 1
				nat = TAILQ_LAST(pf_nats_inactive, pf_natqueue);
d221 1
a221 1
				nat = TAILQ_FIRST(pf_nats_inactive);
d236 2
a237 1
			if (check_ticket && ticket != ticket_rdrs_active)
d240 2
a241 1
				rdr = TAILQ_LAST(pf_rdrs_active, pf_rdrqueue);
d243 1
a243 1
				rdr = TAILQ_FIRST(pf_rdrs_active);
d245 2
a246 1
			if (check_ticket && ticket != ticket_rdrs_inactive)
d249 2
a250 1
				rdr = TAILQ_LAST(pf_rdrs_inactive, pf_rdrqueue);
d252 1
a252 1
				rdr = TAILQ_FIRST(pf_rdrs_inactive);
d381 1
d473 136
a608 3
/*
 * Move the contents of poola to poolb
 */
a619 3
/*
 * Functions to clean up after ourselves.
 */
a675 1

d710 4
d739 4
d776 2
a777 1
		u_int32_t *ticket = (u_int32_t *)addr;
d780 4
a783 2
		while ((rule = TAILQ_FIRST(pf_rules_inactive)) != NULL) {
			pf_rm_rule(pf_rules_inactive, rule);
d785 4
a788 1
		*ticket = ++ticket_rules_inactive;
d794 1
d797 13
a813 1

d820 2
d837 1
a837 1
		tail = TAILQ_LAST(pf_rules_inactive, pf_rulequeue);
d849 1
a849 2
		} else
			rule->ifp = NULL;
d862 1
a862 1
		TAILQ_INSERT_TAIL(pf_rules_inactive, rule, entries);
d867 2
a868 1
		u_int32_t *ticket = (u_int32_t *)addr;
d873 6
a878 1
		if (*ticket != ticket_rules_inactive) {
d888 9
a896 8
		RB_FOREACH(n, pf_state_tree, &tree_ext_gwy)
			n->state->rule.ptr = NULL;
		old_rules = pf_rules_active;
		pf_rules_active = pf_rules_inactive;
		pf_rules_inactive = old_rules;
		ticket_rules_active = ticket_rules_inactive;
		pf_calc_skip_steps(pf_rules_active);
		splx(s);
d899 1
a899 1
		while ((rule = TAILQ_FIRST(old_rules)) != NULL) {
d901 3
a903 1
		}
d909 1
d912 5
d918 1
a918 1
		tail = TAILQ_LAST(pf_rules_active, pf_rulequeue);
d923 1
a923 1
		pr->ticket = ticket_rules_active;
d930 1
d933 6
a938 1
		if (pr->ticket != ticket_rules_active) {
d943 1
a943 1
		rule = TAILQ_FIRST(pf_rules_active);
d960 1
d974 5
d1029 1
a1029 1
			oldrule = TAILQ_FIRST(pf_rules_active);
d1031 2
a1032 1
			oldrule = TAILQ_LAST(pf_rules_active, pf_rulequeue);
d1035 1
a1035 1
			oldrule = TAILQ_FIRST(pf_rules_active);
d1051 5
a1055 3
			RB_FOREACH(n, pf_state_tree, &tree_ext_gwy)
				if (n->state->rule.ptr == oldrule)
					n->state->rule.ptr = NULL;
d1059 2
a1060 2
				TAILQ_INSERT_TAIL(pf_rules_active, newrule,
				    entries);
d1065 2
a1066 2
				TAILQ_INSERT_AFTER(pf_rules_active, oldrule,
				    newrule, entries);
d1069 1
a1069 1
		TAILQ_FOREACH(oldrule, pf_rules_active, entries)
d1072 3
a1074 1
		pf_calc_skip_steps(pf_rules_active);
d1076 1
a1076 1
		ticket_rules_active++;
d1082 2
a1083 1
		u_int32_t *ticket = (u_int32_t *)addr;
d1086 4
a1089 2
		while ((nat = TAILQ_FIRST(pf_nats_inactive)) != NULL) {
			pf_rm_nat(pf_nats_inactive, nat);
d1091 4
a1094 1
		*ticket = ++ticket_nats_inactive;
d1100 1
d1103 10
a1112 1
		if (pn->pool_ticket != ticket_pabuf) {
d1116 1
a1116 2

		if (pn->ticket != ticket_nats_inactive) {
d1126 2
d1150 1
a1150 2
		} else
			nat->ifp = NULL;
d1162 1
a1162 1
		TAILQ_INSERT_TAIL(pf_nats_inactive, nat, entries);
d1167 2
a1168 1
		u_int32_t *ticket = (u_int32_t *)addr;
d1172 6
a1177 1
		if (*ticket != ticket_nats_inactive) {
d1184 4
a1187 5
		old_nats = pf_nats_active;
		pf_nats_active = pf_nats_inactive;
		pf_nats_inactive = old_nats;
		ticket_nats_active = ticket_nats_inactive;
		splx(s);
d1190 1
a1190 1
		while ((nat = TAILQ_FIRST(old_nats)) != NULL) {
d1192 3
a1194 1
		}
d1200 1
d1203 5
d1210 1
a1210 1
		TAILQ_FOREACH(nat, pf_nats_active, entries)
d1212 1
a1212 1
		pn->ticket = ticket_nats_active;
d1219 1
d1223 6
a1228 1
		if (pn->ticket != ticket_nats_active) {
d1234 1
a1234 1
		nat = TAILQ_FIRST(pf_nats_active);
d1253 1
d1266 5
d1319 1
a1319 1
			oldnat = TAILQ_FIRST(pf_nats_active);
d1321 2
a1322 1
			oldnat = TAILQ_LAST(pf_nats_active, pf_natqueue);
d1325 1
a1325 1
			oldnat = TAILQ_FIRST(pf_nats_active);
d1338 3
a1340 3
		if (pcn->action == PF_CHANGE_REMOVE) {
			pf_rm_nat(pf_nats_active, oldnat);
		} else {
d1342 2
a1343 2
				TAILQ_INSERT_TAIL(pf_nats_active, newnat,
				    entries);
d1348 2
a1349 2
				TAILQ_INSERT_AFTER(pf_nats_active, oldnat,
				    newnat, entries);
d1352 4
a1355 1
		ticket_nats_active++;
d1361 2
a1362 1
		u_int32_t *ticket = (u_int32_t *)addr;
d1365 4
a1368 2
		while ((binat = TAILQ_FIRST(pf_binats_inactive)) != NULL) {
			pf_rm_binat(pf_binats_inactive, binat);
d1370 4
a1373 1
		*ticket = ++ticket_binats_inactive;
d1379 1
d1382 10
a1391 1
		if (pb->ticket != ticket_binats_inactive) {
d1401 2
d1424 2
a1425 2
		} else
			binat->ifp = NULL;
d1436 2
a1437 1
		TAILQ_INSERT_TAIL(pf_binats_inactive, binat, entries);
d1442 2
a1443 1
		u_int32_t *ticket = (u_int32_t *)addr;
d1447 6
a1452 1
		if (*ticket != ticket_binats_inactive) {
d1459 4
a1462 5
		old_binats = pf_binats_active;
		pf_binats_active = pf_binats_inactive;
		pf_binats_inactive = old_binats;
		ticket_binats_active = ticket_binats_inactive;
		splx(s);
d1465 1
a1465 1
		while ((binat = TAILQ_FIRST(old_binats)) != NULL) {
d1467 3
a1469 1
		}
d1475 1
d1478 5
d1485 1
a1485 1
		TAILQ_FOREACH(binat, pf_binats_active, entries)
d1487 1
a1487 1
		pb->ticket = ticket_binats_active;
d1494 1
d1498 6
a1503 1
		if (pb->ticket != ticket_binats_active) {
d1509 1
a1509 1
		binat = TAILQ_FIRST(pf_binats_active);
d1528 3
a1530 1
		struct pfioc_changebinat *pcn = (struct pfioc_changebinat *)addr;
d1538 5
d1590 1
a1590 1
			oldbinat = TAILQ_FIRST(pf_binats_active);
d1592 2
a1593 1
			oldbinat = TAILQ_LAST(pf_binats_active, pf_binatqueue);
d1595 1
a1595 1
			oldbinat = TAILQ_FIRST(pf_binats_active);
d1607 3
a1609 3
		if (pcn->action == PF_CHANGE_REMOVE) {
			pf_rm_binat(pf_binats_active, oldbinat);
		} else {
d1611 2
a1612 2
				TAILQ_INSERT_TAIL(pf_binats_active, newbinat,
				    entries);
d1618 2
a1619 2
				TAILQ_INSERT_AFTER(pf_binats_active, oldbinat,
				    newbinat, entries);
d1622 4
a1625 1
		ticket_binats_active++;
d1631 2
a1632 1
		u_int32_t *ticket = (u_int32_t *)addr;
d1635 4
a1638 2
		while ((rdr = TAILQ_FIRST(pf_rdrs_inactive)) != NULL) {
			pf_rm_rdr(pf_rdrs_inactive, rdr);
d1640 4
a1643 1
		*ticket = ++ticket_rdrs_inactive;
d1649 1
d1652 10
a1661 1
		if (pr->pool_ticket != ticket_pabuf) {
d1665 1
a1665 2

		if (pr->ticket != ticket_rdrs_inactive) {
d1675 2
d1699 1
a1699 2
		} else
			rdr->ifp = NULL;
d1711 1
a1711 1
		TAILQ_INSERT_TAIL(pf_rdrs_inactive, rdr, entries);
d1716 2
a1717 1
		u_int32_t *ticket = (u_int32_t *)addr;
d1721 6
a1726 1
		if (*ticket != ticket_rdrs_inactive) {
d1733 4
a1736 5
		old_rdrs = pf_rdrs_active;
		pf_rdrs_active = pf_rdrs_inactive;
		pf_rdrs_inactive = old_rdrs;
		ticket_rdrs_active = ticket_rdrs_inactive;
		splx(s);
d1739 1
a1739 1
		while ((rdr = TAILQ_FIRST(old_rdrs)) != NULL) {
d1741 3
a1743 1
		}
d1749 1
d1752 5
d1759 1
a1759 1
		TAILQ_FOREACH(rdr, pf_rdrs_active, entries)
d1761 1
a1761 1
		pr->ticket = ticket_rdrs_active;
d1768 1
d1772 6
a1777 1
		if (pr->ticket != ticket_rdrs_active) {
d1783 1
a1783 1
		rdr = TAILQ_FIRST(pf_rdrs_active);
d1802 1
d1815 5
d1858 1
a1858 1
				pf_rm_rdr(pf_rdrs_inactive, newrdr);
d1868 1
a1868 1
			oldrdr = TAILQ_FIRST(pf_rdrs_active);
d1870 2
a1871 1
			oldrdr = TAILQ_LAST(pf_rdrs_active, pf_rdrqueue);
d1874 1
a1874 1
			oldrdr = TAILQ_FIRST(pf_rdrs_active);
d1887 3
a1889 3
		if (pcn->action == PF_CHANGE_REMOVE) {
			pf_rm_rdr(pf_rdrs_active, oldrdr);
		} else {
d1891 2
a1892 2
				TAILQ_INSERT_TAIL(pf_rdrs_active, newrdr,
				    entries);
d1897 2
a1898 2
				TAILQ_INSERT_AFTER(pf_rdrs_active, oldrdr,
				    newrdr, entries);
d1901 4
a1904 1
		ticket_rdrs_active++;
d2070 2
a2071 1
				strlcpy(pf_status.ifname, ifp->if_xname, IFNAMSIZ);
d2215 1
d2219 1
a2219 1
		TAILQ_FOREACH(rule, pf_rules_active, entries)
d2482 1
a2482 1
		u_int32_t *ticket = (u_int32_t *)addr;
d2486 1
a2486 3

		*ticket = ++ticket_pabuf;

d2535 2
a2536 1
		pool = pf_get_pool(pp->ticket, pp->r_id, pp->r_num, 1, 0);
d2553 2
a2554 1
		pool = pf_get_pool(pp->ticket, pp->r_id, pp->r_num, 1, 1);
d2586 2
a2587 1
		pool = pf_get_pool(0, pca->r_id, pca->r_num, 1, 0);
d2667 65
@


1.21
log
@- Clean up pf_ioctl mainly by adding new functions to handle cleaning and
  freeing rules. Fixes a number of potential memory leaks and other bugs.
- Add new pool_ticket to insure that address pools don't get messed
  with by someone else while we add rules.
- Add a second address pool buffer, so that DIOCCHANGE* operations which use
  pf_compare* will work correctly.

Excellent bug report and anaylsis from DJ Gregor.

ok dhartmei@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.20 2002/11/29 13:03:24 mcbride Exp $ */
d473 1
a473 1
	struct pf_pooladdr *mv_pool_pa; 
d497 1
a497 1
pf_rm_rule(struct pf_rulequeue *rulequeue, struct pf_rule *rule) 
d504 1
a504 1
	pool_put(&pf_rule_pl, rule); 
d515 1
a515 1
	pool_put(&pf_nat_pl, nat); 
@


1.20
log
@Get the address pool in DIOCCHANGEADDR for all operations, prevents
PF_CHANGE_REMOVE from dereferencing a NULL pointer.

Noticed by dhartmei@@

ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.19 2002/11/26 03:44:53 kjc Exp $ */
d89 6
d97 1
a97 1
extern struct timeout          pf_expire_to;
d133 2
a134 1
	TAILQ_INIT(&pf_pabuf);
d467 74
d637 1
a637 9
			TAILQ_REMOVE(pf_rules_inactive, rule, entries);
			pf_dynaddr_remove(&rule->src.addr);
			pf_dynaddr_remove(&rule->dst.addr);
			while ((pa = TAILQ_FIRST(&rule->rt_pool.list)) != NULL) {
				pf_dynaddr_remove(&pa->addr);
				TAILQ_REMOVE(&rule->rt_pool.list, pa, entries);
				pool_put(&pf_pooladdr_pl, pa);
			}
			pool_put(&pf_rule_pl, rule);
d647 5
d693 1
a693 3
			pf_dynaddr_remove(&rule->src.addr);
			pf_dynaddr_remove(&rule->dst.addr);
			pool_put(&pf_rule_pl, rule);
d696 1
a696 4
		while ((pa = TAILQ_FIRST(&pf_pabuf)) != NULL) {
			TAILQ_REMOVE(&pf_pabuf, pa, entries);
			TAILQ_INSERT_TAIL(&rule->rt_pool.list, pa, entries);
		}
d730 1
a730 9
			TAILQ_REMOVE(old_rules, rule, entries);
			pf_dynaddr_remove(&rule->src.addr);
			pf_dynaddr_remove(&rule->dst.addr);
			while ((pa = TAILQ_FIRST(&rule->rt_pool.list)) != NULL) {
				pf_dynaddr_remove(&pa->addr);
				TAILQ_REMOVE(&rule->rt_pool.list, pa, entries);
				pool_put(&pf_pooladdr_pl, pa);
			}
			pool_put(&pf_rule_pl, rule);
d779 5
d827 1
a827 3
				pf_dynaddr_remove(&newrule->src.addr);
				pf_dynaddr_remove(&newrule->dst.addr);
				pool_put(&pf_rule_pl, newrule);
d830 1
a830 5
			while ((pa = TAILQ_FIRST(&pf_pabuf)) != NULL) {
				TAILQ_REMOVE(&pf_pabuf, pa, entries);
				TAILQ_INSERT_TAIL(&newrule->rt_pool.list,
				    pa, entries);
			}
d834 1
d843 1
d848 1
d850 1
d863 1
a863 11
			TAILQ_REMOVE(pf_rules_active, oldrule, entries);
			pf_dynaddr_remove(&oldrule->src.addr);
			pf_dynaddr_remove(&oldrule->dst.addr);
			while ((pa =
			    TAILQ_FIRST(&oldrule->rt_pool.list)) != NULL) {
				pf_dynaddr_remove(&pa->addr);
				TAILQ_REMOVE(&oldrule->rt_pool.list,
				    pa, entries);
				pool_put(&pf_pooladdr_pl, pa);
			}
			pool_put(&pf_rule_pl, oldrule);
d891 1
a891 10
			pf_dynaddr_remove(&nat->src.addr);
			pf_dynaddr_remove(&nat->dst.addr);
			while ((pa = TAILQ_FIRST(&nat->rpool.list)) != NULL) {
				pf_dynaddr_remove(&pa->addr);
				TAILQ_REMOVE(&nat->rpool.list,
				    pa, entries);
				pool_put(&pf_pooladdr_pl, pa);
			}
			TAILQ_REMOVE(pf_nats_inactive, nat, entries);
			pool_put(&pf_nat_pl, nat);
d901 5
d946 1
a946 3
			pf_dynaddr_remove(&nat->src.addr);
			pf_dynaddr_remove(&nat->dst.addr);
			pool_put(&pf_nat_pl, nat);
d949 1
a949 4
		while ((pa = TAILQ_FIRST(&pf_pabuf)) != NULL) {
			TAILQ_REMOVE(&pf_pabuf, pa, entries);
			TAILQ_INSERT_TAIL(&nat->rpool.list, pa, entries);
		}
d975 1
a975 9
			pf_dynaddr_remove(&nat->src.addr);
			pf_dynaddr_remove(&nat->dst.addr);
			while ((pa = TAILQ_FIRST(&nat->rpool.list)) != NULL) {
				pf_dynaddr_remove(&pa->addr);
				TAILQ_REMOVE(&nat->rpool.list, pa, entries);
				pool_put(&pf_pooladdr_pl, pa);
			}
			TAILQ_REMOVE(old_nats, nat, entries);
			pool_put(&pf_nat_pl, nat);
d1025 5
d1073 1
a1073 3
				pf_dynaddr_remove(&newnat->src.addr);
				pf_dynaddr_remove(&newnat->dst.addr);
				pool_put(&pf_nat_pl, newnat);
d1076 1
a1076 5
			while ((pa = TAILQ_FIRST(&pf_pabuf)) != NULL) {
				TAILQ_REMOVE(&pf_pabuf, pa, entries);
				TAILQ_INSERT_TAIL(&newnat->rpool.list,
				    pa, entries);
			}
d1078 1
d1087 1
d1092 1
d1094 1
d1102 1
a1102 10
			pf_dynaddr_remove(&oldnat->src.addr);
			pf_dynaddr_remove(&oldnat->dst.addr);
			while ((pa =
			    TAILQ_FIRST(&oldnat->rpool.list)) != NULL) {
				pf_dynaddr_remove(&pa->addr);
				TAILQ_REMOVE(&oldnat->rpool.list, pa, entries);
				pool_put(&pf_pooladdr_pl, pa);
			}
			TAILQ_REMOVE(pf_nats_active, oldnat, entries);
			pool_put(&pf_nat_pl, oldnat);
d1125 1
a1125 5
			TAILQ_REMOVE(pf_binats_inactive, binat, entries);
			pf_dynaddr_remove(&binat->saddr);
			pf_dynaddr_remove(&binat->daddr);
			pf_dynaddr_remove(&binat->raddr);
			pool_put(&pf_binat_pl, binat);
d1172 2
d1175 1
a1175 4
			pf_dynaddr_remove(&binat->saddr);
			pf_dynaddr_remove(&binat->daddr);
			pf_dynaddr_remove(&binat->raddr);
			pool_put(&pf_binat_pl, binat);
d1202 1
a1202 5
			TAILQ_REMOVE(old_binats, binat, entries);
			pf_dynaddr_remove(&binat->saddr);
			pf_dynaddr_remove(&binat->daddr);
			pf_dynaddr_remove(&binat->raddr);
			pool_put(&pf_binat_pl, binat);
d1297 1
a1297 4
				pf_dynaddr_remove(&newbinat->saddr);
				pf_dynaddr_remove(&newbinat->daddr);
				pf_dynaddr_remove(&newbinat->raddr);
				pool_put(&pf_binat_pl, newbinat);
d1314 1
d1322 1
a1322 5
			TAILQ_REMOVE(pf_binats_active, oldbinat, entries);
			pf_dynaddr_remove(&oldbinat->saddr);
			pf_dynaddr_remove(&oldbinat->daddr);
			pf_dynaddr_remove(&oldbinat->raddr);
			pool_put(&pf_binat_pl, oldbinat);
d1346 1
a1346 9
			TAILQ_REMOVE(pf_rdrs_inactive, rdr, entries);
			pf_dynaddr_remove(&rdr->saddr);
			pf_dynaddr_remove(&rdr->daddr);
			while ((pa = TAILQ_FIRST(&rdr->rpool.list)) != NULL) {
				pf_dynaddr_remove(&pa->addr);
				TAILQ_REMOVE(&rdr->rpool.list, pa, entries);
				pool_put(&pf_pooladdr_pl, pa);
			}
			pool_put(&pf_rdr_pl, rdr);
d1356 5
d1401 1
a1401 3
			pf_dynaddr_remove(&rdr->saddr);
			pf_dynaddr_remove(&rdr->daddr);
			pool_put(&pf_rdr_pl, rdr);
d1404 1
a1404 4
		while ((pa = TAILQ_FIRST(&pf_pabuf)) != NULL) {
			TAILQ_REMOVE(&pf_pabuf, pa, entries);
			TAILQ_INSERT_TAIL(&rdr->rpool.list, pa, entries);
		}
d1430 1
a1430 9
			TAILQ_REMOVE(old_rdrs, rdr, entries);
			pf_dynaddr_remove(&rdr->saddr);
			pf_dynaddr_remove(&rdr->daddr);
			while ((pa = TAILQ_FIRST(&rdr->rpool.list)) != NULL) {
				pf_dynaddr_remove(&pa->addr);
				TAILQ_REMOVE(&rdr->rpool.list, pa, entries);
				pool_put(&pf_pooladdr_pl, pa);
			}
			pool_put(&pf_rdr_pl, rdr);
d1480 5
d1528 1
a1528 3
				pf_dynaddr_remove(&newrdr->saddr);
				pf_dynaddr_remove(&newrdr->daddr);
				pool_put(&pf_rdr_pl, newrdr);
d1531 1
a1531 5
			while ((pa = TAILQ_FIRST(&pf_pabuf)) != NULL) {
				TAILQ_REMOVE(&pf_pabuf, pa, entries);
				TAILQ_INSERT_TAIL(&newrdr->rpool.list,
				    pa, entries);
			}
d1533 1
d1542 1
d1547 1
d1549 1
d1557 1
a1557 10
			TAILQ_REMOVE(pf_rdrs_active, oldrdr, entries);
			pf_dynaddr_remove(&oldrdr->saddr);
			pf_dynaddr_remove(&oldrdr->daddr);
			while ((pa =
			    TAILQ_FIRST(&oldrdr->rpool.list)) != NULL) {
				pf_dynaddr_remove(&pa->addr);
				TAILQ_REMOVE(&oldrdr->rpool.list, pa, entries);
				pool_put(&pf_pooladdr_pl, pa);
			}
			pool_put(&pf_rdr_pl, oldrdr);
d2148 3
a2150 5
		while ((pa = TAILQ_FIRST(&pf_pabuf)) != NULL) {
			pf_dynaddr_remove(&pa->addr);
			TAILQ_REMOVE(&pf_pabuf, pa, entries);
			pool_put(&pf_pooladdr_pl, pa);
		}
d2191 1
a2191 1
		TAILQ_INSERT_TAIL(&pf_pabuf, pa, entries);
@


1.19
log
@fix "pfctl -Fq".
after altq gets flushed, altq forgot that it was enabled since
altq is actually detached with an empty ruleset.
so, add a variable, pfaltq_running, to remember the running state
and re-enable altq when a new ruleset is loaded.

noticed, tested, and oked by henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.18 2002/11/23 09:37:02 deraadt Exp $ */
d2254 5
a2259 5
			pool = pf_get_pool(0, pca->r_id, pca->r_num, 1, 0);
			if (pool == NULL) {
				error = EBUSY;
				break;
			}
@


1.18
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.17 2002/11/23 05:16:58 mcbride Exp $ */
d1918 2
d1951 2
@


1.17
log
@kernel code to allow multiple redirection addresses to be specified for nat
and rdr, as well as route-to, dup-to and reply-to.

Addresses can be allocated in a number of ways:
- masking out the network portion of the address and replacing it
- randomly assigning an address in the block
- hashing the source address and a key to determine the redirection address
- iterating through the addresses sequentially (this is the only allocation
  scheme which works when a list of addresses is specified)

ok dhartmei@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.16 2002/11/12 15:38:36 mpech Exp $ */
d175 2
a176 2
				break;	
			if (r_id & PF_POOL_LAST) 
d183 2
a184 2
				break;	
			if (r_id & PF_POOL_LAST) 
d191 1
a191 1
			while ((rule != NULL) && (rule->nr < r_num)) 
d202 2
a203 2
				break;	
			if (r_id & PF_POOL_LAST) 
d209 2
a210 2
				break;	
			if (r_id & PF_POOL_LAST) 
d221 1
a221 1
		if (nat == NULL) 
d229 2
a230 2
				break;	
			if (r_id & PF_POOL_LAST) 
d236 2
a237 2
				break;	
			if (r_id & PF_POOL_LAST) 
d248 1
a248 1
		if (rdr == NULL) 
d536 1
a536 1
				strlcpy(pf_status.ifname, 
@


1.16
log
@Missing splx.

dhartmei@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.15 2002/11/07 22:24:46 dhartmei Exp $ */
d73 4
d78 3
a80 1
			    struct pf_addr_wrap *, sa_family_t af);
d86 2
d114 2
d127 1
d162 126
d301 26
d354 1
a354 2
	if (PF_ANEQ(&a->src.mask, &b->src.mask, a->af) ||
	    a->src.port[0] != b->src.port[0] ||
d361 1
a361 2
	if (PF_ANEQ(&a->dst.mask, &b->dst.mask, a->af) ||
	    a->dst.port[0] != b->dst.port[0] ||
d366 2
d384 1
a384 2
	if (PF_ANEQ(&a->src.mask, &b->src.mask, a->af) ||
	    a->src.port[0] != b->src.port[0] ||
d391 1
a391 2
	if (PF_ANEQ(&a->dst.mask, &b->dst.mask, a->af) ||
	    a->dst.port[0] != b->dst.port[0] ||
d396 1
a396 1
	if (pf_compare_addr_wrap(&a->raddr, &b->raddr, a->af))
d413 1
a413 1
	if (PF_ANEQ(&a->smask, &b->smask, a->af))
d417 1
a417 3
	if (PF_ANEQ(&a->dmask, &b->dmask, a->af))
		return (1);
	if (pf_compare_addr_wrap(&a->raddr, &b->raddr, a->af))
d440 1
a440 1
	if (PF_ANEQ(&a->smask, &b->smask, a->af))
d442 1
a442 1
	if (pf_compare_addr_wrap(&a->daddr, &b->daddr, a->af))
d444 1
a444 1
	if (PF_ANEQ(&a->dmask, &b->dmask, a->af))
d446 8
a453 1
	if (pf_compare_addr_wrap(&a->raddr, &b->raddr, a->af))
d464 2
d479 2
d507 2
d559 5
a573 4
		if (pr->ticket != ticket_rules_inactive) {
			error = EBUSY;
			break;
		}
d580 1
d609 1
a609 9
		if (rule->rt_ifname[0]) {
			rule->rt_ifp = ifunit(rule->rt_ifname);
			if (rule->rt_ifp == NULL) {
				pool_put(&pf_rule_pl, rule);
				error = EINVAL;
				break;
			}
		} else
			rule->rt_ifp = NULL;
d620 5
d660 5
d727 1
d751 1
a751 9
			if (newrule->rt_ifname[0]) {
				newrule->rt_ifp = ifunit(newrule->rt_ifname);
				if (newrule->rt_ifp == NULL) {
					pool_put(&pf_rule_pl, newrule);
					error = EINVAL;
					break;
				}
			} else
				newrule->rt_ifp = NULL;
d762 5
d798 7
d835 6
a840 1
			pf_dynaddr_remove(&nat->raddr);
d862 1
d886 1
a890 2
		if (pf_dynaddr_setup(&nat->raddr, nat->af))
			error = EINVAL;
a893 1
			pf_dynaddr_remove(&nat->raddr);
d897 5
d928 5
a932 1
			pf_dynaddr_remove(&nat->raddr);
a975 1
		pf_dynaddr_copyout(&pn->nat.raddr);
d997 1
d1021 1
a1025 2
			if (pf_dynaddr_setup(&newnat->raddr, newnat->af))
				error = EINVAL;
a1028 1
				pf_dynaddr_remove(&newnat->raddr);
d1032 5
d1060 6
a1065 1
			pf_dynaddr_remove(&oldnat->raddr);
a1140 2
		if (pf_dynaddr_setup(&binat->raddr, binat->af))
			error = EINVAL;
d1329 5
a1333 1
			pf_dynaddr_remove(&rdr->raddr);
d1354 1
d1378 1
a1382 2
		if (pf_dynaddr_setup(&rdr->raddr, rdr->af))
			error = EINVAL;
a1385 1
			pf_dynaddr_remove(&rdr->raddr);
d1389 5
d1421 5
a1425 1
			pf_dynaddr_remove(&rdr->raddr);
a1467 1
		pf_dynaddr_copyout(&pr->rdr.raddr);
d1489 1
d1513 1
a1517 2
			if (pf_dynaddr_setup(&newrdr->raddr, newrdr->af))
				error = EINVAL;
a1520 1
				pf_dynaddr_remove(&newrdr->raddr);
d1524 5
d1553 6
a1558 1
			pf_dynaddr_remove(&oldrdr->raddr);
d1602 1
a1602 1
			    &psk->psk_src.mask, &st->lan.addr, st->af) &&
d1604 1
a1604 1
			    &psk->psk_dst.mask, &st->ext.addr, st->af) &&
d2142 190
@


1.15
log
@Short-circuit evaluation can leave invalid pointers, closes PR2874.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.14 2002/11/02 17:04:13 mcbride Exp $ */
d1819 2
a1820 1
				if (error)
d1822 1
@


1.14
log
@Compare dynamic addresses correctly in pf_compare_*: check the interface name
rather than the ip address if it exists.

ok dhartmei@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.13 2002/10/25 15:18:20 dhartmei Exp $ */
d444 5
a448 2
		if (pf_dynaddr_setup(&rule->src.addr, rule->af) ||
		    pf_dynaddr_setup(&rule->dst.addr, rule->af)) {
a451 1
			error = EINVAL;
d583 5
a587 2
			if (pf_dynaddr_setup(&newrule->src.addr, newrule->af) ||
			    pf_dynaddr_setup(&newrule->dst.addr, newrule->af)) {
a590 1
				error = EINVAL;
d699 7
a705 3
		if (pf_dynaddr_setup(&nat->src.addr, nat->af) ||
		    pf_dynaddr_setup(&nat->dst.addr, nat->af) ||
		    pf_dynaddr_setup(&nat->raddr, nat->af)) {
a709 1
			error = EINVAL;
d827 7
a833 3
			if (pf_dynaddr_setup(&newnat->src.addr, newnat->af) ||
			    pf_dynaddr_setup(&newnat->dst.addr, newnat->af) ||
			    pf_dynaddr_setup(&newnat->raddr, newnat->af)) {
a837 1
				error = EINVAL;
d935 7
a941 3
		if (pf_dynaddr_setup(&binat->saddr, binat->af) ||
		    pf_dynaddr_setup(&binat->daddr, binat->af) ||
		    pf_dynaddr_setup(&binat->raddr, binat->af)) {
a945 1
			error = EINVAL;
d1064 7
a1070 3
			if (pf_dynaddr_setup(&newbinat->saddr, newbinat->af) ||
			    pf_dynaddr_setup(&newbinat->daddr, newbinat->af) ||
			    pf_dynaddr_setup(&newbinat->raddr, newbinat->af)) {
a1074 1
				error = EINVAL;
d1173 7
a1179 3
		if (pf_dynaddr_setup(&rdr->saddr, rdr->af) ||
		    pf_dynaddr_setup(&rdr->daddr, rdr->af) ||
		    pf_dynaddr_setup(&rdr->raddr, rdr->af)) {
a1183 1
			error = EINVAL;
d1301 7
a1307 3
			if (pf_dynaddr_setup(&newrdr->saddr, newrdr->af) ||
			    pf_dynaddr_setup(&newrdr->daddr, newrdr->af) ||
			    pf_dynaddr_setup(&newrdr->raddr, newrdr->af)) {
a1311 1
				error = EINVAL;
@


1.13
log
@Compare pf_rule->label in pf_compare_rules(), too.
Found by DJ Gregor.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.12 2002/10/22 00:39:23 mcbride Exp $ */
d73 2
d152 16
d189 3
a191 2
	if (PF_ANEQ(&a->src.addr.addr, &b->src.addr.addr, a->af) ||
	    PF_ANEQ(&a->src.mask, &b->src.mask, a->af) ||
d197 3
a199 2
	if (PF_ANEQ(&a->dst.addr.addr, &b->dst.addr.addr, a->af) ||
	    PF_ANEQ(&a->dst.mask, &b->dst.mask, a->af) ||
d219 3
a221 2
	if (PF_ANEQ(&a->src.addr.addr, &b->src.addr.addr, a->af) ||
	    PF_ANEQ(&a->src.mask, &b->src.mask, a->af) ||
d227 3
a229 2
	if (PF_ANEQ(&a->dst.addr.addr, &b->dst.addr.addr, a->af) ||
	    PF_ANEQ(&a->dst.mask, &b->dst.mask, a->af) ||
d235 1
a235 1
	if (PF_ANEQ(&a->raddr.addr, &b->raddr.addr, a->af))
d250 1
a250 1
	if (PF_ANEQ(&a->saddr.addr, &b->saddr.addr, a->af))
d254 1
a254 1
	if (PF_ANEQ(&a->daddr.addr, &b->daddr.addr, a->af))
d258 1
a258 3
	if (PF_ANEQ(&a->raddr.addr, &b->raddr.addr, a->af))
		return (1);
	if (PF_ANEQ(&a->rmask, &b->rmask, a->af))
d279 1
a279 1
	if (PF_ANEQ(&a->saddr.addr, &b->saddr.addr, a->af))
d283 1
a283 1
	if (PF_ANEQ(&a->daddr.addr, &b->daddr.addr, a->af))
d287 1
a287 1
	if (PF_ANEQ(&a->raddr.addr, &b->raddr.addr, a->af))
@


1.12
log
@check the correct return value from ifunit()
(returns ifp, not ifname)

ok dhartmei@@ ish@@ camield@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.11 2002/10/20 13:08:29 mcbride Exp $ */
d168 2
a169 1
	    a->allow_opts != b->allow_opts)
d185 2
a186 3
	if (strcmp(a->ifname, b->ifname))
		return (1);
	if (a->ifnot != b->ifnot)
@


1.11
log
@Move pf_compare_(rules|nats|binats|rdrs) to pf_ioctl.c. Simplifies and
reduces cross-file dependancies.

ok dhartmei@@ ish@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.10 2002/10/08 05:12:08 kjc Exp $ */
d417 1
a417 1
			if (rule->rt_ifname == NULL) {
d554 1
a554 1
				if (newrule->rt_ifname == NULL) {
@


1.10
log
@the first step of pf/altq merge.
this commit is to allow further development in both userland and kernel.

the goal is to replace altq's classifier by pf(4).
- make pf tag a queue id to mbuf and make altq read the queue id
- merge altq config into pf.conf(5)

ok dhartmei@@, henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.9 2002/10/07 14:53:00 dhartmei Exp $ */
d73 6
d146 125
@


1.9
log
@-Wsign-compare clean
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.8 2002/08/12 16:41:25 dhartmei Exp $ */
d66 4
d96 2
d107 2
d117 2
d170 3
d193 3
d1498 249
@


1.8
log
@Use state tree instead of separate (flat) list to find NAT proxy ports,
allows to use the same proxy port with different external peers.
From Ryan McBride
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.7 2002/07/05 14:05:44 henning Exp $ */
d1263 1
a1263 1
		if (ps->state.expire <= secs)
d1291 1
a1291 1
			if ((nr + 1) * sizeof(*p) > ps->ps_len)
d1300 1
a1300 1
			if (pstore.expire <= secs)
@


1.7
log
@fix a small bug I found while installing a -current pf firewall at a
client some days ago:

if you had a rulefile with "set loginterface <interface>" and loaded through
pfctl -e -f /etc/pf.conf, pfctl -si didn't display the interface stats,
because on DIOCSTART pf_status.ifname was cleared and enableing is done after
loading the ruleset.
similar for DIOCCLRSTATUS, remember pf_status.ifname there as well.

added feature:

On DIOCSETSTATUSIF unset the statusinterface if pi->ifname is empty.

ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.6 2002/06/16 17:00:39 aaron Exp $ */
a89 2
	pool_init(&pf_sport_pl, sizeof(struct pf_port_node), 0, 0, 0, "pfsport",
	    NULL);
a108 3

	LIST_INIT(&pf_tcp_ports);
	LIST_INIT(&pf_udp_ports);
@


1.6
log
@Missing braces around else case, fixes a kernel crash introduced in r1.5 if
a non-existent interface is passed to "pfctl -l". Reported by
grange@@disorder.ru.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.5 2002/06/11 01:58:00 henning Exp $ */
d201 3
d1326 10
a1335 6
		if ((ifp = ifunit(pi->ifname)) == NULL)
			error = EINVAL;
		else {
			status_ifp = ifp;
			strlcpy(pf_status.ifname, ifp->if_xname, IFNAMSIZ);
		}
d1356 3
@


1.5
log
@rework pfctl statistics display
move FCNT_NAMES from pfvar.h to pfctl_parser.h, only used by pfctl
some input by nick@@
ok frantzen@@, dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.4 2002/06/10 18:52:44 dhartmei Exp $ */
d1325 1
a1325 1
		else
d1328 1
@


1.5.2.1
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD$ */
a44 1
#include <sys/malloc.h>
d46 1
d483 2
a484 2
			pf_dynaddr_remove(&nat->saddr);
			pf_dynaddr_remove(&nat->daddr);
d530 2
a531 2
		if (pf_dynaddr_setup(&nat->saddr, nat->af) ||
		    pf_dynaddr_setup(&nat->daddr, nat->af) ||
d533 2
a534 2
			pf_dynaddr_remove(&nat->saddr);
			pf_dynaddr_remove(&nat->daddr);
d564 2
a565 2
			pf_dynaddr_remove(&nat->saddr);
			pf_dynaddr_remove(&nat->daddr);
d608 2
a609 2
		pf_dynaddr_copyout(&pn->nat.saddr);
		pf_dynaddr_copyout(&pn->nat.daddr);
d655 2
a656 2
			if (pf_dynaddr_setup(&newnat->saddr, newnat->af) ||
			    pf_dynaddr_setup(&newnat->daddr, newnat->af) ||
d658 2
a659 2
				pf_dynaddr_remove(&newnat->saddr);
				pf_dynaddr_remove(&newnat->daddr);
d686 2
a687 2
			pf_dynaddr_remove(&oldnat->saddr);
			pf_dynaddr_remove(&oldnat->daddr);
d1327 1
@


1.5.2.2
log
@sync to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.5.2.1 2002/06/11 03:30:46 art Exp $ */
d45 1
a46 1
#include <sys/timeout.h>
a65 4
#ifdef ALTQ
#include <altq/altq.h>
#endif

a68 6
int			 pf_compare_rules(struct pf_rule *,
			    struct pf_rule *);
int			 pf_compare_nats(struct pf_nat *, struct pf_nat *);
int			 pf_compare_binats(struct pf_binat *,
			    struct pf_binat *);
int			 pf_compare_rdrs(struct pf_rdr *, struct pf_rdr *);
d90 2
a93 2
	pool_init(&pf_altq_pl, sizeof(struct pf_altq), 0, 0, 0, "pfaltqpl",
	    NULL);
a102 2
	TAILQ_INIT(&pf_altqs[0]);
	TAILQ_INIT(&pf_altqs[1]);
d111 3
a113 2
	pf_altqs_active = &pf_altqs[0];
	pf_altqs_inactive = &pf_altqs[1];
a138 125
pf_compare_rules(struct pf_rule *a, struct pf_rule *b)
{
	if (a->return_icmp != b->return_icmp ||
	    a->return_icmp6 != b->return_icmp6 ||
	    a->action != b->action ||
	    a->direction != b->direction ||
	    a->log != b->log ||
	    a->quick != b->quick ||
	    a->keep_state != b->keep_state ||
	    a->af != b->af ||
	    a->proto != b->proto ||
	    a->type != b->type ||
	    a->code != b->code ||
	    a->flags != b->flags ||
	    a->flagset != b->flagset ||
	    a->rule_flag != b->rule_flag ||
	    a->min_ttl != b->min_ttl ||
	    a->tos != b->tos ||
	    a->allow_opts != b->allow_opts ||
	    a->ifnot != b->ifnot)
		return (1);
	if (PF_ANEQ(&a->src.addr.addr, &b->src.addr.addr, a->af) ||
	    PF_ANEQ(&a->src.mask, &b->src.mask, a->af) ||
	    a->src.port[0] != b->src.port[0] ||
	    a->src.port[1] != b->src.port[1] ||
	    a->src.not != b->src.not ||
	    a->src.port_op != b->src.port_op)
		return (1);
	if (PF_ANEQ(&a->dst.addr.addr, &b->dst.addr.addr, a->af) ||
	    PF_ANEQ(&a->dst.mask, &b->dst.mask, a->af) ||
	    a->dst.port[0] != b->dst.port[0] ||
	    a->dst.port[1] != b->dst.port[1] ||
	    a->dst.not != b->dst.not ||
	    a->dst.port_op != b->dst.port_op)
		return (1);
	if (strcmp(a->ifname, b->ifname) ||
	    strcmp(a->label, b->label))
		return (1);
	return (0);
}

int
pf_compare_nats(struct pf_nat *a, struct pf_nat *b)
{
	if (a->proto != b->proto ||
	    a->af != b->af ||
	    a->ifnot != b->ifnot ||
	    a->no != b->no)
		return (1);
	if (PF_ANEQ(&a->src.addr.addr, &b->src.addr.addr, a->af) ||
	    PF_ANEQ(&a->src.mask, &b->src.mask, a->af) ||
	    a->src.port[0] != b->src.port[0] ||
	    a->src.port[1] != b->src.port[1] ||
	    a->src.not != b->src.not ||
	    a->src.port_op != b->src.port_op)
		return (1);
	if (PF_ANEQ(&a->dst.addr.addr, &b->dst.addr.addr, a->af) ||
	    PF_ANEQ(&a->dst.mask, &b->dst.mask, a->af) ||
	    a->dst.port[0] != b->dst.port[0] ||
	    a->dst.port[1] != b->dst.port[1] ||
	    a->dst.not != b->dst.not ||
	    a->dst.port_op != b->dst.port_op)
		return (1);
	if (PF_ANEQ(&a->raddr.addr, &b->raddr.addr, a->af))
		return (1);
	if (strcmp(a->ifname, b->ifname))
		return (1);
	return (0);
}

int
pf_compare_binats(struct pf_binat *a, struct pf_binat *b)
{
	if (a->proto != b->proto ||
	    a->dnot != b->dnot ||
	    a->af != b->af ||
	    a->no != b->no)
		return (1);
	if (PF_ANEQ(&a->saddr.addr, &b->saddr.addr, a->af))
		return (1);
	if (PF_ANEQ(&a->smask, &b->smask, a->af))
		return (1);
	if (PF_ANEQ(&a->daddr.addr, &b->daddr.addr, a->af))
		return (1);
	if (PF_ANEQ(&a->dmask, &b->dmask, a->af))
		return (1);
	if (PF_ANEQ(&a->raddr.addr, &b->raddr.addr, a->af))
		return (1);
	if (PF_ANEQ(&a->rmask, &b->rmask, a->af))
		return (1);
	if (strcmp(a->ifname, b->ifname))
		return (1);
	return (0);
}

int
pf_compare_rdrs(struct pf_rdr *a, struct pf_rdr *b)
{
	if (a->dport != b->dport ||
	    a->dport2 != b->dport2 ||
	    a->rport != b->rport ||
	    a->proto != b->proto ||
	    a->af != b->af ||
	    a->snot != b->snot ||
	    a->dnot != b->dnot ||
	    a->ifnot != b->ifnot ||
	    a->opts != b->opts ||
	    a->no != b->no)
		return (1);
	if (PF_ANEQ(&a->saddr.addr, &b->saddr.addr, a->af))
		return (1);
	if (PF_ANEQ(&a->smask, &b->smask, a->af))
		return (1);
	if (PF_ANEQ(&a->daddr.addr, &b->daddr.addr, a->af))
		return (1);
	if (PF_ANEQ(&a->dmask, &b->dmask, a->af))
		return (1);
	if (PF_ANEQ(&a->raddr.addr, &b->raddr.addr, a->af))
		return (1);
	if (strcmp(a->ifname, b->ifname))
		return (1);
	return (0);
}

int
a164 3
		case DIOCGETALTQS:
		case DIOCGETALTQ:
		case DIOCGETQSTATS:
a184 3
		case DIOCGETALTQS:
		case DIOCGETALTQ:
		case DIOCGETQSTATS:
a200 3
			if (status_ifp != NULL)
				strlcpy(pf_status.ifname, 
				    status_ifp->if_xname, IFNAMSIZ);
d272 1
a272 1
			if (rule->rt_ifp == NULL) {
d409 1
a409 1
				if (newrule->rt_ifp == NULL) {
d483 2
a484 2
			pf_dynaddr_remove(&nat->src.addr);
			pf_dynaddr_remove(&nat->dst.addr);
d530 2
a531 2
		if (pf_dynaddr_setup(&nat->src.addr, nat->af) ||
		    pf_dynaddr_setup(&nat->dst.addr, nat->af) ||
d533 2
a534 2
			pf_dynaddr_remove(&nat->src.addr);
			pf_dynaddr_remove(&nat->dst.addr);
d564 2
a565 2
			pf_dynaddr_remove(&nat->src.addr);
			pf_dynaddr_remove(&nat->dst.addr);
d608 2
a609 2
		pf_dynaddr_copyout(&pn->nat.src.addr);
		pf_dynaddr_copyout(&pn->nat.dst.addr);
d655 2
a656 2
			if (pf_dynaddr_setup(&newnat->src.addr, newnat->af) ||
			    pf_dynaddr_setup(&newnat->dst.addr, newnat->af) ||
d658 2
a659 2
				pf_dynaddr_remove(&newnat->src.addr);
				pf_dynaddr_remove(&newnat->dst.addr);
d686 2
a687 2
			pf_dynaddr_remove(&oldnat->src.addr);
			pf_dynaddr_remove(&oldnat->dst.addr);
d1265 1
a1265 1
		if (ps->state.expire <= (unsigned)secs)
d1293 1
a1293 1
			if ((nr + 1) * sizeof(*p) > (unsigned)ps->ps_len)
d1302 1
a1302 1
			if (pstore.expire <= (unsigned)secs)
d1323 4
a1326 10
		if (pi->ifname[0] == 0) {
			status_ifp = NULL;
			bzero(pf_status.ifname, IFNAMSIZ);
		} else
			if ((ifp = ifunit(pi->ifname)) == NULL)
				error = EINVAL;
			else {
				status_ifp = ifp;
				strlcpy(pf_status.ifname, ifp->if_xname, IFNAMSIZ);
			}
a1346 3
		if (status_ifp != NULL)
			strlcpy(pf_status.ifname,
			    status_ifp->if_xname, IFNAMSIZ);
a1474 249

#ifdef ALTQ
	case DIOCSTARTALTQ: {
		struct pf_altq *altq;
		struct ifnet *ifp;
		struct tb_profile tb;

		/* enable all altq interfaces on active list */
		s = splsoftnet();
		TAILQ_FOREACH(altq, pf_altqs_active, entries) {
			if (altq->qname[0] == 0) {
				if ((ifp = ifunit(altq->ifname)) == NULL) {
					error = EINVAL;
					break;
				}
				if (ifp->if_snd.altq_type != ALTQT_NONE)
					error = altq_enable(&ifp->if_snd);
				if (error != 0)
					break;
				/* set tokenbucket regulator */
				tb.rate = altq->ifbandwidth;
				tb.depth = altq->tbrsize;
				error = tbr_set(&ifp->if_snd, &tb);
				if (error != 0)
					break;
			}
		}
		splx(s);
		DPFPRINTF(PF_DEBUG_MISC, ("altq: started\n"));
		break;
	}

	case DIOCSTOPALTQ: {
		struct pf_altq *altq;
		struct ifnet *ifp;
		struct tb_profile tb;
		int err;

		/* disable all altq interfaces on active list */
		s = splsoftnet();
		TAILQ_FOREACH(altq, pf_altqs_active, entries) {
			if (altq->qname[0] == 0) {
				if ((ifp = ifunit(altq->ifname)) == NULL) {
					error = EINVAL;
					break;
				}
				if (ifp->if_snd.altq_type != ALTQT_NONE) {
					err = altq_disable(&ifp->if_snd);
					if (err != 0 && error == 0)
						error = err;
				}
				/* clear tokenbucket regulator */
				tb.rate = 0;
				err = tbr_set(&ifp->if_snd, &tb);
				if (err != 0 && error == 0)
					error = err;
			}
		}
		splx(s);
		DPFPRINTF(PF_DEBUG_MISC, ("altq: stopped\n"));
		break;
	}

	case DIOCBEGINALTQS: {
		u_int32_t *ticket = (u_int32_t *)addr;
		struct pf_altq *altq;

		/* Purge the old altq list */
		while ((altq = TAILQ_FIRST(pf_altqs_inactive)) != NULL) {
			TAILQ_REMOVE(pf_altqs_inactive, altq, entries);

			if (altq->qname[0] == 0) {
				/* detach and destroy the discipline */
				error = altq_remove(altq);
			}

			pool_put(&pf_altq_pl, altq);
		}

		*ticket = ++ticket_altqs_inactive;
		break;
	}

	case DIOCADDALTQ: {
		struct pfioc_altq *pa = (struct pfioc_altq *)addr;
		struct pf_altq *altq, *a;

		if (pa->ticket != ticket_altqs_inactive) {
			error = EBUSY;
			break;
		}
		altq = pool_get(&pf_altq_pl, PR_NOWAIT);
		if (altq == NULL) {
			error = ENOMEM;
			break;
		}
		bcopy(&pa->altq, altq, sizeof(struct pf_altq));

		/*
		 * if this is for a queue, find the discipline and
		 * copy the necessary fields
		 */
		if (altq->qname[0] != 0) {
			TAILQ_FOREACH(a, pf_altqs_inactive, entries) {
				if (strncmp(a->ifname, altq->ifname, IFNAMSIZ)
				    == 0 && a->qname[0] == 0) {
					altq->altq_disc = a->altq_disc;
					break;
				}
			}
		}

		error = altq_add(altq);

		if (error) {
			pool_put(&pf_altq_pl, altq);
			break;
		}

		TAILQ_INSERT_TAIL(pf_altqs_inactive, altq, entries);

		bcopy(altq, &pa->altq, sizeof(struct pf_altq));
		break;
	}

	case DIOCCOMMITALTQS: {
		u_int32_t *ticket = (u_int32_t *)addr;
		struct pf_altqqueue *old_altqs;
		struct pf_altq *altq;
		int err;

		if (*ticket != ticket_altqs_inactive) {
			error = EBUSY;
			break;
		}

		/* Swap altqs, keep the old. */
		s = splsoftnet();
		old_altqs = pf_altqs_active;
		pf_altqs_active = pf_altqs_inactive;
		pf_altqs_inactive = old_altqs;
		ticket_altqs_active = ticket_altqs_inactive;

		/* Attach new disciplines */
		TAILQ_FOREACH(altq, pf_altqs_active, entries) {
			if (altq->qname[0] == 0) {
				/* attach the discipline */
				error = altq_pfattach(altq);
				if (error)
					goto fail;
			}
		}

		/* Purge the old altq list */
		while ((altq = TAILQ_FIRST(pf_altqs_inactive)) != NULL) {
			TAILQ_REMOVE(pf_altqs_inactive, altq, entries);

			if (altq->qname[0] == 0) {
				/* detach and destroy the discipline */
				err = altq_pfdetach(altq);
				if (err != 0 && error == 0)
					error = err;
				err = altq_remove(altq);
				if (err != 0 && error == 0)
					error = err;
			}

			pool_put(&pf_altq_pl, altq);
		}
		splx(s);
		break;
	}

	case DIOCGETALTQS: {
		struct pfioc_altq *pa = (struct pfioc_altq *)addr;
		struct pf_altq *altq;

		pa->nr = 0;
		s = splsoftnet();
		TAILQ_FOREACH(altq, pf_altqs_active, entries)
			pa->nr++;
		pa->ticket = ticket_altqs_active;
		splx(s);
		break;
	}

	case DIOCGETALTQ: {
		struct pfioc_altq *pa = (struct pfioc_altq *)addr;
		struct pf_altq *altq;
		u_int32_t nr;

		if (pa->ticket != ticket_altqs_active) {
			error = EBUSY;
			break;
		}
		nr = 0;
		s = splsoftnet();
		altq = TAILQ_FIRST(pf_altqs_active);
		while ((altq != NULL) && (nr < pa->nr)) {
			altq = TAILQ_NEXT(altq, entries);
			nr++;
		}
		if (altq == NULL) {
			error = EBUSY;
			splx(s);
			break;
		}
		bcopy(altq, &pa->altq, sizeof(struct pf_altq));
		splx(s);
		break;
	}

	case DIOCCHANGEALTQ:
		/* CHANGEALTQ not supported yet! */
		error = ENODEV;
		break;

	case DIOCGETQSTATS: {
		struct pfioc_qstats *pq = (struct pfioc_qstats *)addr;
		struct pf_altq *altq;
		u_int32_t nr;
		int nbytes;

		if (pq->ticket != ticket_altqs_active) {
			error = EBUSY;
			break;
		}
		nbytes = pq->nbytes;
		nr = 0;
		s = splsoftnet();
		altq = TAILQ_FIRST(pf_altqs_active);
		while ((altq != NULL) && (nr < pq->nr)) {
			altq = TAILQ_NEXT(altq, entries);
			nr++;
		}
		if (altq == NULL) {
			error = EBUSY;
			splx(s);
			break;
		}
		error = altq_getqstats(altq, pq->buf, &nbytes);
		splx(s);
		if (error == 0) {
			pq->scheduler = altq->scheduler;
			pq->nbytes = nbytes;
		}
		break;
	}
#endif /* ALTQ */
@


1.5.2.3
log
@sync
@
text
@d1 1
a1 1
/*	$OpenBSD$ */
a47 1
#include <sys/malloc.h>
a57 1
#include <netinet/ip_icmp.h>
d73 6
a78 10
struct pf_pool		*pf_get_pool(char *, char *, u_int32_t,
			    u_int8_t, u_int8_t, u_int8_t, u_int8_t, u_int8_t);
int			 pf_get_ruleset_number(u_int8_t);
void			 pf_init_ruleset(struct pf_ruleset *);
struct pf_anchor	*pf_find_anchor(const char *);
struct pf_ruleset	*pf_find_ruleset(char *, char *);
struct pf_ruleset	*pf_find_or_create_ruleset(char *, char *);
void			 pf_remove_if_empty_ruleset(struct pf_ruleset *);
void			 pf_mv_pool(struct pf_palist *, struct pf_palist *);
void			 pf_empty_pool(struct pf_palist *);
a79 3
u_int16_t		 pf_tagname2tag(char *);
void			 pf_tag_unref(u_int16_t);
void			 pf_tag_purge(void);
d81 1
a81 7
extern struct timeout	 pf_expire_to;

struct pf_rule		 pf_default_rule;

#define	TAGID_MAX	 50000
static u_int16_t	 tagid = 0;
TAILQ_HEAD(pf_tags, pf_tagname)	pf_tags = TAILQ_HEAD_INITIALIZER(pf_tags);
a87 2
	u_int32_t *timeout = pf_default_rule.timeout;

d92 5
a96 1
	pool_init(&pf_addr_pl, sizeof(struct pf_addr_dyn), 0, 0, 0, "pfaddrpl",
d100 2
d104 9
a112 11
	pool_init(&pf_pooladdr_pl, sizeof(struct pf_pooladdr), 0, 0, 0,
	    "pfpooladdrpl", NULL);
	pfr_initialize();

	pool_sethardlimit(&pf_state_pl, pf_pool_limits[PF_LIMIT_STATES].limit,
	    NULL, 0);

	RB_INIT(&tree_lan_ext);
	RB_INIT(&tree_ext_gwy);
	TAILQ_INIT(&pf_anchors);
	pf_init_ruleset(&pf_main_ruleset);
d115 8
a122 1
	TAILQ_INIT(&pf_pabuf);
a125 23
	/* default rule should never be garbage collected */
	pf_default_rule.entries.tqe_prev = &pf_default_rule.entries.tqe_next;
	pf_default_rule.action = PF_PASS;
	pf_default_rule.nr = -1;

	/* initialize default timeouts */
	timeout[PFTM_TCP_FIRST_PACKET] = 120;		/* First TCP packet */
	timeout[PFTM_TCP_OPENING] = 30;			/* No response yet */
	timeout[PFTM_TCP_ESTABLISHED] = 24*60*60;	/* Established */
	timeout[PFTM_TCP_CLOSING] = 15 * 60;		/* Half closed */
	timeout[PFTM_TCP_FIN_WAIT] = 45;		/* Got both FINs */
	timeout[PFTM_TCP_CLOSED] = 90;			/* Got a RST */
	timeout[PFTM_UDP_FIRST_PACKET] = 60;		/* First UDP packet */
	timeout[PFTM_UDP_SINGLE] = 30;			/* Unidirectional */
	timeout[PFTM_UDP_MULTIPLE] = 60;		/* Bidirectional */
	timeout[PFTM_ICMP_FIRST_PACKET] = 20;		/* First ICMP packet */
	timeout[PFTM_ICMP_ERROR_REPLY] = 10;		/* Got error response */
	timeout[PFTM_OTHER_FIRST_PACKET] = 60;		/* First packet */
	timeout[PFTM_OTHER_SINGLE] = 30;		/* Unidirectional */
	timeout[PFTM_OTHER_MULTIPLE] = 60;		/* Bidirectional */
	timeout[PFTM_FRAG] = 30;			/* Fragment expire */
	timeout[PFTM_INTERVAL] = 10;			/* Expire interval */

d127 1
a127 1
	timeout_add(&pf_expire_to, timeout[PFTM_INTERVAL] * hz);
d149 2
a150 4
struct pf_pool *
pf_get_pool(char *anchorname, char *rulesetname, u_int32_t ticket,
    u_int8_t rule_action, u_int8_t rule_number, u_int8_t r_last,
    u_int8_t active, u_int8_t check_ticket)
d152 37
a188 37
	struct pf_ruleset	*ruleset;
	struct pf_rule		*rule;
	int			 rs_num;

	ruleset = pf_find_ruleset(anchorname, rulesetname);
	if (ruleset == NULL)
		return (NULL);
	rs_num = pf_get_ruleset_number(rule_action);
	if (rs_num >= PF_RULESET_MAX)
		return (NULL);
	if (active) {
		if (check_ticket && ticket !=
		    ruleset->rules[rs_num].active.ticket)
			return (NULL);
		if (r_last)
			rule = TAILQ_LAST(ruleset->rules[rs_num].active.ptr,
			    pf_rulequeue);
		else
			rule = TAILQ_FIRST(ruleset->rules[rs_num].active.ptr);
	} else {
		if (check_ticket && ticket !=
		    ruleset->rules[rs_num].inactive.ticket)
			return (NULL);
		if (r_last)
			rule = TAILQ_LAST(ruleset->rules[rs_num].inactive.ptr,
			    pf_rulequeue);
		else
			rule = TAILQ_FIRST(ruleset->rules[rs_num].inactive.ptr);
	}
	if (!r_last) {
		while ((rule != NULL) && (rule->nr != rule_number))
			rule = TAILQ_NEXT(rule, entries);
	}
	if (rule == NULL)
		return (NULL);

	return (&rule->rpool);
d192 1
a192 1
pf_get_ruleset_number(u_int8_t action)
d194 24
a217 24
	switch (action) {
	case PF_SCRUB:
		return (PF_RULESET_SCRUB);
		break;
	case PF_PASS:
	case PF_DROP:
		return (PF_RULESET_FILTER);
		break;
	case PF_NAT:
	case PF_NONAT:
		return (PF_RULESET_NAT);
		break;
	case PF_BINAT:
	case PF_NOBINAT:
		return (PF_RULESET_BINAT);
		break;
	case PF_RDR:
	case PF_NORDR:
		return (PF_RULESET_RDR);
		break;
	default:
		return (PF_RULESET_MAX);
		break;
	}
d220 2
a221 2
void
pf_init_ruleset(struct pf_ruleset *ruleset)
d223 20
a242 9
	int	i;

	memset(ruleset, 0, sizeof(struct pf_ruleset));
	for (i = 0; i < PF_RULESET_MAX; i++) {
		TAILQ_INIT(&ruleset->rules[i].queues[0]);
		TAILQ_INIT(&ruleset->rules[i].queues[1]);
		ruleset->rules[i].active.ptr = &ruleset->rules[i].queues[0];
		ruleset->rules[i].inactive.ptr = &ruleset->rules[i].queues[1];
	}
d245 2
a246 2
struct pf_anchor *
pf_find_anchor(const char *anchorname)
d248 24
a271 215
	struct pf_anchor	*anchor;
	int			 n = -1;

	anchor = TAILQ_FIRST(&pf_anchors);
	while (anchor != NULL && (n = strcmp(anchor->name, anchorname)) < 0)
		anchor = TAILQ_NEXT(anchor, entries);
	if (n == 0)
		return (anchor);
	else
		return (NULL);
}

struct pf_ruleset *
pf_find_ruleset(char *anchorname, char *rulesetname)
{
	struct pf_anchor	*anchor;
	struct pf_ruleset	*ruleset;

	if (!anchorname[0] && !rulesetname[0])
		return (&pf_main_ruleset);
	if (!anchorname[0] || !rulesetname[0])
		return (NULL);
	anchorname[PF_ANCHOR_NAME_SIZE-1] = 0;
	rulesetname[PF_RULESET_NAME_SIZE-1] = 0;
	anchor = pf_find_anchor(anchorname);
	if (anchor == NULL)
		return (NULL);
	ruleset = TAILQ_FIRST(&anchor->rulesets);
	while (ruleset != NULL && strcmp(ruleset->name, rulesetname) < 0)
		ruleset = TAILQ_NEXT(ruleset, entries);
	if (ruleset != NULL && !strcmp(ruleset->name, rulesetname))
		return (ruleset);
	else
		return (NULL);
}

struct pf_ruleset *
pf_find_or_create_ruleset(char *anchorname, char *rulesetname)
{
	struct pf_anchor	*anchor, *a;
	struct pf_ruleset	*ruleset, *r;

	if (!anchorname[0] && !rulesetname[0])
		return (&pf_main_ruleset);
	if (!anchorname[0] || !rulesetname[0])
		return (NULL);
	anchorname[PF_ANCHOR_NAME_SIZE-1] = 0;
	rulesetname[PF_RULESET_NAME_SIZE-1] = 0;
	a = TAILQ_FIRST(&pf_anchors);
	while (a != NULL && strcmp(a->name, anchorname) < 0)
		a = TAILQ_NEXT(a, entries);
	if (a != NULL && !strcmp(a->name, anchorname))
		anchor = a;
	else {
		anchor = (struct pf_anchor *)malloc(sizeof(struct pf_anchor),
		    M_TEMP, M_NOWAIT);
		if (anchor == NULL)
			return (NULL);
		memset(anchor, 0, sizeof(struct pf_anchor));
		bcopy(anchorname, anchor->name, sizeof(anchor->name));
		TAILQ_INIT(&anchor->rulesets);
		if (a != NULL)
			TAILQ_INSERT_BEFORE(a, anchor, entries);
		else
			TAILQ_INSERT_TAIL(&pf_anchors, anchor, entries);
	}
	r = TAILQ_FIRST(&anchor->rulesets);
	while (r != NULL && strcmp(r->name, rulesetname) < 0)
		r = TAILQ_NEXT(r, entries);
	if (r != NULL && !strcmp(r->name, rulesetname))
		return (r);
	ruleset = (struct pf_ruleset *)malloc(sizeof(struct pf_ruleset),
	    M_TEMP, M_NOWAIT);
	if (ruleset != NULL) {
		pf_init_ruleset(ruleset);
		bcopy(rulesetname, ruleset->name, sizeof(ruleset->name));
		ruleset->anchor = anchor;
		if (r != NULL)
			TAILQ_INSERT_BEFORE(r, ruleset, entries);
		else
			TAILQ_INSERT_TAIL(&anchor->rulesets, ruleset, entries);
	}
	return (ruleset);
}

void
pf_remove_if_empty_ruleset(struct pf_ruleset *ruleset)
{
	struct pf_anchor	*anchor;
	int			 i;

	if (ruleset == NULL || ruleset->anchor == NULL)
		return;
	for (i = 0; i < PF_RULESET_MAX; ++i)
		if (!TAILQ_EMPTY(ruleset->rules[i].active.ptr) ||
		    !TAILQ_EMPTY(ruleset->rules[i].inactive.ptr))
			return;

	anchor = ruleset->anchor;
	TAILQ_REMOVE(&anchor->rulesets, ruleset, entries);
	free(ruleset, M_TEMP);

	if (TAILQ_EMPTY(&anchor->rulesets)) {
		TAILQ_REMOVE(&pf_anchors, anchor, entries);
		free(anchor, M_TEMP);
	}
}

void
pf_mv_pool(struct pf_palist *poola, struct pf_palist *poolb)
{
	struct pf_pooladdr	*mv_pool_pa;

	while ((mv_pool_pa = TAILQ_FIRST(poola)) != NULL) {
		TAILQ_REMOVE(poola, mv_pool_pa, entries);
		TAILQ_INSERT_TAIL(poolb, mv_pool_pa, entries);
	}
}

void
pf_empty_pool(struct pf_palist *poola)
{
	struct pf_pooladdr	*empty_pool_pa;

	while ((empty_pool_pa = TAILQ_FIRST(poola)) != NULL) {
		pf_dynaddr_remove(&empty_pool_pa->addr.addr);
		TAILQ_REMOVE(poola, empty_pool_pa, entries);
		pool_put(&pf_pooladdr_pl, empty_pool_pa);
	}
}

void
pf_rm_rule(struct pf_rulequeue *rulequeue, struct pf_rule *rule)
{
	if (rulequeue != NULL) {
		TAILQ_REMOVE(rulequeue, rule, entries);
		rule->entries.tqe_prev = NULL;
		rule->nr = -1;
	}
	pf_tag_unref(rule->tag);
	pf_tag_unref(rule->match_tag);
	if (rule->states > 0 || rule->entries.tqe_prev != NULL)
		return;
	pf_dynaddr_remove(&rule->src.addr);
	pf_dynaddr_remove(&rule->dst.addr);
	pf_tbladdr_remove(&rule->src.addr);
	pf_tbladdr_remove(&rule->dst.addr);
	pf_empty_pool(&rule->rpool.list);
	pool_put(&pf_rule_pl, rule);
}

u_int16_t
pf_tagname2tag(char *tagname)
{
	struct pf_tagname	*tag, *p;
	int			 wrapped = 0;

	TAILQ_FOREACH(tag, &pf_tags, entries)
		if (strcmp(tagname, tag->name) == 0) {
			tag->ref++;
			return (tag->tag);
		}
	/* new entry */
	if (++tagid > TAGID_MAX)	/* > 50000 reserved for special use */
		tagid = wrapped = 1;
	for (p = TAILQ_FIRST(&pf_tags); p != NULL; p = TAILQ_NEXT(p, entries))
		if (p->tag == tagid) {
			if (++tagid > TAGID_MAX) {
				if (wrapped)
					return (0);
				else
					tagid = wrapped = 1;
			}
			p = TAILQ_FIRST(&pf_tags);
		}

	tag = (struct pf_tagname *)malloc(sizeof(struct pf_tagname),
	    M_TEMP, M_NOWAIT);
	if (tag == NULL)
		return (0);
	bzero(tag, sizeof(struct pf_tagname));
	strlcpy(tag->name, tagname, sizeof(tag->name));
	tag->tag = tagid;
	tag->ref++;
	TAILQ_INSERT_TAIL(&pf_tags, tag, entries);
	return (tag->tag);
}

void
pf_tag_unref(u_int16_t tag)
{
	struct pf_tagname	*p;

	if (tag > 0)
		TAILQ_FOREACH(p, &pf_tags, entries)
			if (tag == p->tag) {
				p->ref--;
				return;
			}
}

void
pf_tag_purge(void)
{
	struct pf_tagname	*p, *next;

	for (p = TAILQ_LAST(&pf_tags, pf_tags); p != NULL; p = next) {
		next = TAILQ_PREV(p, pf_tags, entries);
		if (p->ref == 0) {
			if (p->tag == tagid)
				tagid--;
			TAILQ_REMOVE(&pf_tags, p, entries);
			free(p, M_TEMP);
		}
	}
d277 2
a278 4
	struct pf_pooladdr	*pa = NULL;
	struct pf_pool		*pool = NULL;
	int			 s;
	int			 error = 0;
d285 6
a290 2
		case DIOCGETADDRS:
		case DIOCGETADDR:
a303 15
		case DIOCGETANCHORS:
		case DIOCGETANCHOR:
		case DIOCGETRULESETS:
		case DIOCGETRULESET:
		case DIOCRGETTABLES:
		case DIOCRGETTSTATS:
		case DIOCRCLRTSTATS:
		case DIOCRCLRADDRS:
		case DIOCRADDADDRS:
		case DIOCRDELADDRS:
		case DIOCRSETADDRS:
		case DIOCRGETADDRS:
		case DIOCRGETASTATS:
		case DIOCRCLRASTATS:
		case DIOCRTSTADDRS:
d313 4
a316 2
		case DIOCGETADDRS:
		case DIOCGETADDR:
d321 2
a326 9
		case DIOCGETANCHORS:
		case DIOCGETANCHOR:
		case DIOCGETRULESETS:
		case DIOCGETRULESET:
		case DIOCRGETTABLES:
		case DIOCRGETTSTATS:
		case DIOCRGETADDRS:
		case DIOCRGETASTATS:
		case DIOCRTSTADDRS:
d344 1
a344 1
				strlcpy(pf_status.ifname,
d360 2
a361 4
		struct pfioc_rule	*pr = (struct pfioc_rule *)addr;
		struct pf_ruleset	*ruleset;
		struct pf_rule		*rule;
		int			 rs_num;
d363 5
a367 9
		ruleset = pf_find_or_create_ruleset(pr->anchor, pr->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		rs_num = pf_get_ruleset_number(pr->rule.action);
		if (rs_num >= PF_RULESET_MAX) {
			error = EINVAL;
			break;
d369 1
a369 4
		while ((rule =
		    TAILQ_FIRST(ruleset->rules[rs_num].inactive.ptr)) != NULL)
			pf_rm_rule(ruleset->rules[rs_num].inactive.ptr, rule);
		pr->ticket = ++ruleset->rules[rs_num].inactive.ticket;
d374 2
a375 4
		struct pfioc_rule	*pr = (struct pfioc_rule *)addr;
		struct pf_ruleset	*ruleset;
		struct pf_rule		*rule, *tail;
		int			 rs_num;
d377 1
a377 23
		ruleset = pf_find_ruleset(pr->anchor, pr->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		rs_num = pf_get_ruleset_number(pr->rule.action);
		if (rs_num >= PF_RULESET_MAX) {
			error = EINVAL;
			break;
		}
		if (pr->rule.anchorname[0] && ruleset != &pf_main_ruleset) {
			error = EINVAL;
			break;
		}
		if (pr->rule.return_icmp >> 8 > ICMP_MAXTYPE) {
			error = EINVAL;
			break;
		}
		if (pr->ticket != ruleset->rules[rs_num].inactive.ticket) {
			error = EBUSY;
			break;
		}
		if (pr->pool_ticket != ticket_pabuf) {
a386 6
		rule->anchor = NULL;
		rule->ifp = NULL;
		TAILQ_INIT(&rule->rpool.list);
		/* initialize refcounting */
		rule->states = 0;
		rule->entries.tqe_prev = NULL;
d401 1
a401 2
		tail = TAILQ_LAST(ruleset->rules[rs_num].inactive.ptr,
		    pf_rulequeue);
d413 16
a428 16
		}

		if (rule->tagname[0])
			if ((rule->tag = pf_tagname2tag(rule->tagname)) == 0)
				error = EBUSY;
		if (rule->match_tagname[0])
			if ((rule->match_tag =
			    pf_tagname2tag(rule->match_tagname)) == 0)
				error = EBUSY;
		if (rule->rt && !rule->direction)
			error = EINVAL;
		if (pf_dynaddr_setup(&rule->src.addr, rule->af))
			error = EINVAL;
		if (pf_dynaddr_setup(&rule->dst.addr, rule->af))
			error = EINVAL;
		if (pf_tbladdr_setup(ruleset, &rule->src.addr))
a429 12
		if (pf_tbladdr_setup(ruleset, &rule->dst.addr))
			error = EINVAL;

		pf_mv_pool(&pf_pabuf, &rule->rpool.list);
		if (((((rule->action == PF_NAT) || (rule->action == PF_RDR) ||
		    (rule->action == PF_BINAT)) && !rule->anchorname[0]) ||
		    (rule->rt > PF_FASTROUTE)) &&
		    (TAILQ_FIRST(&rule->rpool.list) == NULL))
			error = EINVAL;

		if (error) {
			pf_rm_rule(NULL, rule);
a431 1
		rule->rpool.cur = TAILQ_FIRST(&rule->rpool.list);
d433 1
a433 2
		TAILQ_INSERT_TAIL(ruleset->rules[rs_num].inactive.ptr,
		    rule, entries);
d438 4
a441 5
		struct pfioc_rule	*pr = (struct pfioc_rule *)addr;
		struct pf_ruleset	*ruleset;
		struct pf_rulequeue	*old_rules;
		struct pf_rule		*rule;
		int			 rs_num;
d443 1
a443 11
		ruleset = pf_find_ruleset(pr->anchor, pr->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		rs_num = pf_get_ruleset_number(pr->rule.action);
		if (rs_num >= PF_RULESET_MAX) {
			error = EINVAL;
			break;
		}
		if (pr->ticket != ruleset->rules[rs_num].inactive.ticket) {
a447 6
#ifdef ALTQ
		/* set queue IDs */
		if (rs_num == PF_RULESET_FILTER)
			pf_rule_set_qid(ruleset->rules[rs_num].inactive.ptr);
#endif

d450 11
a460 7
		old_rules = ruleset->rules[rs_num].active.ptr;
		ruleset->rules[rs_num].active.ptr =
		    ruleset->rules[rs_num].inactive.ptr;
		ruleset->rules[rs_num].inactive.ptr = old_rules;
		ruleset->rules[rs_num].active.ticket =
		    ruleset->rules[rs_num].inactive.ticket;
		pf_calc_skip_steps(ruleset->rules[rs_num].active.ptr);
d463 6
a468 6
		while ((rule = TAILQ_FIRST(old_rules)) != NULL)
			pf_rm_rule(old_rules, rule);
		pf_remove_if_empty_ruleset(ruleset);
		pf_update_anchor_rules();
		pf_tag_purge();
		splx(s);
d473 2
a474 4
		struct pfioc_rule	*pr = (struct pfioc_rule *)addr;
		struct pf_ruleset	*ruleset;
		struct pf_rule		*tail;
		int			 rs_num;
a475 10
		ruleset = pf_find_ruleset(pr->anchor, pr->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		rs_num = pf_get_ruleset_number(pr->rule.action);
		if (rs_num >= PF_RULESET_MAX) {
			error = EINVAL;
			break;
		}
d477 1
a477 2
		tail = TAILQ_LAST(ruleset->rules[rs_num].active.ptr,
		    pf_rulequeue);
d482 1
a482 1
		pr->ticket = ruleset->rules[rs_num].active.ticket;
d488 2
a489 4
		struct pfioc_rule	*pr = (struct pfioc_rule *)addr;
		struct pf_ruleset	*ruleset;
		struct pf_rule		*rule;
		int			 rs_num, i;
d491 1
a491 11
		ruleset = pf_find_ruleset(pr->anchor, pr->ruleset);
		if (ruleset == NULL) {
			error = EINVAL;
			break;
		}
		rs_num = pf_get_ruleset_number(pr->rule.action);
		if (rs_num >= PF_RULESET_MAX) {
			error = EINVAL;
			break;
		}
		if (pr->ticket != ruleset->rules[rs_num].active.ticket) {
d496 1
a496 1
		rule = TAILQ_FIRST(ruleset->rules[rs_num].active.ptr);
a506 8
		pf_tbladdr_copyout(&pr->rule.src.addr);
		pf_tbladdr_copyout(&pr->rule.dst.addr);
		for (i = 0; i < PF_SKIP_COUNT; ++i)
			if (rule->skip[i].ptr == NULL)
				pr->rule.skip[i].nr = -1;
			else
				pr->rule.skip[i].nr =
				    rule->skip[i].ptr->nr;
d512 3
a514 12
		struct pfioc_rule	*pcr = (struct pfioc_rule *)addr;
		struct pf_ruleset	*ruleset;
		struct pf_rule		*oldrule = NULL, *newrule = NULL;
		u_int32_t		 nr = 0;
		int			 rs_num;

		if (!(pcr->action == PF_CHANGE_REMOVE ||
		    pcr->action == PF_CHANGE_GET_TICKET) &&
		    pcr->pool_ticket != ticket_pabuf) {
			error = EBUSY;
			break;
		}
d517 1
a517 6
		    pcr->action > PF_CHANGE_GET_TICKET) {
			error = EINVAL;
			break;
		}
		ruleset = pf_find_ruleset(pcr->anchor, pcr->ruleset);
		if (ruleset == NULL) {
a520 20
		rs_num = pf_get_ruleset_number(pcr->rule.action);
		if (rs_num >= PF_RULESET_MAX) {
			error = EINVAL;
			break;
		}

		if (pcr->action == PF_CHANGE_GET_TICKET) {
			pcr->ticket = ++ruleset->rules[rs_num].active.ticket;
			break;
		} else {
			if (pcr->ticket !=
			    ruleset->rules[rs_num].active.ticket) {
				error = EINVAL;
				break;
			}
			if (pcr->rule.return_icmp >> 8 > ICMP_MAXTYPE) {
				error = EINVAL;
				break;
			}
		}
d528 1
a528 5
			bcopy(&pcr->rule, newrule, sizeof(struct pf_rule));
			TAILQ_INIT(&newrule->rpool.list);
			/* initialize refcounting */
			newrule->states = 0;
			newrule->entries.tqe_prev = NULL;
d552 14
a565 15

#ifdef ALTQ
			/* set queue IDs */
			if (newrule->qname[0] != 0) {
				newrule->qid = pf_qname_to_qid(newrule->qname);
				if (newrule->pqname[0] != 0)
					newrule->pqid =
					    pf_qname_to_qid(newrule->pqname);
				else
					newrule->pqid = newrule->qid;
			}
#endif
			if (newrule->rt && !newrule->direction)
				error = EINVAL;
			if (pf_dynaddr_setup(&newrule->src.addr, newrule->af))
a566 18
			if (pf_dynaddr_setup(&newrule->dst.addr, newrule->af))
				error = EINVAL;
			if (pf_tbladdr_setup(ruleset, &newrule->src.addr))
				error = EINVAL;
			if (pf_tbladdr_setup(ruleset, &newrule->dst.addr))
				error = EINVAL;

			pf_mv_pool(&pf_pabuf, &newrule->rpool.list);
			if (((((newrule->action == PF_NAT) ||
			    (newrule->action == PF_RDR) ||
			    (newrule->action == PF_BINAT) ||
			    (newrule->rt > PF_FASTROUTE)) &&
			    !newrule->anchorname[0])) &&
			    (TAILQ_FIRST(&newrule->rpool.list) == NULL))
				error = EINVAL;

			if (error) {
				pf_rm_rule(NULL, newrule);
a568 1
			newrule->rpool.cur = TAILQ_FIRST(&newrule->rpool.list);
a571 1
		pf_empty_pool(&pf_pabuf);
d576 1
a576 2
			oldrule = TAILQ_FIRST(
			    ruleset->rules[rs_num].active.ptr);
d578 1
a578 2
			oldrule = TAILQ_LAST(
			    ruleset->rules[rs_num].active.ptr, pf_rulequeue);
d580 3
a582 3
			oldrule = TAILQ_FIRST(
			    ruleset->rules[rs_num].active.ptr);
			while ((oldrule != NULL) && (oldrule->nr != pcr->nr))
a584 1
				pf_rm_rule(NULL, newrule);
d591 11
a601 3
		if (pcr->action == PF_CHANGE_REMOVE)
			pf_rm_rule(ruleset->rules[rs_num].active.ptr, oldrule);
		else {
d603 2
a604 3
				TAILQ_INSERT_TAIL(
				    ruleset->rules[rs_num].active.ptr,
				    newrule, entries);
d609 2
a610 3
				TAILQ_INSERT_AFTER(
				    ruleset->rules[rs_num].active.ptr,
				    oldrule, newrule, entries);
d613 1
a613 3
		nr = 0;
		TAILQ_FOREACH(oldrule,
		    ruleset->rules[rs_num].active.ptr, entries)
d616 1
a616 3
		pf_calc_skip_steps(ruleset->rules[rs_num].active.ptr);
		pf_remove_if_empty_ruleset(ruleset);
		pf_update_anchor_rules();
d618 1
a618 1
		ruleset->rules[rs_num].active.ticket++;
d623 3
a625 2
	case DIOCCLRSTATES: {
		struct pf_tree_node	*n;
d627 8
a634 6
		s = splsoftnet();
		RB_FOREACH(n, pf_state_tree, &tree_ext_gwy)
			n->state->timeout = PFTM_PURGE;
		pf_purge_expired_states();
		pf_status.states = 0;
		splx(s);
d638 3
a640 5
	case DIOCKILLSTATES: {
		struct pf_tree_node	*n;
		struct pf_state		*st;
		struct pfioc_state_kill	*psk = (struct pfioc_state_kill *)addr;
		int			 killed = 0;
d642 30
a671 23
		s = splsoftnet();
		RB_FOREACH(n, pf_state_tree, &tree_ext_gwy) {
			st = n->state;
			if ((!psk->psk_af || st->af == psk->psk_af) &&
			    (!psk->psk_proto || psk->psk_proto == st->proto) &&
			    PF_MATCHA(psk->psk_src.not,
			    &psk->psk_src.addr.v.a.addr,
			    &psk->psk_src.addr.v.a.mask, &st->lan.addr,
			    st->af) &&
			    PF_MATCHA(psk->psk_dst.not,
			    &psk->psk_dst.addr.v.a.addr,
			    &psk->psk_dst.addr.v.a.mask, &st->ext.addr,
			    st->af) &&
			    (psk->psk_src.port_op == 0 ||
			    pf_match_port(psk->psk_src.port_op,
			    psk->psk_src.port[0], psk->psk_src.port[1],
			    st->lan.port)) &&
			    (psk->psk_dst.port_op == 0 ||
			    pf_match_port(psk->psk_dst.port_op,
			    psk->psk_dst.port[0], psk->psk_dst.port[1],
			    st->ext.port))) {
				st->timeout = PFTM_PURGE;
				killed++;
d673 11
d685 1
a685 3
		pf_purge_expired_states();
		splx(s);
		psk->psk_af = killed;
d689 4
a692 3
	case DIOCADDSTATE: {
		struct pfioc_state	*ps = (struct pfioc_state *)addr;
		struct pf_state		*state;
d694 2
a695 8
		if (ps->state.timeout >= PFTM_MAX &&
		    ps->state.timeout != PFTM_UNTIL_PACKET) {
			error = EINVAL;
			break;
		}
		state = pool_get(&pf_state_pl, PR_NOWAIT);
		if (state == NULL) {
			error = ENOMEM;
d698 2
d701 13
a713 11
		bcopy(&ps->state, state, sizeof(struct pf_state));
		state->rule.ptr = NULL;
		state->nat_rule.ptr = NULL;
		state->anchor.ptr = NULL;
		state->rt_ifp = NULL;
		state->creation = time.tv_sec;
		state->packets = 0;
		state->bytes = 0;
		if (pf_insert_state(state)) {
			pool_put(&pf_state_pl, state);
			error = ENOMEM;
a714 1
		splx(s);
d718 666
d1385 4
a1388 3
		struct pfioc_state	*ps = (struct pfioc_state *)addr;
		struct pf_tree_node	*n;
		u_int32_t		 nr;
d1403 2
a1404 9
		ps->state.rule.nr = n->state->rule.ptr->nr;
		ps->state.nat_rule.nr = (n->state->nat_rule.ptr == NULL) ?
		    -1 : n->state->nat_rule.ptr->nr;
		ps->state.anchor.nr = (n->state->anchor.ptr == NULL) ?
		    -1 : n->state->anchor.ptr->nr;
		splx(s);
		ps->state.expire = pf_state_expires(n->state);
		if (ps->state.expire > time.tv_sec)
			ps->state.expire -= time.tv_sec;
d1406 5
d1412 2
d1418 5
a1422 5
		struct pfioc_states	*ps = (struct pfioc_states *)addr;
		struct pf_tree_node	*n;
		struct pf_state		*p, pstore;
		u_int32_t		 nr = 0;
		int			 space = ps->ps_len;
d1436 1
a1436 1
			int	secs = time.tv_sec;
d1442 4
a1445 5
			pstore.rule.nr = n->state->rule.ptr->nr;
			pstore.nat_rule.nr = (n->state->nat_rule.ptr == NULL) ?
			    -1 : n->state->nat_rule.ptr->nr;
			pstore.anchor.nr = (n->state->anchor.ptr == NULL) ?
			    -1 : n->state->anchor.ptr->nr;
d1447 3
a1449 2
			pstore.expire = pf_state_expires(n->state);
			if (pstore.expire > secs)
a1450 2
			else
				pstore.expire = 0;
d1465 2
a1466 2
		struct pfioc_if	*pi = (struct pfioc_if *)addr;
		struct ifnet	*ifp;
d1476 1
a1476 2
				strlcpy(pf_status.ifname, ifp->if_xname,
				    IFNAMSIZ);
d1488 4
a1491 4
		u_int32_t	running = pf_status.running;
		u_int32_t	states = pf_status.states;
		u_int32_t	since = pf_status.since;
		u_int32_t	debug = pf_status.debug;
d1505 4
a1508 4
		struct pfioc_natlook	*pnl = (struct pfioc_natlook *)addr;
		struct pf_state		*st;
		struct pf_tree_node	 key;
		int			 direction = pnl->direction;
d1535 1
a1535 1
				if (direction == PF_IN) {
d1558 2
a1559 2
		struct pfioc_tm	*pt = (struct pfioc_tm *)addr;
		int		 old;
d1566 2
a1567 2
		old = pf_default_rule.timeout[pt->timeout];
		pf_default_rule.timeout[pt->timeout] = pt->seconds;
d1573 1
a1573 1
		struct pfioc_tm	*pt = (struct pfioc_tm *)addr;
d1579 1
a1579 1
		pt->seconds = pf_default_rule.timeout[pt->timeout];
d1584 1
a1584 1
		struct pfioc_limit	*pl = (struct pfioc_limit *)addr;
d1595 2
a1596 2
		struct pfioc_limit	*pl = (struct pfioc_limit *)addr;
		int			 old_limit;
d1614 1
a1614 2
		u_int32_t	*level = (u_int32_t *)addr;

d1620 1
a1620 2
		struct pf_ruleset	*ruleset = &pf_main_ruleset;
		struct pf_rule		*rule;
d1623 1
a1623 2
		TAILQ_FOREACH(rule,
		    ruleset->rules[PF_RULESET_FILTER].active.ptr, entries)
d1632 3
a1634 3
		struct pf_altq		*altq;
		struct ifnet		*ifp;
		struct tb_profile	 tb;
a1655 2
		if (error == 0)
			pfaltq_running = 1;
d1662 4
a1665 4
		struct pf_altq		*altq;
		struct ifnet		*ifp;
		struct tb_profile	 tb;
		int			 err;
a1686 2
		if (error == 0)
			pfaltq_running = 0;
d1693 2
a1694 2
		u_int32_t	*ticket = (u_int32_t *)addr;
		struct pf_altq	*altq;
d1699 1
d1704 1
d1707 1
d1713 2
a1714 2
		struct pfioc_altq	*pa = (struct pfioc_altq *)addr;
		struct pf_altq		*altq, *a;
d1733 2
a1734 2
				if (strncmp(a->ifname, altq->ifname,
				    IFNAMSIZ) == 0 && a->qname[0] == 0) {
d1742 1
d1749 1
d1755 4
a1758 6
		u_int32_t		*ticket = (u_int32_t *)addr;
		struct pf_altqqueue	*old_altqs;
		struct pf_altq		*altq;
		struct pf_anchor	*anchor;
		struct pf_ruleset	*ruleset;
		int			 err;
d1777 1
a1777 2
				if (error) {
					splx(s);
a1778 1
				}
d1785 1
d1795 1
a1798 11

		/* update queue IDs */
		pf_rule_set_qid(
		    pf_main_ruleset.rules[PF_RULESET_FILTER].active.ptr);
		TAILQ_FOREACH(anchor, &pf_anchors, entries) {
			TAILQ_FOREACH(ruleset, &anchor->rulesets, entries) {
				pf_rule_set_qid(
				    ruleset->rules[PF_RULESET_FILTER].active.ptr
				    );
			}
		}
d1803 2
a1804 2
		struct pfioc_altq	*pa = (struct pfioc_altq *)addr;
		struct pf_altq		*altq;
d1816 3
a1818 3
		struct pfioc_altq	*pa = (struct pfioc_altq *)addr;
		struct pf_altq		*altq;
		u_int32_t		 nr;
d1847 4
a1850 4
		struct pfioc_qstats	*pq = (struct pfioc_qstats *)addr;
		struct pf_altq		*altq;
		u_int32_t		 nr;
		int			 nbytes;
a1877 483

	case DIOCBEGINADDRS: {
		struct pfioc_pooladdr	*pp = (struct pfioc_pooladdr *)addr;

		pf_empty_pool(&pf_pabuf);
		pp->ticket = ++ticket_pabuf;
		break;
	}

	case DIOCADDADDR: {
		struct pfioc_pooladdr	*pp = (struct pfioc_pooladdr *)addr;

#ifndef INET
		if (pp->af == AF_INET) {
			error = EAFNOSUPPORT;
			break;
		}
#endif /* INET */
#ifndef INET6
		if (pp->af == AF_INET6) {
			error = EAFNOSUPPORT;
			break;
		}
#endif /* INET6 */
		if (pp->addr.addr.addr.type != PF_ADDR_ADDRMASK &&
		    pp->addr.addr.addr.type != PF_ADDR_DYNIFTL) {
			error = EINVAL;
			break;
		}
		pa = pool_get(&pf_pooladdr_pl, PR_NOWAIT);
		if (pa == NULL) {
			error = ENOMEM;
			break;
		}
		bcopy(&pp->addr, pa, sizeof(struct pf_pooladdr));
		if (pa->ifname[0]) {
			pa->ifp = ifunit(pa->ifname);
			if (pa->ifp == NULL) {
				pool_put(&pf_pooladdr_pl, pa);
				error = EINVAL;
				break;
			}
		}
		if (pf_dynaddr_setup(&pa->addr.addr, pp->af)) {
			pf_dynaddr_remove(&pa->addr.addr);
			pool_put(&pf_pooladdr_pl, pa);
			error = EINVAL;
			break;
		}
		TAILQ_INSERT_TAIL(&pf_pabuf, pa, entries);
		break;
	}

	case DIOCGETADDRS: {
		struct pfioc_pooladdr	*pp = (struct pfioc_pooladdr *)addr;

		pp->nr = 0;
		s = splsoftnet();
		pool = pf_get_pool(pp->anchor, pp->ruleset, pp->ticket,
		    pp->r_action, pp->r_num, 0, 1, 0);
		if (pool == NULL) {
			error = EBUSY;
			splx(s);
			break;
		}
		TAILQ_FOREACH(pa, &pool->list, entries)
			pp->nr++;
		splx(s);
		break;
	}

	case DIOCGETADDR: {
		struct pfioc_pooladdr	*pp = (struct pfioc_pooladdr *)addr;
		u_int32_t		 nr = 0;

		s = splsoftnet();
		pool = pf_get_pool(pp->anchor, pp->ruleset, pp->ticket,
		    pp->r_action, pp->r_num, 0, 1, 1);
		if (pool == NULL) {
			error = EBUSY;
			splx(s);
			break;
		}
		pa = TAILQ_FIRST(&pool->list);
		while ((pa != NULL) && (nr < pp->nr)) {
			pa = TAILQ_NEXT(pa, entries);
			nr++;
		}
		if (pa == NULL) {
			error = EBUSY;
			splx(s);
			break;
		}
		bcopy(pa, &pp->addr, sizeof(struct pf_pooladdr));
		pf_dynaddr_copyout(&pp->addr.addr.addr);
		splx(s);
		break;
	}

	case DIOCCHANGEADDR: {
		struct pfioc_pooladdr	*pca = (struct pfioc_pooladdr *)addr;
		struct pf_pooladdr	*oldpa = NULL, *newpa = NULL;

		if (pca->action < PF_CHANGE_ADD_HEAD ||
		    pca->action > PF_CHANGE_REMOVE) {
			error = EINVAL;
			break;
		}
		if (pca->addr.addr.addr.type != PF_ADDR_ADDRMASK &&
		    pca->addr.addr.addr.type != PF_ADDR_DYNIFTL) {
			error = EINVAL;
			break;
		}

		pool = pf_get_pool(pca->anchor, pca->ruleset, 0,
		    pca->r_action, pca->r_num, pca->r_last, 1, 1);
		if (pool == NULL) {
			error = EBUSY;
			break;
		}
		if (pca->action != PF_CHANGE_REMOVE) {
			newpa = pool_get(&pf_pooladdr_pl, PR_NOWAIT);
			if (newpa == NULL) {
				error = ENOMEM;
				break;
			}
			bcopy(&pca->addr, newpa, sizeof(struct pf_pooladdr));
#ifndef INET
			if (pca->af == AF_INET) {
				pool_put(&pf_pooladdr_pl, newpa);
				error = EAFNOSUPPORT;
				break;
			}
#endif /* INET */
#ifndef INET6
			if (pca->af == AF_INET6) {
				pool_put(&pf_pooladdr_pl, newpa);
				error = EAFNOSUPPORT;
				break;
			}
#endif /* INET6 */
			if (newpa->ifname[0]) {
				newpa->ifp = ifunit(newpa->ifname);
				if (newpa->ifp == NULL) {
					pool_put(&pf_pooladdr_pl, newpa);
					error = EINVAL;
					break;
				}
			} else
				newpa->ifp = NULL;
			if (pf_dynaddr_setup(&newpa->addr.addr, pca->af)) {
				pf_dynaddr_remove(&newpa->addr.addr);
				pool_put(&pf_pooladdr_pl, newpa);
				error = EINVAL;
				break;
			}
		}

		s = splsoftnet();

		if (pca->action == PF_CHANGE_ADD_HEAD)
			oldpa = TAILQ_FIRST(&pool->list);
		else if (pca->action == PF_CHANGE_ADD_TAIL)
			oldpa = TAILQ_LAST(&pool->list, pf_palist);
		else {
			int	i = 0;

			oldpa = TAILQ_FIRST(&pool->list);
			while ((oldpa != NULL) && (i < pca->nr)) {
				oldpa = TAILQ_NEXT(oldpa, entries);
				i++;
			}
			if (oldpa == NULL) {
				error = EINVAL;
				splx(s);
				break;
			}
		}

		if (pca->action == PF_CHANGE_REMOVE) {
			TAILQ_REMOVE(&pool->list, oldpa, entries);
			pf_dynaddr_remove(&oldpa->addr.addr);
			pool_put(&pf_pooladdr_pl, oldpa);
		} else {
			if (oldpa == NULL)
				TAILQ_INSERT_TAIL(&pool->list, newpa, entries);
			else if (pca->action == PF_CHANGE_ADD_HEAD ||
			    pca->action == PF_CHANGE_ADD_BEFORE)
				TAILQ_INSERT_BEFORE(oldpa, newpa, entries);
			else
				TAILQ_INSERT_AFTER(&pool->list, oldpa,
				    newpa, entries);
		}

		pool->cur = TAILQ_FIRST(&pool->list);
		PF_ACPY(&pool->counter, &pool->cur->addr.addr.v.a.addr,
		    pca->af);
		splx(s);
		break;
	}

	case DIOCGETANCHORS: {
		struct pfioc_anchor	*pa = (struct pfioc_anchor *)addr;
		struct pf_anchor	*anchor;

		pa->nr = 0;
		TAILQ_FOREACH(anchor, &pf_anchors, entries)
			pa->nr++;
		break;
	}

	case DIOCGETANCHOR: {
		struct pfioc_anchor	*pa = (struct pfioc_anchor *)addr;
		struct pf_anchor	*anchor;
		u_int32_t		 nr = 0;

		anchor = TAILQ_FIRST(&pf_anchors);
		while (anchor != NULL && nr < pa->nr) {
			anchor = TAILQ_NEXT(anchor, entries);
			nr++;
		}
		if (anchor == NULL)
			error = EBUSY;
		else
			bcopy(anchor->name, pa->name, sizeof(pa->name));
		break;
	}

	case DIOCGETRULESETS: {
		struct pfioc_ruleset	*pr = (struct pfioc_ruleset *)addr;
		struct pf_anchor	*anchor;
		struct pf_ruleset	*ruleset;

		pr->anchor[PF_ANCHOR_NAME_SIZE-1] = 0;
		if ((anchor = pf_find_anchor(pr->anchor)) == NULL) {
			error = EINVAL;
			break;
		}
		pr->nr = 0;
		TAILQ_FOREACH(ruleset, &anchor->rulesets, entries)
			pr->nr++;
		break;
	}

	case DIOCGETRULESET: {
		struct pfioc_ruleset	*pr = (struct pfioc_ruleset *)addr;
		struct pf_anchor	*anchor;
		struct pf_ruleset	*ruleset;
		u_int32_t		 nr = 0;

		if ((anchor = pf_find_anchor(pr->anchor)) == NULL) {
			error = EINVAL;
			break;
		}
		ruleset = TAILQ_FIRST(&anchor->rulesets);
		while (ruleset != NULL && nr < pr->nr) {
			ruleset = TAILQ_NEXT(ruleset, entries);
			nr++;
		}
		if (ruleset == NULL)
			error = EBUSY;
		else
			bcopy(ruleset->name, pr->name, sizeof(pr->name));
		break;
	}

	case DIOCRCLRTABLES: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != 0) {
			error = ENODEV;
			break;
		}
		error = pfr_clr_tables(&io->pfrio_ndel, io->pfrio_flags);
		break;
	}

	case DIOCRADDTABLES: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_table)) {
			error = ENODEV;
			break;
		}
		error = pfr_add_tables(io->pfrio_buffer, io->pfrio_size,
		    &io->pfrio_nadd, io->pfrio_flags);
		break;
	}

	case DIOCRDELTABLES: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_table)) {
			error = ENODEV;
			break;
		}
		error = pfr_del_tables(io->pfrio_buffer, io->pfrio_size,
		    &io->pfrio_ndel, io->pfrio_flags);
		break;
	}

	case DIOCRGETTABLES: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_table)) {
			error = ENODEV;
			break;
		}
		error = pfr_get_tables(io->pfrio_buffer, &io->pfrio_size,
		    io->pfrio_flags);
		break;
	}

	case DIOCRGETTSTATS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_tstats)) {
			error = ENODEV;
			break;
		}
		error = pfr_get_tstats(io->pfrio_buffer, &io->pfrio_size,
		    io->pfrio_flags);
		break;
	}

	case DIOCRCLRTSTATS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_table)) {
			error = ENODEV;
			break;
		}
		error = pfr_clr_tstats(io->pfrio_buffer, io->pfrio_size,
		    &io->pfrio_nzero, io->pfrio_flags);
		break;
	}

	case DIOCRSETTFLAGS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_table)) {
			error = ENODEV;
			break;
		}
		error = pfr_set_tflags(io->pfrio_buffer, io->pfrio_size,
		    io->pfrio_setflag, io->pfrio_clrflag, &io->pfrio_nchange,
		    &io->pfrio_ndel, io->pfrio_flags);
		break;
	}

	case DIOCRCLRADDRS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != 0) {
			error = ENODEV;
			break;
		}
		error = pfr_clr_addrs(&io->pfrio_table, &io->pfrio_ndel,
		    io->pfrio_flags);
		break;
	}

	case DIOCRADDADDRS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
		error = pfr_add_addrs(&io->pfrio_table, io->pfrio_buffer,
		    io->pfrio_size, &io->pfrio_nadd, io->pfrio_flags);
		break;
	}

	case DIOCRDELADDRS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
		error = pfr_del_addrs(&io->pfrio_table, io->pfrio_buffer,
		    io->pfrio_size, &io->pfrio_ndel, io->pfrio_flags);
		break;
	}

	case DIOCRSETADDRS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
		error = pfr_set_addrs(&io->pfrio_table, io->pfrio_buffer,
		    io->pfrio_size, &io->pfrio_size2, &io->pfrio_nadd,
		    &io->pfrio_ndel, &io->pfrio_nchange, io->pfrio_flags);
		break;
	}

	case DIOCRGETADDRS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
		error = pfr_get_addrs(&io->pfrio_table, io->pfrio_buffer,
		    &io->pfrio_size, io->pfrio_flags);
		break;
	}

	case DIOCRGETASTATS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_astats)) {
			error = ENODEV;
			break;
		}
		error = pfr_get_astats(&io->pfrio_table, io->pfrio_buffer,
		    &io->pfrio_size, io->pfrio_flags);
		break;
	}

	case DIOCRCLRASTATS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
		error = pfr_clr_astats(&io->pfrio_table, io->pfrio_buffer,
		    io->pfrio_size, &io->pfrio_nzero, io->pfrio_flags);
		break;
	}

	case DIOCRTSTADDRS: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
		error = pfr_tst_addrs(&io->pfrio_table, io->pfrio_buffer,
		    io->pfrio_size, &io->pfrio_nmatch, io->pfrio_flags);
		break;
	}

	case DIOCRINABEGIN: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != 0) {
			error = ENODEV;
			break;
		}
		error = pfr_ina_begin(&io->pfrio_ticket, &io->pfrio_ndel,
		    io->pfrio_flags);
		break;
	}

	case DIOCRINACOMMIT: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != 0) {
			error = ENODEV;
			break;
		}
		error = pfr_ina_commit(io->pfrio_ticket, &io->pfrio_nadd,
		    &io->pfrio_nchange, io->pfrio_flags);
		break;
	}

	case DIOCRINADEFINE: {
		struct pfioc_table *io = (struct pfioc_table *)addr;

		if (io->pfrio_esize != sizeof(struct pfr_addr)) {
			error = ENODEV;
			break;
		}
		error = pfr_ina_define(&io->pfrio_table, io->pfrio_buffer,
		    io->pfrio_size, &io->pfrio_nadd, &io->pfrio_naddr,
		    io->pfrio_ticket, io->pfrio_flags);
		break;
	}
@


1.4
log
@#include <sys/timeout.h>, from Chris Kuethe
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.3 2002/06/10 17:05:11 dhartmei Exp $ */
d1327 1
@


1.3
log
@Don't #include <sys/malloc.h>
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.2 2002/06/09 20:20:58 dhartmei Exp $ */
d46 1
@


1.2
log
@Make pf_nat.saddr/daddr a pf_rule_addr instead of pf_addr_wrap, so it
includes ports and operator.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_ioctl.c,v 1.1 2002/06/09 03:57:18 pb Exp $ */
a44 1
#include <sys/malloc.h>
@


1.1
log
@
new file sys/net/pf_ioctl.c

functions moved from pf.c to there

ok dhartmei@@, frantzen@@

testing myself + henning@@, kernel & userland utils fine
@
text
@d1 1
a1 1
/*	$OpenBSD$ */
d483 2
a484 2
			pf_dynaddr_remove(&nat->saddr);
			pf_dynaddr_remove(&nat->daddr);
d530 2
a531 2
		if (pf_dynaddr_setup(&nat->saddr, nat->af) ||
		    pf_dynaddr_setup(&nat->daddr, nat->af) ||
d533 2
a534 2
			pf_dynaddr_remove(&nat->saddr);
			pf_dynaddr_remove(&nat->daddr);
d564 2
a565 2
			pf_dynaddr_remove(&nat->saddr);
			pf_dynaddr_remove(&nat->daddr);
d608 2
a609 2
		pf_dynaddr_copyout(&pn->nat.saddr);
		pf_dynaddr_copyout(&pn->nat.daddr);
d655 2
a656 2
			if (pf_dynaddr_setup(&newnat->saddr, newnat->af) ||
			    pf_dynaddr_setup(&newnat->daddr, newnat->af) ||
d658 2
a659 2
				pf_dynaddr_remove(&newnat->saddr);
				pf_dynaddr_remove(&newnat->daddr);
d686 2
a687 2
			pf_dynaddr_remove(&oldnat->saddr);
			pf_dynaddr_remove(&oldnat->daddr);
@

