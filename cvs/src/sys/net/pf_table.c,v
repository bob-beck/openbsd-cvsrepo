head	1.125;
access;
symbols
	OPENBSD_6_1_BASE:1.125
	OPENBSD_6_0:1.116.0.6
	OPENBSD_6_0_BASE:1.116
	OPENBSD_5_9:1.116.0.2
	OPENBSD_5_9_BASE:1.116
	OPENBSD_5_8:1.113.0.4
	OPENBSD_5_8_BASE:1.113
	OPENBSD_5_7:1.105.0.2
	OPENBSD_5_7_BASE:1.105
	OPENBSD_5_6:1.102.0.4
	OPENBSD_5_6_BASE:1.102
	OPENBSD_5_5:1.101.0.6
	OPENBSD_5_5_BASE:1.101
	OPENBSD_5_4:1.101.0.2
	OPENBSD_5_4_BASE:1.101
	OPENBSD_5_3:1.97.0.2
	OPENBSD_5_3_BASE:1.97
	OPENBSD_5_2:1.94.0.4
	OPENBSD_5_2_BASE:1.94
	OPENBSD_5_1_BASE:1.94
	OPENBSD_5_1:1.94.0.2
	OPENBSD_5_0:1.93.0.2
	OPENBSD_5_0_BASE:1.93
	OPENBSD_4_9:1.88.0.2
	OPENBSD_4_9_BASE:1.88
	OPENBSD_4_8:1.85.0.2
	OPENBSD_4_8_BASE:1.85
	OPENBSD_4_7:1.83.0.2
	OPENBSD_4_7_BASE:1.83
	OPENBSD_4_6:1.80.0.6
	OPENBSD_4_6_BASE:1.80
	OPENBSD_4_5:1.80.0.2
	OPENBSD_4_5_BASE:1.80
	OPENBSD_4_4:1.78.0.2
	OPENBSD_4_4_BASE:1.78
	OPENBSD_4_3:1.72.0.2
	OPENBSD_4_3_BASE:1.72
	OPENBSD_4_2:1.70.0.2
	OPENBSD_4_2_BASE:1.70
	OPENBSD_4_1:1.68.0.4
	OPENBSD_4_1_BASE:1.68
	OPENBSD_4_0:1.68.0.2
	OPENBSD_4_0_BASE:1.68
	OPENBSD_3_9:1.67.0.4
	OPENBSD_3_9_BASE:1.67
	OPENBSD_3_8:1.67.0.2
	OPENBSD_3_8_BASE:1.67
	OPENBSD_3_7:1.62.0.2
	OPENBSD_3_7_BASE:1.62
	OPENBSD_3_6:1.59.0.2
	OPENBSD_3_6_BASE:1.59
	SMP_SYNC_A:1.56
	SMP_SYNC_B:1.55
	OPENBSD_3_5:1.47.0.2
	OPENBSD_3_5_BASE:1.47
	OPENBSD_3_4:1.41.0.2
	OPENBSD_3_4_BASE:1.41
	UBC:1.34.0.2
	UBC_SYNC_A:1.34
	SMP:1.31.0.4
	OPENBSD_3_3:1.31.0.2
	OPENBSD_3_3_BASE:1.31;
locks; strict;
comment	@ * @;


1.125
date	2017.02.14.10.31.15;	author mpi;	state Exp;
branches;
next	1.124;
commitid	PmGi4EGraGC0Z0ml;

1.124
date	2017.02.09.10.29.37;	author mpi;	state Exp;
branches;
next	1.123;
commitid	SXHovsxRHHKOWCzN;

1.123
date	2017.01.24.10.08.30;	author krw;	state Exp;
branches;
next	1.122;
commitid	6c6qq5OdS4VVnyVM;

1.122
date	2017.01.23.09.08.24;	author mpi;	state Exp;
branches;
next	1.121;
commitid	88u0uWxFR2EXj8bl;

1.121
date	2016.10.26.21.07.22;	author bluhm;	state Exp;
branches;
next	1.120;
commitid	aaKAr0kv3QWNHoVo;

1.120
date	2016.09.27.04.57.17;	author dlg;	state Exp;
branches;
next	1.119;
commitid	irzdR7hwk1GHVaEu;

1.119
date	2016.09.27.02.51.12;	author dlg;	state Exp;
branches;
next	1.118;
commitid	bZuzILta8BoFCDiT;

1.118
date	2016.09.15.02.00.18;	author dlg;	state Exp;
branches;
next	1.117;
commitid	RlO92XR575sygHqm;

1.117
date	2016.09.02.10.19.49;	author dlg;	state Exp;
branches;
next	1.116;
commitid	BjJg5d9vjutHaOpJ;

1.116
date	2015.11.03.22.10.33;	author sashan;	state Exp;
branches;
next	1.115;
commitid	jATfCoW9kRfzIUqF;

1.115
date	2015.10.07.11.57.44;	author mpi;	state Exp;
branches;
next	1.114;
commitid	LJy1v4RiHUSLry9o;

1.114
date	2015.09.04.08.43.39;	author mpi;	state Exp;
branches;
next	1.113;
commitid	qAevExm24QrBjVNL;

1.113
date	2015.07.20.18.42.08;	author jsg;	state Exp;
branches;
next	1.112;
commitid	nffqezEm9k9xuYCt;

1.112
date	2015.07.18.19.06.37;	author sashan;	state Exp;
branches;
next	1.111;
commitid	3mKgVGfXwxDVj6Uu;

1.111
date	2015.07.18.15.19.44;	author sashan;	state Exp;
branches;
next	1.110;
commitid	FkfdBMmgICAjEgne;

1.110
date	2015.07.16.18.17.27;	author claudio;	state Exp;
branches;
next	1.109;
commitid	VvtF6H2REt7RsEKf;

1.109
date	2015.06.07.12.02.28;	author jsg;	state Exp;
branches;
next	1.108;
commitid	st7eUqjf7vKTD48M;

1.108
date	2015.04.09.12.04.14;	author mikeb;	state Exp;
branches;
next	1.107;
commitid	NrKWZV0Ql4OJnLZG;

1.107
date	2015.04.08.14.19.28;	author mikeb;	state Exp;
branches;
next	1.106;
commitid	ejQ1BkD0Fi3qz57Z;

1.106
date	2015.03.14.03.38.51;	author jsg;	state Exp;
branches;
next	1.105;
commitid	p4LJxGKbi0BU2cG6;

1.105
date	2015.01.20.17.25.35;	author mikeb;	state Exp;
branches;
next	1.104;
commitid	BTdrGkI9CiSB1FLB;

1.104
date	2014.12.19.17.14.40;	author tedu;	state Exp;
branches;
next	1.103;
commitid	zhW8jJrfVCoAthrR;

1.103
date	2014.09.08.06.24.13;	author jsg;	state Exp;
branches;
next	1.102;
commitid	ZqXwxwmeo3l29NOg;

1.102
date	2014.07.12.18.44.22;	author tedu;	state Exp;
branches;
next	1.101;
commitid	B4dZSbxas1X1IpXI;

1.101
date	2013.07.05.13.07.58;	author blambert;	state Exp;
branches;
next	1.100;

1.100
date	2013.07.04.00.19.00;	author guenther;	state Exp;
branches;
next	1.99;

1.99
date	2013.07.02.05.57.37;	author guenther;	state Exp;
branches;
next	1.98;

1.98
date	2013.07.02.01.42.01;	author guenther;	state Exp;
branches;
next	1.97;

1.97
date	2013.02.18.14.48.13;	author mikeb;	state Exp;
branches;
next	1.96;

1.96
date	2013.01.16.09.18.34;	author markus;	state Exp;
branches;
next	1.95;

1.95
date	2012.12.29.14.53.05;	author markus;	state Exp;
branches;
next	1.94;

1.94
date	2012.01.26.11.30.39;	author mikeb;	state Exp;
branches;
next	1.93;

1.93
date	2011.07.27.00.26.10;	author mcbride;	state Exp;
branches;
next	1.92;

1.92
date	2011.07.08.22.11.17;	author mikeb;	state Exp;
branches;
next	1.91;

1.91
date	2011.07.03.23.37.55;	author zinke;	state Exp;
branches;
next	1.90;

1.90
date	2011.06.14.10.14.01;	author mcbride;	state Exp;
branches;
next	1.89;

1.89
date	2011.05.17.12.44.05;	author mikeb;	state Exp;
branches;
next	1.88;

1.88
date	2010.11.20.23.58.13;	author tedu;	state Exp;
branches;
next	1.87;

1.87
date	2010.10.23.15.38.18;	author tedu;	state Exp;
branches;
next	1.86;

1.86
date	2010.09.30.07.14.02;	author mcbride;	state Exp;
branches;
next	1.85;

1.85
date	2010.08.07.03.50.02;	author krw;	state Exp;
branches;
next	1.84;

1.84
date	2010.06.28.18.50.37;	author claudio;	state Exp;
branches;
next	1.83;

1.83
date	2010.02.24.15.04.40;	author henning;	state Exp;
branches;
next	1.82;

1.82
date	2010.01.18.23.52.46;	author mcbride;	state Exp;
branches;
next	1.81;

1.81
date	2010.01.12.03.20.51;	author mcbride;	state Exp;
branches;
next	1.80;

1.80
date	2008.11.24.13.22.09;	author mikeb;	state Exp;
branches;
next	1.79;

1.79
date	2008.10.08.06.24.50;	author mcbride;	state Exp;
branches;
next	1.78;

1.78
date	2008.06.14.03.50.14;	author art;	state Exp;
branches;
next	1.77;

1.77
date	2008.06.14.02.22.13;	author henning;	state Exp;
branches;
next	1.76;

1.76
date	2008.06.10.22.39.31;	author mcbride;	state Exp;
branches;
next	1.75;

1.75
date	2008.06.10.21.25.29;	author mcbride;	state Exp;
branches;
next	1.74;

1.74
date	2008.06.10.20.55.02;	author mcbride;	state Exp;
branches;
next	1.73;

1.73
date	2008.05.07.05.14.21;	author claudio;	state Exp;
branches;
next	1.72;

1.72
date	2007.12.20.20.07.41;	author reyk;	state Exp;
branches;
next	1.71;

1.71
date	2007.09.01.18.49.27;	author henning;	state Exp;
branches;
next	1.70;

1.70
date	2007.05.23.11.53.45;	author markus;	state Exp;
branches;
next	1.69;

1.69
date	2007.03.20.10.37.29;	author mickey;	state Exp;
branches;
next	1.68;

1.68
date	2006.05.02.10.08.45;	author dhartmei;	state Exp;
branches;
next	1.67;

1.67
date	2005.08.02.12.40.42;	author pascoe;	state Exp;
branches;
next	1.66;

1.66
date	2005.06.06.09.01.55;	author dhartmei;	state Exp;
branches;
next	1.65;

1.65
date	2005.05.27.18.53.09;	author henning;	state Exp;
branches;
next	1.64;

1.64
date	2005.05.23.23.28.53;	author dhartmei;	state Exp;
branches;
next	1.63;

1.63
date	2005.05.23.20.47.02;	author henning;	state Exp;
branches;
next	1.62;

1.62
date	2004.12.07.18.02.04;	author mcbride;	state Exp;
branches;
next	1.61;

1.61
date	2004.12.04.07.49.48;	author mcbride;	state Exp;
branches;
next	1.60;

1.60
date	2004.10.15.00.15.06;	author jaredy;	state Exp;
branches;
next	1.59;

1.59
date	2004.07.08.23.17.38;	author mcbride;	state Exp;
branches;
next	1.58;

1.58
date	2004.06.23.04.34.17;	author mcbride;	state Exp;
branches;
next	1.57;

1.57
date	2004.06.21.23.50.37;	author tholo;	state Exp;
branches;
next	1.56;

1.56
date	2004.06.11.05.21.20;	author mcbride;	state Exp;
branches;
next	1.55;

1.55
date	2004.06.07.13.16.19;	author cedric;	state Exp;
branches;
next	1.54;

1.54
date	2004.06.02.22.18.25;	author tedu;	state Exp;
branches;
next	1.53;

1.53
date	2004.05.19.17.50.52;	author dhartmei;	state Exp;
branches;
next	1.52;

1.52
date	2004.04.28.15.12.20;	author pb;	state Exp;
branches;
next	1.51;

1.51
date	2004.04.28.03.31.33;	author pb;	state Exp;
branches;
next	1.50;

1.50
date	2004.04.28.02.43.09;	author pb;	state Exp;
branches;
next	1.49;

1.49
date	2004.04.25.02.48.03;	author itojun;	state Exp;
branches;
next	1.48;

1.48
date	2004.04.09.19.30.41;	author frantzen;	state Exp;
branches;
next	1.47;

1.47
date	2004.03.09.21.44.41;	author mcbride;	state Exp;
branches;
next	1.46;

1.46
date	2004.02.10.22.42.57;	author dhartmei;	state Exp;
branches;
next	1.45;

1.45
date	2004.02.10.18.49.10;	author henning;	state Exp;
branches;
next	1.44;

1.44
date	2003.12.31.22.14.42;	author deraadt;	state Exp;
branches;
next	1.43;

1.43
date	2003.12.31.11.18.25;	author cedric;	state Exp;
branches;
next	1.42;

1.42
date	2003.09.26.21.44.09;	author cedric;	state Exp;
branches;
next	1.41;

1.41
date	2003.08.22.15.19.23;	author henning;	state Exp;
branches;
next	1.40;

1.40
date	2003.08.09.14.56.48;	author cedric;	state Exp;
branches;
next	1.39;

1.39
date	2003.07.31.22.25.55;	author cedric;	state Exp;
branches;
next	1.38;

1.38
date	2003.06.24.13.52.50;	author henning;	state Exp;
branches;
next	1.37;

1.37
date	2003.06.08.10.32.35;	author cedric;	state Exp;
branches;
next	1.36;

1.36
date	2003.06.08.09.41.08;	author cedric;	state Exp;
branches;
next	1.35;

1.35
date	2003.05.24.14.22.03;	author cedric;	state Exp;
branches;
next	1.34;

1.34
date	2003.04.30.12.30.27;	author cedric;	state Exp;
branches;
next	1.33;

1.33
date	2003.04.27.16.02.08;	author cedric;	state Exp;
branches;
next	1.32;

1.32
date	2003.04.04.01.46.04;	author deraadt;	state Exp;
branches;
next	1.31;

1.31
date	2003.03.21.12.47.36;	author cedric;	state Exp;
branches
	1.31.4.1;
next	1.30;

1.30
date	2003.03.14.12.36.40;	author cedric;	state Exp;
branches;
next	1.29;

1.29
date	2003.03.13.17.56.16;	author cedric;	state Exp;
branches;
next	1.28;

1.28
date	2003.03.05.12.13.03;	author cedric;	state Exp;
branches;
next	1.27;

1.27
date	2003.02.28.11.04.05;	author cedric;	state Exp;
branches;
next	1.26;

1.26
date	2003.02.27.12.56.05;	author cedric;	state Exp;
branches;
next	1.25;

1.25
date	2003.02.12.20.10.08;	author henric;	state Exp;
branches;
next	1.24;

1.24
date	2003.01.15.16.55.10;	author cedric;	state Exp;
branches;
next	1.23;

1.23
date	2003.01.15.16.28.56;	author cedric;	state Exp;
branches;
next	1.22;

1.22
date	2003.01.15.10.42.48;	author cedric;	state Exp;
branches;
next	1.21;

1.21
date	2003.01.15.09.42.52;	author cedric;	state Exp;
branches;
next	1.20;

1.20
date	2003.01.13.07.57.47;	author cedric;	state Exp;
branches;
next	1.19;

1.19
date	2003.01.10.16.09.19;	author cedric;	state Exp;
branches;
next	1.18;

1.18
date	2003.01.10.13.21.35;	author cedric;	state Exp;
branches;
next	1.17;

1.17
date	2003.01.09.15.58.35;	author dhartmei;	state Exp;
branches;
next	1.16;

1.16
date	2003.01.09.10.40.44;	author cedric;	state Exp;
branches;
next	1.15;

1.15
date	2003.01.07.00.21.07;	author dhartmei;	state Exp;
branches;
next	1.14;

1.14
date	2003.01.06.14.19.40;	author cedric;	state Exp;
branches;
next	1.13;

1.13
date	2003.01.06.10.08.36;	author deraadt;	state Exp;
branches;
next	1.12;

1.12
date	2003.01.05.22.14.23;	author dhartmei;	state Exp;
branches;
next	1.11;

1.11
date	2003.01.03.19.31.43;	author deraadt;	state Exp;
branches;
next	1.10;

1.10
date	2003.01.03.10.39.09;	author cedric;	state Exp;
branches;
next	1.9;

1.9
date	2003.01.01.22.07.57;	author cedric;	state Exp;
branches;
next	1.8;

1.8
date	2003.01.01.16.08.52;	author henning;	state Exp;
branches;
next	1.7;

1.7
date	2003.01.01.15.26.17;	author cedric;	state Exp;
branches;
next	1.6;

1.6
date	2003.01.01.14.16.56;	author cedric;	state Exp;
branches;
next	1.5;

1.5
date	2003.01.01.13.23.17;	author cedric;	state Exp;
branches;
next	1.4;

1.4
date	2002.12.30.15.39.18;	author cedric;	state Exp;
branches;
next	1.3;

1.3
date	2002.12.30.13.34.55;	author cedric;	state Exp;
branches;
next	1.2;

1.2
date	2002.12.30.02.37.27;	author henning;	state Exp;
branches;
next	1.1;

1.1
date	2002.12.29.20.07.34;	author cedric;	state Exp;
branches;
next	;

1.31.4.1
date	2003.05.13.19.36.16;	author ho;	state Exp;
branches;
next	1.31.4.2;

1.31.4.2
date	2003.06.07.11.06.07;	author ho;	state Exp;
branches;
next	1.31.4.3;

1.31.4.3
date	2004.02.19.10.57.22;	author niklas;	state Exp;
branches;
next	1.31.4.4;

1.31.4.4
date	2004.06.05.23.11.24;	author niklas;	state Exp;
branches;
next	1.31.4.5;

1.31.4.5
date	2004.06.07.20.41.37;	author niklas;	state Exp;
branches;
next	1.31.4.6;

1.31.4.6
date	2004.06.13.08.50.17;	author niklas;	state Exp;
branches;
next	;


desc
@@


1.125
log
@Convert most of the manual checks for CPU hogging to sched_pause().

The distinction between preempt() and yield() stays as it is usueful
to know if a thread decided to yield by itself or if the kernel told
him to go away.

ok tedu@@, guenther@@
@
text
@/*	$OpenBSD: pf_table.c,v 1.124 2017/02/09 10:29:37 mpi Exp $	*/

/*
 * Copyright (c) 2002 Cedric Berger
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 *
 *    - Redistributions of source code must retain the above copyright
 *      notice, this list of conditions and the following disclaimer.
 *    - Redistributions in binary form must reproduce the above
 *      copyright notice, this list of conditions and the following
 *      disclaimer in the documentation and/or other materials provided
 *      with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
 * FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
 * COPYRIGHT HOLDERS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
 * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
 * BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
 * ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 * POSSIBILITY OF SUCH DAMAGE.
 *
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/socket.h>
#include <sys/mbuf.h>
#include <sys/pool.h>
#include <sys/syslog.h>
#include <sys/proc.h>

#include <net/if.h>

#include <netinet/in.h>
#include <netinet/ip.h>
#include <netinet/ip_ipsp.h>
#include <netinet/ip_icmp.h>
#include <netinet/tcp.h>
#include <netinet/udp.h>

#ifdef INET6
#include <netinet/ip6.h>
#include <netinet/icmp6.h>
#endif /* INET6 */

#include <net/pfvar.h>
#include <net/pfvar_priv.h>

#define ACCEPT_FLAGS(flags, oklist)		\
	do {					\
		if ((flags & ~(oklist)) &	\
		    PFR_FLAG_ALLMASK)		\
			return (EINVAL);	\
	} while (0)

#define COPYIN(from, to, size, flags)		\
	((flags & PFR_FLAG_USERIOCTL) ?		\
	copyin((from), (to), (size)) :		\
	(bcopy((from), (to), (size)), 0))

#define COPYOUT(from, to, size, flags)		\
	((flags & PFR_FLAG_USERIOCTL) ?		\
	copyout((from), (to), (size)) :		\
	(bcopy((from), (to), (size)), 0))

#define YIELD(cnt, ok)				\
	sched_pause(preempt)

#define	FILLIN_SIN(sin, addr)			\
	do {					\
		(sin).sin_len = sizeof(sin);	\
		(sin).sin_family = AF_INET;	\
		(sin).sin_addr = (addr);	\
	} while (0)

#define	FILLIN_SIN6(sin6, addr)			\
	do {					\
		(sin6).sin6_len = sizeof(sin6);	\
		(sin6).sin6_family = AF_INET6;	\
		(sin6).sin6_addr = (addr);	\
	} while (0)

#define SWAP(type, a1, a2)			\
	do {					\
		type tmp = a1;			\
		a1 = a2;			\
		a2 = tmp;			\
	} while (0)

#define SUNION2PF(su, af) (((af)==AF_INET) ?	\
    (struct pf_addr *)&(su)->sin.sin_addr :	\
    (struct pf_addr *)&(su)->sin6.sin6_addr)

#define	AF_BITS(af)		(((af)==AF_INET)?32:128)
#define	ADDR_NETWORK(ad)	((ad)->pfra_net < AF_BITS((ad)->pfra_af))
#define	KENTRY_NETWORK(ke)	((ke)->pfrke_net < AF_BITS((ke)->pfrke_af))

#define NO_ADDRESSES		(-1)
#define ENQUEUE_UNMARKED_ONLY	(1)
#define INVERT_NEG_FLAG		(1)

struct pfr_walktree {
	enum pfrw_op {
		PFRW_MARK,
		PFRW_SWEEP,
		PFRW_ENQUEUE,
		PFRW_GET_ADDRS,
		PFRW_GET_ASTATS,
		PFRW_POOL_GET,
		PFRW_DYNADDR_UPDATE
	}	 pfrw_op;
	union {
		struct pfr_addr		*pfrw1_addr;
		struct pfr_astats	*pfrw1_astats;
		struct pfr_kentryworkq	*pfrw1_workq;
		struct pfr_kentry	*pfrw1_kentry;
		struct pfi_dynaddr	*pfrw1_dyn;
	}	 pfrw_1;
	int	 pfrw_free;
	int	 pfrw_flags;
};
#define pfrw_addr	pfrw_1.pfrw1_addr
#define pfrw_astats	pfrw_1.pfrw1_astats
#define pfrw_workq	pfrw_1.pfrw1_workq
#define pfrw_kentry	pfrw_1.pfrw1_kentry
#define pfrw_dyn	pfrw_1.pfrw1_dyn
#define pfrw_cnt	pfrw_free

#define senderr(e)	do { rv = (e); goto _bad; } while (0)

struct pool		 pfr_ktable_pl;
struct pool		 pfr_kentry_pl[PFRKE_MAX];
struct pool		 pfr_kcounters_pl;
struct sockaddr_in	 pfr_sin;
#ifdef	INET6
struct sockaddr_in6	 pfr_sin6;
#endif	/* INET6 */
union sockaddr_union	 pfr_mask;
struct pf_addr		 pfr_ffaddr;

int			 pfr_gcd(int, int);
void			 pfr_copyout_addr(struct pfr_addr *,
			    struct pfr_kentry *ke);
int			 pfr_validate_addr(struct pfr_addr *);
void			 pfr_enqueue_addrs(struct pfr_ktable *,
			    struct pfr_kentryworkq *, int *, int);
void			 pfr_mark_addrs(struct pfr_ktable *);
struct pfr_kentry	*pfr_lookup_addr(struct pfr_ktable *,
			    struct pfr_addr *, int);
struct pfr_kentry	*pfr_create_kentry(struct pfr_addr *);
void			 pfr_destroy_kentries(struct pfr_kentryworkq *);
void			 pfr_destroy_kentry(struct pfr_kentry *);
void			 pfr_insert_kentries(struct pfr_ktable *,
			    struct pfr_kentryworkq *, time_t);
void			 pfr_remove_kentries(struct pfr_ktable *,
			    struct pfr_kentryworkq *);
void			 pfr_clstats_kentries(struct pfr_kentryworkq *, time_t,
			    int);
void			 pfr_reset_feedback(struct pfr_addr *, int, int);
void			 pfr_prepare_network(union sockaddr_union *, int, int);
int			 pfr_route_kentry(struct pfr_ktable *,
			    struct pfr_kentry *);
int			 pfr_unroute_kentry(struct pfr_ktable *,
			    struct pfr_kentry *);
int			 pfr_walktree(struct radix_node *, void *, u_int);
int			 pfr_validate_table(struct pfr_table *, int, int);
int			 pfr_fix_anchor(char *);
void			 pfr_commit_ktable(struct pfr_ktable *, time_t);
void			 pfr_insert_ktables(struct pfr_ktableworkq *);
void			 pfr_insert_ktable(struct pfr_ktable *);
void			 pfr_setflags_ktables(struct pfr_ktableworkq *);
void			 pfr_setflags_ktable(struct pfr_ktable *, int);
void			 pfr_clstats_ktables(struct pfr_ktableworkq *, time_t,
			    int);
void			 pfr_clstats_ktable(struct pfr_ktable *, time_t, int);
struct pfr_ktable	*pfr_create_ktable(struct pfr_table *, time_t, int,
			    int);
void			 pfr_destroy_ktables(struct pfr_ktableworkq *, int);
void			 pfr_destroy_ktable(struct pfr_ktable *, int);
int			 pfr_ktable_compare(struct pfr_ktable *,
			    struct pfr_ktable *);
void			 pfr_ktable_winfo_update(struct pfr_ktable *,
			    struct pfr_kentry *);
struct pfr_ktable	*pfr_lookup_table(struct pfr_table *);
void			 pfr_clean_node_mask(struct pfr_ktable *,
			    struct pfr_kentryworkq *);
int			 pfr_table_count(struct pfr_table *, int);
int			 pfr_skip_table(struct pfr_table *,
			    struct pfr_ktable *, int);
struct pfr_kentry	*pfr_kentry_byidx(struct pfr_ktable *, int, int);
int			 pfr_islinklocal(sa_family_t, struct pf_addr *);

RB_PROTOTYPE(pfr_ktablehead, pfr_ktable, pfrkt_tree, pfr_ktable_compare);
RB_GENERATE(pfr_ktablehead, pfr_ktable, pfrkt_tree, pfr_ktable_compare);

struct pfr_ktablehead	 pfr_ktables;
struct pfr_table	 pfr_nulltable;
int			 pfr_ktable_cnt;

int
pfr_gcd(int m, int n)
{
       int t;

       while (m > 0) {
	       t = n % m;
	       n = m;
	       m = t;
       }
       return (n);
}

void
pfr_initialize(void)
{
	rn_init(sizeof(struct sockaddr_in6));

	pool_init(&pfr_ktable_pl, sizeof(struct pfr_ktable),
	    0, IPL_SOFTNET, 0, "pfrktable", NULL);
	pool_init(&pfr_kentry_pl[PFRKE_PLAIN], sizeof(struct pfr_kentry),
	    0, IPL_SOFTNET, 0, "pfrke_plain", NULL);
	pool_init(&pfr_kentry_pl[PFRKE_ROUTE], sizeof(struct pfr_kentry_route),
	    0, IPL_SOFTNET, 0, "pfrke_route", NULL);
	pool_init(&pfr_kentry_pl[PFRKE_COST], sizeof(struct pfr_kentry_cost),
	    0, IPL_SOFTNET, 0, "pfrke_cost", NULL);
	pool_init(&pfr_kcounters_pl, sizeof(struct pfr_kcounters),
	    0, IPL_SOFTNET, 0, "pfrkcounters", NULL);

	pfr_sin.sin_len = sizeof(pfr_sin);
	pfr_sin.sin_family = AF_INET;
#ifdef	INET6
	pfr_sin6.sin6_len = sizeof(pfr_sin6);
	pfr_sin6.sin6_family = AF_INET6;
#endif	/* INET6 */

	memset(&pfr_ffaddr, 0xff, sizeof(pfr_ffaddr));
}

int
pfr_clr_addrs(struct pfr_table *tbl, int *ndel, int flags)
{
	struct pfr_ktable	*kt;
	struct pfr_kentryworkq	 workq;

	ACCEPT_FLAGS(flags, PFR_FLAG_DUMMY);
	if (pfr_validate_table(tbl, 0, flags & PFR_FLAG_USERIOCTL))
		return (EINVAL);
	kt = pfr_lookup_table(tbl);
	if (kt == NULL || !(kt->pfrkt_flags & PFR_TFLAG_ACTIVE))
		return (ESRCH);
	if (kt->pfrkt_flags & PFR_TFLAG_CONST)
		return (EPERM);
	pfr_enqueue_addrs(kt, &workq, ndel, 0);

	if (!(flags & PFR_FLAG_DUMMY)) {
		pfr_remove_kentries(kt, &workq);
		if (kt->pfrkt_cnt) {
			DPFPRINTF(LOG_NOTICE,
			    "pfr_clr_addrs: corruption detected (%d).",
			    kt->pfrkt_cnt);
			kt->pfrkt_cnt = 0;
		}
	}
	return (0);
}

int
pfr_add_addrs(struct pfr_table *tbl, struct pfr_addr *addr, int size,
    int *nadd, int flags)
{
	struct pfr_ktable	*kt, *tmpkt;
	struct pfr_kentryworkq	 workq;
	struct pfr_kentry	*p, *q;
	struct pfr_addr		 ad;
	int			 i, rv, xadd = 0;
	time_t			 tzero = time_second;

	ACCEPT_FLAGS(flags, PFR_FLAG_DUMMY | PFR_FLAG_FEEDBACK);
	if (pfr_validate_table(tbl, 0, flags & PFR_FLAG_USERIOCTL))
		return (EINVAL);
	kt = pfr_lookup_table(tbl);
	if (kt == NULL || !(kt->pfrkt_flags & PFR_TFLAG_ACTIVE))
		return (ESRCH);
	if (kt->pfrkt_flags & PFR_TFLAG_CONST)
		return (EPERM);
	tmpkt = pfr_create_ktable(&pfr_nulltable, 0, 0,
	    !(flags & PFR_FLAG_USERIOCTL));
	if (tmpkt == NULL)
		return (ENOMEM);
	SLIST_INIT(&workq);
	for (i = 0; i < size; i++) {
		YIELD(i, flags & PFR_FLAG_USERIOCTL);
		if (COPYIN(addr+i, &ad, sizeof(ad), flags))
			senderr(EFAULT);
		if (pfr_validate_addr(&ad))
			senderr(EINVAL);
		p = pfr_lookup_addr(kt, &ad, 1);
		q = pfr_lookup_addr(tmpkt, &ad, 1);
		if (flags & PFR_FLAG_FEEDBACK) {
			if (q != NULL)
				ad.pfra_fback = PFR_FB_DUPLICATE;
			else if (p == NULL)
				ad.pfra_fback = PFR_FB_ADDED;
			else if ((p->pfrke_flags & PFRKE_FLAG_NOT) !=
			    ad.pfra_not)
				ad.pfra_fback = PFR_FB_CONFLICT;
			else
				ad.pfra_fback = PFR_FB_NONE;
		}
		if (p == NULL && q == NULL) {
			p = pfr_create_kentry(&ad);
			if (p == NULL)
				senderr(ENOMEM);
			if (pfr_route_kentry(tmpkt, p)) {
				pfr_destroy_kentry(p);
				ad.pfra_fback = PFR_FB_NONE;
			} else {
				SLIST_INSERT_HEAD(&workq, p, pfrke_workq);
				xadd++;
			}
		}
		if (flags & PFR_FLAG_FEEDBACK)
			if (COPYOUT(&ad, addr+i, sizeof(ad), flags))
				senderr(EFAULT);
	}
	pfr_clean_node_mask(tmpkt, &workq);
	if (!(flags & PFR_FLAG_DUMMY)) {
		pfr_insert_kentries(kt, &workq, tzero);
	} else
		pfr_destroy_kentries(&workq);
	if (nadd != NULL)
		*nadd = xadd;
	pfr_destroy_ktable(tmpkt, 0);
	return (0);
_bad:
	pfr_clean_node_mask(tmpkt, &workq);
	pfr_destroy_kentries(&workq);
	if (flags & PFR_FLAG_FEEDBACK)
		pfr_reset_feedback(addr, size, flags);
	pfr_destroy_ktable(tmpkt, 0);
	return (rv);
}

int
pfr_del_addrs(struct pfr_table *tbl, struct pfr_addr *addr, int size,
    int *ndel, int flags)
{
	struct pfr_ktable	*kt;
	struct pfr_kentryworkq	 workq;
	struct pfr_kentry	*p;
	struct pfr_addr		 ad;
	int			 i, rv, xdel = 0, log = 1;

	ACCEPT_FLAGS(flags, PFR_FLAG_DUMMY | PFR_FLAG_FEEDBACK);
	if (pfr_validate_table(tbl, 0, flags & PFR_FLAG_USERIOCTL))
		return (EINVAL);
	kt = pfr_lookup_table(tbl);
	if (kt == NULL || !(kt->pfrkt_flags & PFR_TFLAG_ACTIVE))
		return (ESRCH);
	if (kt->pfrkt_flags & PFR_TFLAG_CONST)
		return (EPERM);
	/*
	 * there are two algorithms to choose from here.
	 * with:
	 *   n: number of addresses to delete
	 *   N: number of addresses in the table
	 *
	 * one is O(N) and is better for large 'n'
	 * one is O(n*LOG(N)) and is better for small 'n'
	 *
	 * following code try to decide which one is best.
	 */
	for (i = kt->pfrkt_cnt; i > 0; i >>= 1)
		log++;
	if (size > kt->pfrkt_cnt/log) {
		/* full table scan */
		pfr_mark_addrs(kt);
	} else {
		/* iterate over addresses to delete */
		for (i = 0; i < size; i++) {
			YIELD(i, flags & PFR_FLAG_USERIOCTL);
			if (COPYIN(addr+i, &ad, sizeof(ad), flags))
				return (EFAULT);
			if (pfr_validate_addr(&ad))
				return (EINVAL);
			p = pfr_lookup_addr(kt, &ad, 1);
			if (p != NULL)
				p->pfrke_flags &= ~PFRKE_FLAG_MARK;
		}
	}
	SLIST_INIT(&workq);
	for (i = 0; i < size; i++) {
		YIELD(i, flags & PFR_FLAG_USERIOCTL);
		if (COPYIN(addr+i, &ad, sizeof(ad), flags))
			senderr(EFAULT);
		if (pfr_validate_addr(&ad))
			senderr(EINVAL);
		p = pfr_lookup_addr(kt, &ad, 1);
		if (flags & PFR_FLAG_FEEDBACK) {
			if (p == NULL)
				ad.pfra_fback = PFR_FB_NONE;
			else if ((p->pfrke_flags & PFRKE_FLAG_NOT) !=
			    ad.pfra_not)
				ad.pfra_fback = PFR_FB_CONFLICT;
			else if (p->pfrke_flags & PFRKE_FLAG_MARK)
				ad.pfra_fback = PFR_FB_DUPLICATE;
			else
				ad.pfra_fback = PFR_FB_DELETED;
		}
		if (p != NULL &&
		    (p->pfrke_flags & PFRKE_FLAG_NOT) == ad.pfra_not &&
		    !(p->pfrke_flags & PFRKE_FLAG_MARK)) {
			p->pfrke_flags |= PFRKE_FLAG_MARK;
			SLIST_INSERT_HEAD(&workq, p, pfrke_workq);
			xdel++;
		}
		if (flags & PFR_FLAG_FEEDBACK)
			if (COPYOUT(&ad, addr+i, sizeof(ad), flags))
				senderr(EFAULT);
	}
	if (!(flags & PFR_FLAG_DUMMY)) {
		pfr_remove_kentries(kt, &workq);
	}
	if (ndel != NULL)
		*ndel = xdel;
	return (0);
_bad:
	if (flags & PFR_FLAG_FEEDBACK)
		pfr_reset_feedback(addr, size, flags);
	return (rv);
}

int
pfr_set_addrs(struct pfr_table *tbl, struct pfr_addr *addr, int size,
    int *size2, int *nadd, int *ndel, int *nchange, int flags,
    u_int32_t ignore_pfrt_flags)
{
	struct pfr_ktable	*kt, *tmpkt;
	struct pfr_kentryworkq	 addq, delq, changeq;
	struct pfr_kentry	*p, *q;
	struct pfr_addr		 ad;
	int			 i, rv, xadd = 0, xdel = 0, xchange = 0;
	time_t			 tzero = time_second;

	ACCEPT_FLAGS(flags, PFR_FLAG_DUMMY | PFR_FLAG_FEEDBACK);
	if (pfr_validate_table(tbl, ignore_pfrt_flags, flags &
	    PFR_FLAG_USERIOCTL))
		return (EINVAL);
	kt = pfr_lookup_table(tbl);
	if (kt == NULL || !(kt->pfrkt_flags & PFR_TFLAG_ACTIVE))
		return (ESRCH);
	if (kt->pfrkt_flags & PFR_TFLAG_CONST)
		return (EPERM);
	tmpkt = pfr_create_ktable(&pfr_nulltable, 0, 0,
	    !(flags & PFR_FLAG_USERIOCTL));
	if (tmpkt == NULL)
		return (ENOMEM);
	pfr_mark_addrs(kt);
	SLIST_INIT(&addq);
	SLIST_INIT(&delq);
	SLIST_INIT(&changeq);
	for (i = 0; i < size; i++) {
		YIELD(i, flags & PFR_FLAG_USERIOCTL);
		if (COPYIN(addr+i, &ad, sizeof(ad), flags))
			senderr(EFAULT);
		if (pfr_validate_addr(&ad))
			senderr(EINVAL);
		ad.pfra_fback = PFR_FB_NONE;
		p = pfr_lookup_addr(kt, &ad, 1);
		if (p != NULL) {
			if (p->pfrke_flags & PFRKE_FLAG_MARK) {
				ad.pfra_fback = PFR_FB_DUPLICATE;
				goto _skip;
			}
			p->pfrke_flags |= PFRKE_FLAG_MARK;
			if ((p->pfrke_flags & PFRKE_FLAG_NOT) != ad.pfra_not) {
				SLIST_INSERT_HEAD(&changeq, p, pfrke_workq);
				ad.pfra_fback = PFR_FB_CHANGED;
				xchange++;
			}
		} else {
			q = pfr_lookup_addr(tmpkt, &ad, 1);
			if (q != NULL) {
				ad.pfra_fback = PFR_FB_DUPLICATE;
				goto _skip;
			}
			p = pfr_create_kentry(&ad);
			if (p == NULL)
				senderr(ENOMEM);
			if (pfr_route_kentry(tmpkt, p)) {
				pfr_destroy_kentry(p);
				ad.pfra_fback = PFR_FB_NONE;
				goto _skip;
			}
			SLIST_INSERT_HEAD(&addq, p, pfrke_workq);
			ad.pfra_fback = PFR_FB_ADDED;
			xadd++;
			if (p->pfrke_type == PFRKE_COST)
				kt->pfrkt_refcntcost++;
			pfr_ktable_winfo_update(kt, p);
		}
_skip:
		if (flags & PFR_FLAG_FEEDBACK)
			if (COPYOUT(&ad, addr+i, sizeof(ad), flags))
				senderr(EFAULT);
	}
	pfr_enqueue_addrs(kt, &delq, &xdel, ENQUEUE_UNMARKED_ONLY);
	if ((flags & PFR_FLAG_FEEDBACK) && *size2) {
		if (*size2 < size+xdel) {
			*size2 = size+xdel;
			senderr(0);
		}
		i = 0;
		SLIST_FOREACH(p, &delq, pfrke_workq) {
			pfr_copyout_addr(&ad, p);
			ad.pfra_fback = PFR_FB_DELETED;
			if (COPYOUT(&ad, addr+size+i, sizeof(ad), flags))
				senderr(EFAULT);
			i++;
		}
	}
	pfr_clean_node_mask(tmpkt, &addq);
	if (!(flags & PFR_FLAG_DUMMY)) {
		pfr_insert_kentries(kt, &addq, tzero);
		pfr_remove_kentries(kt, &delq);
		pfr_clstats_kentries(&changeq, tzero, INVERT_NEG_FLAG);
	} else
		pfr_destroy_kentries(&addq);
	if (nadd != NULL)
		*nadd = xadd;
	if (ndel != NULL)
		*ndel = xdel;
	if (nchange != NULL)
		*nchange = xchange;
	if ((flags & PFR_FLAG_FEEDBACK) && size2)
		*size2 = size+xdel;
	pfr_destroy_ktable(tmpkt, 0);
	return (0);
_bad:
	pfr_clean_node_mask(tmpkt, &addq);
	pfr_destroy_kentries(&addq);
	if (flags & PFR_FLAG_FEEDBACK)
		pfr_reset_feedback(addr, size, flags);
	pfr_destroy_ktable(tmpkt, 0);
	return (rv);
}

int
pfr_tst_addrs(struct pfr_table *tbl, struct pfr_addr *addr, int size,
	int *nmatch, int flags)
{
	struct pfr_ktable	*kt;
	struct pfr_kentry	*p;
	struct pfr_addr		 ad;
	int			 i, xmatch = 0;

	ACCEPT_FLAGS(flags, PFR_FLAG_REPLACE);
	if (pfr_validate_table(tbl, 0, 0))
		return (EINVAL);
	kt = pfr_lookup_table(tbl);
	if (kt == NULL || !(kt->pfrkt_flags & PFR_TFLAG_ACTIVE))
		return (ESRCH);

	for (i = 0; i < size; i++) {
		YIELD(i, flags & PFR_FLAG_USERIOCTL);
		if (COPYIN(addr+i, &ad, sizeof(ad), flags))
			return (EFAULT);
		if (pfr_validate_addr(&ad))
			return (EINVAL);
		if (ADDR_NETWORK(&ad))
			return (EINVAL);
		p = pfr_lookup_addr(kt, &ad, 0);
		if (flags & PFR_FLAG_REPLACE)
			pfr_copyout_addr(&ad, p);
		ad.pfra_fback = (p == NULL) ? PFR_FB_NONE :
		    ((p->pfrke_flags & PFRKE_FLAG_NOT) ?
		    PFR_FB_NOTMATCH : PFR_FB_MATCH);
		if (p != NULL && !(p->pfrke_flags & PFRKE_FLAG_NOT))
			xmatch++;
		if (COPYOUT(&ad, addr+i, sizeof(ad), flags))
			return (EFAULT);
	}
	if (nmatch != NULL)
		*nmatch = xmatch;
	return (0);
}

int
pfr_get_addrs(struct pfr_table *tbl, struct pfr_addr *addr, int *size,
	int flags)
{
	struct pfr_ktable	*kt;
	struct pfr_walktree	 w;
	int			 rv;

	ACCEPT_FLAGS(flags, 0);
	if (pfr_validate_table(tbl, 0, 0))
		return (EINVAL);
	kt = pfr_lookup_table(tbl);
	if (kt == NULL || !(kt->pfrkt_flags & PFR_TFLAG_ACTIVE))
		return (ESRCH);
	if (kt->pfrkt_cnt > *size) {
		*size = kt->pfrkt_cnt;
		return (0);
	}

	bzero(&w, sizeof(w));
	w.pfrw_op = PFRW_GET_ADDRS;
	w.pfrw_addr = addr;
	w.pfrw_free = kt->pfrkt_cnt;
	w.pfrw_flags = flags;
	rv = rn_walktree(kt->pfrkt_ip4, pfr_walktree, &w);
	if (!rv)
		rv = rn_walktree(kt->pfrkt_ip6, pfr_walktree, &w);
	if (rv)
		return (rv);

	if (w.pfrw_free) {
		DPFPRINTF(LOG_ERR,
		    "pfr_get_addrs: corruption detected (%d)", w.pfrw_free);
		return (ENOTTY);
	}
	*size = kt->pfrkt_cnt;
	return (0);
}

int
pfr_get_astats(struct pfr_table *tbl, struct pfr_astats *addr, int *size,
	int flags)
{
	struct pfr_ktable	*kt;
	struct pfr_walktree	 w;
	struct pfr_kentryworkq	 workq;
	int			 rv;
	time_t			 tzero = time_second;

	if (pfr_validate_table(tbl, 0, 0))
		return (EINVAL);
	kt = pfr_lookup_table(tbl);
	if (kt == NULL || !(kt->pfrkt_flags & PFR_TFLAG_ACTIVE))
		return (ESRCH);
	if (kt->pfrkt_cnt > *size) {
		*size = kt->pfrkt_cnt;
		return (0);
	}

	bzero(&w, sizeof(w));
	w.pfrw_op = PFRW_GET_ASTATS;
	w.pfrw_astats = addr;
	w.pfrw_free = kt->pfrkt_cnt;
	w.pfrw_flags = flags;
	rv = rn_walktree(kt->pfrkt_ip4, pfr_walktree, &w);
	if (!rv)
		rv = rn_walktree(kt->pfrkt_ip6, pfr_walktree, &w);
	if (!rv && (flags & PFR_FLAG_CLSTATS)) {
		pfr_enqueue_addrs(kt, &workq, NULL, 0);
		pfr_clstats_kentries(&workq, tzero, 0);
	}
	if (rv)
		return (rv);

	if (w.pfrw_free) {
		DPFPRINTF(LOG_ERR,
		    "pfr_get_astats: corruption detected (%d)", w.pfrw_free);
		return (ENOTTY);
	}
	*size = kt->pfrkt_cnt;
	return (0);
}

int
pfr_clr_astats(struct pfr_table *tbl, struct pfr_addr *addr, int size,
    int *nzero, int flags)
{
	struct pfr_ktable	*kt;
	struct pfr_kentryworkq	 workq;
	struct pfr_kentry	*p;
	struct pfr_addr		 ad;
	int			 i, rv, xzero = 0;

	ACCEPT_FLAGS(flags, PFR_FLAG_DUMMY | PFR_FLAG_FEEDBACK);
	if (pfr_validate_table(tbl, 0, 0))
		return (EINVAL);
	kt = pfr_lookup_table(tbl);
	if (kt == NULL || !(kt->pfrkt_flags & PFR_TFLAG_ACTIVE))
		return (ESRCH);
	SLIST_INIT(&workq);
	for (i = 0; i < size; i++) {
		YIELD(i, flags & PFR_FLAG_USERIOCTL);
		if (COPYIN(addr+i, &ad, sizeof(ad), flags))
			senderr(EFAULT);
		if (pfr_validate_addr(&ad))
			senderr(EINVAL);
		p = pfr_lookup_addr(kt, &ad, 1);
		if (flags & PFR_FLAG_FEEDBACK) {
			ad.pfra_fback = (p != NULL) ?
			    PFR_FB_CLEARED : PFR_FB_NONE;
			if (COPYOUT(&ad, addr+i, sizeof(ad), flags))
				senderr(EFAULT);
		}
		if (p != NULL) {
			SLIST_INSERT_HEAD(&workq, p, pfrke_workq);
			xzero++;
		}
	}

	if (!(flags & PFR_FLAG_DUMMY)) {
		pfr_clstats_kentries(&workq, time_second, 0);
	}
	if (nzero != NULL)
		*nzero = xzero;
	return (0);
_bad:
	if (flags & PFR_FLAG_FEEDBACK)
		pfr_reset_feedback(addr, size, flags);
	return (rv);
}

int
pfr_validate_addr(struct pfr_addr *ad)
{
	int i;

	switch (ad->pfra_af) {
	case AF_INET:
		if (ad->pfra_net > 32)
			return (-1);
		break;
#ifdef INET6
	case AF_INET6:
		if (ad->pfra_net > 128)
			return (-1);
		break;
#endif /* INET6 */
	default:
		return (-1);
	}
	if (ad->pfra_net < 128 &&
		(((caddr_t)ad)[ad->pfra_net/8] & (0xFF >> (ad->pfra_net%8))))
			return (-1);
	for (i = (ad->pfra_net+7)/8; i < sizeof(ad->pfra_u); i++)
		if (((caddr_t)ad)[i])
			return (-1);
	if (ad->pfra_not && ad->pfra_not != 1)
		return (-1);
	if (ad->pfra_fback)
		return (-1);
	return (0);
}

void
pfr_enqueue_addrs(struct pfr_ktable *kt, struct pfr_kentryworkq *workq,
	int *naddr, int sweep)
{
	struct pfr_walktree	w;

	SLIST_INIT(workq);
	bzero(&w, sizeof(w));
	w.pfrw_op = sweep ? PFRW_SWEEP : PFRW_ENQUEUE;
	w.pfrw_workq = workq;
	if (kt->pfrkt_ip4 != NULL)
		if (rn_walktree(kt->pfrkt_ip4, pfr_walktree, &w))
			DPFPRINTF(LOG_ERR,
			    "pfr_enqueue_addrs: IPv4 walktree failed.");
	if (kt->pfrkt_ip6 != NULL)
		if (rn_walktree(kt->pfrkt_ip6, pfr_walktree, &w))
			DPFPRINTF(LOG_ERR,
			    "pfr_enqueue_addrs: IPv6 walktree failed.");
	if (naddr != NULL)
		*naddr = w.pfrw_cnt;
}

void
pfr_mark_addrs(struct pfr_ktable *kt)
{
	struct pfr_walktree	w;

	bzero(&w, sizeof(w));
	w.pfrw_op = PFRW_MARK;
	if (rn_walktree(kt->pfrkt_ip4, pfr_walktree, &w))
		DPFPRINTF(LOG_ERR,
		    "pfr_mark_addrs: IPv4 walktree failed.");
	if (rn_walktree(kt->pfrkt_ip6, pfr_walktree, &w))
		DPFPRINTF(LOG_ERR,
		    "pfr_mark_addrs: IPv6 walktree failed.");
}


struct pfr_kentry *
pfr_lookup_addr(struct pfr_ktable *kt, struct pfr_addr *ad, int exact)
{
	union sockaddr_union	 sa, mask;
	struct radix_node_head	*head;
	struct pfr_kentry	*ke;

	bzero(&sa, sizeof(sa));
	switch (ad->pfra_af) {
	case AF_INET:
		FILLIN_SIN(sa.sin, ad->pfra_ip4addr);
		head = kt->pfrkt_ip4;
		break;
#ifdef	INET6
	case AF_INET6:
		FILLIN_SIN6(sa.sin6, ad->pfra_ip6addr);
		head = kt->pfrkt_ip6;
		break;
#endif	/* INET6 */
	default:
		unhandled_af(ad->pfra_af);
	}
	if (ADDR_NETWORK(ad)) {
		pfr_prepare_network(&mask, ad->pfra_af, ad->pfra_net);
		ke = (struct pfr_kentry *)rn_lookup(&sa, &mask, head);
	} else {
		ke = (struct pfr_kentry *)rn_match(&sa, head);
		if (exact && ke && KENTRY_NETWORK(ke))
			ke = NULL;
	}
	return (ke);
}

struct pfr_kentry *
pfr_create_kentry(struct pfr_addr *ad)
{
	struct pfr_kentry_all	*ke;

	ke = pool_get(&pfr_kentry_pl[ad->pfra_type], PR_NOWAIT | PR_ZERO);
	if (ke == NULL)
		return (NULL);

	ke->pfrke_type = ad->pfra_type;

	/* set weight allowing implicit weights */
	if (ad->pfra_weight == 0)
		ad->pfra_weight = 1;

	switch (ke->pfrke_type) {
	case PFRKE_PLAIN:
		break;
	case PFRKE_COST:
		((struct pfr_kentry_cost *)ke)->weight = ad->pfra_weight;
		/* FALLTHROUGH */
	case PFRKE_ROUTE:
		if (ad->pfra_ifname[0])
			ke->pfrke_rkif = pfi_kif_get(ad->pfra_ifname);
		if (ke->pfrke_rkif)
			pfi_kif_ref(ke->pfrke_rkif, PFI_KIF_REF_ROUTE);
		break;
	default:
		panic("unknown pfrke_type %d", ke->pfrke_type);
		break;
	}

	switch (ad->pfra_af) {
	case AF_INET:
		FILLIN_SIN(ke->pfrke_sa.sin, ad->pfra_ip4addr);
		break;
#ifdef	INET6
	case AF_INET6:
		FILLIN_SIN6(ke->pfrke_sa.sin6, ad->pfra_ip6addr);
		break;
#endif	/* INET6 */
	default:
		unhandled_af(ad->pfra_af);
	}
	ke->pfrke_af = ad->pfra_af;
	ke->pfrke_net = ad->pfra_net;
	if (ad->pfra_not)
		ke->pfrke_flags |= PFRKE_FLAG_NOT;
	return ((struct pfr_kentry *)ke);
}

void
pfr_destroy_kentries(struct pfr_kentryworkq *workq)
{
	struct pfr_kentry	*p, *q;
	int			 i;

	for (i = 0, p = SLIST_FIRST(workq); p != NULL; i++, p = q) {
		YIELD(i, 1);
		q = SLIST_NEXT(p, pfrke_workq);
		pfr_destroy_kentry(p);
	}
}

void
pfr_destroy_kentry(struct pfr_kentry *ke)
{
	if (ke->pfrke_counters)
		pool_put(&pfr_kcounters_pl, ke->pfrke_counters);
	if (ke->pfrke_type == PFRKE_COST || ke->pfrke_type == PFRKE_ROUTE)
		pfi_kif_unref(((struct pfr_kentry_all *)ke)->pfrke_rkif,
		    PFI_KIF_REF_ROUTE);
	pool_put(&pfr_kentry_pl[ke->pfrke_type], ke);
}

void
pfr_insert_kentries(struct pfr_ktable *kt,
    struct pfr_kentryworkq *workq, time_t tzero)
{
	struct pfr_kentry	*p;
	int			 rv, n = 0;

	SLIST_FOREACH(p, workq, pfrke_workq) {
		rv = pfr_route_kentry(kt, p);
		if (rv) {
			DPFPRINTF(LOG_ERR,
			    "pfr_insert_kentries: cannot route entry "
			    "(code=%d).", rv);
			break;
		}
		p->pfrke_tzero = tzero;
		++n;
		if (p->pfrke_type == PFRKE_COST)
			kt->pfrkt_refcntcost++;
		pfr_ktable_winfo_update(kt, p);
		YIELD(n, 1);
	}
	kt->pfrkt_cnt += n;
}

int
pfr_insert_kentry(struct pfr_ktable *kt, struct pfr_addr *ad, time_t tzero)
{
	struct pfr_kentry	*p;
	int			 rv;

	p = pfr_lookup_addr(kt, ad, 1);
	if (p != NULL)
		return (0);
	p = pfr_create_kentry(ad);
	if (p == NULL)
		return (EINVAL);

	rv = pfr_route_kentry(kt, p);
	if (rv)
		return (rv);

	p->pfrke_tzero = tzero;
	if (p->pfrke_type == PFRKE_COST)
		kt->pfrkt_refcntcost++;
	kt->pfrkt_cnt++;
	pfr_ktable_winfo_update(kt, p);

	return (0);
}

void
pfr_remove_kentries(struct pfr_ktable *kt,
    struct pfr_kentryworkq *workq)
{
	struct pfr_kentry	*p;
	struct pfr_kentryworkq   addrq;
	int			 n = 0;

	SLIST_FOREACH(p, workq, pfrke_workq) {
		pfr_unroute_kentry(kt, p);
		++n;
		YIELD(n, 1);
		if (p->pfrke_type == PFRKE_COST)
			kt->pfrkt_refcntcost--;
	}
	kt->pfrkt_cnt -= n;
	pfr_destroy_kentries(workq);

	/* update maxweight and gcd for load balancing */
	if (kt->pfrkt_refcntcost > 0) {
		kt->pfrkt_gcdweight = 0;
		kt->pfrkt_maxweight = 1;
		pfr_enqueue_addrs(kt, &addrq, NULL, 0);
		SLIST_FOREACH(p, &addrq, pfrke_workq)
			pfr_ktable_winfo_update(kt, p);
	}
}

void
pfr_clean_node_mask(struct pfr_ktable *kt,
    struct pfr_kentryworkq *workq)
{
	struct pfr_kentry	*p;

	SLIST_FOREACH(p, workq, pfrke_workq) {
		pfr_unroute_kentry(kt, p);
	}
}

void
pfr_clstats_kentries(struct pfr_kentryworkq *workq, time_t tzero, int negchange)
{
	struct pfr_kentry	*p;

	SLIST_FOREACH(p, workq, pfrke_workq) {
		if (negchange)
			p->pfrke_flags ^= PFRKE_FLAG_NOT;
		if (p->pfrke_counters) {
			pool_put(&pfr_kcounters_pl, p->pfrke_counters);
			p->pfrke_counters = NULL;
		}
		p->pfrke_tzero = tzero;
	}
}

void
pfr_reset_feedback(struct pfr_addr *addr, int size, int flags)
{
	struct pfr_addr	ad;
	int		i;

	for (i = 0; i < size; i++) {
		YIELD(i, flags & PFR_FLAG_USERIOCTL);
		if (COPYIN(addr+i, &ad, sizeof(ad), flags))
			break;
		ad.pfra_fback = PFR_FB_NONE;
		if (COPYOUT(&ad, addr+i, sizeof(ad), flags))
			break;
	}
}

void
pfr_prepare_network(union sockaddr_union *sa, int af, int net)
{
#ifdef	INET6
	int	i;
#endif	/* INET6 */

	bzero(sa, sizeof(*sa));
	switch (af) {
	case AF_INET:
		sa->sin.sin_len = sizeof(sa->sin);
		sa->sin.sin_family = AF_INET;
		sa->sin.sin_addr.s_addr = net ? htonl(-1 << (32-net)) : 0;
		break;
#ifdef	INET6
	case AF_INET6:
		sa->sin6.sin6_len = sizeof(sa->sin6);
		sa->sin6.sin6_family = AF_INET6;
		for (i = 0; i < 4; i++) {
			if (net <= 32) {
				sa->sin6.sin6_addr.s6_addr32[i] =
				    net ? htonl(-1 << (32-net)) : 0;
				break;
			}
			sa->sin6.sin6_addr.s6_addr32[i] = 0xFFFFFFFF;
			net -= 32;
		}
		break;
#endif	/* INET6 */
	default:
		unhandled_af(af);
	}
}

int
pfr_route_kentry(struct pfr_ktable *kt, struct pfr_kentry *ke)
{
	union sockaddr_union	 mask;
	struct radix_node	*rn;
	struct radix_node_head	*head;

	bzero(ke->pfrke_node, sizeof(ke->pfrke_node));
	switch (ke->pfrke_af) {
	case AF_INET:
		head = kt->pfrkt_ip4;
		break;
#ifdef	INET6
	case AF_INET6:
		head = kt->pfrkt_ip6;
		break;
#endif	/* INET6 */
	default:
		unhandled_af(ke->pfrke_af);
	}

	if (KENTRY_NETWORK(ke)) {
		pfr_prepare_network(&mask, ke->pfrke_af, ke->pfrke_net);
		rn = rn_addroute(&ke->pfrke_sa, &mask, head, ke->pfrke_node, 0);
	} else
		rn = rn_addroute(&ke->pfrke_sa, NULL, head, ke->pfrke_node, 0);

	return (rn == NULL ? -1 : 0);
}

int
pfr_unroute_kentry(struct pfr_ktable *kt, struct pfr_kentry *ke)
{
	union sockaddr_union	 mask;
	struct radix_node	*rn;
	struct radix_node_head	*head;

	switch (ke->pfrke_af) {
	case AF_INET:
		head = kt->pfrkt_ip4;
		break;
#ifdef	INET6
	case AF_INET6:
		head = kt->pfrkt_ip6;
		break;
#endif	/* INET6 */
	default:
		unhandled_af(ke->pfrke_af);
	}

	if (KENTRY_NETWORK(ke)) {
		pfr_prepare_network(&mask, ke->pfrke_af, ke->pfrke_net);
		rn = rn_delete(&ke->pfrke_sa, &mask, head, NULL);
	} else
		rn = rn_delete(&ke->pfrke_sa, NULL, head, NULL);

	if (rn == NULL) {
		DPFPRINTF(LOG_ERR, "pfr_unroute_kentry: delete failed.\n");
		return (-1);
	}
	return (0);
}

void
pfr_copyout_addr(struct pfr_addr *ad, struct pfr_kentry *ke)
{
	bzero(ad, sizeof(*ad));
	if (ke == NULL)
		return;
	ad->pfra_af = ke->pfrke_af;
	ad->pfra_net = ke->pfrke_net;
	ad->pfra_type = ke->pfrke_type;
	if (ke->pfrke_flags & PFRKE_FLAG_NOT)
		ad->pfra_not = 1;

	switch (ad->pfra_af) {
	case AF_INET:
		ad->pfra_ip4addr = ke->pfrke_sa.sin.sin_addr;
		break;
#ifdef	INET6
	case AF_INET6:
		ad->pfra_ip6addr = ke->pfrke_sa.sin6.sin6_addr;
		break;
#endif	/* INET6 */
	default:
		unhandled_af(ad->pfra_af);
	}
	if (ke->pfrke_counters != NULL)
		ad->pfra_states = ke->pfrke_counters->states;
	switch (ke->pfrke_type) {
	case PFRKE_COST:
		ad->pfra_weight = ((struct pfr_kentry_cost *)ke)->weight;
		/* FALLTHROUGH */
	case PFRKE_ROUTE:
		if (((struct pfr_kentry_route *)ke)->kif != NULL)
			strlcpy(ad->pfra_ifname,
			    ((struct pfr_kentry_route *)ke)->kif->pfik_name,
			    IFNAMSIZ);
		break;
	default:
		break;
	}
}

int
pfr_walktree(struct radix_node *rn, void *arg, u_int id)
{
	struct pfr_kentry	*ke = (struct pfr_kentry *)rn;
	struct pfr_walktree	*w = arg;
	int			 flags = w->pfrw_flags;

	switch (w->pfrw_op) {
	case PFRW_MARK:
		ke->pfrke_flags &= ~PFRKE_FLAG_MARK;
		break;
	case PFRW_SWEEP:
		if (ke->pfrke_flags & PFRKE_FLAG_MARK)
			break;
		/* FALLTHROUGH */
	case PFRW_ENQUEUE:
		SLIST_INSERT_HEAD(w->pfrw_workq, ke, pfrke_workq);
		w->pfrw_cnt++;
		break;
	case PFRW_GET_ADDRS:
		if (w->pfrw_free-- > 0) {
			struct pfr_addr ad;

			pfr_copyout_addr(&ad, ke);
			if (copyout(&ad, w->pfrw_addr, sizeof(ad)))
				return (EFAULT);
			w->pfrw_addr++;
		}
		break;
	case PFRW_GET_ASTATS:
		if (w->pfrw_free-- > 0) {
			struct pfr_astats as;

			pfr_copyout_addr(&as.pfras_a, ke);

			if (ke->pfrke_counters) {
				bcopy(ke->pfrke_counters->pfrkc_packets,
				    as.pfras_packets, sizeof(as.pfras_packets));
				bcopy(ke->pfrke_counters->pfrkc_bytes,
				    as.pfras_bytes, sizeof(as.pfras_bytes));
			} else {
				bzero(as.pfras_packets,
				    sizeof(as.pfras_packets));
				bzero(as.pfras_bytes, sizeof(as.pfras_bytes));
				as.pfras_a.pfra_fback = PFR_FB_NOCOUNT;
			}
			as.pfras_tzero = ke->pfrke_tzero;

			if (COPYOUT(&as, w->pfrw_astats, sizeof(as), flags))
				return (EFAULT);
			w->pfrw_astats++;
		}
		break;
	case PFRW_POOL_GET:
		if (ke->pfrke_flags & PFRKE_FLAG_NOT)
			break; /* negative entries are ignored */
		if (!w->pfrw_cnt--) {
			w->pfrw_kentry = ke;
			return (1); /* finish search */
		}
		break;
	case PFRW_DYNADDR_UPDATE:
		switch (ke->pfrke_af) {
		case AF_INET:
			if (w->pfrw_dyn->pfid_acnt4++ > 0)
				break;
			pfr_prepare_network(&pfr_mask, AF_INET, ke->pfrke_net);
			w->pfrw_dyn->pfid_addr4 = *SUNION2PF(
			    &ke->pfrke_sa, AF_INET);
			w->pfrw_dyn->pfid_mask4 = *SUNION2PF(
			    &pfr_mask, AF_INET);
			break;
#ifdef	INET6
		case AF_INET6:
			if (w->pfrw_dyn->pfid_acnt6++ > 0)
				break;
			pfr_prepare_network(&pfr_mask, AF_INET6, ke->pfrke_net);
			w->pfrw_dyn->pfid_addr6 = *SUNION2PF(
			    &ke->pfrke_sa, AF_INET6);
			w->pfrw_dyn->pfid_mask6 = *SUNION2PF(
			    &pfr_mask, AF_INET6);
			break;
#endif	/* INET6 */
		default:
			unhandled_af(ke->pfrke_af);
		}
		break;
	}
	return (0);
}

int
pfr_clr_tables(struct pfr_table *filter, int *ndel, int flags)
{
	struct pfr_ktableworkq	 workq;
	struct pfr_ktable	*p;
	int			 xdel = 0;

	ACCEPT_FLAGS(flags, PFR_FLAG_DUMMY | PFR_FLAG_ALLRSETS);
	if (pfr_fix_anchor(filter->pfrt_anchor))
		return (EINVAL);
	if (pfr_table_count(filter, flags) < 0)
		return (ENOENT);

	SLIST_INIT(&workq);
	RB_FOREACH(p, pfr_ktablehead, &pfr_ktables) {
		if (pfr_skip_table(filter, p, flags))
			continue;
		if (!strcmp(p->pfrkt_anchor, PF_RESERVED_ANCHOR))
			continue;
		if (!(p->pfrkt_flags & PFR_TFLAG_ACTIVE))
			continue;
		p->pfrkt_nflags = p->pfrkt_flags & ~PFR_TFLAG_ACTIVE;
		SLIST_INSERT_HEAD(&workq, p, pfrkt_workq);
		xdel++;
	}
	if (!(flags & PFR_FLAG_DUMMY)) {
		pfr_setflags_ktables(&workq);
	}
	if (ndel != NULL)
		*ndel = xdel;
	return (0);
}

int
pfr_add_tables(struct pfr_table *tbl, int size, int *nadd, int flags)
{
	struct pfr_ktableworkq	 addq, changeq;
	struct pfr_ktable	*p, *q, *r, key;
	int			 i, rv, xadd = 0;
	time_t			 tzero = time_second;

	ACCEPT_FLAGS(flags, PFR_FLAG_DUMMY);
	SLIST_INIT(&addq);
	SLIST_INIT(&changeq);
	for (i = 0; i < size; i++) {
		YIELD(i, flags & PFR_FLAG_USERIOCTL);
		if (COPYIN(tbl+i, &key.pfrkt_t, sizeof(key.pfrkt_t), flags))
			senderr(EFAULT);
		if (pfr_validate_table(&key.pfrkt_t, PFR_TFLAG_USRMASK,
		    flags & PFR_FLAG_USERIOCTL))
			senderr(EINVAL);
		key.pfrkt_flags |= PFR_TFLAG_ACTIVE;
		p = RB_FIND(pfr_ktablehead, &pfr_ktables, &key);
		if (p == NULL) {
			p = pfr_create_ktable(&key.pfrkt_t, tzero, 1,
			    !(flags & PFR_FLAG_USERIOCTL));
			if (p == NULL)
				senderr(ENOMEM);
			SLIST_FOREACH(q, &addq, pfrkt_workq) {
				if (!pfr_ktable_compare(p, q))
					goto _skip;
			}
			SLIST_INSERT_HEAD(&addq, p, pfrkt_workq);
			xadd++;
			if (!key.pfrkt_anchor[0])
				goto _skip;

			/* find or create root table */
			bzero(key.pfrkt_anchor, sizeof(key.pfrkt_anchor));
			r = RB_FIND(pfr_ktablehead, &pfr_ktables, &key);
			if (r != NULL) {
				p->pfrkt_root = r;
				goto _skip;
			}
			SLIST_FOREACH(q, &addq, pfrkt_workq) {
				if (!pfr_ktable_compare(&key, q)) {
					p->pfrkt_root = q;
					goto _skip;
				}
			}
			key.pfrkt_flags = 0;
			r = pfr_create_ktable(&key.pfrkt_t, 0, 1,
			    !(flags & PFR_FLAG_USERIOCTL));
			if (r == NULL)
				senderr(ENOMEM);
			SLIST_INSERT_HEAD(&addq, r, pfrkt_workq);
			p->pfrkt_root = r;
		} else if (!(p->pfrkt_flags & PFR_TFLAG_ACTIVE)) {
			SLIST_FOREACH(q, &changeq, pfrkt_workq)
				if (!pfr_ktable_compare(&key, q))
					goto _skip;
			p->pfrkt_nflags = (p->pfrkt_flags &
			    ~PFR_TFLAG_USRMASK) | key.pfrkt_flags;
			SLIST_INSERT_HEAD(&changeq, p, pfrkt_workq);
			xadd++;
		}
_skip:
	;
	}
	if (!(flags & PFR_FLAG_DUMMY)) {
		pfr_insert_ktables(&addq);
		pfr_setflags_ktables(&changeq);
	} else
		 pfr_destroy_ktables(&addq, 0);
	if (nadd != NULL)
		*nadd = xadd;
	return (0);
_bad:
	pfr_destroy_ktables(&addq, 0);
	return (rv);
}

int
pfr_del_tables(struct pfr_table *tbl, int size, int *ndel, int flags)
{
	struct pfr_ktableworkq	 workq;
	struct pfr_ktable	*p, *q, key;
	int			 i, xdel = 0;

	ACCEPT_FLAGS(flags, PFR_FLAG_DUMMY);
	SLIST_INIT(&workq);
	for (i = 0; i < size; i++) {
		YIELD(i, flags & PFR_FLAG_USERIOCTL);
		if (COPYIN(tbl+i, &key.pfrkt_t, sizeof(key.pfrkt_t), flags))
			return (EFAULT);
		if (pfr_validate_table(&key.pfrkt_t, 0,
		    flags & PFR_FLAG_USERIOCTL))
			return (EINVAL);
		p = RB_FIND(pfr_ktablehead, &pfr_ktables, &key);
		if (p != NULL && (p->pfrkt_flags & PFR_TFLAG_ACTIVE)) {
			SLIST_FOREACH(q, &workq, pfrkt_workq)
				if (!pfr_ktable_compare(p, q))
					goto _skip;
			p->pfrkt_nflags = p->pfrkt_flags & ~PFR_TFLAG_ACTIVE;
			SLIST_INSERT_HEAD(&workq, p, pfrkt_workq);
			xdel++;
		}
_skip:
	;
	}

	if (!(flags & PFR_FLAG_DUMMY)) {
		pfr_setflags_ktables(&workq);
	}
	if (ndel != NULL)
		*ndel = xdel;
	return (0);
}

int
pfr_get_tables(struct pfr_table *filter, struct pfr_table *tbl, int *size,
	int flags)
{
	struct pfr_ktable	*p;
	int			 n, nn;

	ACCEPT_FLAGS(flags, PFR_FLAG_ALLRSETS);
	if (pfr_fix_anchor(filter->pfrt_anchor))
		return (EINVAL);
	n = nn = pfr_table_count(filter, flags);
	if (n < 0)
		return (ENOENT);
	if (n > *size) {
		*size = n;
		return (0);
	}
	RB_FOREACH(p, pfr_ktablehead, &pfr_ktables) {
		if (pfr_skip_table(filter, p, flags))
			continue;
		if (n-- <= 0)
			continue;
		if (COPYOUT(&p->pfrkt_t, tbl++, sizeof(*tbl), flags))
			return (EFAULT);
	}
	if (n) {
		DPFPRINTF(LOG_ERR,
		    "pfr_get_tables: corruption detected (%d).", n);
		return (ENOTTY);
	}
	*size = nn;
	return (0);
}

int
pfr_get_tstats(struct pfr_table *filter, struct pfr_tstats *tbl, int *size,
	int flags)
{
	struct pfr_ktable	*p;
	struct pfr_ktableworkq	 workq;
	int			 n, nn;
	time_t			 tzero = time_second;

	/* XXX PFR_FLAG_CLSTATS disabled */
	ACCEPT_FLAGS(flags, PFR_FLAG_ALLRSETS);
	if (pfr_fix_anchor(filter->pfrt_anchor))
		return (EINVAL);
	n = nn = pfr_table_count(filter, flags);
	if (n < 0)
		return (ENOENT);
	if (n > *size) {
		*size = n;
		return (0);
	}
	SLIST_INIT(&workq);
	RB_FOREACH(p, pfr_ktablehead, &pfr_ktables) {
		if (pfr_skip_table(filter, p, flags))
			continue;
		if (n-- <= 0)
			continue;
		if (COPYOUT(&p->pfrkt_ts, tbl++, sizeof(*tbl), flags))
			return (EFAULT);
		SLIST_INSERT_HEAD(&workq, p, pfrkt_workq);
	}
	if (flags & PFR_FLAG_CLSTATS)
		pfr_clstats_ktables(&workq, tzero,
		    flags & PFR_FLAG_ADDRSTOO);
	if (n) {
		DPFPRINTF(LOG_ERR,
		    "pfr_get_tstats: corruption detected (%d).", n);
		return (ENOTTY);
	}
	*size = nn;
	return (0);
}

int
pfr_clr_tstats(struct pfr_table *tbl, int size, int *nzero, int flags)
{
	struct pfr_ktableworkq	 workq;
	struct pfr_ktable	*p, key;
	int			 i, xzero = 0;
	time_t			 tzero = time_second;

	ACCEPT_FLAGS(flags, PFR_FLAG_DUMMY | PFR_FLAG_ADDRSTOO);
	SLIST_INIT(&workq);
	for (i = 0; i < size; i++) {
		YIELD(i, flags & PFR_FLAG_USERIOCTL);
		if (COPYIN(tbl+i, &key.pfrkt_t, sizeof(key.pfrkt_t), flags))
			return (EFAULT);
		if (pfr_validate_table(&key.pfrkt_t, 0, 0))
			return (EINVAL);
		p = RB_FIND(pfr_ktablehead, &pfr_ktables, &key);
		if (p != NULL) {
			SLIST_INSERT_HEAD(&workq, p, pfrkt_workq);
			xzero++;
		}
	}
	if (!(flags & PFR_FLAG_DUMMY)) {
		pfr_clstats_ktables(&workq, tzero, flags & PFR_FLAG_ADDRSTOO);
	}
	if (nzero != NULL)
		*nzero = xzero;
	return (0);
}

int
pfr_set_tflags(struct pfr_table *tbl, int size, int setflag, int clrflag,
	int *nchange, int *ndel, int flags)
{
	struct pfr_ktableworkq	 workq;
	struct pfr_ktable	*p, *q, key;
	int			 i, xchange = 0, xdel = 0;

	ACCEPT_FLAGS(flags, PFR_FLAG_DUMMY);
	if ((setflag & ~PFR_TFLAG_USRMASK) ||
	    (clrflag & ~PFR_TFLAG_USRMASK) ||
	    (setflag & clrflag))
		return (EINVAL);
	SLIST_INIT(&workq);
	for (i = 0; i < size; i++) {
		YIELD(i, flags & PFR_FLAG_USERIOCTL);
		if (COPYIN(tbl+i, &key.pfrkt_t, sizeof(key.pfrkt_t), flags))
			return (EFAULT);
		if (pfr_validate_table(&key.pfrkt_t, 0,
		    flags & PFR_FLAG_USERIOCTL))
			return (EINVAL);
		p = RB_FIND(pfr_ktablehead, &pfr_ktables, &key);
		if (p != NULL && (p->pfrkt_flags & PFR_TFLAG_ACTIVE)) {
			p->pfrkt_nflags = (p->pfrkt_flags | setflag) &
			    ~clrflag;
			if (p->pfrkt_nflags == p->pfrkt_flags)
				goto _skip;
			SLIST_FOREACH(q, &workq, pfrkt_workq)
				if (!pfr_ktable_compare(p, q))
					goto _skip;
			SLIST_INSERT_HEAD(&workq, p, pfrkt_workq);
			if ((p->pfrkt_flags & PFR_TFLAG_PERSIST) &&
			    (clrflag & PFR_TFLAG_PERSIST) &&
			    !(p->pfrkt_flags & PFR_TFLAG_REFERENCED))
				xdel++;
			else
				xchange++;
		}
_skip:
	;
	}
	if (!(flags & PFR_FLAG_DUMMY)) {
		pfr_setflags_ktables(&workq);
	}
	if (nchange != NULL)
		*nchange = xchange;
	if (ndel != NULL)
		*ndel = xdel;
	return (0);
}

int
pfr_ina_begin(struct pfr_table *trs, u_int32_t *ticket, int *ndel, int flags)
{
	struct pfr_ktableworkq	 workq;
	struct pfr_ktable	*p;
	struct pf_ruleset	*rs;
	int			 xdel = 0;

	ACCEPT_FLAGS(flags, PFR_FLAG_DUMMY);
	rs = pf_find_or_create_ruleset(trs->pfrt_anchor);
	if (rs == NULL)
		return (ENOMEM);
	SLIST_INIT(&workq);
	RB_FOREACH(p, pfr_ktablehead, &pfr_ktables) {
		if (!(p->pfrkt_flags & PFR_TFLAG_INACTIVE) ||
		    pfr_skip_table(trs, p, 0))
			continue;
		p->pfrkt_nflags = p->pfrkt_flags & ~PFR_TFLAG_INACTIVE;
		SLIST_INSERT_HEAD(&workq, p, pfrkt_workq);
		xdel++;
	}
	if (!(flags & PFR_FLAG_DUMMY)) {
		pfr_setflags_ktables(&workq);
		if (ticket != NULL)
			*ticket = ++rs->tticket;
		rs->topen = 1;
	} else
		pf_remove_if_empty_ruleset(rs);
	if (ndel != NULL)
		*ndel = xdel;
	return (0);
}

int
pfr_ina_define(struct pfr_table *tbl, struct pfr_addr *addr, int size,
    int *nadd, int *naddr, u_int32_t ticket, int flags)
{
	struct pfr_ktableworkq	 tableq;
	struct pfr_kentryworkq	 addrq;
	struct pfr_ktable	*kt, *rt, *shadow, key;
	struct pfr_kentry	*p;
	struct pfr_addr		 ad;
	struct pf_ruleset	*rs;
	int			 i, rv, xadd = 0, xaddr = 0;

	ACCEPT_FLAGS(flags, PFR_FLAG_DUMMY | PFR_FLAG_ADDRSTOO);
	if (size && !(flags & PFR_FLAG_ADDRSTOO))
		return (EINVAL);
	if (pfr_validate_table(tbl, PFR_TFLAG_USRMASK,
	    flags & PFR_FLAG_USERIOCTL))
		return (EINVAL);
	rs = pf_find_ruleset(tbl->pfrt_anchor);
	if (rs == NULL || !rs->topen || ticket != rs->tticket)
		return (EBUSY);
	tbl->pfrt_flags |= PFR_TFLAG_INACTIVE;
	SLIST_INIT(&tableq);
	kt = RB_FIND(pfr_ktablehead, &pfr_ktables, (struct pfr_ktable *)tbl);
	if (kt == NULL) {
		kt = pfr_create_ktable(tbl, 0, 1,
		    !(flags & PFR_FLAG_USERIOCTL));
		if (kt == NULL)
			return (ENOMEM);
		SLIST_INSERT_HEAD(&tableq, kt, pfrkt_workq);
		xadd++;
		if (!tbl->pfrt_anchor[0])
			goto _skip;

		/* find or create root table */
		bzero(&key, sizeof(key));
		strlcpy(key.pfrkt_name, tbl->pfrt_name, sizeof(key.pfrkt_name));
		rt = RB_FIND(pfr_ktablehead, &pfr_ktables, &key);
		if (rt != NULL) {
			kt->pfrkt_root = rt;
			goto _skip;
		}
		rt = pfr_create_ktable(&key.pfrkt_t, 0, 1,
		    !(flags & PFR_FLAG_USERIOCTL));
		if (rt == NULL) {
			pfr_destroy_ktables(&tableq, 0);
			return (ENOMEM);
		}
		SLIST_INSERT_HEAD(&tableq, rt, pfrkt_workq);
		kt->pfrkt_root = rt;
	} else if (!(kt->pfrkt_flags & PFR_TFLAG_INACTIVE))
		xadd++;
_skip:
	shadow = pfr_create_ktable(tbl, 0, 0, !(flags & PFR_FLAG_USERIOCTL));
	if (shadow == NULL) {
		pfr_destroy_ktables(&tableq, 0);
		return (ENOMEM);
	}
	SLIST_INIT(&addrq);
	for (i = 0; i < size; i++) {
		YIELD(i, flags & PFR_FLAG_USERIOCTL);
		if (COPYIN(addr+i, &ad, sizeof(ad), flags))
			senderr(EFAULT);
		if (pfr_validate_addr(&ad))
			senderr(EINVAL);
		if (pfr_lookup_addr(shadow, &ad, 1) != NULL)
			continue;
		p = pfr_create_kentry(&ad);
		if (p == NULL)
			senderr(ENOMEM);
		if (pfr_route_kentry(shadow, p)) {
			pfr_destroy_kentry(p);
			continue;
		}
		SLIST_INSERT_HEAD(&addrq, p, pfrke_workq);
		xaddr++;
		if (p->pfrke_type == PFRKE_COST)
			kt->pfrkt_refcntcost++;
		pfr_ktable_winfo_update(kt, p);
	}
	if (!(flags & PFR_FLAG_DUMMY)) {
		if (kt->pfrkt_shadow != NULL)
			pfr_destroy_ktable(kt->pfrkt_shadow, 1);
		kt->pfrkt_flags |= PFR_TFLAG_INACTIVE;
		pfr_insert_ktables(&tableq);
		shadow->pfrkt_cnt = (flags & PFR_FLAG_ADDRSTOO) ?
		    xaddr : NO_ADDRESSES;
		kt->pfrkt_shadow = shadow;
	} else {
		pfr_clean_node_mask(shadow, &addrq);
		pfr_destroy_ktable(shadow, 0);
		pfr_destroy_ktables(&tableq, 0);
		pfr_destroy_kentries(&addrq);
	}
	if (nadd != NULL)
		*nadd = xadd;
	if (naddr != NULL)
		*naddr = xaddr;
	return (0);
_bad:
	pfr_destroy_ktable(shadow, 0);
	pfr_destroy_ktables(&tableq, 0);
	pfr_destroy_kentries(&addrq);
	return (rv);
}

int
pfr_ina_rollback(struct pfr_table *trs, u_int32_t ticket, int *ndel, int flags)
{
	struct pfr_ktableworkq	 workq;
	struct pfr_ktable	*p;
	struct pf_ruleset	*rs;
	int			 xdel = 0;

	ACCEPT_FLAGS(flags, PFR_FLAG_DUMMY);
	rs = pf_find_ruleset(trs->pfrt_anchor);
	if (rs == NULL || !rs->topen || ticket != rs->tticket)
		return (0);
	SLIST_INIT(&workq);
	RB_FOREACH(p, pfr_ktablehead, &pfr_ktables) {
		if (!(p->pfrkt_flags & PFR_TFLAG_INACTIVE) ||
		    pfr_skip_table(trs, p, 0))
			continue;
		p->pfrkt_nflags = p->pfrkt_flags & ~PFR_TFLAG_INACTIVE;
		SLIST_INSERT_HEAD(&workq, p, pfrkt_workq);
		xdel++;
	}
	if (!(flags & PFR_FLAG_DUMMY)) {
		pfr_setflags_ktables(&workq);
		rs->topen = 0;
		pf_remove_if_empty_ruleset(rs);
	}
	if (ndel != NULL)
		*ndel = xdel;
	return (0);
}

int
pfr_ina_commit(struct pfr_table *trs, u_int32_t ticket, int *nadd,
    int *nchange, int flags)
{
	struct pfr_ktable	*p, *q;
	struct pfr_ktableworkq	 workq;
	struct pf_ruleset	*rs;
	int			 xadd = 0, xchange = 0;
	time_t			 tzero = time_second;

	ACCEPT_FLAGS(flags, PFR_FLAG_DUMMY);
	rs = pf_find_ruleset(trs->pfrt_anchor);
	if (rs == NULL || !rs->topen || ticket != rs->tticket)
		return (EBUSY);

	SLIST_INIT(&workq);
	RB_FOREACH(p, pfr_ktablehead, &pfr_ktables) {
		if (!(p->pfrkt_flags & PFR_TFLAG_INACTIVE) ||
		    pfr_skip_table(trs, p, 0))
			continue;
		SLIST_INSERT_HEAD(&workq, p, pfrkt_workq);
		if (p->pfrkt_flags & PFR_TFLAG_ACTIVE)
			xchange++;
		else
			xadd++;
	}

	if (!(flags & PFR_FLAG_DUMMY)) {
		for (p = SLIST_FIRST(&workq); p != NULL; p = q) {
			q = SLIST_NEXT(p, pfrkt_workq);
			pfr_commit_ktable(p, tzero);
		}
		rs->topen = 0;
		pf_remove_if_empty_ruleset(rs);
	}
	if (nadd != NULL)
		*nadd = xadd;
	if (nchange != NULL)
		*nchange = xchange;

	return (0);
}

void
pfr_commit_ktable(struct pfr_ktable *kt, time_t tzero)
{
	struct pfr_ktable	*shadow = kt->pfrkt_shadow;
	int			 nflags;

	if (shadow->pfrkt_cnt == NO_ADDRESSES) {
		if (!(kt->pfrkt_flags & PFR_TFLAG_ACTIVE))
			pfr_clstats_ktable(kt, tzero, 1);
	} else if (kt->pfrkt_flags & PFR_TFLAG_ACTIVE) {
		/* kt might contain addresses */
		struct pfr_kentryworkq	 addrq, addq, changeq, delq, garbageq;
		struct pfr_kentry	*p, *q, *next;
		struct pfr_addr		 ad;

		pfr_enqueue_addrs(shadow, &addrq, NULL, 0);
		pfr_mark_addrs(kt);
		SLIST_INIT(&addq);
		SLIST_INIT(&changeq);
		SLIST_INIT(&delq);
		SLIST_INIT(&garbageq);
		pfr_clean_node_mask(shadow, &addrq);
		for (p = SLIST_FIRST(&addrq); p != NULL; p = next) {
			next = SLIST_NEXT(p, pfrke_workq);	/* XXX */
			pfr_copyout_addr(&ad, p);
			q = pfr_lookup_addr(kt, &ad, 1);
			if (q != NULL) {
				if ((q->pfrke_flags & PFRKE_FLAG_NOT) !=
				    (p->pfrke_flags & PFRKE_FLAG_NOT))
					SLIST_INSERT_HEAD(&changeq, q,
					    pfrke_workq);
				q->pfrke_flags |= PFRKE_FLAG_MARK;
				SLIST_INSERT_HEAD(&garbageq, p, pfrke_workq);
			} else {
				p->pfrke_tzero = tzero;
				SLIST_INSERT_HEAD(&addq, p, pfrke_workq);
			}
		}
		pfr_enqueue_addrs(kt, &delq, NULL, ENQUEUE_UNMARKED_ONLY);
		pfr_insert_kentries(kt, &addq, tzero);
		pfr_remove_kentries(kt, &delq);
		pfr_clstats_kentries(&changeq, tzero, INVERT_NEG_FLAG);
		pfr_destroy_kentries(&garbageq);
	} else {
		/* kt cannot contain addresses */
		SWAP(struct radix_node_head *, kt->pfrkt_ip4,
		    shadow->pfrkt_ip4);
		SWAP(struct radix_node_head *, kt->pfrkt_ip6,
		    shadow->pfrkt_ip6);
		SWAP(int, kt->pfrkt_cnt, shadow->pfrkt_cnt);
		pfr_clstats_ktable(kt, tzero, 1);
	}
	nflags = ((shadow->pfrkt_flags & PFR_TFLAG_USRMASK) |
	    (kt->pfrkt_flags & PFR_TFLAG_SETMASK) | PFR_TFLAG_ACTIVE)
		& ~PFR_TFLAG_INACTIVE;
	pfr_destroy_ktable(shadow, 0);
	kt->pfrkt_shadow = NULL;
	pfr_setflags_ktable(kt, nflags);
}

int
pfr_validate_table(struct pfr_table *tbl, int allowedflags, int no_reserved)
{
	int i;

	if (!tbl->pfrt_name[0])
		return (-1);
	if (no_reserved && !strcmp(tbl->pfrt_anchor, PF_RESERVED_ANCHOR))
		 return (-1);
	if (tbl->pfrt_name[PF_TABLE_NAME_SIZE-1])
		return (-1);
	for (i = strlen(tbl->pfrt_name); i < PF_TABLE_NAME_SIZE; i++)
		if (tbl->pfrt_name[i])
			return (-1);
	if (pfr_fix_anchor(tbl->pfrt_anchor))
		return (-1);
	if (tbl->pfrt_flags & ~allowedflags)
		return (-1);
	return (0);
}

/*
 * Rewrite anchors referenced by tables to remove slashes
 * and check for validity.
 */
int
pfr_fix_anchor(char *anchor)
{
	size_t siz = MAXPATHLEN;
	int i;

	if (anchor[0] == '/') {
		char *path;
		int off;

		path = anchor;
		off = 1;
		while (*++path == '/')
			off++;
		bcopy(path, anchor, siz - off);
		memset(anchor + siz - off, 0, off);
	}
	if (anchor[siz - 1])
		return (-1);
	for (i = strlen(anchor); i < siz; i++)
		if (anchor[i])
			return (-1);
	return (0);
}

int
pfr_table_count(struct pfr_table *filter, int flags)
{
	struct pf_ruleset *rs;

	if (flags & PFR_FLAG_ALLRSETS)
		return (pfr_ktable_cnt);
	if (filter->pfrt_anchor[0]) {
		rs = pf_find_ruleset(filter->pfrt_anchor);
		return ((rs != NULL) ? rs->tables : -1);
	}
	return (pf_main_ruleset.tables);
}

int
pfr_skip_table(struct pfr_table *filter, struct pfr_ktable *kt, int flags)
{
	if (flags & PFR_FLAG_ALLRSETS)
		return (0);
	if (strcmp(filter->pfrt_anchor, kt->pfrkt_anchor))
		return (1);
	return (0);
}

void
pfr_insert_ktables(struct pfr_ktableworkq *workq)
{
	struct pfr_ktable	*p;

	SLIST_FOREACH(p, workq, pfrkt_workq)
		pfr_insert_ktable(p);
}

void
pfr_insert_ktable(struct pfr_ktable *kt)
{
	RB_INSERT(pfr_ktablehead, &pfr_ktables, kt);
	pfr_ktable_cnt++;
	if (kt->pfrkt_root != NULL)
		if (!kt->pfrkt_root->pfrkt_refcnt[PFR_REFCNT_ANCHOR]++)
			pfr_setflags_ktable(kt->pfrkt_root,
			    kt->pfrkt_root->pfrkt_flags|PFR_TFLAG_REFDANCHOR);
}

void
pfr_setflags_ktables(struct pfr_ktableworkq *workq)
{
	struct pfr_ktable	*p, *q;

	for (p = SLIST_FIRST(workq); p; p = q) {
		q = SLIST_NEXT(p, pfrkt_workq);
		pfr_setflags_ktable(p, p->pfrkt_nflags);
	}
}

void
pfr_setflags_ktable(struct pfr_ktable *kt, int newf)
{
	struct pfr_kentryworkq	addrq;

	if (!(newf & PFR_TFLAG_REFERENCED) &&
	    !(newf & PFR_TFLAG_REFDANCHOR) &&
	    !(newf & PFR_TFLAG_PERSIST))
		newf &= ~PFR_TFLAG_ACTIVE;
	if (!(newf & PFR_TFLAG_ACTIVE))
		newf &= ~PFR_TFLAG_USRMASK;
	if (!(newf & PFR_TFLAG_SETMASK)) {
		RB_REMOVE(pfr_ktablehead, &pfr_ktables, kt);
		if (kt->pfrkt_root != NULL)
			if (!--kt->pfrkt_root->pfrkt_refcnt[PFR_REFCNT_ANCHOR])
				pfr_setflags_ktable(kt->pfrkt_root,
				    kt->pfrkt_root->pfrkt_flags &
					~PFR_TFLAG_REFDANCHOR);
		pfr_destroy_ktable(kt, 1);
		pfr_ktable_cnt--;
		return;
	}
	if (!(newf & PFR_TFLAG_ACTIVE) && kt->pfrkt_cnt) {
		pfr_enqueue_addrs(kt, &addrq, NULL, 0);
		pfr_remove_kentries(kt, &addrq);
	}
	if (!(newf & PFR_TFLAG_INACTIVE) && kt->pfrkt_shadow != NULL) {
		pfr_destroy_ktable(kt->pfrkt_shadow, 1);
		kt->pfrkt_shadow = NULL;
	}
	kt->pfrkt_flags = newf;
}

void
pfr_clstats_ktables(struct pfr_ktableworkq *workq, time_t tzero, int recurse)
{
	struct pfr_ktable	*p;

	SLIST_FOREACH(p, workq, pfrkt_workq)
		pfr_clstats_ktable(p, tzero, recurse);
}

void
pfr_clstats_ktable(struct pfr_ktable *kt, time_t tzero, int recurse)
{
	struct pfr_kentryworkq	 addrq;

	if (recurse) {
		pfr_enqueue_addrs(kt, &addrq, NULL, 0);
		pfr_clstats_kentries(&addrq, tzero, 0);
	}
	bzero(kt->pfrkt_packets, sizeof(kt->pfrkt_packets));
	bzero(kt->pfrkt_bytes, sizeof(kt->pfrkt_bytes));
	kt->pfrkt_match = kt->pfrkt_nomatch = 0;
	kt->pfrkt_tzero = tzero;
}

struct pfr_ktable *
pfr_create_ktable(struct pfr_table *tbl, time_t tzero, int attachruleset,
    int intr)
{
	struct pfr_ktable	*kt;
	struct pf_ruleset	*rs;

	if (intr)
		kt = pool_get(&pfr_ktable_pl, PR_NOWAIT|PR_ZERO|PR_LIMITFAIL);
	else
		kt = pool_get(&pfr_ktable_pl, PR_WAITOK|PR_ZERO|PR_LIMITFAIL);
	if (kt == NULL)
		return (NULL);
	kt->pfrkt_t = *tbl;

	if (attachruleset) {
		rs = pf_find_or_create_ruleset(tbl->pfrt_anchor);
		if (!rs) {
			pfr_destroy_ktable(kt, 0);
			return (NULL);
		}
		kt->pfrkt_rs = rs;
		rs->tables++;
	}

	if (!rn_inithead((void **)&kt->pfrkt_ip4,
	    offsetof(struct sockaddr_in, sin_addr)) ||
	    !rn_inithead((void **)&kt->pfrkt_ip6,
	    offsetof(struct sockaddr_in6, sin6_addr))) {
		pfr_destroy_ktable(kt, 0);
		return (NULL);
	}
	kt->pfrkt_tzero = tzero;
	kt->pfrkt_refcntcost = 0;
	kt->pfrkt_gcdweight = 0;
	kt->pfrkt_maxweight = 1;

	return (kt);
}

void
pfr_destroy_ktables(struct pfr_ktableworkq *workq, int flushaddr)
{
	struct pfr_ktable	*p, *q;

	for (p = SLIST_FIRST(workq); p; p = q) {
		q = SLIST_NEXT(p, pfrkt_workq);
		pfr_destroy_ktable(p, flushaddr);
	}
}

void
pfr_destroy_ktable(struct pfr_ktable *kt, int flushaddr)
{
	struct pfr_kentryworkq	 addrq;

	if (flushaddr) {
		pfr_enqueue_addrs(kt, &addrq, NULL, 0);
		pfr_clean_node_mask(kt, &addrq);
		pfr_destroy_kentries(&addrq);
	}
	if (kt->pfrkt_ip4 != NULL)
		free((caddr_t)kt->pfrkt_ip4, M_RTABLE, 0);
	if (kt->pfrkt_ip6 != NULL)
		free((caddr_t)kt->pfrkt_ip6, M_RTABLE, 0);
	if (kt->pfrkt_shadow != NULL)
		pfr_destroy_ktable(kt->pfrkt_shadow, flushaddr);
	if (kt->pfrkt_rs != NULL) {
		kt->pfrkt_rs->tables--;
		pf_remove_if_empty_ruleset(kt->pfrkt_rs);
	}
	pool_put(&pfr_ktable_pl, kt);
}

int
pfr_ktable_compare(struct pfr_ktable *p, struct pfr_ktable *q)
{
	int d;

	if ((d = strncmp(p->pfrkt_name, q->pfrkt_name, PF_TABLE_NAME_SIZE)))
		return (d);
	return (strcmp(p->pfrkt_anchor, q->pfrkt_anchor));
}

struct pfr_ktable *
pfr_lookup_table(struct pfr_table *tbl)
{
	/* struct pfr_ktable start like a struct pfr_table */
	return (RB_FIND(pfr_ktablehead, &pfr_ktables,
	    (struct pfr_ktable *)tbl));
}

int
pfr_match_addr(struct pfr_ktable *kt, struct pf_addr *a, sa_family_t af)
{
	struct pfr_kentry	*ke = NULL;
	int			 match;

	if (!(kt->pfrkt_flags & PFR_TFLAG_ACTIVE) && kt->pfrkt_root != NULL)
		kt = kt->pfrkt_root;
	if (!(kt->pfrkt_flags & PFR_TFLAG_ACTIVE))
		return (0);

	switch (af) {
	case AF_INET:
		pfr_sin.sin_addr.s_addr = a->addr32[0];
		ke = (struct pfr_kentry *)rn_match(&pfr_sin, kt->pfrkt_ip4);
		break;
#ifdef INET6
	case AF_INET6:
		bcopy(a, &pfr_sin6.sin6_addr, sizeof(pfr_sin6.sin6_addr));
		ke = (struct pfr_kentry *)rn_match(&pfr_sin6, kt->pfrkt_ip6);
		break;
#endif /* INET6 */
	default:
		unhandled_af(af);
	}
	match = (ke && !(ke->pfrke_flags & PFRKE_FLAG_NOT));
	if (match)
		kt->pfrkt_match++;
	else
		kt->pfrkt_nomatch++;
	return (match);
}

void
pfr_update_stats(struct pfr_ktable *kt, struct pf_addr *a, struct pf_pdesc *pd,
    int op, int notrule)
{
	struct pfr_kentry	*ke = NULL;
	sa_family_t		 af = pd->af;
	u_int64_t		 len = pd->tot_len;
	int			 dir_idx = (pd->dir == PF_OUT);
	int			 op_idx;

	if (!(kt->pfrkt_flags & PFR_TFLAG_ACTIVE) && kt->pfrkt_root != NULL)
		kt = kt->pfrkt_root;
	if (!(kt->pfrkt_flags & PFR_TFLAG_ACTIVE))
		return;

	switch (af) {
	case AF_INET:
		pfr_sin.sin_addr.s_addr = a->addr32[0];
		ke = (struct pfr_kentry *)rn_match(&pfr_sin, kt->pfrkt_ip4);
		break;
#ifdef INET6
	case AF_INET6:
		bcopy(a, &pfr_sin6.sin6_addr, sizeof(pfr_sin6.sin6_addr));
		ke = (struct pfr_kentry *)rn_match(&pfr_sin6, kt->pfrkt_ip6);
		break;
#endif /* INET6 */
	default:
		unhandled_af(af);
	}

	switch (op) {
	case PF_PASS:
		op_idx = PFR_OP_PASS;
		break;
	case PF_MATCH:
		op_idx = PFR_OP_MATCH;
		break;
	case PF_DROP:
		op_idx = PFR_OP_BLOCK;
		break;
	default:
		panic("unhandled op");
	}

	if ((ke == NULL || (ke->pfrke_flags & PFRKE_FLAG_NOT)) != notrule) {
		if (op_idx != PFR_OP_PASS)
			DPFPRINTF(LOG_DEBUG,
			    "pfr_update_stats: assertion failed.");
		op_idx = PFR_OP_XPASS;
	}
	kt->pfrkt_packets[dir_idx][op_idx]++;
	kt->pfrkt_bytes[dir_idx][op_idx] += len;
	if (ke != NULL && op_idx != PFR_OP_XPASS &&
	    (kt->pfrkt_flags & PFR_TFLAG_COUNTERS)) {
		if (ke->pfrke_counters == NULL)
			ke->pfrke_counters = pool_get(&pfr_kcounters_pl,
			    PR_NOWAIT | PR_ZERO);
		if (ke->pfrke_counters != NULL) {
			ke->pfrke_counters->pfrkc_packets[dir_idx][op_idx]++;
			ke->pfrke_counters->pfrkc_bytes[dir_idx][op_idx] += len;
		}
	}
}

struct pfr_ktable *
pfr_attach_table(struct pf_ruleset *rs, char *name, int intr)
{
	struct pfr_ktable	*kt, *rt;
	struct pfr_table	 tbl;
	struct pf_anchor	*ac = rs->anchor;

	bzero(&tbl, sizeof(tbl));
	strlcpy(tbl.pfrt_name, name, sizeof(tbl.pfrt_name));
	if (ac != NULL)
		strlcpy(tbl.pfrt_anchor, ac->path, sizeof(tbl.pfrt_anchor));
	kt = pfr_lookup_table(&tbl);
	if (kt == NULL) {
		kt = pfr_create_ktable(&tbl, time_second, 1, intr);
		if (kt == NULL)
			return (NULL);
		if (ac != NULL) {
			bzero(tbl.pfrt_anchor, sizeof(tbl.pfrt_anchor));
			rt = pfr_lookup_table(&tbl);
			if (rt == NULL) {
				rt = pfr_create_ktable(&tbl, 0, 1, intr);
				if (rt == NULL) {
					pfr_destroy_ktable(kt, 0);
					return (NULL);
				}
				pfr_insert_ktable(rt);
			}
			kt->pfrkt_root = rt;
		}
		pfr_insert_ktable(kt);
	}
	if (!kt->pfrkt_refcnt[PFR_REFCNT_RULE]++)
		pfr_setflags_ktable(kt, kt->pfrkt_flags|PFR_TFLAG_REFERENCED);
	return (kt);
}

void
pfr_detach_table(struct pfr_ktable *kt)
{
	if (kt->pfrkt_refcnt[PFR_REFCNT_RULE] <= 0)
		DPFPRINTF(LOG_NOTICE, "pfr_detach_table: refcount = %d.",
		    kt->pfrkt_refcnt[PFR_REFCNT_RULE]);
	else if (!--kt->pfrkt_refcnt[PFR_REFCNT_RULE])
		pfr_setflags_ktable(kt, kt->pfrkt_flags&~PFR_TFLAG_REFERENCED);
}

int
pfr_islinklocal(sa_family_t af, struct pf_addr *addr)
{
#ifdef	INET6
	if (af == AF_INET6 && IN6_IS_ADDR_LINKLOCAL(&addr->v6))
		return (1);
#endif	/* INET6 */
	return (0);
}

int
pfr_pool_get(struct pf_pool *rpool, struct pf_addr **raddr,
    struct pf_addr **rmask, sa_family_t af)
{
	struct pfr_ktable	*kt;
	struct pfr_kentry	*ke, *ke2;
	struct pf_addr		*addr, *counter;
	union sockaddr_union	 mask;
	int			 startidx, idx = -1, loop = 0, use_counter = 0;

	switch (af) {
	case AF_INET:
		addr = (struct pf_addr *)&pfr_sin.sin_addr;
		break;
#ifdef	INET6
	case AF_INET6:
		addr = (struct pf_addr *)&pfr_sin6.sin6_addr;
		break;
#endif	/* INET6 */
	default:
		unhandled_af(af);
	}

	if (rpool->addr.type == PF_ADDR_TABLE)
		kt = rpool->addr.p.tbl;
	else if (rpool->addr.type == PF_ADDR_DYNIFTL)
		kt = rpool->addr.p.dyn->pfid_kt;
	else
		return (-1);
	if (!(kt->pfrkt_flags & PFR_TFLAG_ACTIVE) && kt->pfrkt_root != NULL)
		kt = kt->pfrkt_root;
	if (!(kt->pfrkt_flags & PFR_TFLAG_ACTIVE))
		return (-1);

	counter = &rpool->counter;
	idx = rpool->tblidx;
	if (idx < 0 || idx >= kt->pfrkt_cnt)
		idx = 0;
	else
		use_counter = 1;
	startidx = idx;

 _next_block:
	if (loop && startidx == idx) {
		kt->pfrkt_nomatch++;
		return (1);
	}

	ke = pfr_kentry_byidx(kt, idx, af);
	if (ke == NULL) {
		/* we don't have this idx, try looping */
		if (loop || (ke = pfr_kentry_byidx(kt, 0, af)) == NULL) {
			kt->pfrkt_nomatch++;
			return (1);
		}
		idx = 0;
		loop++;
	}

	/* Get current weight for weighted round-robin */
	if (idx == 0 && use_counter == 1 && kt->pfrkt_refcntcost > 0) {
		rpool->curweight = rpool->curweight - kt->pfrkt_gcdweight;

		if (rpool->curweight < 1)
			rpool->curweight = kt->pfrkt_maxweight;
	}

	pfr_prepare_network(&pfr_mask, af, ke->pfrke_net);
	*raddr = SUNION2PF(&ke->pfrke_sa, af);
	*rmask = SUNION2PF(&pfr_mask, af);

	if (use_counter && !PF_AZERO(counter, af)) {
		/* is supplied address within block? */
		if (!PF_MATCHA(0, *raddr, *rmask, counter, af)) {
			/* no, go to next block in table */
			idx++;
			use_counter = 0;
			goto _next_block;
		}
		PF_ACPY(addr, counter, af);
	} else {
		/* use first address of block */
		PF_ACPY(addr, *raddr, af);
	}

	if (!KENTRY_NETWORK(ke)) {
		/* this is a single IP address - no possible nested block */
		if (rpool->addr.type == PF_ADDR_DYNIFTL &&
		    pfr_islinklocal(af, addr)) {
			idx++;
			goto _next_block;
		}
		PF_ACPY(counter, addr, af);
		rpool->tblidx = idx;
		kt->pfrkt_match++;
		rpool->states = 0;
		if (ke->pfrke_counters != NULL)
			rpool->states = ke->pfrke_counters->states;
		switch (ke->pfrke_type) {
		case PFRKE_COST:
			rpool->weight = ((struct pfr_kentry_cost *)ke)->weight;
			/* FALLTHROUGH */
		case PFRKE_ROUTE:
			rpool->kif = ((struct pfr_kentry_route *)ke)->kif;
			break;
		default:
			rpool->weight = 1;
			break;
		}
		return (0);
	}
	for (;;) {
		/* we don't want to use a nested block */
		switch (af) {
		case AF_INET:
			ke2 = (struct pfr_kentry *)rn_match(&pfr_sin,
			    kt->pfrkt_ip4);
			break;
#ifdef	INET6
		case AF_INET6:
			ke2 = (struct pfr_kentry *)rn_match(&pfr_sin6,
			    kt->pfrkt_ip6);
			break;
#endif	/* INET6 */
		default:
			unhandled_af(af);
		}
		if (ke2 == ke) {
			/* lookup return the same block - perfect */
			if (rpool->addr.type == PF_ADDR_DYNIFTL &&
			    pfr_islinklocal(af, addr))
				goto _next_entry;
			PF_ACPY(counter, addr, af);
			rpool->tblidx = idx;
			kt->pfrkt_match++;
			rpool->states = 0;
			if (ke->pfrke_counters != NULL)
				rpool->states = ke->pfrke_counters->states;
			switch (ke->pfrke_type) {
			case PFRKE_COST:
				rpool->weight =
				    ((struct pfr_kentry_cost *)ke)->weight;
				/* FALLTHROUGH */
			case PFRKE_ROUTE:
				rpool->kif = ((struct pfr_kentry_route *)ke)->kif;
				break;
			default:
				rpool->weight = 1;
				break;
			}
			return (0);
		}
_next_entry:
		/* we need to increase the counter past the nested block */
		pfr_prepare_network(&mask, AF_INET, ke2->pfrke_net);
		PF_POOLMASK(addr, addr, SUNION2PF(&mask, af), &pfr_ffaddr, af);
		PF_AINC(addr, af);
		if (!PF_MATCHA(0, *raddr, *rmask, addr, af)) {
			/* ok, we reached the end of our main block */
			/* go to next block in table */
			idx++;
			use_counter = 0;
			goto _next_block;
		}
	}
}

struct pfr_kentry *
pfr_kentry_byidx(struct pfr_ktable *kt, int idx, int af)
{
	struct pfr_walktree	w;

	bzero(&w, sizeof(w));
	w.pfrw_op = PFRW_POOL_GET;
	w.pfrw_cnt = idx;

	switch (af) {
	case AF_INET:
		rn_walktree(kt->pfrkt_ip4, pfr_walktree, &w);
		return (w.pfrw_kentry);
#ifdef INET6
	case AF_INET6:
		rn_walktree(kt->pfrkt_ip6, pfr_walktree, &w);
		return (w.pfrw_kentry);
#endif /* INET6 */
	default:
		return (NULL);
	}
}

/* Added for load balancing state counter use. */
int
pfr_states_increase(struct pfr_ktable *kt, struct pf_addr *addr, int af)
{
	struct pfr_kentry *ke;

	ke = pfr_kentry_byaddr(kt, addr, af, 1);
	if (ke == NULL)
		return (-1);

	if (ke->pfrke_counters == NULL)
		ke->pfrke_counters = pool_get(&pfr_kcounters_pl,
		    PR_NOWAIT | PR_ZERO);
	if (ke->pfrke_counters == NULL)
		return (-1);

	ke->pfrke_counters->states++;
	return ke->pfrke_counters->states;
}

/* Added for load balancing state counter use. */
int
pfr_states_decrease(struct pfr_ktable *kt, struct pf_addr *addr, int af)
{
	struct pfr_kentry *ke;

	ke = pfr_kentry_byaddr(kt, addr, af, 1);
	if (ke == NULL)
		return (-1);

	if (ke->pfrke_counters == NULL)
		ke->pfrke_counters = pool_get(&pfr_kcounters_pl,
		    PR_NOWAIT | PR_ZERO);
	if (ke->pfrke_counters == NULL)
		return (-1);

	if (ke->pfrke_counters->states > 0)
		ke->pfrke_counters->states--;
	else
		DPFPRINTF(LOG_DEBUG,
		    "pfr_states_decrease: states-- when states <= 0");

	return ke->pfrke_counters->states;
}

/*
 * Added for load balancing to find a kentry outside of the table.
 * We need to create a custom pfr_addr struct.
 */
struct pfr_kentry *
pfr_kentry_byaddr(struct pfr_ktable *kt, struct pf_addr *addr, sa_family_t af,
    int exact)
{
	struct pfr_kentry *ke;
	struct pfr_addr p;

	bzero(&p, sizeof(p));
	p.pfra_af = af;
	switch (af) {
	case AF_INET:
		p.pfra_net = 32;
		p.pfra_ip4addr = addr->v4;
		break;
#ifdef INET6
	case AF_INET6:
		p.pfra_net = 128;
		p.pfra_ip6addr = addr->v6;
		break;
#endif /* INET6 */
	default:
		unhandled_af(af);
	}

	ke = pfr_lookup_addr(kt, &p, exact);

	return ke;
}

void
pfr_dynaddr_update(struct pfr_ktable *kt, struct pfi_dynaddr *dyn)
{
	struct pfr_walktree	w;

	bzero(&w, sizeof(w));
	w.pfrw_op = PFRW_DYNADDR_UPDATE;
	w.pfrw_dyn = dyn;

	dyn->pfid_acnt4 = 0;
	dyn->pfid_acnt6 = 0;
	switch (dyn->pfid_af) {
	case AF_UNSPEC:	/* look up all both addresses IPv4 + IPv6 */
		rn_walktree(kt->pfrkt_ip4, pfr_walktree, &w);
		rn_walktree(kt->pfrkt_ip6, pfr_walktree, &w);
		break;
	case AF_INET:
		rn_walktree(kt->pfrkt_ip4, pfr_walktree, &w);
		break;
#ifdef	INET6
	case AF_INET6:
		rn_walktree(kt->pfrkt_ip6, pfr_walktree, &w);
		break;
#endif	/* INET6 */
	default:
		unhandled_af(dyn->pfid_af);
	}
}

void
pfr_ktable_winfo_update(struct pfr_ktable *kt, struct pfr_kentry *p) {
	/*
	 * If cost flag is set,
	 * gcdweight is needed for round-robin.
	 */
	if (kt->pfrkt_refcntcost > 0) {
		u_int16_t weight;

		weight = (p->pfrke_type == PFRKE_COST) ?
		    ((struct pfr_kentry_cost *)p)->weight : 1;

		if (kt->pfrkt_gcdweight == 0)
			kt->pfrkt_gcdweight = weight;

		kt->pfrkt_gcdweight =
			pfr_gcd(weight, kt->pfrkt_gcdweight);

		if (kt->pfrkt_maxweight < weight)
			kt->pfrkt_maxweight = weight;
	}
}
@


1.124
log
@Replace a custom loop calling yield() by the idiom to check if the
current process is hogging a CPU.

ok mikeb@@, visa@@, tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.123 2017/01/24 10:08:30 krw Exp $	*/
d76 1
a76 2
	if (curcpu()->ci_schedstate.spc_schedflags & SPCF_SHOULDYIELD) \
		preempt(NULL)			\
@


1.123
log
@A space here, a space there. Soon we're talking real whitespace
rectification.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.122 2017/01/23 09:08:24 mpi Exp $	*/
d39 1
d76 2
a77 5
	do {					\
		if ((cnt % 1024 == 1023) &&	\
		    (ok))			\
			yield();		\
	} while (0)
@


1.122
log
@Kill unecessary splsoftnet()/splx() dances, what's protecting radix
globals is the KERNEL_LOCK().

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.121 2016/10/26 21:07:22 bluhm Exp $	*/
d382 1
a382 1
	 * 
d2481 1
a2481 1
/* 
d2483 1
a2483 1
 * We need to create a custom pfr_addr struct. 
d2545 2
a2546 2
	/* 
	 * If cost flag is set, 
@


1.121
log
@Put union pf_headers and struct pf_pdesc into separate header file
pfvar_priv.h.  The pf_headers had to be defined in multiple .c files
before.  In pfvar.h it would have unknown storage size, this file
is included in too many places.  The idea is to have a private pf
header that is only included in the pf part of the kernel.  For now
it contains pf_pdesc and pf_headers, it may be extended later.
discussion, input and OK henning@@ procter@@ sashan@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.120 2016/09/27 04:57:17 dlg Exp $	*/
a806 1
	int			 s;
a824 1
		s = splsoftnet(); /* rn_lookup makes use of globals */
a825 1
		splx(s);
a1002 1
	int			 s;
a1004 1
		s = splsoftnet();
a1010 1
		splx(s);
a1070 1
	int			 s;
a1085 1
	s = splsoftnet();
a1090 1
	splx(s);
a1100 1
	int			 s;
a1114 1
	s = splsoftnet();
a1119 1
	splx(s);
d1174 1
a1174 1
	int			 s, flags = w->pfrw_flags;
a1203 1
			s = splsoftnet();
a1214 1
			splx(s);
d1449 1
a1449 1
	int			 s, n, nn;
d1469 1
a1469 3
		s = splsoftnet();
		if (COPYOUT(&p->pfrkt_ts, tbl++, sizeof(*tbl), flags)) {
			splx(s);
a1470 2
		}
		splx(s);
a1989 1
	int			 s;
a1994 1
	s = splsoftnet();
a1997 1
	splx(s);
a2517 1
	int			s;
a2522 1
	s = splsoftnet();
a2540 1
	splx(s);
@


1.120
log
@roll back turning RB into RBT until i get better at this process.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.119 2016/09/27 02:51:12 dlg Exp $	*/
d41 1
d43 1
d45 9
d55 1
@


1.119
log
@move pf from the RB macros to the RBT functions.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.118 2016/09/15 02:00:18 dlg Exp $	*/
d180 2
a181 2
int			 pfr_ktable_compare(const struct pfr_ktable *,
			    const struct pfr_ktable *);
d193 2
a194 2
RBT_PROTOTYPE(pfr_ktablehead, pfr_ktable, pfrkt_tree, pfr_ktable_compare);
RBT_GENERATE(pfr_ktablehead, pfr_ktable, pfrkt_tree, pfr_ktable_compare);
d1276 1
a1276 1
	RBT_FOREACH(p, pfr_ktablehead, &pfr_ktables) {
d1314 1
a1314 1
		p = RBT_FIND(pfr_ktablehead, &pfr_ktables, &key);
d1331 1
a1331 1
			r = RBT_FIND(pfr_ktablehead, &pfr_ktables, &key);
d1390 1
a1390 1
		p = RBT_FIND(pfr_ktablehead, &pfr_ktables, &key);
d1428 1
a1428 1
	RBT_FOREACH(p, pfr_ktablehead, &pfr_ktables) {
d1466 1
a1466 1
	RBT_FOREACH(p, pfr_ktablehead, &pfr_ktables) {
d1507 1
a1507 1
		p = RBT_FIND(pfr_ktablehead, &pfr_ktables, &key);
d1542 1
a1542 1
		p = RBT_FIND(pfr_ktablehead, &pfr_ktables, &key);
d1585 1
a1585 1
	RBT_FOREACH(p, pfr_ktablehead, &pfr_ktables) {
d1628 1
a1628 1
	kt = RBT_FIND(pfr_ktablehead, &pfr_ktables, (struct pfr_ktable *)tbl);
d1642 1
a1642 1
		rt = RBT_FIND(pfr_ktablehead, &pfr_ktables, &key);
d1724 1
a1724 1
	RBT_FOREACH(p, pfr_ktablehead, &pfr_ktables) {
d1758 1
a1758 1
	RBT_FOREACH(p, pfr_ktablehead, &pfr_ktables) {
d1931 1
a1931 1
	RBT_INSERT(pfr_ktablehead, &pfr_ktables, kt);
d1962 1
a1962 1
		RBT_REMOVE(pfr_ktablehead, &pfr_ktables, kt);
d2085 1
a2085 1
pfr_ktable_compare(const struct pfr_ktable *p, const struct pfr_ktable *q)
d2098 1
a2098 1
	return (RBT_FIND(pfr_ktablehead, &pfr_ktables,
@


1.118
log
@all pools have their ipl set via pool_setipl, so fold it into pool_init.

the ioff argument to pool_init() is unused and has been for many
years, so this replaces it with an ipl argument. because the ipl
will be set on init we no longer need pool_setipl.

most of these changes have been done with coccinelle using the spatch
below. cocci sucks at formatting code though, so i fixed that by hand.

the manpage and subr_pool.c bits i did myself.

ok tedu@@ jmatthew@@

@@ipl@@
expression pp;
expression ipl;
expression s, a, o, f, m, p;
@@@@
-pool_init(pp, s, a, o, f, m, p);
-pool_setipl(pp, ipl);
+pool_init(pp, s, a, ipl, f, m, p);
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.117 2016/09/02 10:19:49 dlg Exp $	*/
d180 2
a181 2
int			 pfr_ktable_compare(struct pfr_ktable *,
			    struct pfr_ktable *);
d193 2
a194 2
RB_PROTOTYPE(pfr_ktablehead, pfr_ktable, pfrkt_tree, pfr_ktable_compare);
RB_GENERATE(pfr_ktablehead, pfr_ktable, pfrkt_tree, pfr_ktable_compare);
d1276 1
a1276 1
	RB_FOREACH(p, pfr_ktablehead, &pfr_ktables) {
d1314 1
a1314 1
		p = RB_FIND(pfr_ktablehead, &pfr_ktables, &key);
d1331 1
a1331 1
			r = RB_FIND(pfr_ktablehead, &pfr_ktables, &key);
d1390 1
a1390 1
		p = RB_FIND(pfr_ktablehead, &pfr_ktables, &key);
d1428 1
a1428 1
	RB_FOREACH(p, pfr_ktablehead, &pfr_ktables) {
d1466 1
a1466 1
	RB_FOREACH(p, pfr_ktablehead, &pfr_ktables) {
d1507 1
a1507 1
		p = RB_FIND(pfr_ktablehead, &pfr_ktables, &key);
d1542 1
a1542 1
		p = RB_FIND(pfr_ktablehead, &pfr_ktables, &key);
d1585 1
a1585 1
	RB_FOREACH(p, pfr_ktablehead, &pfr_ktables) {
d1628 1
a1628 1
	kt = RB_FIND(pfr_ktablehead, &pfr_ktables, (struct pfr_ktable *)tbl);
d1642 1
a1642 1
		rt = RB_FIND(pfr_ktablehead, &pfr_ktables, &key);
d1724 1
a1724 1
	RB_FOREACH(p, pfr_ktablehead, &pfr_ktables) {
d1758 1
a1758 1
	RB_FOREACH(p, pfr_ktablehead, &pfr_ktables) {
d1931 1
a1931 1
	RB_INSERT(pfr_ktablehead, &pfr_ktables, kt);
d1962 1
a1962 1
		RB_REMOVE(pfr_ktablehead, &pfr_ktables, kt);
d2085 1
a2085 1
pfr_ktable_compare(struct pfr_ktable *p, struct pfr_ktable *q)
d2098 1
a2098 1
	return (RB_FIND(pfr_ktablehead, &pfr_ktables,
@


1.117
log
@pool_setipl for pf bits

ok phessler@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.116 2015/11/03 22:10:33 sashan Exp $	*/
d218 2
a219 3
	pool_init(&pfr_ktable_pl, sizeof(struct pfr_ktable), 0, 0, 0,
	    "pfrktable", NULL);
	pool_setipl(&pfr_ktable_pl, IPL_SOFTNET);
d221 1
a221 2
	    0, 0, 0, "pfrke_plain", NULL);
	pool_setipl(&pfr_kentry_pl[PFRKE_PLAIN], IPL_SOFTNET);
d223 1
a223 2
	    0, 0, 0, "pfrke_route", NULL);
	pool_setipl(&pfr_kentry_pl[PFRKE_ROUTE], IPL_SOFTNET);
d225 1
a225 3
	    0, 0, 0, "pfrke_cost", NULL);
	pool_setipl(&pfr_kentry_pl[PFRKE_COST], IPL_SOFTNET);

d227 1
a227 2
	    0, 0, 0, "pfrkcounters", NULL);
	pool_setipl(&pfr_kcounters_pl, IPL_SOFTNET);
@


1.116
log
@- fixes potential use-after-free in pfr_set_addrs()

OK mikeb@@, OK bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.115 2015/10/07 11:57:44 mpi Exp $	*/
d220 1
d223 1
d226 1
d229 1
d233 1
@


1.115
log
@rn_inithead() offset argument is now specified in byte, missed in previous.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.114 2015/09/04 08:43:39 mpi Exp $	*/
d494 1
a494 4
			} else {
				SLIST_INSERT_HEAD(&addq, p, pfrke_workq);
				ad.pfra_fback = PFR_FB_ADDED;
				xadd++;
d496 3
@


1.114
log
@Make every subsystem using a radix tree call rn_init() and pass the
length of the key as argument.

This way every consumer of the radix tree has a chance to explicitly
initialize the shared data structures and no longer rely on another
subsystem to do the initialization.

As a bonus ``dom_maxrtkey'' is no longer used an die.

ART kernels should now be fully usable because pf(4) and IPSEC properly
initialized the radix tree.

ok chris@@, reyk@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.113 2015/07/20 18:42:08 jsg Exp $	*/
d2037 1
a2037 1
	    offsetof(struct sockaddr_in, sin_addr) * 8) ||
d2039 1
a2039 1
	    offsetof(struct sockaddr_in6, sin6_addr) * 8)) {
@


1.113
log
@Add some panics to default paths where code later assumes a non default
path was taken.  This both prevents warnings from clang and acts as a
sanity check.

ok mcbride@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.112 2015/07/18 19:06:37 sashan Exp $	*/
d216 2
@


1.112
log
@follow up changes on unknown AF handling

- PF should always use unhandled_af()
- 0 is lame, AF_UNSPEC is profi


ok bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.111 2015/07/18 15:19:44 sashan Exp $	*/
d2174 2
@


1.111
log
@INET/INET6 address family check should be unified in PF

it also adds af_unhandled(), where it is currently missing.

ok mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.110 2015/07/16 18:17:27 claudio Exp $	*/
d866 1
a866 2
		pool_put(&pfr_kentry_pl[ad->pfra_type], ke);
		return (NULL);
d1027 1
d1029 1
a2241 1
/* ARGSUSED */
d2534 1
a2534 1
	case 0:	/* look up all both addresses IPv4 + IPv6 */
d2536 5
a2540 1
		/* FALLTHROUGH */
a2545 3
	case AF_INET:
		rn_walktree(kt->pfrkt_ip4, pfr_walktree, &w);
		break;
@


1.110
log
@Fix rn_match and there for the expoerted lookup functions in radix.c
to never return the internal RNF_ROOT nodes. This removes the checks
in the callee to verify that not an RNF_ROOT node was returned.
OK mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.109 2015/06/07 12:02:28 jsg Exp $	*/
d135 1
d137 1
d230 1
d233 1
d802 1
d807 1
d856 2
a857 1
	if (ad->pfra_af == AF_INET)
d859 3
a861 1
	else if (ad->pfra_af == AF_INET6)
d863 6
d1031 2
a1032 1
	if (af == AF_INET) {
d1036 3
a1038 1
	} else if (af == AF_INET6) {
d1050 4
d1070 1
d1074 1
d1102 1
d1106 1
d1137 3
a1139 1
	if (ad->pfra_af == AF_INET)
d1141 3
a1143 1
	else if (ad->pfra_af == AF_INET6)
d1145 5
d1231 2
a1232 1
		if (ke->pfrke_af == AF_INET) {
d1240 3
a1242 1
		} else if (ke->pfrke_af == AF_INET6){
d1250 4
d2122 2
d2160 1
a2160 1
		;
d2241 1
d2245 1
d2248 1
d2262 2
a2263 1
	if (af == AF_INET)
d2265 3
a2267 1
	else if (af == AF_INET6)
d2269 6
d2365 2
a2366 1
		if (af == AF_INET)
d2369 3
a2371 1
		else if (af == AF_INET6)
d2374 5
d2511 2
d2533 2
a2534 1
	if (!dyn->pfid_af || dyn->pfid_af == AF_INET)
d2536 3
a2538 1
	if (!dyn->pfid_af || dyn->pfid_af == AF_INET6)
d2540 8
@


1.109
log
@Introduce unhandled_af() for cases where code conditionally does
something based on an address family and later assumes one of the paths
was taken.  This was initially just calls to panic until guenther
suggested a function to reduce the amount of strings needed.

This reduces the amount of noise with static analysers and acts
as a sanity check.

ok guenther@@ bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.108 2015/04/09 12:04:14 mikeb Exp $	*/
a96 2
#define KENTRY_RNF_ROOT(ke) \
		((((struct radix_node *)(ke))->rn_flags & RNF_ROOT) != 0)
a809 2
		if (ke && KENTRY_RNF_ROOT(ke))
			ke = NULL;
a811 2
		if (ke && KENTRY_RNF_ROOT(ke))
			ke = NULL;
a2072 2
		if (ke && KENTRY_RNF_ROOT(ke))
			ke = NULL;
a2077 2
		if (ke && KENTRY_RNF_ROOT(ke))
			ke = NULL;
a2107 2
		if (ke && KENTRY_RNF_ROOT(ke))
			ke = NULL;
a2112 2
		if (ke && KENTRY_RNF_ROOT(ke))
			ke = NULL;
a2314 1
		/* no need to check KENTRY_RNF_ROOT() here */
@


1.108
log
@Plug a memory leak in pfr_destroy_kentry

pfi_kif objects allocated for table entries created by route-to or
by specifying weight weren't garbage collected when the table entry
was destroyed.

Spotted by Alexandr Nedvedicky <alexandr ! nedvedicky at oracle ! com>,
thanks!  Ok henning, florian
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.107 2015/04/08 14:19:28 mikeb Exp $	*/
d795 2
a796 1
	if (ad->pfra_af == AF_INET) {
d799 2
a800 1
	} else if ( ad->pfra_af == AF_INET6 ) {
d803 3
d1050 2
a1051 1
	if (ke->pfrke_af == AF_INET)
d1053 2
a1054 1
	else if (ke->pfrke_af == AF_INET6)
d1056 4
d1080 2
a1081 1
	if (ke->pfrke_af == AF_INET)
d1083 2
a1084 1
	else if (ke->pfrke_af == AF_INET6)
d1086 4
@


1.107
log
@Table flags are not looked at when a table entry is created.

Spotted by Alexandr Nedvedicky <alexandr ! nedvedicky at oracle ! com>,
thanks!
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.106 2015/03/14 03:38:51 jsg Exp $	*/
d880 3
@


1.106
log
@Remove some includes include-what-you-use claims don't
have any direct symbols used.  Tested for indirect use by compiling
amd64/i386/sparc64 kernels.

ok tedu@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.105 2015/01/20 17:25:35 mikeb Exp $	*/
d150 1
a150 1
struct pfr_kentry	*pfr_create_kentry(struct pfr_addr *, u_int32_t);
d308 1
a308 1
			p = pfr_create_kentry(&ad, kt->pfrkt_flags);
d484 1
a484 1
			p = pfr_create_kentry(&ad, kt->pfrkt_flags);
d820 1
a820 1
pfr_create_kentry(struct pfr_addr *ad, u_int32_t flags)
d917 1
a917 1
	p = pfr_create_kentry(ad, kt->pfrkt_flags);
d1614 1
a1614 1
		p = pfr_create_kentry(&ad, kt->pfrkt_flags);
d1624 1
a1624 1
			kt->pfrkt_refcntcost++;		
@


1.105
log
@Prevent tables referenced by rules in anchors from getting disabled.
Analysis and patch by Richard Kojedzinszky, thanks!  ok henning
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.104 2014/12/19 17:14:40 tedu Exp $	*/
a36 1
#include <sys/kernel.h>
@


1.104
log
@unifdef INET in net code as a precursor to removing the pretend option.
long live the one true internet.
ok henning mikeb
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.103 2014/09/08 06:24:13 jsg Exp $	*/
d1899 1
@


1.103
log
@remove uneeded route.h includes
ok miod@@ mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.102 2014/07/12 18:44:22 tedu Exp $	*/
a722 1
#ifdef INET
a726 1
#endif /* INET */
a2055 1
#ifdef INET
a2061 1
#endif /* INET */
a2094 1
#ifdef INET
a2100 1
#endif /* INET */
a2359 1
#ifdef INET
a2362 1
#endif /* INET */
a2431 1
#ifdef INET
a2435 1
#endif /* INET */
@


1.102
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.101 2013/07/05 13:07:58 blambert Exp $	*/
a41 1
#include <net/route.h>
@


1.101
log
@Collect and display 'match' counters for pf tables.

While here, fix pf table displays to fit within 80 chars.

Manpage input jmc@@

ok henning@@ reyk@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.100 2013/07/04 00:19:00 guenther Exp $	*/
d2017 1
a2017 1
		free((caddr_t)kt->pfrkt_ip4, M_RTABLE);
d2019 1
a2019 1
		free((caddr_t)kt->pfrkt_ip6, M_RTABLE);
@


1.100
log
@Re-commit: use time_t for storing time_t values.  This is an ABI
change for pf, but that's fine at this time.  You'll need to rebuild
pf userland after updating your kernel.

change to 'since' member ok henning@@
rest ok henning@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.99 2013/07/02 05:57:37 guenther Exp $	*/
d2085 2
a2086 2
pfr_update_stats(struct pfr_ktable *kt, struct pf_addr *a, sa_family_t af,
    u_int64_t len, int dir_out, int op_pass, int notrule)
d2089 4
d2119 13
d2133 1
a2133 1
		if (op_pass != PFR_OP_PASS)
d2136 1
a2136 1
		op_pass = PFR_OP_XPASS;
d2138 3
a2140 3
	kt->pfrkt_packets[dir_out][op_pass]++;
	kt->pfrkt_bytes[dir_out][op_pass] += len;
	if (ke != NULL && op_pass != PFR_OP_XPASS &&
d2146 2
a2147 2
			ke->pfrke_counters->pfrkc_packets[dir_out][op_pass]++;
			ke->pfrke_counters->pfrkc_bytes[dir_out][op_pass] += len;
@


1.99
log
@Revert previous: sizeof(time_t) != sizeof(long) on LP64, so there was
an ABI change involved.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.98 2013/07/02 01:42:01 guenther Exp $	*/
d156 1
a156 1
			    struct pfr_kentryworkq *, long);
d159 1
a159 1
void			 pfr_clstats_kentries(struct pfr_kentryworkq *, long,
d170 1
a170 1
void			 pfr_commit_ktable(struct pfr_ktable *, long);
d175 4
a178 1
void			 pfr_clstats_ktables(struct pfr_ktableworkq *, long,
a179 2
void			 pfr_clstats_ktable(struct pfr_ktable *, long, int);
struct pfr_ktable	*pfr_create_ktable(struct pfr_table *, long, int, int);
d275 1
a275 1
	long			 tzero = time_second;
d442 1
a442 1
	long			 tzero = time_second;
d634 1
a634 1
	long			 tzero = time_second;
d889 1
a889 1
    struct pfr_kentryworkq *workq, long tzero)
d913 1
a913 1
pfr_insert_kentry(struct pfr_ktable *kt, struct pfr_addr *ad, long tzero)
d978 1
a978 1
pfr_clstats_kentries(struct pfr_kentryworkq *workq, long tzero, int negchange)
d1247 1
a1247 1
	long			 tzero = time_second;
d1398 1
a1398 1
	long			 tzero = time_second;
d1443 1
a1443 1
	long			 tzero = time_second;
d1696 1
a1696 1
	long			 tzero = time_second;
d1732 1
a1732 1
pfr_commit_ktable(struct pfr_ktable *kt, long tzero)
d1929 1
a1929 1
pfr_clstats_ktables(struct pfr_ktableworkq *workq, long tzero, int recurse)
d1938 1
a1938 1
pfr_clstats_ktable(struct pfr_ktable *kt, long tzero, int recurse)
d1956 1
a1956 1
pfr_create_ktable(struct pfr_table *tbl, long tzero, int attachruleset,
@


1.98
log
@Use time_t for storing time_t values.  No change to the underlying
type**, so no ABI change.

ok henning@@ deraadt@@

** ...yet
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.97 2013/02/18 14:48:13 mikeb Exp $	*/
d156 1
a156 1
			    struct pfr_kentryworkq *, time_t);
d159 1
a159 1
void			 pfr_clstats_kentries(struct pfr_kentryworkq *, time_t,
d170 1
a170 1
void			 pfr_commit_ktable(struct pfr_ktable *, time_t);
d175 1
a175 4
void			 pfr_clstats_ktables(struct pfr_ktableworkq *, time_t,
			    int);
void			 pfr_clstats_ktable(struct pfr_ktable *, time_t, int);
struct pfr_ktable	*pfr_create_ktable(struct pfr_table *, time_t, int,
d177 2
d274 1
a274 1
	time_t			 tzero = time_second;
d441 1
a441 1
	time_t			 tzero = time_second;
d633 1
a633 1
	time_t			 tzero = time_second;
d888 1
a888 1
    struct pfr_kentryworkq *workq, time_t tzero)
d912 1
a912 1
pfr_insert_kentry(struct pfr_ktable *kt, struct pfr_addr *ad, time_t tzero)
d977 1
a977 1
pfr_clstats_kentries(struct pfr_kentryworkq *workq, time_t tzero, int negchange)
d1246 1
a1246 1
	time_t			 tzero = time_second;
d1397 1
a1397 1
	time_t			 tzero = time_second;
d1442 1
a1442 1
	time_t			 tzero = time_second;
d1695 1
a1695 1
	time_t			 tzero = time_second;
d1731 1
a1731 1
pfr_commit_ktable(struct pfr_ktable *kt, time_t tzero)
d1928 1
a1928 1
pfr_clstats_ktables(struct pfr_ktableworkq *workq, time_t tzero, int recurse)
d1937 1
a1937 1
pfr_clstats_ktable(struct pfr_ktable *kt, time_t tzero, int recurse)
d1955 1
a1955 1
pfr_create_ktable(struct pfr_table *tbl, time_t tzero, int attachruleset,
@


1.97
log
@DIOCRCLRASTATS ioctl wasn't specifying a timestamp when cleared
table statistics so it appeared later on as the Epoch.  Noticed
by [the] Shining on bugs@@.  Thanks!

ok sthen, waver from deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.96 2013/01/16 09:18:34 markus Exp $	*/
d156 1
a156 1
			    struct pfr_kentryworkq *, long);
d159 1
a159 1
void			 pfr_clstats_kentries(struct pfr_kentryworkq *, long,
d170 1
a170 1
void			 pfr_commit_ktable(struct pfr_ktable *, long);
d175 4
a178 1
void			 pfr_clstats_ktables(struct pfr_ktableworkq *, long,
a179 2
void			 pfr_clstats_ktable(struct pfr_ktable *, long, int);
struct pfr_ktable	*pfr_create_ktable(struct pfr_table *, long, int, int);
d275 1
a275 1
	long			 tzero = time_second;
d442 1
a442 1
	long			 tzero = time_second;
d634 1
a634 1
	long			 tzero = time_second;
d889 1
a889 1
    struct pfr_kentryworkq *workq, long tzero)
d913 1
a913 1
pfr_insert_kentry(struct pfr_ktable *kt, struct pfr_addr *ad, long tzero)
d978 1
a978 1
pfr_clstats_kentries(struct pfr_kentryworkq *workq, long tzero, int negchange)
d1247 1
a1247 1
	long			 tzero = time_second;
d1398 1
a1398 1
	long			 tzero = time_second;
d1443 1
a1443 1
	long			 tzero = time_second;
d1696 1
a1696 1
	long			 tzero = time_second;
d1732 1
a1732 1
pfr_commit_ktable(struct pfr_ktable *kt, long tzero)
d1929 1
a1929 1
pfr_clstats_ktables(struct pfr_ktableworkq *workq, long tzero, int recurse)
d1938 1
a1938 1
pfr_clstats_ktable(struct pfr_ktable *kt, long tzero, int recurse)
d1956 1
a1956 1
pfr_create_ktable(struct pfr_table *tbl, long tzero, int attachruleset,
@


1.96
log
@Unbreak the negation toggle code when re-loading pf tables. Otherwise
negating existing entries on re-load does not work (e.g. changing
192.168.6.0/24 to !192.168.6.0/24 in table was ignoed).
ok mikeb@@, henning@@ mpf@@, bluhm@@,
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.95 2012/12/29 14:53:05 markus Exp $	*/
d706 1
a706 1
		pfr_clstats_kentries(&workq, 0, 0);
@


1.95
log
@pass pf_pool directly to pfr_pool_get(); simplifies the API;
ok henning@@, zinke@@, mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.94 2012/01/26 11:30:39 mikeb Exp $	*/
d985 1
a985 1
			p->pfrke_flags ^= p->pfrke_flags & PFRKE_FLAG_NOT;
@


1.94
log
@when table content changes we need to reset index
to the initial value and do not use the counter;
reported by Sebastian Benoit and Daniel Krambrock,
tested by Sebastian Benoit, ok henning zinke
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.93 2011/07/27 00:26:10 mcbride Exp $	*/
d192 1
d2181 1
a2181 4
pfr_pool_get(struct pfr_ktable *kt, int *pidx, struct pf_addr *counter,
    struct pf_addr **raddr, struct pf_addr **rmask, struct pfi_kif **kif,
    u_int64_t *states, u_int16_t *weight, int *curweight, sa_family_t af,
    int (*filter)(sa_family_t, struct pf_addr *))
d2183 10
d2194 1
a2194 1
	struct pf_addr		*addr;
d2202 6
d2213 2
a2214 2
	if (pidx != NULL)
		idx = *pidx;
d2217 1
a2217 1
	else if (counter != NULL)
d2240 1
a2240 1
		*curweight = *curweight - kt->pfrkt_gcdweight;
d2242 2
a2243 2
		if (*curweight < 1)
			*curweight = kt->pfrkt_maxweight;
d2266 2
a2267 1
		if (filter && filter(af, addr)) {
d2272 1
a2272 1
		*pidx = idx;
d2274 1
a2274 1
		*states = 0;
d2276 1
a2276 1
			*states = ke->pfrke_counters->states;
d2279 1
a2279 1
			*weight = ((struct pfr_kentry_cost *)ke)->weight;
d2282 1
a2282 1
			*kif = ((struct pfr_kentry_route *)ke)->kif;
d2285 1
a2285 1
			*weight = 1;
d2301 2
a2302 1
			if (filter && filter(af, addr))
d2305 1
a2305 1
			*pidx = idx;
d2307 1
a2307 1
			*states = 0;
d2309 1
a2309 1
				*states = ke->pfrke_counters->states;
d2312 1
a2312 1
				*weight =
d2316 1
a2316 1
				*kif = ((struct pfr_kentry_route *)ke)->kif;
d2319 1
a2319 1
				*weight = 1;
@


1.93
log
@Add support for weighted round-robin in load balancing pools and tables.
Diff from zinke@@ with a some minor cleanup.
ok henning claudio deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.92 2011/07/08 22:11:17 mikeb Exp $	*/
d2201 3
a2203 1
	if (counter != NULL && idx >= 0)
a2204 2
	if (idx < 0)
		idx = 0;
@


1.92
log
@ensure that we won't enter an endless loop while iterating over
an address pool.  problem found and solution tested by claudio.
ok claudio, henning, "reads fine" to zinke
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.91 2011/07/03 23:37:55 zinke Exp $	*/
d143 1
d183 2
d200 13
d495 3
a825 15
	if (flags & PFR_TFLAG_COST) {
		switch (ad->pfra_type) {
		case PFRKE_PLAIN:
		case PFRKE_ROUTE:
			ad->pfra_type = PFRKE_COST;
			break;
		case PFRKE_COST:
			break;
		default:
			/* not compatible with PFR_FLAG_COST */
			/* XXX debug output? check earlier? */
			return (NULL);
		}
	}

d832 4
d837 5
d843 2
a844 2
	case PFRKE_COST:
		ke->pfrke_rkif = pfi_kif_get(ad->pfra_ifname);
a847 2
	case PFRKE_PLAIN:
		break;
d902 3
d928 2
d931 1
d941 1
d948 2
d953 9
d1103 2
d1107 1
a1107 1
		ad->pfra_states = ((struct pfr_kentry_cost *)ke)->states;
d1625 3
d1986 3
d2182 1
a2182 1
    u_int32_t *states, sa_family_t af,
d2207 1
a2207 1
_next_block:
d2223 9
d2259 3
d2264 1
a2264 1
			*states = ((struct pfr_kentry_cost *)ke)->states;
d2270 1
d2291 3
d2296 2
a2297 2
				*states =
				    ((struct pfr_kentry_cost *)ke)->states;
d2303 1
d2348 1
a2348 1
/* added for slb counter use */
d2355 1
a2355 1
	if (ke == NULL || ke->pfrke_type != PFRKE_COST)
d2358 8
a2365 2
	((struct pfr_kentry_cost *)ke)->states++;
	return (((struct pfr_kentry_cost *)ke)->states);
d2368 1
a2368 1
/* added for slb counter use */
d2375 1
a2375 1
	if (ke == NULL || ke->pfrke_type != PFRKE_COST)
d2378 8
a2385 2
	if (((struct pfr_kentry_cost *)ke)->states > 0)
		((struct pfr_kentry_cost *)ke)->states--;
d2388 1
a2388 1
		    "pfr_states_increase: states-- when states <= 0");
d2390 1
a2390 1
	return (((struct pfr_kentry_cost *)ke)->states);
d2394 1
a2394 1
 * Added for slb to find a kentry outside of the table.
d2444 23
@


1.91
log
@bring in least-states load balancing algorithm

ok mcbride@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.90 2011/06/14 10:14:01 mcbride Exp $	*/
d2151 1
a2151 1
	int			 idx = -1, use_counter = 0;
d2168 1
d2171 5
d2179 1
a2179 3
		idx = 0;
		ke = pfr_kentry_byidx(kt, idx, af);
		if (ke == NULL) {
d2183 2
d2190 1
a2190 1
	if (use_counter) {
@


1.90
log
@KNF (no change in .o files)
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.89 2011/05/17 12:44:05 mikeb Exp $	*/
d151 1
a151 1
struct pfr_kentry	*pfr_create_kentry(struct pfr_addr *);
d206 2
d292 1
a292 1
			p = pfr_create_kentry(&ad);
d468 1
a468 1
			p = pfr_create_kentry(&ad);
d803 1
a803 1
pfr_create_kentry(struct pfr_addr *ad)
d807 15
a828 2
	case PFRKE_PLAIN:
		break;
d830 1
d835 2
d905 1
a905 1
	p = pfr_create_kentry(ad);
d1067 1
d1074 13
a1086 5
	if (ke->pfrke_type == PFRKE_ROUTE &&
	    ((struct pfr_kentry_route *)ke)->kif != NULL)
		strlcpy(ad->pfra_ifname,
		    ((struct pfr_kentry_route *)ke)->kif->pfik_name,
		    IFNAMSIZ);
d1585 1
a1585 1
		p = pfr_create_kentry(&ad);
d2145 2
a2146 1
    sa_family_t af, int (*filter)(sa_family_t, struct pf_addr *))
d2207 5
a2211 1
		if (ke->pfrke_type == PFRKE_ROUTE)
d2213 4
d2235 6
a2240 1
			if (ke->pfrke_type == PFRKE_ROUTE)
d2242 4
d2286 66
@


1.89
log
@exclude link local address from the dynamic interface address pool
so that rules like "pass out on vr1 inet6 nat-to (vr1)" won't map
to the non routable ipv6 link local address; with suggestions and
ok claudio, henning
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.88 2010/11/20 23:58:13 tedu Exp $	*/
d64 6
a69 1
#define YIELD(cnt, ok) do { if ((cnt % 1024 == 1023) && (ok)) yield(); } while (0)
d283 1
a283 1
			else if ((p->pfrke_flags & PFRKE_FLAG_NOT) != 
d1104 2
a1105 1
				bzero(as.pfras_packets, sizeof(as.pfras_packets));
d1696 1
a1696 1
				   (p->pfrke_flags & PFRKE_FLAG_NOT))
@


1.88
log
@throw some yields into the pf table code so it doesn't lock up the kernel.
ok deraadt henning
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.87 2010/10/23 15:38:18 tedu Exp $	*/
d2112 1
a2112 1
    sa_family_t af)
d2166 4
d2188 2
d2197 1
a2197 1

@


1.87
log
@remove PFR_FLAG_ATOMIC.  not used, and doesn't work as advertised.
ok henning
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.86 2010/09/30 07:14:02 mcbride Exp $	*/
d64 2
d266 1
d355 1
d367 1
d437 1
d536 1
d660 1
d834 1
d836 2
a837 1
	for (p = SLIST_FIRST(workq); p != NULL; p = q) {
d868 1
d906 1
d949 1
d1187 1
d1264 1
d1382 1
d1416 1
d1545 1
@


1.86
log
@Convert printf()'s to DPFDEBUG() macro.

ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.85 2010/08/07 03:50:02 krw Exp $	*/
a215 1
	int			 s;
d217 1
a217 1
	ACCEPT_FLAGS(flags, PFR_FLAG_ATOMIC | PFR_FLAG_DUMMY);
a227 2
		if (flags & PFR_FLAG_ATOMIC)
			s = splsoftnet();
a228 2
		if (flags & PFR_FLAG_ATOMIC)
			splx(s);
d247 1
a247 1
	int			 i, rv, s, xadd = 0;
d250 1
a250 2
	ACCEPT_FLAGS(flags, PFR_FLAG_ATOMIC | PFR_FLAG_DUMMY |
	    PFR_FLAG_FEEDBACK);
a298 2
		if (flags & PFR_FLAG_ATOMIC)
			s = splsoftnet();
a299 2
		if (flags & PFR_FLAG_ATOMIC)
			splx(s);
d323 1
a323 1
	int			 i, rv, s, xdel = 0, log = 1;
d325 1
a325 2
	ACCEPT_FLAGS(flags, PFR_FLAG_ATOMIC | PFR_FLAG_DUMMY |
	    PFR_FLAG_FEEDBACK);
a390 2
		if (flags & PFR_FLAG_ATOMIC)
			s = splsoftnet();
a391 2
		if (flags & PFR_FLAG_ATOMIC)
			splx(s);
d411 1
a411 1
	int			 i, rv, s, xadd = 0, xdel = 0, xchange = 0;
d414 1
a414 2
	ACCEPT_FLAGS(flags, PFR_FLAG_ATOMIC | PFR_FLAG_DUMMY |
	    PFR_FLAG_FEEDBACK);
a488 2
		if (flags & PFR_FLAG_ATOMIC)
			s = splsoftnet();
a491 2
		if (flags & PFR_FLAG_ATOMIC)
			splx(s);
d598 1
a598 1
	int			 rv, s;
a600 2
	/* XXX PFR_FLAG_CLSTATS disabled */
	ACCEPT_FLAGS(flags, PFR_FLAG_ATOMIC);
a615 2
	if (flags & PFR_FLAG_ATOMIC)
		s = splsoftnet();
a622 2
	if (flags & PFR_FLAG_ATOMIC)
		splx(s);
d643 1
a643 1
	int			 i, rv, s, xzero = 0;
d645 1
a645 2
	ACCEPT_FLAGS(flags, PFR_FLAG_ATOMIC | PFR_FLAG_DUMMY |
	    PFR_FLAG_FEEDBACK);
a670 2
		if (flags & PFR_FLAG_ATOMIC)
			s = splsoftnet();
a671 2
		if (flags & PFR_FLAG_ATOMIC)
			splx(s);
d857 1
a857 1
		n++;
d894 1
a894 1
		n++;
d906 1
a906 1
	SLIST_FOREACH(p, workq, pfrke_workq)
d908 1
d1134 1
a1134 1
	int			 s, xdel = 0;
d1136 1
a1136 2
	ACCEPT_FLAGS(flags, PFR_FLAG_ATOMIC | PFR_FLAG_DUMMY |
	    PFR_FLAG_ALLRSETS);
a1154 2
		if (flags & PFR_FLAG_ATOMIC)
			s = splsoftnet();
a1155 2
		if (flags & PFR_FLAG_ATOMIC)
			splx(s);
d1167 1
a1167 1
	int			 i, rv, s, xadd = 0;
d1170 1
a1170 1
	ACCEPT_FLAGS(flags, PFR_FLAG_ATOMIC | PFR_FLAG_DUMMY);
a1227 2
		if (flags & PFR_FLAG_ATOMIC)
			s = splsoftnet();
a1229 2
		if (flags & PFR_FLAG_ATOMIC)
			splx(s);
d1245 1
a1245 1
	int			 i, s, xdel = 0;
d1247 1
a1247 1
	ACCEPT_FLAGS(flags, PFR_FLAG_ATOMIC | PFR_FLAG_DUMMY);
a1268 2
		if (flags & PFR_FLAG_ATOMIC)
			s = splsoftnet();
a1269 2
		if (flags & PFR_FLAG_ATOMIC)
			splx(s);
d1320 1
a1320 1
	ACCEPT_FLAGS(flags, PFR_FLAG_ATOMIC | PFR_FLAG_ALLRSETS);
a1330 2
	if (flags & PFR_FLAG_ATOMIC)
		s = splsoftnet();
d1336 1
a1336 2
		if (!(flags & PFR_FLAG_ATOMIC))
			s = splsoftnet();
d1341 1
a1341 2
		if (!(flags & PFR_FLAG_ATOMIC))
			splx(s);
a1346 2
	if (flags & PFR_FLAG_ATOMIC)
		splx(s);
d1361 1
a1361 1
	int			 i, s, xzero = 0;
d1364 1
a1364 2
	ACCEPT_FLAGS(flags, PFR_FLAG_ATOMIC | PFR_FLAG_DUMMY |
	    PFR_FLAG_ADDRSTOO);
a1377 2
		if (flags & PFR_FLAG_ATOMIC)
			s = splsoftnet();
a1378 2
		if (flags & PFR_FLAG_ATOMIC)
			splx(s);
d1391 1
a1391 1
	int			 i, s, xchange = 0, xdel = 0;
d1393 1
a1393 1
	ACCEPT_FLAGS(flags, PFR_FLAG_ATOMIC | PFR_FLAG_DUMMY);
a1425 2
		if (flags & PFR_FLAG_ATOMIC)
			s = splsoftnet();
a1426 2
		if (flags & PFR_FLAG_ATOMIC)
			splx(s);
d1608 1
a1608 1
	int			 s, xadd = 0, xchange = 0;
d1611 1
a1611 1
	ACCEPT_FLAGS(flags, PFR_FLAG_ATOMIC | PFR_FLAG_DUMMY);
a1628 2
		if (flags & PFR_FLAG_ATOMIC)
			s = splsoftnet();
a1632 2
		if (flags & PFR_FLAG_ATOMIC)
			splx(s);
@


1.85
log
@No "\n" needed at the end of panic() strings.

Bogus chunks pointed out by matthew@@ and miod@@. No cookies for
marco@@ and jasper@@.

ok deraadt@@ miod@@ matthew@@ jasper@@ macro@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.84 2010/06/28 18:50:37 claudio Exp $	*/
d235 2
a236 1
			printf("pfr_clr_addrs: corruption detected (%d).\n",
d603 2
a604 2
		printf("pfr_get_addrs: corruption detected (%d).\n",
		    w.pfrw_free);
d653 2
a654 2
		printf("pfr_get_astats: corruption detected (%d).\n",
		    w.pfrw_free);
d759 2
a760 1
			printf("pfr_enqueue_addrs: IPv4 walktree failed.\n");
d763 2
a764 1
			printf("pfr_enqueue_addrs: IPv6 walktree failed.\n");
d777 2
a778 1
		printf("pfr_mark_addrs: IPv4 walktree failed.\n");
d780 2
a781 1
		printf("pfr_mark_addrs: IPv6 walktree failed.\n");
d882 3
a884 2
			printf("pfr_insert_kentries: cannot route entry "
			    "(code=%d).\n", rv);
d1047 1
a1047 1
		printf("pfr_unroute_kentry: delete failed.\n");
d1345 2
a1346 1
		printf("pfr_get_tables: corruption detected (%d).\n", n);
d1397 2
a1398 1
		printf("pfr_get_tstats: corruption detected (%d).\n", n);
d2089 2
a2090 1
			printf("pfr_update_stats: assertion failed.\n");
d2147 1
a2147 1
		printf("pfr_detach_table: refcount = %d.\n",
@


1.84
log
@Add the rtable id as an argument to rn_walktree(). Functions like
rt_if_remove_rtdelete() need to know the table id to be able to correctly
remove nodes.
Problem found by Andrea Parazzini and analyzed by Martin Pelikn.
OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.83 2010/02/24 15:04:40 henning Exp $	*/
d833 1
a833 1
		panic("unknown pfrke_type %d\n", ke->pfrke_type);
@


1.83
log
@put back the line of code that copies the timestamp out for tables
tracked down by  Dan Harnett <daniel at harnett.name>
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.82 2010/01/18 23:52:46 mcbride Exp $	*/
d159 1
a159 1
int			 pfr_walktree(struct radix_node *, void *);
d1069 1
a1069 1
pfr_walktree(struct radix_node *rn, void *arg)
@


1.82
log
@Convert pf debug logging to using log()/addlog(), a single standardised
definition of DPFPRINTF(), and log priorities from syslog.h. Old debug
levels will still work for now, but will eventually be phased out.

discussed with henning, ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.81 2010/01/12 03:20:51 mcbride Exp $	*/
d1115 1
@


1.81
log
@First pass at removing the 'pf_pool' mechanism for translation and routing
actions. Allow interfaces to be specified in special table entries for
the routing actions. Lists of addresses can now only be done using tables,
which pfctl will generate automatically from the existing syntax.

Functionally, this deprecates the use of multiple tables or dynamic
interfaces in a single nat or rdr rule.

ok henning dlg claudio
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.80 2008/11/24 13:22:09 mikeb Exp $	*/
d39 1
@


1.80
log
@Fix splasserts seen in pr 5987 by propagating a flag that discribes
whether we're called from the interrupt context to the functions
performing allocations.

Looked at by mpf@@ and henning@@, tested by mpf@@ and Antti Harri,
the pr originator.

ok tedu
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.79 2008/10/08 06:24:50 mcbride Exp $	*/
d128 1
a128 1
struct pool		 pfr_kentry_pl;
d143 1
a143 1
struct pfr_kentry	*pfr_create_kentry(struct pfr_addr *, int);
d194 7
a200 4
	pool_init(&pfr_kentry_pl, sizeof(struct pfr_kentry), 0, 0, 0,
	    "pfrkentry", NULL);
	pool_init(&pfr_kcounters_pl, sizeof(struct pfr_kcounters), 0, 0, 0,
	    "pfrkcounters", NULL);
d279 2
a280 1
			else if (p->pfrke_not != ad.pfra_not)
d286 1
a286 2
			p = pfr_create_kentry(&ad,
			    !(flags & PFR_FLAG_USERIOCTL));
d367 1
a367 1
				p->pfrke_mark = 0;
d380 2
a381 1
			else if (p->pfrke_not != ad.pfra_not)
d383 1
a383 1
			else if (p->pfrke_mark)
d388 4
a391 3
		if (p != NULL && p->pfrke_not == ad.pfra_not &&
		    !p->pfrke_mark) {
			p->pfrke_mark = 1;
d453 1
a453 1
			if (p->pfrke_mark) {
d457 2
a458 2
			p->pfrke_mark = 1;
			if (p->pfrke_not != ad.pfra_not) {
d469 1
a469 2
			p = pfr_create_kentry(&ad,
			    !(flags & PFR_FLAG_USERIOCTL));
d558 3
a560 2
		    (p->pfrke_not ? PFR_FB_NOTMATCH : PFR_FB_MATCH);
		if (p != NULL && !p->pfrke_not)
d813 1
a813 1
pfr_create_kentry(struct pfr_addr *ad, int intr)
d815 1
a815 1
	struct pfr_kentry	*ke;
d817 1
a817 4
	if (intr)
		ke = pool_get(&pfr_kentry_pl, PR_NOWAIT | PR_ZERO);
	else
		ke = pool_get(&pfr_kentry_pl, PR_WAITOK|PR_ZERO|PR_LIMITFAIL);
d821 15
d842 3
a844 2
	ke->pfrke_not = ad->pfra_not;
	return (ke);
d863 1
a863 1
	pool_put(&pfr_kentry_pl, ke);
d895 1
a895 1
	p = pfr_create_kentry(ad, 1);
d943 1
a943 1
			p->pfrke_not = !p->pfrke_not;
d1054 2
a1055 1
	ad->pfra_not = ke->pfrke_not;
d1060 5
d1076 1
a1076 1
		ke->pfrke_mark = 0;
d1079 1
a1079 1
		if (ke->pfrke_mark)
a1113 1
			as.pfras_tzero = ke->pfrke_tzero;
d1121 1
a1121 1
		if (ke->pfrke_not)
d1582 1
a1582 1
		p = pfr_create_kentry(&ad, 0);
d1723 2
a1724 1
				if (q->pfrke_not != p->pfrke_not)
d1727 1
a1727 1
				q->pfrke_mark = 1;
d2038 1
a2038 1
	match = (ke && !ke->pfrke_not);
d2077 1
a2077 1
	if ((ke == NULL || ke->pfrke_not) != notrule) {
d2144 2
a2145 1
    struct pf_addr **raddr, struct pf_addr **rmask, sa_family_t af)
d2171 7
a2177 2
		kt->pfrkt_nomatch++;
		return (1);
d2202 2
d2220 2
@


1.79
log
@Get rid of the second table entry pool (pfr_kentry_pl2); we're already
using the default interrupt handler for both, so there's no need to keep
table entries created in interrupt context separate.

ok henning art
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.78 2008/06/14 03:50:14 art Exp $	*/
d169 1
a169 1
struct pfr_ktable	*pfr_create_ktable(struct pfr_table *, long, int);
d259 2
a260 1
	tmpkt = pfr_create_ktable(&pfr_nulltable, 0, 0);
d432 2
a433 1
	tmpkt = pfr_create_ktable(&pfr_nulltable, 0, 0);
d1186 2
a1187 1
			p = pfr_create_ktable(&key.pfrkt_t, tzero, 1);
d1213 2
a1214 1
			r = pfr_create_ktable(&key.pfrkt_t, 0, 1);
d1518 2
a1519 1
		kt = pfr_create_ktable(tbl, 0, 1);
d1535 2
a1536 1
		rt = pfr_create_ktable(&key.pfrkt_t, 0, 1);
d1546 1
a1546 1
	shadow = pfr_create_ktable(tbl, 0, 0);
d1897 2
a1898 1
pfr_create_ktable(struct pfr_table *tbl, long tzero, int attachruleset)
d1903 4
a1906 1
	kt = pool_get(&pfr_ktable_pl, PR_WAITOK | PR_ZERO | PR_LIMITFAIL);
d2073 1
a2073 1
pfr_attach_table(struct pf_ruleset *rs, char *name)
d2085 1
a2085 1
		kt = pfr_create_ktable(&tbl, time_second, 1);
d2092 1
a2092 1
				rt = pfr_create_ktable(&tbl, 0, 1);
@


1.78
log
@There's no more reason to use oldnointr allocator here since we pace
the allocations in uvm_km_thread, as long as they are PR_WAITOK and
all the memory hogs should be WAITOK in pf now.

"following your explaination, it's ok" henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.77 2008/06/14 02:22:13 henning Exp $	*/
a128 1
struct pool		 pfr_kentry_pl2;
a195 2
	pool_init(&pfr_kentry_pl2, sizeof(struct pfr_kentry), 0, 0, 0,
	    "pfrkentry2", NULL);
d811 1
a811 1
		ke = pool_get(&pfr_kentry_pl2, PR_NOWAIT | PR_ZERO);
a823 1
	ke->pfrke_intrpool = intr;
d843 1
a843 4
	if (ke->pfrke_intrpool)
		pool_put(&pfr_kentry_pl2, ke);
	else
		pool_put(&pfr_kentry_pl, ke);
@


1.77
log
@pool_get()s not in interrupt context should not be PR_NOWAIT, but
PR_WAITOK | PR_LIMITFAIL. from discussion with art. ok ryan claudio thib
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.76 2008/06/10 22:39:31 mcbride Exp $	*/
d194 1
a194 1
	    "pfrktable", &pool_allocator_oldnointr);
d196 1
a196 1
	    "pfrkentry", &pool_allocator_oldnointr);
@


1.76
log
@Simplify code slightly; use PR_ZERO with pool_get() rather than bzero().

ok mpf henning
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.75 2008/06/10 21:25:29 mcbride Exp $	*/
d816 1
a816 1
		ke = pool_get(&pfr_kentry_pl, PR_NOWAIT | PR_ZERO);
d1903 1
a1903 1
	kt = pool_get(&pfr_ktable_pl, PR_NOWAIT | PR_ZERO);
@


1.75
log
@Free the counters struct when we free the table entry.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.74 2008/06/10 20:55:02 mcbride Exp $	*/
d814 1
a814 1
		ke = pool_get(&pfr_kentry_pl2, PR_NOWAIT);
d816 1
a816 1
		ke = pool_get(&pfr_kentry_pl, PR_NOWAIT);
a818 1
	bzero(ke, sizeof(*ke));
d1903 1
a1903 1
	kt = pool_get(&pfr_ktable_pl, PR_NOWAIT);
a1905 1
	bzero(kt, sizeof(*kt));
d2061 1
a2061 1
			    PR_NOWAIT|PR_ZERO);
@


1.74
log
@Make counters on table addresses optional and disabled by default.
Use the 'counters' table option in pf.conf if you actually need them.
If enabled, memory is not allocated until packets match an address.

This saves about 40% memory if counters are not being used, and paves the way
for some more significant cleanups coming soon.

ok henning mpf deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.73 2008/05/07 05:14:21 claudio Exp $	*/
d846 2
@


1.73
log
@Implement routing priorities. Every route inserted has a priority assigned
and the one route with the lowest number wins. This will be used by the
routing daemons to resolve the synchronisations issue in case of conflicts.
The nasty bits of this are in the multipath code. If no priority is specified
the kernel will choose an appropriate priority.

Looked at by a few people at n2k8 code is much older
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.72 2007/12/20 20:07:41 reyk Exp $	*/
d130 1
d199 2
d930 4
a933 2
		bzero(p->pfrke_packets, sizeof(p->pfrke_packets));
		bzero(p->pfrke_bytes, sizeof(p->pfrke_bytes));
d1083 10
a1092 4
			bcopy(ke->pfrke_packets, as.pfras_packets,
			    sizeof(as.pfras_packets));
			bcopy(ke->pfrke_bytes, as.pfras_bytes,
			    sizeof(as.pfras_bytes));
d2057 9
a2065 3
	if (ke != NULL && op_pass != PFR_OP_XPASS) {
		ke->pfrke_packets[dir_out][op_pass]++;
		ke->pfrke_bytes[dir_out][op_pass] += len;
@


1.72
log
@increment the match/nomatch table counters when using a table/pool in
rdr rules. this helps to get some statistics about l3 redirections.

ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.71 2007/09/01 18:49:27 henning Exp $	*/
d991 1
a991 1
		rn = rn_addroute(&ke->pfrke_sa, &mask, head, ke->pfrke_node);
d993 1
a993 1
		rn = rn_addroute(&ke->pfrke_sa, NULL, head, ke->pfrke_node);
@


1.71
log
@since the
MGET* macros were changed to function calls, there wasn't any
need for the pool declarations and the inclusion of pool.h
From: tbert <bret.lambert@@gmail.com>
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.70 2007/05/23 11:53:45 markus Exp $	*/
d2125 2
a2126 1
	if (ke == NULL)
d2128 1
d2151 1
d2167 1
@


1.70
log
@use the intr pool when allocating from interrupt context;
fixes pppoe f_addrhooks panics (e.g. pr 5454); ok canacar
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.69 2007/03/20 10:37:29 mickey Exp $	*/
d38 1
@


1.69
log
@do not use out of scope variable in macros -- only use the macro arguments passed; makes it less of nfs kind of code; henning@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.68 2006/05/02 10:08:45 dhartmei Exp $	*/
d280 2
a281 1
			p = pfr_create_kentry(&ad, 0);
d461 2
a462 1
			p = pfr_create_kentry(&ad, 0);
@


1.68
log
@fix creation of sub-anchors, e.g. if you create an anchor /foo/bar, create
only bar under foo, not /bar as well.
secondly, when using "load anchor from" from a sub-anchor, the loading
point should be relative to the sub-anchor doing the load (unless absolute
paths are used, of course).
from Boris Polevoy. probably a -stable candidate.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.67 2005/08/02 12:40:42 pascoe Exp $	*/
d45 1
a45 1
#define ACCEPT_FLAGS(oklist)			\
d52 1
a52 1
#define COPYIN(from, to, size)			\
d57 1
a57 1
#define COPYOUT(from, to, size)			\
d213 1
a213 1
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC+PFR_FLAG_DUMMY);
d249 2
a250 1
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC+PFR_FLAG_DUMMY+PFR_FLAG_FEEDBACK);
d263 1
a263 1
		if (COPYIN(addr+i, &ad, sizeof(ad)))
d292 1
a292 1
			if (COPYOUT(&ad, addr+i, sizeof(ad)))
d327 2
a328 1
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC+PFR_FLAG_DUMMY+PFR_FLAG_FEEDBACK);
d355 1
a355 1
			if (COPYIN(addr+i, &ad, sizeof(ad)))
d366 1
a366 1
		if (COPYIN(addr+i, &ad, sizeof(ad)))
d388 1
a388 1
			if (COPYOUT(&ad, addr+i, sizeof(ad)))
d419 2
a420 1
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC+PFR_FLAG_DUMMY+PFR_FLAG_FEEDBACK);
d437 1
a437 1
		if (COPYIN(addr+i, &ad, sizeof(ad)))
d474 1
a474 1
			if (COPYOUT(&ad, addr+i, sizeof(ad)))
d487 1
a487 1
			if (COPYOUT(&ad, addr+size+i, sizeof(ad)))
d531 1
a531 1
	ACCEPT_FLAGS(PFR_FLAG_REPLACE);
d539 1
a539 1
		if (COPYIN(addr+i, &ad, sizeof(ad)))
d552 1
a552 1
		if (COPYOUT(&ad, addr+i, sizeof(ad)))
d568 1
a568 1
	ACCEPT_FLAGS(0);
d609 2
a610 1
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC); /* XXX PFR_FLAG_CLSTATS disabled */
d659 2
a660 1
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC+PFR_FLAG_DUMMY+PFR_FLAG_FEEDBACK);
d668 1
a668 1
		if (COPYIN(addr+i, &ad, sizeof(ad)))
d676 1
a676 1
			if (COPYOUT(&ad, addr+i, sizeof(ad)))
d938 1
a938 1
		if (COPYIN(addr+i, &ad, sizeof(ad)))
d941 1
a941 1
		if (COPYOUT(&ad, addr+i, sizeof(ad)))
d1082 1
a1082 1
			if (COPYOUT(&as, w->pfrw_astats, sizeof(as)))
d1125 2
a1126 1
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC+PFR_FLAG_DUMMY+PFR_FLAG_ALLRSETS);
d1164 1
a1164 1
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC+PFR_FLAG_DUMMY);
d1168 1
a1168 1
		if (COPYIN(tbl+i, &key.pfrkt_t, sizeof(key.pfrkt_t)))
d1243 1
a1243 1
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC+PFR_FLAG_DUMMY);
d1246 1
a1246 1
		if (COPYIN(tbl+i, &key.pfrkt_t, sizeof(key.pfrkt_t)))
d1283 1
a1283 1
	ACCEPT_FLAGS(PFR_FLAG_ALLRSETS);
d1298 1
a1298 1
		if (COPYOUT(&p->pfrkt_t, tbl++, sizeof(*tbl)))
d1318 2
a1319 2
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC|PFR_FLAG_ALLRSETS);
					/* XXX PFR_FLAG_CLSTATS disabled */
d1339 1
a1339 1
		if (COPYOUT(&p->pfrkt_ts, tbl++, sizeof(*tbl))) {
d1368 2
a1369 1
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC+PFR_FLAG_DUMMY+PFR_FLAG_ADDRSTOO);
d1372 1
a1372 1
		if (COPYIN(tbl+i, &key.pfrkt_t, sizeof(key.pfrkt_t)))
d1402 1
a1402 1
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC+PFR_FLAG_DUMMY);
d1409 1
a1409 1
		if (COPYIN(tbl+i, &key.pfrkt_t, sizeof(key.pfrkt_t)))
d1456 1
a1456 1
	ACCEPT_FLAGS(PFR_FLAG_DUMMY);
d1493 1
a1493 1
	ACCEPT_FLAGS(PFR_FLAG_DUMMY|PFR_FLAG_ADDRSTOO);
d1539 1
a1539 1
		if (COPYIN(addr+i, &ad, sizeof(ad)))
d1589 1
a1589 1
	ACCEPT_FLAGS(PFR_FLAG_DUMMY);
d1622 1
a1622 1
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC+PFR_FLAG_DUMMY);
@


1.67
log
@Instead of copying a table structure so we can mask off a bit before
"validating" it, pass the bits to be ignored down to the validating
function in its allowedflags argument.  Saves a 1kB+ stack allocation.

ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.66 2005/06/06 09:01:55 dhartmei Exp $	*/
d2052 1
a2052 1
		strlcpy(tbl.pfrt_anchor, ac->name, sizeof(tbl.pfrt_anchor));
@


1.66
log
@Backout 1.64, switch back to two-pool allocation scheme (with oldnointr
allocator on one pool). Should fix PR 4231 and 4240, but reintroduces 4186.
ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.65 2005/05/27 18:53:09 henning Exp $	*/
d407 2
a408 1
    int *size2, int *nadd, int *ndel, int *nchange, int flags)
d418 2
a419 1
	if (pfr_validate_table(tbl, 0, flags & PFR_FLAG_USERIOCTL))
@


1.65
log
@add back ACCEPT_GLAGS and active flag check, pointed out by cedric
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.62 2004/12/07 18:02:04 mcbride Exp $	*/
d128 1
d192 1
a192 1
	    "pfrktable", NULL);
d194 3
a196 1
	    "pfrkentry", NULL);
d800 4
a803 2
	ke = pool_get(&pfr_kentry_pl, intr ? PR_NOWAIT :
	    (PR_WAITOK | PR_LIMITFAIL));
d833 4
a836 1
	pool_put(&pfr_kentry_pl, ke);
d1879 1
a1879 1
	kt = pool_get(&pfr_ktable_pl, PR_WAITOK | PR_LIMITFAIL);
@


1.64
log
@change pool allocation of table entries, no longer use the oldnointr
allocator and two pools, but PR_WAITOK when called from non-interrupt
context (ioctl). add configurable hard limits for tables and table
entries (set limit tables/table-entries), defaulting to 1000/100000.
ok aaron@@, henning@@, mcbride@@, art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.63 2005/05/23 20:47:02 henning Exp $	*/
d560 1
d564 1
a564 1
	if (kt == NULL)
@


1.63
log
@don't deny access to "special" tables in get_addrs
with this, when you know their name you can list their contents with pfctl
ok ryan
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.62 2004/12/07 18:02:04 mcbride Exp $	*/
a127 1
struct pool		 pfr_kentry_pl2;
d191 1
a191 1
	    "pfrktable", &pool_allocator_oldnointr);
d193 1
a193 3
	    "pfrkentry", &pool_allocator_oldnointr);
	pool_init(&pfr_kentry_pl2, sizeof(struct pfr_kentry), 0, 0, 0,
	    "pfrkentry2", NULL);
d796 2
a797 4
	if (intr)
		ke = pool_get(&pfr_kentry_pl2, PR_NOWAIT);
	else
		ke = pool_get(&pfr_kentry_pl, PR_NOWAIT);
d827 1
a827 4
	if (ke->pfrke_intrpool)
		pool_put(&pfr_kentry_pl2, ke);
	else
		pool_put(&pfr_kentry_pl, ke);
d1870 1
a1870 1
	kt = pool_get(&pfr_ktable_pl, PR_NOWAIT);
@


1.62
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.61 2004/12/04 07:49:48 mcbride Exp $	*/
a562 1
	ACCEPT_FLAGS(0);
d566 1
a566 1
	if (kt == NULL || !(kt->pfrkt_flags & PFR_TFLAG_ACTIVE))
@


1.61
log
@Add kernel code to keep track of tcp connections which have completed
the 3-way handshake. Allow limits on both total connections and connection
rate, put offenders in a table which can be used in the ruleset, and optionally
kill existing states. Rate tracking code from dhartmei@@.

Adds a second pool for table entries using the default allocator, which
allows entries to be added at splsoftnet().

ok deraadt@@ dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.60 2004/10/15 00:15:06 jaredy Exp $	*/
d868 1
a868 1
 	p = pfr_create_kentry(ad, 1);
@


1.60
log
@correctly parse the anchor names to which tables refer.
now they abide to the same rules as anchor names referred to by rules:
- initial slashes (/) are stripped
- anchor names with characters after the terminating NUL byte are
  considered invalid

ok dhartmei (and previously) beck henning
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.59 2004/07/08 23:17:38 mcbride Exp $	*/
d128 1
d142 1
a142 1
struct pfr_kentry	*pfr_create_kentry(struct pfr_addr *);
d195 2
d279 1
a279 1
			p = pfr_create_kentry(&ad);
d455 1
a455 1
			p = pfr_create_kentry(&ad);
d796 1
a796 1
pfr_create_kentry(struct pfr_addr *ad)
d800 4
a803 1
	ke = pool_get(&pfr_kentry_pl, PR_NOWAIT);
d815 1
d833 4
a836 1
	pool_put(&pfr_kentry_pl, ke);
d859 23
d1536 1
a1536 1
		p = pfr_create_kentry(&ad);
@


1.59
log
@Make 0/0 table entries work; also fix a problem setting the network mask
on v6 addresses.

Reported by Ilya A. Kovalenko, fix from Cedric Berger.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.58 2004/06/23 04:34:17 mcbride Exp $	*/
d158 1
d1086 2
d1243 2
d1279 2
d1690 2
d1694 29
@


1.58
log
@pfr_commit_ktable calls functions that can result in the current
ktable being destroyed, which makes it unsafe in a SLIST_FOREACH.

Fix from Chris Pascoe
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.57 2004/06/21 23:50:37 tholo Exp $	*/
d914 1
a914 1
		sa->sin.sin_addr.s_addr = htonl(-1 << (32-net));
d921 1
a921 1
				    htonl(-1 << (32-net));
@


1.57
log
@First step towards more sane time handling in the kernel -- this changes
things such that code that only need a second-resolution uptime or wall
time, and used to get that from time.tv_secs or mono_time.tv_secs now get
this from separate time_t globals time_second and time_uptime.

ok art@@ niklas@@ nordin@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.56 2004/06/11 05:21:20 mcbride Exp $	*/
d1567 1
a1567 1
	struct pfr_ktable	*p;
d1593 2
a1594 1
		SLIST_FOREACH(p, &workq, pfrkt_workq)
d1596 1
@


1.56
log
@Eliminate a dereference after pool_put when an inactive/no-longer referenced
table is destroyed in pfr_setflags_ktable.

Fix from Chris Pascoe
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.55 2004/06/07 13:16:19 cedric Exp $	*/
d243 1
a243 1
	long			 tzero = time.tv_sec;
d410 1
a410 1
	long			 tzero = time.tv_sec;
d598 1
a598 1
	long			 tzero = time.tv_sec;
d1118 1
a1118 1
	long			 tzero = time.tv_sec;
d1270 1
a1270 1
	long			 tzero = time.tv_sec;
d1318 1
a1318 1
	long			 tzero = time.tv_sec;
d1571 1
a1571 1
	long			 tzero = time.tv_sec;
d1980 1
a1980 1
		kt = pfr_create_ktable(&tbl, time.tv_sec, 1);
@


1.55
log
@Make deletion of a few addresses much faster on big tables. ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.54 2004/06/02 22:18:25 tedu Exp $	*/
d1733 1
a1733 1
	struct pfr_ktable	*p;
d1735 2
a1736 1
	SLIST_FOREACH(p, workq, pfrkt_workq)
d1738 1
@


1.54
log
@tables like to allocate lots of memory at once.  use the previous
pool allocator, _nointr.  testing/ok beck@@ cedric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.53 2004/05/19 17:50:52 dhartmei Exp $	*/
d320 1
a320 1
	int			 i, rv, s, xdel = 0;
d330 28
a357 1
	pfr_mark_addrs(kt);
@


1.53
log
@Allow recursive anchors (anchors within anchors, up to 64
levels deep). More work required, but this is already
functional. authpf users will need to adjust their anchor
calls, but this will change again soon. ok beck@@, cedric@@,
henning@@, mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.52 2004/04/28 15:12:20 pb Exp $	*/
d190 1
a190 1
	    "pfrktable", &pool_allocator_nointr);
d192 1
a192 1
	    "pfrkentry", &pool_allocator_nointr);
@


1.52
log
@
gcc3 shut up (from naddy@@)
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.51 2004/04/28 03:31:33 pb Exp $	*/
a1118 1
			bzero(key.pfrkt_ruleset, sizeof(key.pfrkt_ruleset));
d1381 1
a1381 1
	rs = pf_find_or_create_ruleset(trs->pfrt_anchor, trs->pfrt_ruleset);
d1423 1
a1423 1
	rs = pf_find_ruleset(tbl->pfrt_anchor, tbl->pfrt_ruleset);
d1514 1
a1514 1
	rs = pf_find_ruleset(trs->pfrt_anchor, trs->pfrt_ruleset);
d1547 1
a1547 1
	rs = pf_find_ruleset(trs->pfrt_anchor, trs->pfrt_ruleset);
a1662 1
	struct pf_anchor *ac;
d1666 2
a1667 3
	if (filter->pfrt_ruleset[0]) {
		rs = pf_find_ruleset(filter->pfrt_anchor,
		    filter->pfrt_ruleset);
a1669 4
	if (filter->pfrt_anchor[0]) {
		ac = pf_find_anchor(filter->pfrt_anchor);
		return ((ac != NULL) ? ac->tables : -1);
	}
d1678 1
a1678 7
	if (strncmp(filter->pfrt_anchor, kt->pfrkt_anchor,
	    PF_ANCHOR_NAME_SIZE))
		return (1);
	if (!filter->pfrt_ruleset[0])
		return (0);
	if (strncmp(filter->pfrt_ruleset, kt->pfrkt_ruleset,
	    PF_RULESET_NAME_SIZE))
d1784 1
a1784 2
		rs = pf_find_or_create_ruleset(tbl->pfrt_anchor,
		    tbl->pfrt_ruleset);
a1790 2
		if (rs->anchor != NULL)
			rs->anchor->tables++;
a1833 2
		if (kt->pfrkt_rs->anchor != NULL)
			kt->pfrkt_rs->anchor->tables--;
d1846 1
a1846 5
	if ((d = strncmp(p->pfrkt_anchor, q->pfrkt_anchor,
	    PF_ANCHOR_NAME_SIZE)))
		return (d);
	return (strncmp(p->pfrkt_ruleset, q->pfrkt_ruleset,
	    PF_RULESET_NAME_SIZE));
d1947 1
a1947 1
	if (ac != NULL) {
a1948 2
		strlcpy(tbl.pfrt_ruleset, rs->name, sizeof(tbl.pfrt_ruleset));
	}
a1955 1
			bzero(tbl.pfrt_ruleset, sizeof(tbl.pfrt_ruleset));
@


1.51
log
@do not return here
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.50 2004/04/28 02:43:09 pb Exp $	*/
d1945 1
@


1.50
log
@Dont step into INET6 code, just because af != AF_INET
Also comment #endif properly while being here

ok mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.49 2004/04/25 02:48:03 itojun Exp $	*/
a1944 1
		return (0);
@


1.49
log
@radix tree with multipath support.  from kame.  deraadt ok
user visible changes:
- you can add multiple routes with same key (route add A B then route add A C)
- you have to specify gateway address if there are multiple entries on the table
  (route delete A B, instead of route delete A)
kernel change:
- radix_node_head has an extra entry
- rnh_deladdr takes extra argument

TODO:
- actually take advantage of multipath (rtalloc -> rtalloc_mpath)
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.48 2004/04/09 19:30:41 frantzen Exp $	*/
d669 1
d674 2
d680 1
d743 1
a743 1
	} else {
d776 1
a776 1
	else
d888 1
a888 1
	} else {
d914 1
a914 1
	else
d938 1
a938 1
	else
d967 1
a967 1
	else
d1036 1
a1036 1
		} else {
d1891 1
d1898 2
d1906 1
d1928 1
d1935 2
d1943 3
d2018 4
a2021 2
	addr = (af == AF_INET) ? (struct pf_addr *)&pfr_sin.sin_addr :
	    (struct pf_addr *)&pfr_sin6.sin6_addr;
d2064 6
a2069 3
		ke2 = (struct pfr_kentry *)(af == AF_INET ?
		    rn_match(&pfr_sin, kt->pfrkt_ip4) :
		    rn_match(&pfr_sin6, kt->pfrkt_ip6));
d2102 1
d2106 2
d2111 1
@


1.48
log
@move some of the non-interrupt pools from the small kmem_map to the much
larger kernel map
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.47 2004/03/09 21:44:41 mcbride Exp $	*/
d940 1
a940 1
		rn = rn_delete(&ke->pfrke_sa, &mask, head);
d942 1
a942 1
		rn = rn_delete(&ke->pfrke_sa, NULL, head);
@


1.47
log
@KNF, ok cedric@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.46 2004/02/10 22:42:57 dhartmei Exp $	*/
d190 1
a190 1
	    "pfrktable", NULL);
d192 1
a192 1
	    "pfrkentry", NULL);
@


1.46
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.45 2004/02/10 18:49:10 henning Exp $	*/
d981 1
a981 1
		/* fall trough */
d1041 1
d1863 2
a1864 2
	return strncmp(p->pfrkt_ruleset, q->pfrkt_ruleset,
	    PF_RULESET_NAME_SIZE);
d1871 2
a1872 1
	return RB_FIND(pfr_ktablehead, &pfr_ktables, (struct pfr_ktable *)tbl);
d1884 1
a1884 1
		return 0;
d1982 1
a1982 1
	return kt;
d2085 1
a2085 1
		return w.pfrw_kentry;
d2088 1
a2088 1
		return w.pfrw_kentry;
d2090 1
a2090 1
		return NULL;
@


1.45
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.44 2003/12/31 22:14:42 deraadt Exp $	*/
d130 1
a130 1
union  sockaddr_union	 pfr_mask;
d177 1
a177 1
struct pfr_kentry       *pfr_kentry_byidx(struct pfr_ktable *, int, int);
d836 1
a836 1
	struct pfr_kentry       *p;
@


1.44
log
@spacing.  note this, cedric
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.43 2003/12/31 11:18:25 cedric Exp $	*/
d84 2
a85 2
        (struct pf_addr *)&(su)->sin.sin_addr :	\
        (struct pf_addr *)&(su)->sin6.sin6_addr)
d836 1
a836 1
        struct pfr_kentry       *p;
d838 2
a839 2
        SLIST_FOREACH(p, workq, pfrke_workq)
                pfr_unroute_kentry(kt, p);
d2046 1
a2046 1
                ke2 = (struct pfr_kentry *)(af == AF_INET ?
d2076 3
a2078 3
        bzero(&w, sizeof(w));
        w.pfrw_op = PFRW_POOL_GET;
        w.pfrw_cnt = idx;
d2080 1
a2080 1
	switch(af) {
d2096 1
a2096 1
	int 			s;
@


1.43
log
@Many improvements to the handling of interfaces in PF.

1) PF should do the right thing when unplugging/replugging or cloning/
destroying NICs.

2) Rules can be loaded in the kernel for not-yet-existing devices
(USB, PCMCIA, Cardbus). For example, it is valid to write:
"pass in on kue0" before kue USB is plugged in.

3) It is possible to write rules that apply to group of interfaces
(drivers), like "pass in on ppp all"

4) There is a new ":peer" modifier that completes the ":broadcast"
and ":network" modifiers.

5) There is a new ":0" modifier that will filter out interface aliases.
Can also be applied to DNS names to restore original PF behaviour.

6) The dynamic interface syntax (foo) has been vastly improved, and
now support multiple addresses, v4 and v6 addresses, and all userland
modifiers, like "pass in from (fxp0:network)"

7) Scrub rules now support the !if syntax.

8) States can be bound to the specific interface that created them or
to  a group of interfaces for example:

- pass all keep state (if-bound)
- pass all keep state (group-bound)
- pass all keep state (floating)

9) The default value when only keep state is given can be selected by
using the "set state-policy" statement.

10) "pfctl -ss" will now print the interface scope of the state.

This diff change the pf_state structure slighltly, so you should
recompile your userland tools (pfctl, authpf, pflogd, tcpdump...)

Tested on i386, sparc, sparc64 by Ryan
Tested on macppc, sparc64 by Daniel

ok deraadt@@ mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.42 2003/09/26 21:44:09 cedric Exp $	*/
d61 1
a61 1
	
@


1.42
log
@Rearchitecture of the userland/kernel IOCTL interface for transactions.
This brings us close to 100% atomicity for a "pfctl -f pf.conf" command.
(some splxxx work remain in the kernel). Basically, improvements are:

   - Anchors/Rulesets cannot disappear unexpectedly anymore.
   - No more leftover in the kernel if "pfctl -f" fail.
   - Commit is now done in a single atomic IOCTL.

WARNING: The kernel code is fully backward compatible, but the new
pfctl/authpf userland utilities will only run on a new kernel.

The following ioctls are deprecated (i.e. will be deleted sooner or
later, depending on how many 3rd party utilities use them and how soon
they can be upgraded):

   - DIOCBEGINRULES
   - DIOCCOMMITRULES
   - DIOCBEGINALTQS
   - DIOCCOMMITALTQS
   - DIOCRINABEGIN
   - DIOCRINADEFINE

They are replaced by the following ioctls (yes, PF(4) will follow)
which operate on a vector of rulesets:

   - DIOCXBEGIN
   - DIOCXCOMMIT
   - DIOCXROLLBACK

Ok dhartmei@@ mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.41 2003/08/22 15:19:23 henning Exp $	*/
d52 10
d104 2
a105 1
		PFRW_POOL_GET
d112 1
d115 1
d121 1
d150 1
a150 1
void			 pfr_reset_feedback(struct pfr_addr *, int);
d157 1
a157 1
int			 pfr_validate_table(struct pfr_table *, int);
d210 1
a210 1
	if (pfr_validate_table(tbl, 0))
d246 1
a246 1
	if (pfr_validate_table(tbl, 0))
d258 1
a258 1
		if (copyin(addr+i, &ad, sizeof(ad)))
d287 1
a287 1
			if (copyout(&ad, addr+i, sizeof(ad)))
d307 1
a307 1
		pfr_reset_feedback(addr, size);
d323 1
a323 1
	if (pfr_validate_table(tbl, 0))
d333 1
a333 1
		if (copyin(addr+i, &ad, sizeof(ad)))
d355 1
a355 1
			if (copyout(&ad, addr+i, sizeof(ad)))
d370 1
a370 1
		pfr_reset_feedback(addr, size);
d386 1
a386 1
	if (pfr_validate_table(tbl, 0))
d401 1
a401 1
		if (copyin(addr+i, &ad, sizeof(ad)))
d438 1
a438 1
			if (copyout(&ad, addr+i, sizeof(ad)))
d451 1
a451 1
			if (copyout(&ad, addr+size+i, sizeof(ad)))
d473 1
a473 1
	if ((flags & PFR_FLAG_FEEDBACK) && *size2)
d481 1
a481 1
		pfr_reset_feedback(addr, size);
d496 1
a496 1
	if (pfr_validate_table(tbl, 0))
d503 1
a503 1
		if (copyin(addr+i, &ad, sizeof(ad)))
d516 1
a516 1
		if (copyout(&ad, addr+i, sizeof(ad)))
d533 1
a533 1
	if (pfr_validate_table(tbl, 0))
d547 1
d574 1
a574 1
	if (pfr_validate_table(tbl, 0))
d588 1
d623 1
a623 1
	if (pfr_validate_table(tbl, 0))
d630 1
a630 1
		if (copyin(addr+i, &ad, sizeof(ad)))
d638 1
a638 1
			if (copyout(&ad, addr+i, sizeof(ad)))
d659 1
a659 1
		pfr_reset_feedback(addr, size);
d860 1
a860 1
pfr_reset_feedback(struct pfr_addr *addr, int size)
d866 1
a866 1
		if (copyin(addr+i, &ad, sizeof(ad)))
d869 1
a869 1
		if (copyout(&ad, addr+i, sizeof(ad)))
d972 1
a972 1
	int			 s;
d1010 1
a1010 1
			if (copyout(&as, w->pfrw_astats, sizeof(as)))
d1023 18
d1060 2
d1092 1
a1092 1
		if (copyin(tbl+i, &key.pfrkt_t, sizeof(key.pfrkt_t)))
d1094 2
a1095 1
		if (pfr_validate_table(&key.pfrkt_t, PFR_TFLAG_USRMASK))
d1171 1
a1171 1
		if (copyin(tbl+i, &key.pfrkt_t, sizeof(key.pfrkt_t)))
d1173 2
a1174 1
		if (pfr_validate_table(&key.pfrkt_t, 0))
d1221 1
a1221 1
		if (copyout(&p->pfrkt_t, tbl++, sizeof(*tbl)))
d1260 1
a1260 1
		if (copyout(&p->pfrkt_ts, tbl++, sizeof(*tbl))) {
d1292 1
a1292 1
		if (copyin(tbl+i, &key.pfrkt_t, sizeof(key.pfrkt_t)))
d1294 1
a1294 1
		if (pfr_validate_table(&key.pfrkt_t, 0))
d1329 1
a1329 1
		if (copyin(tbl+i, &key.pfrkt_t, sizeof(key.pfrkt_t)))
d1331 2
a1332 1
		if (pfr_validate_table(&key.pfrkt_t, 0))
d1416 2
a1417 1
	if (pfr_validate_table(tbl, PFR_TFLAG_USRMASK))
d1459 1
a1459 1
		if (copyin(addr+i, &ad, sizeof(ad)))
d1637 1
a1637 1
pfr_validate_table(struct pfr_table *tbl, int allowedflags)
d1643 2
d2092 19
@


1.41
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.40 2003/08/09 14:56:48 cedric Exp $	*/
d1459 31
@


1.40
log
@This patch remove the restriction that tables cannot be used in routing or
redirection rules...

The advantage of using tables in redirection/routing rules is not efficiency,
in fact it will run slower than straight address pools. However, this brings
a lot of flexibility to PF, allowing simple scripts/daemons to add/remove
addresses from redirection/routing pools easily.

This implementation support all table features, including cidr blocks and
negated addresses. So specifying { 10.0.0.0/29 !10.0.0.0 !10.0.0.7 } will
correctly round-robin between the six addresses: .1, .2, .3, .4, .5, .6.

Tables can also be combined with simple addresses, so the following rule
will work as expected: "nat on foo0 -> { 1.1.1.1 <bar> }"

ok henning@@ mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.39 2003/07/31 22:25:55 cedric Exp $	*/
d1920 1
a1920 1
int 
d1953 1
a1953 1
		if(!PF_MATCHA(0, *raddr, *rmask, counter, af)) {
d1971 1
a1971 1
	for(;;) {
d1988 1
a1988 1
		if(!PF_MATCHA(0, *raddr, *rmask, addr, af)) {
d2009 1
a2009 1
        	rn_walktree(kt->pfrkt_ip4, pfr_walktree, &w);
@


1.39
log
@Make table tickets per-ruleset instead of global.
Make table tickets u_int32_t for consistency with other parts of PF.
Ok dhartmei@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.38 2003/06/24 13:52:50 henning Exp $	*/
d73 4
d93 2
a94 1
		PFRW_GET_ASTATS
d100 1
d107 1
d116 2
d163 1
d184 2
d999 8
d1919 100
@


1.38
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.37 2003/06/08 10:32:35 cedric Exp $	*/
a160 1
int			 pfr_ticket;
a173 2

	pfr_ticket = 100;
d1310 1
a1310 1
pfr_ina_begin(int *ticket, int *ndel, int flags)
d1314 1
d1318 3
d1323 2
a1324 1
		if (!(p->pfrkt_flags & PFR_TFLAG_INACTIVE))
d1330 1
a1330 1
	if (!(flags & PFR_FLAG_DUMMY))
d1332 5
a1338 2
	if (ticket != NULL && !(flags & PFR_FLAG_DUMMY))
		*ticket = ++pfr_ticket;
d1344 1
a1344 1
    int *nadd, int *naddr, int ticket, int flags)
d1351 1
a1354 2
	if (ticket != pfr_ticket)
		return (EBUSY);
d1359 3
d1442 2
a1443 1
pfr_ina_commit(int ticket, int *nadd, int *nchange, int flags)
d1447 1
d1452 2
a1453 1
	if (ticket != pfr_ticket)
a1454 1
	pfr_ticket++;
d1458 2
a1459 1
		if (!(p->pfrkt_flags & PFR_TFLAG_INACTIVE))
d1475 2
@


1.37
log
@Returns the correct array size.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.36 2003/06/08 09:41:08 cedric Exp $	*/
d1560 1
a1560 1
		    filter->pfrt_ruleset);	
d1695 1
a1695 1
		if(rs->anchor != NULL)
d1740 1
a1740 1
		if(kt->pfrkt_rs->anchor != NULL)
@


1.36
log
@A table in an anchor creates a real anchor: pfctl -sA works.
The following two pfctl functions work with an "-a" option:
  - pfctl [-a foo[:bar]] -sT
  - pfctl [-a foo[:bar]] -FT
ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.35 2003/05/24 14:22:03 cedric Exp $	*/
d1151 1
a1151 1
	int			 n;
d1154 1
a1154 1
	n = pfr_table_count(filter, flags);
d1173 1
a1173 1
	*size = pfr_ktable_cnt;
d1183 1
a1183 1
	int			 s, n;
d1188 1
a1188 1
	n = pfr_table_count(filter, flags);
d1222 1
a1222 1
	*size = pfr_ktable_cnt;
@


1.35
log
@Unused variable.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.34 2003/04/30 12:30:27 cedric Exp $	*/
d143 1
a143 1
struct pfr_ktable	*pfr_create_ktable(struct pfr_table *, long);
d151 3
d230 1
a230 1
	tmpkt = pfr_create_ktable(&pfr_nulltable, 0);
d370 1
a370 1
	tmpkt = pfr_create_ktable(&pfr_nulltable, 0);
d995 1
a995 1
pfr_clr_tables(int *ndel, int flags)
d1001 4
a1004 1
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC+PFR_FLAG_DUMMY);
d1007 2
d1046 1
a1046 1
			p = pfr_create_ktable(&key.pfrkt_t, tzero);
d1073 1
a1073 1
			r = pfr_create_ktable(&key.pfrkt_t, 0);
d1147 2
a1148 1
pfr_get_tables(struct pfr_table *tbl, int *size, int flags)
d1151 1
a1151 1
	int			 n = pfr_ktable_cnt;
d1153 4
a1156 1
	ACCEPT_FLAGS(0);
d1162 2
d1178 2
a1179 1
pfr_get_tstats(struct pfr_tstats *tbl, int *size, int flags)
d1183 1
a1183 1
	int			 s, n = pfr_ktable_cnt;
d1186 5
a1190 1
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC); /* XXX PFR_FLAG_CLSTATS disabled */
d1199 2
d1359 1
a1359 1
		kt = pfr_create_ktable(tbl, 0);
d1375 1
a1375 1
		rt = pfr_create_ktable(&key.pfrkt_t, 0);
d1385 1
a1385 1
	shadow = pfr_create_ktable(tbl, 0);
d1550 36
d1675 1
a1675 1
pfr_create_ktable(struct pfr_table *tbl, long tzero)
d1678 1
d1686 13
d1738 6
d1854 1
a1854 1
		kt = pfr_create_ktable(&tbl, time.tv_sec);
d1862 1
a1862 1
				rt = pfr_create_ktable(&tbl, 0);
@


1.34
log
@Allow tables to be loaded into anchors.
Most pfctl table commands (excluding 'show' and 'flush') support the "-a"
modifier.
ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.33 2003/04/27 16:02:08 cedric Exp $	*/
d818 1
a818 1
	int			 s, n = 0;
a827 1
		n++;
@


1.33
log
@Update the pfioc_table IOCTL structure.
Prepare for anchors, improve robustness.
WARNING: need to sync kernel/userland.
ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.32 2003/04/04 01:46:04 deraadt Exp $	*/
d1024 1
a1024 1
	struct pfr_ktable	*p, *q, key;
d1043 1
a1043 1
				if (!strcmp(p->pfrkt_name, q->pfrkt_name))
d1048 23
d1073 1
a1073 1
				if (!strcmp(key.pfrkt_name, q->pfrkt_name))
d1117 1
a1117 1
				if (!strcmp(p->pfrkt_name, q->pfrkt_name))
d1265 1
a1265 1
				if (!strcmp(p->pfrkt_name, q->pfrkt_name))
d1323 1
a1323 1
	struct pfr_ktable	*kt, *shadow;
d1344 18
d1364 1
d1544 4
d1571 5
d1674 9
a1682 1
	return (strncmp(p->pfrkt_name, q->pfrkt_name, PF_TABLE_NAME_SIZE));
d1698 5
d1731 5
d1764 1
a1764 1
pfr_attach_table(char *name)
d1766 1
a1766 1
	struct pfr_ktable	*kt;
d1768 1
d1772 4
d1780 15
a1794 1
			return NULL;
@


1.32
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.31 2003/03/21 12:47:36 cedric Exp $	*/
d1709 1
a1709 1
	if (!kt->pfrkt_refcnt++)
d1717 1
a1717 1
	if (kt->pfrkt_refcnt <= 0)
d1719 2
a1720 2
		    kt->pfrkt_refcnt);
	else if (!--kt->pfrkt_refcnt)
@


1.31
log
@- Add missing "\n" to some pf_table.c printf()
- Fix two problems with pfr_update_stats().

Filtering was done properly, only stats were wrong.
People should upgrade their kernel if:
  - They use bidirectional rules (without "in" or "out") with tables.
  - They use tables in negated statements, like "block from !<foo>"

Thanks to David Krause for discovering the problem.
Ok dhartmei@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.30 2003/03/14 12:36:40 cedric Exp $	*/
d149 1
a149 1
void			 pfr_clean_node_mask(struct pfr_ktable *, 
@


1.31.4.1
log
@Sync the SMP branch to -current. This includes moving to ELF.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.31 2003/03/21 12:47:36 cedric Exp $	*/
d149 1
a149 1
void			 pfr_clean_node_mask(struct pfr_ktable *,
d1024 1
a1024 1
	struct pfr_ktable	*p, *q, *r, key;
d1043 1
a1043 1
				if (!pfr_ktable_compare(p, q))
a1047 23
			if (!key.pfrkt_anchor[0])
				goto _skip;

			/* find or create root table */
			bzero(key.pfrkt_anchor, sizeof(key.pfrkt_anchor));
			bzero(key.pfrkt_ruleset, sizeof(key.pfrkt_ruleset));
			r = RB_FIND(pfr_ktablehead, &pfr_ktables, &key);
			if (r != NULL) {
				p->pfrkt_root = r;
				goto _skip;
			}
			SLIST_FOREACH(q, &addq, pfrkt_workq) {
				if (!pfr_ktable_compare(&key, q)) {
					p->pfrkt_root = q;
					goto _skip;
				}
			}
			key.pfrkt_flags = 0;
			r = pfr_create_ktable(&key.pfrkt_t, 0);
			if (r == NULL)
				senderr(ENOMEM);
			SLIST_INSERT_HEAD(&addq, r, pfrkt_workq);
			p->pfrkt_root = r;
d1050 1
a1050 1
				if (!pfr_ktable_compare(&key, q))
d1094 1
a1094 1
				if (!pfr_ktable_compare(p, q))
d1242 1
a1242 1
				if (!pfr_ktable_compare(p, q))
d1300 1
a1300 1
	struct pfr_ktable	*kt, *rt, *shadow, key;
a1320 18
		if (!tbl->pfrt_anchor[0])
			goto _skip;

		/* find or create root table */
		bzero(&key, sizeof(key));
		strlcpy(key.pfrkt_name, tbl->pfrt_name, sizeof(key.pfrkt_name));
		rt = RB_FIND(pfr_ktablehead, &pfr_ktables, &key);
		if (rt != NULL) {
			kt->pfrkt_root = rt;
			goto _skip;
		}
		rt = pfr_create_ktable(&key.pfrkt_t, 0);
		if (rt == NULL) {
			pfr_destroy_ktables(&tableq, 0);
			return (ENOMEM);
		}
		SLIST_INSERT_HEAD(&tableq, rt, pfrkt_workq);
		kt->pfrkt_root = rt;
a1322 1
_skip:
a1501 4
	if (kt->pfrkt_root != NULL)
		if (!kt->pfrkt_root->pfrkt_refcnt[PFR_REFCNT_ANCHOR]++)
			pfr_setflags_ktable(kt->pfrkt_root,
			    kt->pfrkt_root->pfrkt_flags|PFR_TFLAG_REFDANCHOR);
a1524 5
		if (kt->pfrkt_root != NULL)
			if (!--kt->pfrkt_root->pfrkt_refcnt[PFR_REFCNT_ANCHOR])
				pfr_setflags_ktable(kt->pfrkt_root,
				    kt->pfrkt_root->pfrkt_flags &
					~PFR_TFLAG_REFDANCHOR);
d1623 1
a1623 9
	int d;

	if ((d = strncmp(p->pfrkt_name, q->pfrkt_name, PF_TABLE_NAME_SIZE)))
		return (d);
	if ((d = strncmp(p->pfrkt_anchor, q->pfrkt_anchor,
	    PF_ANCHOR_NAME_SIZE)))
		return (d);
	return strncmp(p->pfrkt_ruleset, q->pfrkt_ruleset,
	    PF_RULESET_NAME_SIZE);
a1638 5
	if (!(kt->pfrkt_flags & PFR_TFLAG_ACTIVE) && kt->pfrkt_root != NULL)
		kt = kt->pfrkt_root;
	if (!(kt->pfrkt_flags & PFR_TFLAG_ACTIVE))
		return 0;

a1666 5
	if (!(kt->pfrkt_flags & PFR_TFLAG_ACTIVE) && kt->pfrkt_root != NULL)
		kt = kt->pfrkt_root;
	if (!(kt->pfrkt_flags & PFR_TFLAG_ACTIVE))
		return;

d1695 1
a1695 1
pfr_attach_table(struct pf_ruleset *rs, char *name)
d1697 1
a1697 1
	struct pfr_ktable	*kt, *rt;
a1698 1
	struct pf_anchor	*ac = rs->anchor;
a1701 4
	if (ac != NULL) {
		strlcpy(tbl.pfrt_anchor, ac->name, sizeof(tbl.pfrt_anchor));
		strlcpy(tbl.pfrt_ruleset, rs->name, sizeof(tbl.pfrt_ruleset));
	}
d1706 1
a1706 15
			return (NULL);
		if (ac != NULL) {
			bzero(tbl.pfrt_anchor, sizeof(tbl.pfrt_anchor));
			bzero(tbl.pfrt_ruleset, sizeof(tbl.pfrt_ruleset));
			rt = pfr_lookup_table(&tbl);
			if (rt == NULL) {
				rt = pfr_create_ktable(&tbl, 0);
				if (rt == NULL) {
					pfr_destroy_ktable(kt, 0);
					return (NULL);
				}
				pfr_insert_ktable(rt);
			}
			kt->pfrkt_root = rt;
		}
d1709 1
a1709 1
	if (!kt->pfrkt_refcnt[PFR_REFCNT_RULE]++)
d1717 1
a1717 1
	if (kt->pfrkt_refcnt[PFR_REFCNT_RULE] <= 0)
d1719 2
a1720 2
		    kt->pfrkt_refcnt[PFR_REFCNT_RULE]);
	else if (!--kt->pfrkt_refcnt[PFR_REFCNT_RULE])
@


1.31.4.2
log
@Sync SMP branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.31.4.1 2003/05/13 19:36:16 ho Exp $	*/
d818 1
a818 1
	int			 s;
d828 1
@


1.31.4.3
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a51 10
#define COPYIN(from, to, size)			\
	((flags & PFR_FLAG_USERIOCTL) ?		\
	copyin((from), (to), (size)) :		\
	(bcopy((from), (to), (size)), 0))

#define COPYOUT(from, to, size)			\
	((flags & PFR_FLAG_USERIOCTL) ?		\
	copyout((from), (to), (size)) :		\
	(bcopy((from), (to), (size)), 0))

a72 4
#define SUNION2PF(su, af) (((af)==AF_INET) ?	\
        (struct pf_addr *)&(su)->sin.sin_addr :	\
        (struct pf_addr *)&(su)->sin6.sin6_addr)

d89 1
a89 3
		PFRW_GET_ASTATS,
		PFRW_POOL_GET,
		PFRW_DYNADDR_UPDATE
a94 2
		struct pfr_kentry	*pfrw1_kentry;
		struct pfi_dynaddr	*pfrw1_dyn;
a96 1
	int	 pfrw_flags;
a100 2
#define pfrw_kentry	pfrw_1.pfrw1_kentry
#define pfrw_dyn	pfrw_1.pfrw1_dyn
a108 2
union  sockaddr_union	 pfr_mask;
struct pf_addr		 pfr_ffaddr;
d127 1
a127 1
void			 pfr_reset_feedback(struct pfr_addr *, int, int);
d134 1
a134 1
int			 pfr_validate_table(struct pfr_table *, int, int);
d143 1
a143 1
struct pfr_ktable	*pfr_create_ktable(struct pfr_table *, long, int);
a150 4
int			 pfr_table_count(struct pfr_table *, int);
int			 pfr_skip_table(struct pfr_table *,
			    struct pfr_ktable *, int);
struct pfr_kentry       *pfr_kentry_byidx(struct pfr_ktable *, int, int);
d158 1
d173 1
a173 1
	memset(&pfr_ffaddr, 0xff, sizeof(pfr_ffaddr));
d184 1
a184 1
	if (pfr_validate_table(tbl, 0, flags & PFR_FLAG_USERIOCTL))
d220 1
a220 1
	if (pfr_validate_table(tbl, 0, flags & PFR_FLAG_USERIOCTL))
d227 1
a227 1
	tmpkt = pfr_create_ktable(&pfr_nulltable, 0, 0);
d232 1
a232 1
		if (COPYIN(addr+i, &ad, sizeof(ad)))
d261 1
a261 1
			if (COPYOUT(&ad, addr+i, sizeof(ad)))
d281 1
a281 1
		pfr_reset_feedback(addr, size, flags);
d297 1
a297 1
	if (pfr_validate_table(tbl, 0, flags & PFR_FLAG_USERIOCTL))
d307 1
a307 1
		if (COPYIN(addr+i, &ad, sizeof(ad)))
d329 1
a329 1
			if (COPYOUT(&ad, addr+i, sizeof(ad)))
d344 1
a344 1
		pfr_reset_feedback(addr, size, flags);
d360 1
a360 1
	if (pfr_validate_table(tbl, 0, flags & PFR_FLAG_USERIOCTL))
d367 1
a367 1
	tmpkt = pfr_create_ktable(&pfr_nulltable, 0, 0);
d375 1
a375 1
		if (COPYIN(addr+i, &ad, sizeof(ad)))
d412 1
a412 1
			if (COPYOUT(&ad, addr+i, sizeof(ad)))
d425 1
a425 1
			if (COPYOUT(&ad, addr+size+i, sizeof(ad)))
d447 1
a447 1
	if ((flags & PFR_FLAG_FEEDBACK) && size2)
d455 1
a455 1
		pfr_reset_feedback(addr, size, flags);
d470 1
a470 1
	if (pfr_validate_table(tbl, 0, 0))
d477 1
a477 1
		if (COPYIN(addr+i, &ad, sizeof(ad)))
d490 1
a490 1
		if (COPYOUT(&ad, addr+i, sizeof(ad)))
d507 1
a507 1
	if (pfr_validate_table(tbl, 0, 0))
a520 1
	w.pfrw_flags = flags;
d547 1
a547 1
	if (pfr_validate_table(tbl, 0, 0))
a560 1
	w.pfrw_flags = flags;
d595 1
a595 1
	if (pfr_validate_table(tbl, 0, 0))
d602 1
a602 1
		if (COPYIN(addr+i, &ad, sizeof(ad)))
d610 1
a610 1
			if (COPYOUT(&ad, addr+i, sizeof(ad)))
d631 1
a631 1
		pfr_reset_feedback(addr, size, flags);
d832 1
a832 1
pfr_reset_feedback(struct pfr_addr *addr, int size, int flags)
d838 1
a838 1
		if (COPYIN(addr+i, &ad, sizeof(ad)))
d841 1
a841 1
		if (COPYOUT(&ad, addr+i, sizeof(ad)))
d944 1
a944 1
	int			 s, flags = w->pfrw_flags;
d982 1
a982 1
			if (COPYOUT(&as, w->pfrw_astats, sizeof(as)))
a986 26
	case PFRW_POOL_GET:
		if (ke->pfrke_not)
			break; /* negative entries are ignored */
		if (!w->pfrw_cnt--) {
			w->pfrw_kentry = ke;
			return (1); /* finish search */
		}
		break;
	case PFRW_DYNADDR_UPDATE:
		if (ke->pfrke_af == AF_INET) {
			if (w->pfrw_dyn->pfid_acnt4++ > 0)
				break;
			pfr_prepare_network(&pfr_mask, AF_INET, ke->pfrke_net);
			w->pfrw_dyn->pfid_addr4 = *SUNION2PF(
			    &ke->pfrke_sa, AF_INET);
			w->pfrw_dyn->pfid_mask4 = *SUNION2PF(
			    &pfr_mask, AF_INET);
		} else {
			if (w->pfrw_dyn->pfid_acnt6++ > 0)
				break;
			pfr_prepare_network(&pfr_mask, AF_INET6, ke->pfrke_net);
			w->pfrw_dyn->pfid_addr6 = *SUNION2PF(
			    &ke->pfrke_sa, AF_INET6);
			w->pfrw_dyn->pfid_mask6 = *SUNION2PF(
			    &pfr_mask, AF_INET6);
		}
d992 1
a992 1
pfr_clr_tables(struct pfr_table *filter, int *ndel, int flags)
d998 1
a998 4
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC+PFR_FLAG_DUMMY+PFR_FLAG_ALLRSETS);
	if (pfr_table_count(filter, flags) < 0)
		return (ENOENT);

a1000 4
		if (pfr_skip_table(filter, p, flags))
			continue;
		if (!strcmp(p->pfrkt_anchor, PF_RESERVED_ANCHOR))
			continue;
d1031 1
a1031 1
		if (COPYIN(tbl+i, &key.pfrkt_t, sizeof(key.pfrkt_t)))
d1033 1
a1033 2
		if (pfr_validate_table(&key.pfrkt_t, PFR_TFLAG_USRMASK,
		    flags & PFR_FLAG_USERIOCTL))
d1038 1
a1038 1
			p = pfr_create_ktable(&key.pfrkt_t, tzero, 1);
d1065 1
a1065 1
			r = pfr_create_ktable(&key.pfrkt_t, 0, 1);
d1109 1
a1109 1
		if (COPYIN(tbl+i, &key.pfrkt_t, sizeof(key.pfrkt_t)))
d1111 1
a1111 2
		if (pfr_validate_table(&key.pfrkt_t, 0,
		    flags & PFR_FLAG_USERIOCTL))
d1139 1
a1139 2
pfr_get_tables(struct pfr_table *filter, struct pfr_table *tbl, int *size,
	int flags)
d1142 1
a1142 1
	int			 n, nn;
d1144 1
a1144 4
	ACCEPT_FLAGS(PFR_FLAG_ALLRSETS);
	n = nn = pfr_table_count(filter, flags);
	if (n < 0)
		return (ENOENT);
a1149 2
		if (pfr_skip_table(filter, p, flags))
			continue;
d1152 1
a1152 1
		if (COPYOUT(&p->pfrkt_t, tbl++, sizeof(*tbl)))
d1159 1
a1159 1
	*size = nn;
d1164 1
a1164 2
pfr_get_tstats(struct pfr_table *filter, struct pfr_tstats *tbl, int *size,
	int flags)
d1168 1
a1168 1
	int			 s, n, nn;
d1171 1
a1171 5
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC|PFR_FLAG_ALLRSETS);
					/* XXX PFR_FLAG_CLSTATS disabled */
	n = nn = pfr_table_count(filter, flags);
	if (n < 0)
		return (ENOENT);
a1179 2
		if (pfr_skip_table(filter, p, flags))
			continue;
d1184 1
a1184 1
		if (COPYOUT(&p->pfrkt_ts, tbl++, sizeof(*tbl))) {
d1201 1
a1201 1
	*size = nn;
d1216 1
a1216 1
		if (COPYIN(tbl+i, &key.pfrkt_t, sizeof(key.pfrkt_t)))
d1218 1
a1218 1
		if (pfr_validate_table(&key.pfrkt_t, 0, 0))
d1253 1
a1253 1
		if (COPYIN(tbl+i, &key.pfrkt_t, sizeof(key.pfrkt_t)))
d1255 1
a1255 2
		if (pfr_validate_table(&key.pfrkt_t, 0,
		    flags & PFR_FLAG_USERIOCTL))
d1292 1
a1292 1
pfr_ina_begin(struct pfr_table *trs, u_int32_t *ticket, int *ndel, int flags)
a1295 1
	struct pf_ruleset	*rs;
a1298 3
	rs = pf_find_or_create_ruleset(trs->pfrt_anchor, trs->pfrt_ruleset);
	if (rs == NULL)
		return (ENOMEM);
d1301 1
a1301 2
		if (!(p->pfrkt_flags & PFR_TFLAG_INACTIVE) ||
		    pfr_skip_table(trs, p, 0))
d1307 1
a1307 1
	if (!(flags & PFR_FLAG_DUMMY)) {
a1308 5
		if (ticket != NULL)
			*ticket = ++rs->tticket;
		rs->topen = 1;
	} else
		pf_remove_if_empty_ruleset(rs);
d1311 2
d1318 1
a1318 1
    int *nadd, int *naddr, u_int32_t ticket, int flags)
a1324 1
	struct pf_ruleset	*rs;
d1328 2
d1332 1
a1332 2
	if (pfr_validate_table(tbl, PFR_TFLAG_USRMASK,
	    flags & PFR_FLAG_USERIOCTL))
a1333 3
	rs = pf_find_ruleset(tbl->pfrt_anchor, tbl->pfrt_ruleset);
	if (rs == NULL || !rs->topen || ticket != rs->tticket)
		return (EBUSY);
d1338 1
a1338 1
		kt = pfr_create_ktable(tbl, 0, 1);
d1354 1
a1354 1
		rt = pfr_create_ktable(&key.pfrkt_t, 0, 1);
d1364 1
a1364 1
	shadow = pfr_create_ktable(tbl, 0, 0);
d1371 1
a1371 1
		if (COPYIN(addr+i, &ad, sizeof(ad)))
d1414 1
a1414 33
pfr_ina_rollback(struct pfr_table *trs, u_int32_t ticket, int *ndel, int flags)
{
	struct pfr_ktableworkq	 workq;
	struct pfr_ktable	*p;
	struct pf_ruleset	*rs;
	int			 xdel = 0;

	ACCEPT_FLAGS(PFR_FLAG_DUMMY);
	rs = pf_find_ruleset(trs->pfrt_anchor, trs->pfrt_ruleset);
	if (rs == NULL || !rs->topen || ticket != rs->tticket)
		return (0);
	SLIST_INIT(&workq);
	RB_FOREACH(p, pfr_ktablehead, &pfr_ktables) {
		if (!(p->pfrkt_flags & PFR_TFLAG_INACTIVE) ||
		    pfr_skip_table(trs, p, 0))
			continue;
		p->pfrkt_nflags = p->pfrkt_flags & ~PFR_TFLAG_INACTIVE;
		SLIST_INSERT_HEAD(&workq, p, pfrkt_workq);
		xdel++;
	}
	if (!(flags & PFR_FLAG_DUMMY)) {
		pfr_setflags_ktables(&workq);
		rs->topen = 0;
		pf_remove_if_empty_ruleset(rs);
	}
	if (ndel != NULL)
		*ndel = xdel;
	return (0);
}

int
pfr_ina_commit(struct pfr_table *trs, u_int32_t ticket, int *nadd,
    int *nchange, int flags)
a1417 1
	struct pf_ruleset	*rs;
d1422 1
a1422 2
	rs = pf_find_ruleset(trs->pfrt_anchor, trs->pfrt_ruleset);
	if (rs == NULL || !rs->topen || ticket != rs->tticket)
d1424 1
d1428 1
a1428 2
		if (!(p->pfrkt_flags & PFR_TFLAG_INACTIVE) ||
		    pfr_skip_table(trs, p, 0))
a1443 2
		rs->topen = 0;
		pf_remove_if_empty_ruleset(rs);
d1513 1
a1513 1
pfr_validate_table(struct pfr_table *tbl, int allowedflags, int no_reserved)
a1518 2
	if (no_reserved && !strcmp(tbl->pfrt_anchor, PF_RESERVED_ANCHOR))
		 return (-1);
a1528 36
int
pfr_table_count(struct pfr_table *filter, int flags)
{
	struct pf_ruleset *rs;
	struct pf_anchor *ac;

	if (flags & PFR_FLAG_ALLRSETS)
		return (pfr_ktable_cnt);
	if (filter->pfrt_ruleset[0]) {
		rs = pf_find_ruleset(filter->pfrt_anchor,
		    filter->pfrt_ruleset);
		return ((rs != NULL) ? rs->tables : -1);
	}
	if (filter->pfrt_anchor[0]) {
		ac = pf_find_anchor(filter->pfrt_anchor);
		return ((ac != NULL) ? ac->tables : -1);
	}
	return (pf_main_ruleset.tables);
}

int
pfr_skip_table(struct pfr_table *filter, struct pfr_ktable *kt, int flags)
{
	if (flags & PFR_FLAG_ALLRSETS)
		return (0);
	if (strncmp(filter->pfrt_anchor, kt->pfrkt_anchor,
	    PF_ANCHOR_NAME_SIZE))
		return (1);
	if (!filter->pfrt_ruleset[0])
		return (0);
	if (strncmp(filter->pfrt_ruleset, kt->pfrkt_ruleset,
	    PF_RULESET_NAME_SIZE))
		return (1);
	return (0);
}

d1618 1
a1618 1
pfr_create_ktable(struct pfr_table *tbl, long tzero, int attachruleset)
a1620 1
	struct pf_ruleset	*rs;
a1627 13
	if (attachruleset) {
		rs = pf_find_or_create_ruleset(tbl->pfrt_anchor,
		    tbl->pfrt_ruleset);
		if (!rs) {
			pfr_destroy_ktable(kt, 0);
			return (NULL);
		}
		kt->pfrkt_rs = rs;
		rs->tables++;
		if (rs->anchor != NULL)
			rs->anchor->tables++;
	}

a1666 6
	if (kt->pfrkt_rs != NULL) {
		kt->pfrkt_rs->tables--;
		if (kt->pfrkt_rs->anchor != NULL)
			kt->pfrkt_rs->anchor->tables--;
		pf_remove_if_empty_ruleset(kt->pfrkt_rs);
	}
d1777 1
a1777 1
		kt = pfr_create_ktable(&tbl, time.tv_sec, 1);
d1785 1
a1785 1
				rt = pfr_create_ktable(&tbl, 0, 1);
a1808 119
}

int
pfr_pool_get(struct pfr_ktable *kt, int *pidx, struct pf_addr *counter,
    struct pf_addr **raddr, struct pf_addr **rmask, sa_family_t af)
{
	struct pfr_kentry	*ke, *ke2;
	struct pf_addr		*addr;
	union sockaddr_union	 mask;
	int			 idx = -1, use_counter = 0;

	addr = (af == AF_INET) ? (struct pf_addr *)&pfr_sin.sin_addr :
	    (struct pf_addr *)&pfr_sin6.sin6_addr;
	if (!(kt->pfrkt_flags & PFR_TFLAG_ACTIVE) && kt->pfrkt_root != NULL)
		kt = kt->pfrkt_root;
	if (!(kt->pfrkt_flags & PFR_TFLAG_ACTIVE))
		return (-1);

	if (pidx != NULL)
		idx = *pidx;
	if (counter != NULL && idx >= 0)
		use_counter = 1;
	if (idx < 0)
		idx = 0;

_next_block:
	ke = pfr_kentry_byidx(kt, idx, af);
	if (ke == NULL)
		return (1);
	pfr_prepare_network(&pfr_mask, af, ke->pfrke_net);
	*raddr = SUNION2PF(&ke->pfrke_sa, af);
	*rmask = SUNION2PF(&pfr_mask, af);

	if (use_counter) {
		/* is supplied address within block? */
		if (!PF_MATCHA(0, *raddr, *rmask, counter, af)) {
			/* no, go to next block in table */
			idx++;
			use_counter = 0;
			goto _next_block;
		}
		PF_ACPY(addr, counter, af);
	} else {
		/* use first address of block */
		PF_ACPY(addr, *raddr, af);
	}

	if (!KENTRY_NETWORK(ke)) {
		/* this is a single IP address - no possible nested block */
		PF_ACPY(counter, addr, af);
		*pidx = idx;
		return (0);
	}
	for (;;) {
		/* we don't want to use a nested block */
                ke2 = (struct pfr_kentry *)(af == AF_INET ?
		    rn_match(&pfr_sin, kt->pfrkt_ip4) :
		    rn_match(&pfr_sin6, kt->pfrkt_ip6));
		/* no need to check KENTRY_RNF_ROOT() here */
		if (ke2 == ke) {
			/* lookup return the same block - perfect */
			PF_ACPY(counter, addr, af);
			*pidx = idx;
			return (0);
		}

		/* we need to increase the counter past the nested block */
		pfr_prepare_network(&mask, AF_INET, ke2->pfrke_net);
		PF_POOLMASK(addr, addr, SUNION2PF(&mask, af), &pfr_ffaddr, af);
		PF_AINC(addr, af);
		if (!PF_MATCHA(0, *raddr, *rmask, addr, af)) {
			/* ok, we reached the end of our main block */
			/* go to next block in table */
			idx++;
			use_counter = 0;
			goto _next_block;
		}
	}
}

struct pfr_kentry *
pfr_kentry_byidx(struct pfr_ktable *kt, int idx, int af)
{
	struct pfr_walktree	w;

        bzero(&w, sizeof(w));
        w.pfrw_op = PFRW_POOL_GET;
        w.pfrw_cnt = idx;

	switch(af) {
	case AF_INET:
		rn_walktree(kt->pfrkt_ip4, pfr_walktree, &w);
		return w.pfrw_kentry;
	case AF_INET6:
		rn_walktree(kt->pfrkt_ip6, pfr_walktree, &w);
		return w.pfrw_kentry;
	default:
		return NULL;
	}
}

void
pfr_dynaddr_update(struct pfr_ktable *kt, struct pfi_dynaddr *dyn)
{
	struct pfr_walktree	w;
	int 			s;

	bzero(&w, sizeof(w));
	w.pfrw_op = PFRW_DYNADDR_UPDATE;
	w.pfrw_dyn = dyn;

	s = splsoftnet();
	dyn->pfid_acnt4 = 0;
	dyn->pfid_acnt6 = 0;
	if (!dyn->pfid_af || dyn->pfid_af == AF_INET)
		rn_walktree(kt->pfrkt_ip4, pfr_walktree, &w);
	if (!dyn->pfid_af || dyn->pfid_af == AF_INET6)
		rn_walktree(kt->pfrkt_ip6, pfr_walktree, &w);
	splx(s);
@


1.31.4.4
log
@Merge with the trunk
@
text
@d84 2
a85 2
    (struct pf_addr *)&(su)->sin.sin_addr :	\
    (struct pf_addr *)&(su)->sin6.sin6_addr)
d130 1
a130 1
union sockaddr_union	 pfr_mask;
d177 1
a177 1
struct pfr_kentry	*pfr_kentry_byidx(struct pfr_ktable *, int, int);
d190 1
a190 1
	    "pfrktable", &pool_allocator_oldnointr);
d192 1
a192 1
	    "pfrkentry", &pool_allocator_oldnointr);
a668 1
#ifdef INET
a672 2
#endif /* INET */
#ifdef INET6
a676 1
#endif /* INET6 */
d739 1
a739 1
	} else if ( ad->pfra_af == AF_INET6 ) {
d772 1
a772 1
	else if (ad->pfra_af == AF_INET6)
d836 1
a836 1
	struct pfr_kentry	*p;
d838 2
a839 2
	SLIST_FOREACH(p, workq, pfrke_workq)
		pfr_unroute_kentry(kt, p);
d884 1
a884 1
	} else if (af == AF_INET6) {
d910 1
a910 1
	else if (ke->pfrke_af == AF_INET6)
d934 1
a934 1
	else if (ke->pfrke_af == AF_INET6)
d940 1
a940 1
		rn = rn_delete(&ke->pfrke_sa, &mask, head, NULL);
d942 1
a942 1
		rn = rn_delete(&ke->pfrke_sa, NULL, head, NULL);
d963 1
a963 1
	else if (ad->pfra_af == AF_INET6)
d981 1
a981 1
		/* FALLTHROUGH */
d1032 1
a1032 1
		} else if (ke->pfrke_af == AF_INET6){
a1040 1
		break;
d1114 1
d1377 1
a1377 1
	rs = pf_find_or_create_ruleset(trs->pfrt_anchor);
d1419 1
a1419 1
	rs = pf_find_ruleset(tbl->pfrt_anchor);
d1510 1
a1510 1
	rs = pf_find_ruleset(trs->pfrt_anchor);
d1543 1
a1543 1
	rs = pf_find_ruleset(trs->pfrt_anchor);
d1659 1
d1663 5
d1669 2
a1670 2
		rs = pf_find_ruleset(filter->pfrt_anchor);
		return ((rs != NULL) ? rs->tables : -1);
d1680 7
a1686 1
	if (strcmp(filter->pfrt_anchor, kt->pfrkt_anchor))
d1792 2
a1793 1
		rs = pf_find_or_create_ruleset(tbl->pfrt_anchor);
d1800 2
d1845 2
d1859 5
a1863 1
	return (strcmp(p->pfrkt_anchor, q->pfrkt_anchor));
d1870 1
a1870 2
	return (RB_FIND(pfr_ktablehead, &pfr_ktables,
	    (struct pfr_ktable *)tbl));
d1882 1
a1882 1
		return (0);
a1884 1
#ifdef INET
a1890 2
#endif /* INET */
#ifdef INET6
a1896 1
#endif /* INET6 */
a1917 1
#ifdef INET
a1923 2
#endif /* INET */
#ifdef INET6
a1929 3
#endif /* INET6 */
	default:
		;
d1953 1
a1953 1
	if (ac != NULL)
d1955 2
d1964 1
d1980 1
a1980 1
	return (kt);
d2002 2
a2003 4
	if (af == AF_INET)
		addr = (struct pf_addr *)&pfr_sin.sin_addr;
	else if (af == AF_INET6)
		addr = (struct pf_addr *)&pfr_sin6.sin6_addr;
d2046 3
a2048 6
		if (af == AF_INET)
			ke2 = (struct pfr_kentry *)rn_match(&pfr_sin,
			    kt->pfrkt_ip4);
		else if (af == AF_INET6)
			ke2 = (struct pfr_kentry *)rn_match(&pfr_sin6,
			    kt->pfrkt_ip6);
d2076 3
a2078 3
	bzero(&w, sizeof(w));
	w.pfrw_op = PFRW_POOL_GET;
	w.pfrw_cnt = idx;
d2080 1
a2080 2
	switch (af) {
#ifdef INET
d2083 1
a2083 3
		return (w.pfrw_kentry);
#endif /* INET */
#ifdef INET6
d2086 1
a2086 2
		return (w.pfrw_kentry);
#endif /* INET6 */
d2088 1
a2088 1
		return (NULL);
d2096 1
a2096 1
	int			s;
@


1.31.4.5
log
@sync to head
@
text
@d320 1
a320 1
	int			 i, rv, s, xdel = 0, log = 1;
d330 1
a330 28
	/*
	 * there are two algorithms to choose from here.
	 * with:
	 *   n: number of addresses to delete
	 *   N: number of addresses in the table
	 *
	 * one is O(N) and is better for large 'n'
	 * one is O(n*LOG(N)) and is better for small 'n'
	 * 
	 * following code try to decide which one is best.
	 */
	for (i = kt->pfrkt_cnt; i > 0; i >>= 1)
		log++;
	if (size > kt->pfrkt_cnt/log) {
		/* full table scan */
		pfr_mark_addrs(kt);
	} else {
		/* iterate over addresses to delete */
		for (i = 0; i < size; i++) {
			if (COPYIN(addr+i, &ad, sizeof(ad)))
				return (EFAULT);
			if (pfr_validate_addr(&ad))
				return (EINVAL);
			p = pfr_lookup_addr(kt, &ad, 1);
			if (p != NULL)
				p->pfrke_mark = 0;
		}
	}
@


1.31.4.6
log
@sync to HEAD
@
text
@d1733 1
a1733 1
	struct pfr_ktable	*p, *q;
d1735 1
a1735 2
	for (p = SLIST_FIRST(workq); p; p = q) {
		q = SLIST_NEXT(p, pfrkt_workq);
a1736 1
	}
@


1.30
log
@Correctly flag out radix_node entries with RNF_ROOT flag set: this is not
a match. Before that patch, an IP packet with source or dest address of
0.0.0.0 could corrupt the kernel. People filtering DHCP packets on their
firewall using tables should upgrade their kernel now.
Thanks to Chris Cappuccio for the good bug report.
Ok dhartmei@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.29 2003/03/13 17:56:16 cedric Exp $	*/
d200 1
a200 1
			printf("pfr_clr_addrs: corruption detected (%d).",
d528 1
a528 1
		printf("pfr_get_addrs: corruption detected (%d).",
d576 1
a576 1
		printf("pfr_get_astats: corruption detected (%d).",
d677 1
a677 1
			printf("pfr_enqueue_addrs: IPv4 walktree failed.");
d680 1
a680 1
			printf("pfr_enqueue_addrs: IPv6 walktree failed.");
d693 1
a693 1
		printf("pfr_mark_addrs: IPv4 walktree failed.");
d695 1
a695 1
		printf("pfr_mark_addrs: IPv6 walktree failed.");
d919 1
a919 1
		printf("pfr_unroute_kentry: delete failed\n");
d1134 1
a1134 1
		printf("pfr_get_tables: corruption detected (%d).", n);
d1176 1
a1176 1
		printf("pfr_get_tstats: corruption detected (%d).", n);
d1681 1
a1681 1
	if (ke == NULL || ke->pfrke_not != notrule) {
d1683 1
a1683 1
			printf("pfr_update_stats: assertion failed.");
d1688 1
a1688 1
	if (op_pass != PFR_OP_XPASS) {
d1718 1
a1718 1
		printf("pfr_detach_table: refcount = %d\n",
@


1.29
log
@Plug slow memory leak (radix_mask structure).
tested on i386 by me and Daniel on macppc.
ok dhartmei@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.28 2003/03/05 12:13:03 cedric Exp $	*/
d76 2
d720 2
d724 2
d1643 2
d1649 2
d1671 2
d1677 2
@


1.28
log
@Small fixes after code review, mostly on error path.
ok dhartmei@@ henning@@ pb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.27 2003/02/28 11:04:05 cedric Exp $	*/
d147 2
d262 1
d276 1
d428 1
d450 1
d799 10
d1349 1
d1427 1
d1602 1
@


1.27
log
@splsoftnet() around rn_lookup() which is not thread-safe.
ok dhartmei@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.26 2003/02/27 12:56:05 cedric Exp $	*/
d231 1
a231 1
			senderr(EFAULT);
d837 1
a837 1
		sa->sin6.sin6_family = AF_INET;
d1169 1
a1169 1
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC+PFR_FLAG_CLSTATS+PFR_FLAG_ADDRSTOO);
d1302 2
a1303 1
	if (shadow == NULL)
d1305 1
d1311 1
a1311 1
			senderr(EFAULT);
a1607 6

/*
 * Return 1 if the addresses a and b match (with mask m), otherwise return 0.
 * If n is 0, they match if they are equal. If n is != 0, they match if they
 * are different.
 */
@


1.26
log
@Repair IPv6 support for tables.
ok dhartmei@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.25 2003/02/12 20:10:08 henric Exp $	*/
d697 1
d709 1
d711 1
@


1.25
log
@Labels should be followed by statements (fix gcc3 warning).

ok cedric, jason, theo
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.24 2003/01/15 16:55:10 cedric Exp $	*/
d1621 1
a1621 1
		bcopy(&a, &pfr_sin6.sin6_addr, sizeof(pfr_sin6.sin6_addr));
d1645 1
a1645 1
		bcopy(&a, &pfr_sin6.sin6_addr, sizeof(pfr_sin6.sin6_addr));
@


1.24
log
@Fix another buglet with inactive sets.
table <foo> { 1.2.3.4 1.2.3.4 1.2.3.4 }
Was causing the kernel to become noisy.
Now duplicates are silently rejected.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.23 2003/01/15 16:28:56 cedric Exp $	*/
d1033 1
d1076 1
d1228 1
@


1.23
log
@Fix a buglet when one "creates" a table which is already in the
referenced or inactive set. Flags were not updated correctly.
Tested on i386, sparc64. More regression tests coming.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.22 2003/01/15 10:42:48 cedric Exp $	*/
d1309 4
a1315 2
	if (!(flags & PFR_FLAG_ADDRSTOO))
		shadow->pfrkt_cnt = NO_ADDRESSES;
d1321 2
a1323 1
		pfr_insert_kentries(shadow, &addrq, 0);
@


1.22
log
@Cleanup NULL tests in and around pfr_destroy_ktable().
Makes code more readable.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.21 2003/01/15 09:42:52 cedric Exp $	*/
d136 2
a137 3
void			 pfr_setflags_ktables(struct pfr_ktableworkq *, int,
			    int);
void			 pfr_setflags_ktable(struct pfr_ktable *, int, int);
d979 1
d986 1
a986 1
		pfr_setflags_ktables(&workq, 0, PFR_TFLAG_ACTIVE);
d1027 2
d1038 1
a1038 1
		pfr_setflags_ktables(&changeq, PFR_TFLAG_ACTIVE, 0);
d1070 1
d1080 1
a1080 1
		pfr_setflags_ktables(&workq, 0, PFR_TFLAG_ACTIVE);
d1210 3
a1212 2
			if (((p->pfrkt_flags & setflag) == setflag) &&
			    !(p->pfrkt_flags & clrflag))
d1230 1
a1230 1
		pfr_setflags_ktables(&workq, setflag, clrflag);
d1253 1
d1258 1
a1258 1
		pfr_setflags_ktables(&workq, 0, PFR_TFLAG_INACTIVE);
d1382 1
a1382 1
	int			 setflag, clrflag;
d1428 3
a1430 4
	setflag = shadow->pfrkt_flags & PFR_TFLAG_USRMASK;
	clrflag = (kt->pfrkt_flags & ~setflag) & PFR_TFLAG_USRMASK;
	setflag |= PFR_TFLAG_ACTIVE;
	clrflag |= PFR_TFLAG_INACTIVE;
d1433 1
a1433 1
	pfr_setflags_ktable(kt, setflag, clrflag);
d1470 1
a1470 1
pfr_setflags_ktables(struct pfr_ktableworkq *workq, int setflag, int clrflag)
d1475 1
a1475 1
		pfr_setflags_ktable(p, setflag, clrflag);
d1479 1
a1479 1
pfr_setflags_ktable(struct pfr_ktable *kt, int setflag, int clrflag)
a1481 2
	int			oldf = kt->pfrkt_flags;
	int			newf = (oldf | setflag) & ~clrflag;
d1672 1
a1672 1
		pfr_setflags_ktable(kt, PFR_TFLAG_REFERENCED, 0);
d1683 1
a1683 1
		pfr_setflags_ktable(kt, 0, PFR_TFLAG_REFERENCED);
@


1.21
log
@Kill stupid leaks when using FLAG_DUMMY option.
Removes "_" from pool names.
Regression tests for memory allocation coming soon....
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.20 2003/01/13 07:57:47 cedric Exp $	*/
d271 1
a271 2
	if (tmpkt != NULL)
		pfr_destroy_ktable(tmpkt, 0);
d277 1
a277 2
	if (tmpkt != NULL)
		pfr_destroy_ktable(tmpkt, 0);
d443 1
a443 2
	if (tmpkt != NULL)
		pfr_destroy_ktable(tmpkt, 0);
d449 1
a449 2
	if (tmpkt != NULL)
		pfr_destroy_ktable(tmpkt, 0);
d1310 2
a1311 1
		pfr_destroy_ktable(kt->pfrkt_shadow, 1);
d1427 1
a1427 1
	pfr_destroy_ktable(kt->pfrkt_shadow, 0);
a1568 2
	if (kt == NULL)
		return;
d1577 2
a1578 1
	pfr_destroy_ktable(kt->pfrkt_shadow, flushaddr);
@


1.20
log
@Improve robustness & error handling. More thorough checks of user data.
- Reject invalid CIDR networks (1.2.3.4/16 & friends).
- Only allow values 0 or 1 for the "neg" flag.
- Require all unused data to be set to 0 in pfr_addr and pfr_table.
- Always check the return value of pfr_route_entry().
- Remove redundant kernel messages.
Tested on i386, sparc64. Pass my (uncommited) regression tests.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.19 2003/01/10 16:09:19 cedric Exp $	*/
d161 1
a161 1
	    "pfr_ktable", NULL);
d163 1
a163 1
	    "pfr_kentry", NULL);
d267 2
a268 1
	}
d435 2
a436 1
	}
@


1.19
log
@Fix adding and deleting addresses in a table when there is a conflict with
the "negated" attribute of an address. The previous behaviour was incorrect
in both cases (too strict for the add command and too permissive for the
delete command).
ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.18 2003/01/10 13:21:35 cedric Exp $	*/
d118 1
d132 1
d181 2
d217 2
a243 2
			if (copyout(&ad, addr+i, sizeof(ad)))
				senderr(EFAULT);
d245 1
a245 3
		if (q != NULL)
			continue;
		if (p == NULL) {
d249 7
a255 3
			SLIST_INSERT_HEAD(&workq, p, pfrke_workq);
			pfr_route_kentry(tmpkt, p);
			xadd++;
d257 3
d293 2
a316 2
			if (copyout(&ad, addr+i, sizeof(ad)))
				senderr(EFAULT);
d318 2
a319 3
		if (p != NULL && p->pfrke_not == ad.pfra_not) {
			if (p->pfrke_mark)
				continue;
d324 3
d356 2
d375 1
d387 1
a387 2
			} else
				ad.pfra_fback = PFR_FB_NONE;
d397 8
a404 4
			SLIST_INSERT_HEAD(&addq, p, pfrke_workq);
			pfr_route_kentry(tmpkt, p);
			ad.pfra_fback = PFR_FB_ADDED;
			xadd++;
d465 2
d502 2
d542 2
d590 2
d633 2
d637 1
a637 1
		if (ad->pfra_af > 32)
d639 1
a639 1
		return (0);
d641 1
a641 1
		if (ad->pfra_af > 128)
d643 1
a643 1
		return (0);
d647 11
d747 1
a747 1
		pool_put(&pfr_kentry_pl, p);
d752 6
d872 1
a872 5
	if (rn == NULL) {
		printf("pfr_route_kentry: no memory for mask\n");
		return (-1);
	}
	return (0);
d1011 1
a1011 1
		if (key.pfrkt_name[PF_TABLE_NAME_SIZE-1])
a1013 2
		if (key.pfrkt_flags & ~(PFR_TFLAG_USRMASK+PFR_TFLAG_ACTIVE))
			senderr(EINVAL);
d1063 2
d1168 2
d1205 2
d1279 2
a1281 2
	if (tbl->pfrt_flags & ~(PFR_TFLAG_USRMASK+PFR_TFLAG_INACTIVE))
		return (EINVAL);
d1431 17
@


1.18
log
@Cosmetic change, makes code a bit easier to understand.
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.17 2003/01/09 15:58:35 dhartmei Exp $	*/
d230 8
a237 2
			ad.pfra_fback = (q != NULL) ? PFR_FB_DUPLICATE :
			    ((p == NULL) ? PFR_FB_ADDED : PFR_FB_NONE);
d250 1
a250 2
		} else if (p->pfrke_not != ad.pfra_not)
			senderr(EEXIST);
d298 8
a305 3
			ad.pfra_fback = (p == NULL) ? PFR_FB_NONE :
			    (p->pfrke_mark ? PFR_FB_DUPLICATE :
			    PFR_FB_DELETED);
d309 1
a309 1
		if (p != NULL) {
@


1.17
log
@(whitespace) KNF, re-fold -w 80
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.16 2003/01/09 10:40:44 cedric Exp $	*/
d76 1
d78 2
d384 1
a384 1
	pfr_enqueue_addrs(kt, &delq, &xdel, 1);
d404 1
a404 1
		pfr_clstats_kentries(&changeq, tzero, 1);
d1356 1
a1356 1
		pfr_enqueue_addrs(kt, &delq, NULL, 1);
d1359 1
a1359 1
		pfr_clstats_kentries(&changeq, tzero, 1);
@


1.16
log
@Add support for active/inactive tablesets in the kernel.
Add table definition/initialisation construct in pfctl parser.
Add and fix documentation for pf.4 and pf.conf.5.
Tested on i386 and sparc64 by myself, macppc by Daniel.
ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.15 2003/01/07 00:21:07 dhartmei Exp $	*/
d48 1
a48 1
		   PFR_FLAG_ALLMASK)		\
d632 1
a632 1
	struct pfr_walktree     w;
d1212 1
a1212 1
	struct pfr_ktable       *kt, *shadow;
d1280 1
a1280 1
	struct pfr_ktable       *p;
@


1.15
log
@Remove table name hashing (pass the name in each ioctl instead), and
introduce reference counting for tables, they are now automatically
created and deleted through referencing rules. Diff partly from cedric@@.
ok mcbride@@, henning@@, cedric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.14 2003/01/06 14:19:40 cedric Exp $	*/
d66 7
d76 1
d105 2
d108 3
a110 2
int			 pfr_enqueue_addrs(struct pfr_ktable *,
			    struct pfr_kentryworkq *, int *);
d113 1
a113 2
struct pfr_kentry	*pfr_create_kentry(struct pfr_addr *, long);
void			 pfr_destroy_kentry(struct pfr_kentry *);
d116 1
a116 1
			    struct pfr_kentryworkq *);
d119 2
a120 1
void			 pfr_clstats_kentries(struct pfr_kentryworkq *, long);
a126 2
void			 pfr_copyout_addr(struct pfr_addr *,
			    struct pfr_kentry *);
d128 1
d130 4
a133 1
void			 pfr_remove_ktables(struct pfr_ktableworkq *);
d136 1
d138 2
a139 2
void			 pfr_destroy_ktable(struct pfr_ktable *);
void			 pfr_destroy_ktables(struct pfr_ktableworkq *);
d150 1
d164 2
d173 1
a173 1
	int			 s, rv;
d179 3
a181 3
	rv = pfr_enqueue_addrs(kt, &workq, ndel);
	if (rv)
		return rv;
d190 2
a191 1
			printf("pfr_clr_addrs: corruption detected.");
d213 2
d235 1
a235 1
			p = pfr_create_kentry(&ad, tzero);
d247 1
a247 1
		pfr_insert_kentries(kt, &workq);
d253 2
d261 1
a261 1
		pfr_destroy_ktable(tmpkt);
a270 1
	struct pfr_walktree	 w;
d279 3
a281 9

	bzero(&w, sizeof(w));
	w.pfrw_op = PFRW_MARK;
	rv = rn_walktree(kt->pfrkt_ip4, pfr_walktree, &w);
	if (!rv)
		rv = rn_walktree(kt->pfrkt_ip6, pfr_walktree, &w);
	if (rv)
		return (rv);

a325 1
	struct pfr_walktree	 w;
d335 2
d340 1
a340 9

	bzero(&w, sizeof(w));
	w.pfrw_op = PFRW_MARK;
	rv = rn_walktree(kt->pfrkt_ip4, pfr_walktree, &w);
	if (!rv)
		rv = rn_walktree(kt->pfrkt_ip6, pfr_walktree, &w);
	if (rv)
		return (rv);

d368 1
a368 1
			p = pfr_create_kentry(&ad, tzero);
d381 1
a381 8
	w.pfrw_op = PFRW_SWEEP;
	w.pfrw_workq = &delq;
	rv = rn_walktree(kt->pfrkt_ip4, pfr_walktree, &w);
	if (!rv)
		rv = rn_walktree(kt->pfrkt_ip6, pfr_walktree, &w);
	if (rv)
		senderr(rv);
	xdel = w.pfrw_cnt;
d399 1
a399 1
		pfr_insert_kentries(kt, &addq);
d401 1
a401 3
		SLIST_FOREACH(p, &changeq, pfrke_workq)
			p->pfrke_not ^= 1;
		pfr_clstats_kentries(&changeq, time.tv_sec);
d413 2
d421 1
a421 1
		pfr_destroy_ktable(tmpkt);
d489 2
a490 1
		printf("pfr_get_addrs: corruption detected.");
d526 2
a527 4
		rv = pfr_enqueue_addrs(kt, &workq, NULL);
		if (rv)
			return rv;
		pfr_clstats_kentries(&workq, tzero);
d535 2
a536 1
		printf("pfr_get_astats: corruption detected.");
d579 1
a579 1
		pfr_clstats_kentries(&workq, 0);
a591 1

d609 1
a609 1
int
d611 1
a611 1
	int *naddr)
a613 1
	int			rv;
d617 1
a617 1
	w.pfrw_op = PFRW_ENQUEUE;
d619 6
a624 6
	rv = rn_walktree(kt->pfrkt_ip4, pfr_walktree, &w);
	if (rv)
		return (rv);
	rv = rn_walktree(kt->pfrkt_ip6, pfr_walktree, &w);
	if (rv)
		return (rv);
a626 1
	return (0);
d629 14
d670 1
a670 1
pfr_create_kentry(struct pfr_addr *ad, long tzero)
a685 1
	ke->pfrke_tzero = tzero;
a689 7
pfr_destroy_kentry(struct pfr_kentry *ke)
{
	if (ke != NULL)
		pool_put(&pfr_kentry_pl, ke);
}

void
d696 1
a696 1
		pfr_destroy_kentry(p);
d702 1
a702 1
    struct pfr_kentryworkq *workq)
d714 1
d736 1
a736 1
pfr_clstats_kentries(struct pfr_kentryworkq *workq, long tzero)
d743 2
a916 1

d927 2
a931 1

d935 1
a935 1
		pfr_remove_ktables(&workq);
d947 1
a947 1
	struct pfr_ktableworkq	 workq, changeq;
d953 1
a953 1
	SLIST_INIT(&workq);
d960 3
a962 1
		key.pfrkt_flags = PFR_TFLAG_ACTIVE+PFR_TFLAG_PERSIST;
d968 1
a968 1
			SLIST_FOREACH(q, &workq, pfrkt_workq) {
d972 1
a972 1
			SLIST_INSERT_HEAD(&workq, p, pfrkt_workq);
d974 4
a977 1
		} else if (!(p->pfrkt_flags & PFR_TFLAG_PERSIST)) {
d979 1
d986 2
a987 3
		pfr_insert_ktables(&workq);
		SLIST_FOREACH(p, &changeq, pfrkt_workq)
			p->pfrkt_flags |= PFR_TFLAG_PERSIST;
d991 1
a991 1
		 pfr_destroy_ktables(&workq);
d996 1
a996 1
	pfr_destroy_ktables(&workq);
d1003 1
a1003 1
	struct pfr_ktableworkq	 workq, changeq;
a1008 1
	SLIST_INIT(&changeq);
d1013 2
a1014 5
		if (p != NULL) {
                        struct pfr_ktableworkq *queue;

                        queue = (p->pfrkt_refcnt > 0) ? &changeq : &workq;
			SLIST_FOREACH(q, queue, pfrkt_workq)
d1017 2
a1018 3
			SLIST_INSERT_HEAD(queue, p, pfrkt_workq);
			if (queue == &workq)
				xdel++;
d1026 1
a1026 3
		pfr_remove_ktables(&workq);
		SLIST_FOREACH(p, &changeq, pfrkt_workq)
			p->pfrkt_flags &= ~PFR_TFLAG_PERSIST;
d1053 1
a1053 1
		printf("pfr_get_tables: corruption detected.");
d1091 1
a1091 1
		    flags & PFR_FLAG_RECURSE);
d1095 1
a1095 1
		printf("pfr_get_tstats: corruption detected.");
d1110 1
a1110 1
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC+PFR_FLAG_CLSTATS+PFR_FLAG_RECURSE);
a1120 1

d1124 1
a1124 1
		pfr_clstats_ktables(&workq, tzero, flags & PFR_FLAG_RECURSE);
d1133 243
a1379 1
	int			 n = 0;
d1381 9
a1389 6
	/* insert into tree */
	SLIST_FOREACH(p, workq, pfrkt_workq) {
		RB_INSERT(pfr_ktablehead, &pfr_ktables, p);
		n++;
	}
	pfr_ktable_cnt += n;
d1393 1
a1393 1
pfr_remove_ktables(struct pfr_ktableworkq *workq)
a1394 1
	struct pfr_kentryworkq	 addrq;
a1395 1
	int			 n = 0;
d1397 29
a1425 6
	SLIST_FOREACH(p, workq, pfrkt_workq) {
		RB_REMOVE(pfr_ktablehead, &pfr_ktables, p);
		if (pfr_enqueue_addrs(p, &addrq, NULL))
			printf("pfr_remove_ktables: enqueue failed");
		pfr_destroy_kentries(&addrq);
		n++;
d1427 1
a1427 2
	pfr_ktable_cnt -= n;
	pfr_destroy_ktables(workq);
d1433 9
a1442 1
	struct pfr_ktable	*p;
d1445 3
a1447 12
	SLIST_FOREACH(p, workq, pfrkt_workq) {
		if (recurse) {
			if (pfr_enqueue_addrs(p, &addrq, NULL))
				printf("pfr_clr_tstats: enqueue failed");
			pfr_clstats_kentries(&addrq, tzero);
		}
		s = splsoftnet();
		bzero(p->pfrkt_packets, sizeof(p->pfrkt_packets));
		bzero(p->pfrkt_bytes, sizeof(p->pfrkt_bytes));
		p->pfrkt_match = p->pfrkt_nomatch = 0;
		splx(s);
		p->pfrkt_tzero = tzero;
d1449 6
d1472 1
a1472 1
		pfr_destroy_ktable(kt);
d1481 12
a1492 1
pfr_destroy_ktable(struct pfr_ktable *kt)
d1494 2
d1498 4
d1506 1
a1509 11
void
pfr_destroy_ktables(struct pfr_ktableworkq *workq)
{
	struct pfr_ktable	*p, *q;

	for (p = SLIST_FIRST(workq); p; p = q) {
		q = SLIST_NEXT(p, pfrkt_workq);
		pfr_destroy_ktable(p);
	}
}

d1585 2
a1586 2
	struct pfr_ktable *p, key;
	struct pfr_ktableworkq workq;
d1588 6
a1593 7
	bzero(&key, sizeof(key));
	strlcpy(key.pfrkt_name, name, sizeof(key.pfrkt_name));
	key.pfrkt_flags = PFR_TFLAG_ACTIVE;
	p = RB_FIND(pfr_ktablehead, &pfr_ktables, &key);
	if (p == NULL) {
		p = pfr_create_ktable(&key.pfrkt_t, time.tv_sec);
		if (p == NULL)
d1595 1
a1595 3
		SLIST_INIT(&workq);
		SLIST_INSERT_HEAD(&workq, p, pfrkt_workq);
		pfr_insert_ktables(&workq);
d1597 3
a1599 2
	p->pfrkt_refcnt++;
	return p;
a1604 2
	struct pfr_ktableworkq workq;

d1606 1
a1606 1
		printf("pfr_detach_table, refcount = %d\n",
d1608 2
a1609 10
	else {
		kt->pfrkt_refcnt--;
		if (kt->pfrkt_refcnt == 0 &&
		    !(kt->pfrkt_flags & PFR_TFLAG_PERSIST)) {
			kt->pfrkt_flags &= ~PFR_TFLAG_ACTIVE;
			SLIST_INIT(&workq);
			SLIST_INSERT_HEAD(&workq, kt, pfrkt_workq);
			pfr_remove_ktables(&workq);
		}
	}
@


1.14
log
@Move initialisation of radix table globals in pfr_initialize()
ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.13 2003/01/06 10:08:36 deraadt Exp $	*/
a44 2
#include <crypto/sha1.h>

a89 3
#define	PFR_HASH_BUCKETS	1024
#define	PFR_HASH_BUCKET(hash)	((hash).pfrh_int32[1] & (PFR_HASH_BUCKETS-1))

a127 1
struct pfr_ktable	*pfr_lookup_hash(union pfr_hash *);
a128 5
int			 pfr_match_addr(struct pf_addr *, struct pf_addr *,
			    struct pf_addr *, sa_family_t);
void			 pfr_update_stats(struct pf_addr *, struct pf_addr *,
			    struct pf_addr *, sa_family_t, u_int64_t, int, int,
			    int);
a132 1
struct pfr_ktablehashq	 pfr_ktablehash[PFR_HASH_BUCKETS];
d160 1
a160 1
	if (kt == NULL)
d193 1
a193 1
	if (kt == NULL)
d256 1
a256 1
	if (kt == NULL)
d319 1
a319 1
	if (kt == NULL)
d435 1
a435 1
	if (kt == NULL)
d470 1
a470 1
	if (kt == NULL)
d507 1
a507 1
	if (kt == NULL)
d554 1
a554 1
	if (kt == NULL)
d940 1
a940 1
	struct pfr_ktableworkq	 workq;
d947 1
d953 1
a961 6
				if (!memcmp(&p->pfrkt_hash, &q->pfrkt_hash,
				    sizeof(p->pfrkt_hash))) {
					printf("pfr_add_tables: "
					    "sha collision\n");
					senderr(EEXIST);
				}
a963 4
			if (pfr_lookup_hash(&p->pfrkt_hash)) {
				printf("pfr_add_tables: sha collision\n");
				senderr(EEXIST);
			}
d965 2
d974 2
d991 1
a991 1
	struct pfr_ktableworkq	 workq;
d997 1
d1003 4
a1006 1
			SLIST_FOREACH(q, &workq, pfrkt_workq)
d1009 3
a1011 2
			SLIST_INSERT_HEAD(&workq, p, pfrkt_workq);
			xdel++;
d1020 2
a1128 51
int
pfr_wrap_table(struct pfr_table *tbl, struct pf_addr_wrap *wrap,
    int *exists, int flags)
{
	union pfr_hash		hash;
	struct pf_addr_wrap	w;
	SHA1_CTX		sha1;

	ACCEPT_FLAGS(0);
	if (!*tbl->pfrt_name || tbl->pfrt_name[PF_TABLE_NAME_SIZE-1])
		return (EINVAL);
	SHA1Init(&sha1);
	SHA1Update(&sha1, tbl->pfrt_name, strlen(tbl->pfrt_name));
	SHA1Final(hash.pfrh_sha1, &sha1);

	bzero(&w, sizeof(w));
	bcopy(&hash, &w.v.a.addr, sizeof(w.v.a.addr));
	w.v.a.mask.addr32[0] = PF_TABLE_MASK;
	w.v.a.mask.addr32[1] = hash.pfrh_int32[4];
	if (copyout(&w, wrap, sizeof(*wrap)))
		return (EFAULT);

	if (exists != NULL)
		*exists = pfr_lookup_table(tbl) != NULL;
	return (0);
}

int
pfr_unwrap_table(struct pfr_table *tbl, struct pf_addr_wrap *wrap, int flags)
{
	union pfr_hash		 hash;
	struct pf_addr_wrap	 w;
	struct pfr_ktable	*kt;

	ACCEPT_FLAGS(0);
	if (copyin(wrap, &w, sizeof(w)))
		return (EFAULT);

	if (w.v.a.mask.addr32[0] != PF_TABLE_MASK || w.v.a.mask.addr32[2] ||
	    w.v.a.mask.addr32[3])
		return (EINVAL);

	bcopy(&w.v.a.addr, &hash, 16);
	hash.pfrh_int32[4] = w.v.a.mask.addr32[1];
	kt = pfr_lookup_hash(&hash);
	if (kt == NULL)
		return (ENOENT);
	*tbl = kt->pfrkt_t;
	return (0);
}

d1133 1
a1133 1
	int			 s, n = 0;
a1140 8

	SLIST_FOREACH(p, workq, pfrkt_workq) {
		s = splsoftnet();
		SLIST_INSERT_HEAD(pfr_ktablehash +
		    PFR_HASH_BUCKET(p->pfrkt_hash),
		    p, pfrkt_hashq);
		splx(s);
	}
d1148 1
a1148 8
	int			 s, n = 0;

	SLIST_FOREACH(p, workq, pfrkt_workq) {
		s = splsoftnet();
		SLIST_REMOVE(pfr_ktablehash + PFR_HASH_BUCKET(p->pfrkt_hash),
		    p, pfr_ktable, pfrkt_hashq);
		splx(s);
	}
a1186 1
	SHA1_CTX		 sha1;
a1193 5
	/* compute secure hash */
	SHA1Init(&sha1);
	SHA1Update(&sha1, kt->pfrkt_name, strlen(kt->pfrkt_name));
	SHA1Final(kt->pfrkt_hash.pfrh_sha1, &sha1);

a1235 11
pfr_lookup_hash(union pfr_hash *hash)
{
	struct pfr_ktable	*p;

	SLIST_FOREACH(p, pfr_ktablehash+PFR_HASH_BUCKET(*hash), pfrkt_hashq)
		if (!memcmp(p->pfrkt_hash.pfrh_sha1, hash->pfrh_sha1, 20))
			return (p);
	return (NULL);
}

struct pfr_ktable *
d1249 1
a1249 2
pfr_match_addr(struct pf_addr *a, struct pf_addr *m,
    struct pf_addr *b, sa_family_t af)
a1250 2
	union pfr_hash		 hash;
	struct pfr_ktable	*kt;
a1253 5
	bcopy(a, &hash, 16);
	hash.pfrh_int32[4] = m->addr32[1];
	kt = pfr_lookup_hash(&hash);
	if (kt == NULL)
		return (0);
d1256 1
a1256 1
		pfr_sin.sin_addr.s_addr = b->addr32[0];
d1260 1
a1260 1
		bcopy(&b, &pfr_sin6.sin6_addr, sizeof(pfr_sin6.sin6_addr));
d1273 2
a1274 3
pfr_update_stats(struct pf_addr *a, struct pf_addr *m,
    struct pf_addr *b, sa_family_t af, u_int64_t len,
    int dir_out, int op_pass, int notrule)
a1275 2
	union pfr_hash		 hash;
	struct pfr_ktable	*kt;
a1277 6
	bcopy(a, &hash, 16);
	hash.pfrh_int32[4] = m->addr32[1];
	kt = pfr_lookup_hash(&hash);
	if (kt == NULL)
		return;

d1280 1
a1280 1
		pfr_sin.sin_addr.s_addr = b->addr32[0];
d1284 1
a1284 1
		bcopy(&b, &pfr_sin6.sin6_addr, sizeof(pfr_sin6.sin6_addr));
d1298 42
@


1.13
log
@knf
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.12 2003/01/05 22:14:23 dhartmei Exp $	*/
d99 2
a100 2
struct sockaddr_in	 pfr_sin = { sizeof(pfr_sin), AF_INET };
struct sockaddr_in6	 pfr_sin6 = { sizeof(pfr_sin6), AF_INET6 };
d148 14
@


1.12
log
@Move ifname from pf_addr to pf_addr_wrap, prepare pf_addr_wrap for table
name. ok henning@@, mcbride@@, cedric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.11 2003/01/03 19:31:43 deraadt Exp $	*/
d52 1
a52 1
	} while(0)
d95 1
a95 1
#define senderr(e)	do { rv = (e); goto _bad; } while(0)
d206 1
a206 1
				((p == NULL) ? PFR_FB_ADDED : PFR_FB_NONE);
d274 2
a275 2
				(p->pfrke_mark ? PFR_FB_DUPLICATE :
					PFR_FB_DELETED);
d447 1
a447 1
			(p->pfrke_not ? PFR_FB_NOTMATCH : PFR_FB_MATCH);
d563 1
a563 1
				PFR_FB_CLEARED : PFR_FB_NONE;
d705 1
a705 1
				"(code=%d).\n", rv);
d775 1
a775 1
					htonl(-1 << (32-net));
d893 1
a893 1
				sizeof(as.pfras_packets));
d895 1
a895 1
				sizeof(as.pfras_bytes));
d945 1
a945 1
	for(i = 0; i < size; i++) {
d959 1
a959 2
					sizeof(p->pfrkt_hash)))
				{
d961 1
a961 1
						"sha collision\n");
d967 1
a967 2
				printf(
				    "pfr_add_tables: sha collision\n");
d999 1
a999 1
	for(i = 0; i < size; i++) {
d1102 1
a1102 1
	for(i = 0; i < size; i++) {
d1290 1
a1290 1
	for(p = SLIST_FIRST(workq); p; p = q) {
@


1.11
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: pf_table.c,v 1.10 2003/01/03 10:39:09 cedric Exp $	*/
d1142 3
a1144 3
	bcopy(&hash, &w.addr, sizeof(w.addr));
	w.mask.addr32[0] = PF_TABLE_MASK;
	w.mask.addr32[1] = hash.pfrh_int32[4];
d1164 2
a1165 2
	if (w.mask.addr32[0] != PF_TABLE_MASK || w.mask.addr32[2] ||
	    w.mask.addr32[3])
d1168 2
a1169 2
	bcopy(&w.addr, &hash, 16);
	hash.pfrh_int32[4] = w.mask.addr32[1];
@


1.10
log
@1) pfr_insert_kentries() cannot return ENOMEM anymore -> make it void.
2) add new PFR_FLAG_REPLACE for use by pfr_tst_addrs().
3) add new pfrio_nmatch alias to pfioc_table, set by pfr_tst_addrs().
Tested on i386, sparc64
@
text
@d1 1
a1 1
/*      $OpenBSD: pf_table.c,v 1.9 2003/01/01 22:07:57 cedric Exp $ */
d247 1
a247 1
	struct pfr_walktree      w;
d278 1
a278 1
                }
d566 1
a566 1
                }
d750 2
a751 5
        for (i = 0; i < size; i++) {
                if (copyin(addr+i, &ad, sizeof(ad)))
                        break;
                ad.pfra_fback = PFR_FB_NONE;
                if (copyout(&ad, addr+i, sizeof(ad)))
d753 4
a756 1
        }
d1123 1
a1123 1
        return (0);
d1264 1
a1264 1
	    8 * offsetof(struct sockaddr_in, sin_addr)) ||
d1266 1
a1266 1
	    8 * offsetof(struct sockaddr_in6, sin6_addr))) {
@


1.9
log
@Repair my last commit - zero the 2 radix nodes before inserting into table.
@
text
@d1 1
a1 1
/*      $OpenBSD: pf_table.c,v 1.8 2003/01/01 16:08:52 henning Exp $ */
d110 1
a110 1
int			 pfr_insert_kentries(struct pfr_ktable *,
d225 1
a225 4
		if (pfr_insert_kentries(kt, &workq)) {
			splx(s);
			senderr(ENOMEM);
		}
d396 1
a396 5
		if (pfr_insert_kentries(kt, &addq)) {
			if (flags & PFR_FLAG_ATOMIC)
				splx(s);
			senderr(ENOMEM);
		}
d424 1
a424 1
	int flags)
d429 1
a429 1
	int			 i;
d431 1
a431 1
	ACCEPT_FLAGS(0);
d444 6
a449 2
		ad.pfra_fback = (p != NULL && !p->pfrke_not) ?
			PFR_FB_MATCH : PFR_FB_NONE;
d453 2
d694 1
a694 1
int
d698 2
a699 2
	struct pfr_kentry	*p, *q;
	int			 n = 0;
d702 5
a706 8
		if (pfr_route_kentry(kt, p)) {
			/* bad luck - no memory for netmask */
			SLIST_FOREACH(q, workq, pfrke_workq) {
				if (q == p)
					break;
				pfr_unroute_kentry(kt, q);
			}
			return (-1);
a710 1
	return (0);
d845 2
@


1.8
log
@KNF
@
text
@d1 1
a1 1
/*      $OpenBSD: pf_table.c,v 1.7 2003/01/01 15:26:17 cedric Exp $ */
d797 1
@


1.7
log
@disable the CLSTATS flag for now, since it violates the O_RDONLY check.
@
text
@d1 1
a1 1
/*      $OpenBSD: pf_table.c,v 1.6 2003/01/01 14:16:56 cedric Exp $ */
d277 1
a277 1
			    	(p->pfrke_mark ? PFR_FB_DUPLICATE :
d285 1
a285 1
			p->pfrke_mark = 1;				
@


1.6
log
@Behaves correctly when duplicate addresses are given in the same ioctl.
(i.e: pfradix -a test 1.2.3.4 1.2.3.4). The ioctl can also report theses
duplicate to the caller using the new PFR_FB_DUPLICATE feedback tag.
@
text
@d1 1
a1 1
/*      $OpenBSD: pf_table.c,v 1.5 2003/01/01 13:23:17 cedric Exp $ */
d504 1
a504 1
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC+PFR_FLAG_CLSTATS);
d1062 1
a1062 1
	ACCEPT_FLAGS(PFR_FLAG_ATOMIC+PFR_FLAG_CLSTATS+PFR_FLAG_RECURSE);
@


1.5
log
@Behaves properly when someone try to insert/delete the same table name
multiple time in the same ioctl (i.e. pfradix -A/D test test test).
This is not a very efficient implementation, and I'll change it if someone
really add/delete more than hundred of tables in the same ioctl.
@
text
@d1 1
a1 1
/*      $OpenBSD: pf_table.c,v 1.4 2002/12/30 15:39:18 cedric Exp $ */
d146 1
a148 1

d182 1
a182 1
	struct pfr_ktable	*kt;
d184 1
a184 1
	struct pfr_kentry	*p;
d193 3
d203 1
d205 2
a206 2
			ad.pfra_fback = (p == NULL) ?
				PFR_FB_ADDED : PFR_FB_NONE;
d210 2
d213 5
a217 6
			if (!(flags & PFR_FLAG_DUMMY)) {
				p = pfr_create_kentry(&ad, tzero);
				if (p == NULL)
					senderr(ENOMEM);
				SLIST_INSERT_HEAD(&workq, p, pfrke_workq);
			}
d239 2
d250 1
d259 9
d276 3
a278 2
			ad.pfra_fback = (p != NULL) ?
				PFR_FB_DELETED : PFR_FB_NONE;
d283 3
d310 1
a310 1
	struct pfr_ktable	*kt;
d313 1
a313 1
	struct pfr_kentry	*p;
d322 3
d344 4
d356 4
a359 5
			if (!(flags & PFR_FLAG_DUMMY)) {
				p = pfr_create_kentry(&ad, tzero);
				if (p == NULL)
					senderr(ENOMEM);
				SLIST_INSERT_HEAD(&addq, p, pfrke_workq);
d361 5
d369 1
d424 2
@


1.4
log
@Don't forget to copyout the time at which statistics got cleared.
@
text
@d1 1
a1 1
/*      $OpenBSD: pf_table.c,v 1.3 2002/12/30 13:34:55 cedric Exp $ */
d906 2
a907 2
	struct pfr_ktable	*p, key;
	int			 i, s, xadd = 0;
d913 2
a914 4
		if (copyin(tbl+i, &key.pfrkt_t, sizeof(key.pfrkt_t))) {
			pfr_destroy_ktables(&workq);
			return (EFAULT);
		}
d916 1
a916 1
			return (EINVAL);
d919 12
a930 13
			if (!(flags & PFR_FLAG_DUMMY)) {
				p = pfr_create_ktable(&key.pfrkt_t, tzero);
				if (p == NULL) {
					pfr_destroy_ktables(&workq);
					return (ENOMEM);
				}
				SLIST_INSERT_HEAD(&workq, p, pfrkt_workq);
				/* XXX move the following out of the if */
				if (pfr_lookup_hash(&p->pfrkt_hash)) {
					printf(
					    "pfr_add_tables: sha collision\n");
					pfr_destroy_ktables(&workq);
					return (EEXIST);
d932 6
d941 1
d949 2
a950 1
	}
d954 3
d963 1
a963 1
	struct pfr_ktable	*p, key;
d973 3
d979 1
@


1.3
log
@really count the number of deleted tables - obvious fix.
@
text
@d1 1
a1 1
/*      $OpenBSD: pf_table.c,v 1.2 2002/12/30 02:37:27 henning Exp $ */
d864 1
@


1.2
log
@KNF
@
text
@d1 1
a1 1
/*      $OpenBSD: pf_table.c,v 1.1 2002/12/29 20:07:34 cedric Exp $ */
d884 1
a884 1
	RB_FOREACH(p, pfr_ktablehead, &pfr_ktables)
d886 2
@


1.1
log
@Add support for radix tables for source and destination of PF rules.
ok dhartmei@@, mcbride@@, henning@@
@
text
@d1 1
a1 1
/*      $OpenBSD: pf_table.c,v 1.287 2002/12/27 21:43:58 mcbride Exp $ */
d152 3
a154 3
	struct pfr_ktable *kt;
	struct pfr_kentryworkq workq;
	int s, rv;
d182 6
a187 6
	struct pfr_ktable *kt;
	struct pfr_kentryworkq workq;
	struct pfr_kentry *p;
	struct pfr_addr ad;
	int i, rv, s, xadd = 0;
	long tzero = time.tv_sec;
d241 5
a245 5
	struct pfr_ktable *kt;
	struct pfr_kentryworkq workq;
	struct pfr_kentry *p;
	struct pfr_addr ad;
	int i, rv, s, xdel = 0;
d289 7
a295 7
	struct pfr_ktable *kt;
	struct pfr_kentryworkq addq, delq, changeq;
	struct pfr_walktree w;
	struct pfr_kentry *p;
	struct pfr_addr ad;
	int i, rv, s, xadd = 0, xdel = 0, xchange = 0;
	long tzero = time.tv_sec;
d398 4
a401 4
	struct pfr_ktable *kt;
	struct pfr_kentry *p;
	struct pfr_addr ad;
	int i;
d428 3
a430 3
	struct pfr_ktable *kt;
	struct pfr_walktree w;
	int rv;
d463 5
a467 5
	struct pfr_ktable *kt;
	struct pfr_walktree w;
	struct pfr_kentryworkq workq;
	int rv, s;
	long tzero = time.tv_sec;
d489 2
a490 2
        	if (rv)
                	return rv;
d510 5
a514 5
	struct pfr_ktable *kt;
	struct pfr_kentryworkq workq;
	struct pfr_kentry *p;
	struct pfr_addr ad;
	int i, rv, s, xzero = 0;
d577 2
a578 2
	struct pfr_walktree w;
	int rv;
d598 3
a600 3
	union sockaddr_union sa, mask;
	struct radix_node_head *head;
	struct pfr_kentry *ke;
d624 1
a624 1
	struct pfr_kentry *ke;
d645 2
a646 3
	if (ke == NULL)
		return;
	pool_put(&pfr_kentry_pl, ke);
d652 2
a653 1
	struct pfr_kentry *p, *q;
d664 2
a665 2
	struct pfr_kentry *p, *q;
	int n = 0;
d687 2
a688 2
	struct pfr_kentry *p;
	int n = 0;
d701 2
a702 2
	struct pfr_kentry *p;
	int s, n = 0;
d717 2
a718 2
	struct pfr_addr ad;
	int i;
d732 1
a732 1
	int i;
d757 4
a760 4
	union sockaddr_union mask;
	struct radix_node *rn;
	struct radix_node_head *head;
	int s;
d785 4
a788 4
	union sockaddr_union mask;
	struct radix_node *rn;
	struct radix_node_head *head;
	int s;
d826 3
a828 3
	struct pfr_kentry *ke = (struct pfr_kentry *)rn;
	struct pfr_walktree *w = arg;
	int s;
d878 3
a880 3
	struct pfr_ktableworkq workq;
	struct pfr_ktable *p;
	int s, xdel = 0;
d902 4
a905 4
	struct pfr_ktableworkq workq;
	struct pfr_ktable *p, key;
	int i, s, xadd = 0;
	long tzero = time.tv_sec;
d925 1
a925 1
				/* TODO: move the following out of the if */
d951 3
a953 3
	struct pfr_ktableworkq workq;
	struct pfr_ktable *p, key;
	int i, s, xdel = 0;
d982 2
a983 2
	struct pfr_ktable *p;
	int n = pfr_ktable_cnt;
d1007 4
a1010 4
	struct pfr_ktable *p;
	struct pfr_ktableworkq workq;
	int s, n = pfr_ktable_cnt;
	long tzero = time.tv_sec;
d1049 4
a1052 4
	struct pfr_ktableworkq workq;
	struct pfr_ktable *p, key;
	int i, s, xzero = 0;
	long tzero = time.tv_sec;
d1082 3
a1084 3
	union pfr_hash hash;
	struct pf_addr_wrap w;
	SHA1_CTX sha1;
d1108 3
a1110 3
	union pfr_hash hash;
	struct pf_addr_wrap w;
	struct pfr_ktable *kt;
d1132 2
a1133 2
	struct pfr_ktable *p;
	int s, n = 0;
d1154 3
a1156 3
	struct pfr_kentryworkq addrq;
	struct pfr_ktable *p;
	int s, n = 0;
d1179 3
a1181 3
	struct pfr_kentryworkq addrq;
	struct pfr_ktable *p;
	int s;
d1201 2
a1202 2
	struct pfr_ktable *kt;
	SHA1_CTX sha1;
d1242 2
a1243 1
	struct pfr_ktable *p, *q;
d1259 1
a1259 1
	struct pfr_ktable *p;
d1284 4
a1287 4
	union pfr_hash hash;
	struct pfr_ktable *kt;
	struct pfr_kentry *ke = NULL;
	int match;
d1317 3
a1319 3
	union pfr_hash hash;
	struct pfr_ktable *kt;
	struct pfr_kentry *ke = NULL;
@

