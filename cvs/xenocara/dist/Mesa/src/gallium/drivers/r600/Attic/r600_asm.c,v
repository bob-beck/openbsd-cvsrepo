head	1.9;
access;
symbols
	OPENBSD_5_8:1.8.0.4
	OPENBSD_5_8_BASE:1.8
	OPENBSD_5_7:1.8.0.2
	OPENBSD_5_7_BASE:1.8
	v10_2_9:1.1.1.6
	v10_4_3:1.1.1.5
	v10_2_7:1.1.1.4
	OPENBSD_5_6:1.5.0.2
	OPENBSD_5_6_BASE:1.5
	v10_2_3:1.1.1.3
	OPENBSD_5_5:1.4.0.2
	OPENBSD_5_5_BASE:1.4
	v9_2_5:1.1.1.2
	v9_2_3:1.1.1.2
	v9_2_2:1.1.1.2
	v9_2_1:1.1.1.2
	v9_2_0:1.1.1.2
	OPENBSD_5_4:1.3.0.2
	OPENBSD_5_4_BASE:1.3
	OPENBSD_5_3:1.2.0.2
	OPENBSD_5_3_BASE:1.2
	OPENBSD_5_2:1.1.1.1.0.4
	OPENBSD_5_2_BASE:1.1.1.1
	OPENBSD_5_1_BASE:1.1.1.1
	OPENBSD_5_1:1.1.1.1.0.2
	v7_10_3:1.1.1.1
	mesa:1.1.1;
locks; strict;
comment	@ * @;


1.9
date	2015.12.23.05.17.33;	author jsg;	state dead;
branches;
next	1.8;
commitid	TnlogFl9nOv2eaRf;

1.8
date	2015.02.20.23.09.53;	author jsg;	state Exp;
branches;
next	1.7;
commitid	4ry2gvZGMXkCUD2n;

1.7
date	2015.01.25.14.41.16;	author jsg;	state Exp;
branches;
next	1.6;
commitid	mcxB0JvoI9gTDYXU;

1.6
date	2014.09.07.15.20.06;	author jsg;	state Exp;
branches;
next	1.5;
commitid	7kimTMT4YlQauAIU;

1.5
date	2014.07.09.21.08.54;	author jsg;	state Exp;
branches;
next	1.4;
commitid	WPD6rgPryPkvXOr9;

1.4
date	2013.09.05.14.01.00;	author jsg;	state Exp;
branches;
next	1.3;

1.3
date	2013.06.17.23.21.23;	author jsg;	state Exp;
branches;
next	1.2;

1.2
date	2012.08.17.13.58.06;	author mpi;	state Exp;
branches;
next	1.1;

1.1
date	2011.10.23.13.29.28;	author matthieu;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2011.10.23.13.29.28;	author matthieu;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2013.09.05.13.12.19;	author jsg;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2014.07.09.20.34.10;	author jsg;	state Exp;
branches;
next	1.1.1.4;
commitid	3JhLfwcuBALP0ZR7;

1.1.1.4
date	2014.09.07.15.02.52;	author jsg;	state Exp;
branches;
next	1.1.1.5;
commitid	dm8VnQHhowGHmemJ;

1.1.1.5
date	2015.01.25.14.08.16;	author jsg;	state Exp;
branches;
next	1.1.1.6;
commitid	ce2W5rH5aF7VS9gi;

1.1.1.6
date	2015.02.20.22.45.28;	author jsg;	state Exp;
branches;
next	;
commitid	F54a1i0WXHMxq7kE;


desc
@@


1.9
log
@remove the now unused Mesa 10.2.9 code
@
text
@/*
 * Copyright 2010 Jerome Glisse <glisse@@freedesktop.org>
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * on the rights to use, copy, modify, merge, publish, distribute, sub
 * license, and/or sell copies of the Software, and to permit persons to whom
 * the Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice (including the next
 * paragraph) shall be included in all copies or substantial portions of the
 * Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL
 * THE AUTHOR(S) AND/OR THEIR SUPPLIERS BE LIABLE FOR ANY CLAIM,
 * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
 * OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
 * USE OR OTHER DEALINGS IN THE SOFTWARE.
 */
#include "r600_sq.h"
#include "r600_opcodes.h"
#include "r600_formats.h"
#include "r600_shader.h"
#include "r600d.h"

#include <errno.h>
#include "util/u_dump.h"
#include "util/u_memory.h"
#include "util/u_math.h"
#include "pipe/p_shader_tokens.h"

#include "sb/sb_public.h"

#define NUM_OF_CYCLES 3
#define NUM_OF_COMPONENTS 4

static inline unsigned int r600_bytecode_get_num_operands(
		struct r600_bytecode *bc, struct r600_bytecode_alu *alu)
{
	return r600_isa_alu(alu->op)->src_count;
}

int r700_bytecode_alu_build(struct r600_bytecode *bc,
		struct r600_bytecode_alu *alu, unsigned id);

static struct r600_bytecode_cf *r600_bytecode_cf(void)
{
	struct r600_bytecode_cf *cf = CALLOC_STRUCT(r600_bytecode_cf);

	if (cf == NULL)
		return NULL;
	LIST_INITHEAD(&cf->list);
	LIST_INITHEAD(&cf->alu);
	LIST_INITHEAD(&cf->vtx);
	LIST_INITHEAD(&cf->tex);
	return cf;
}

static struct r600_bytecode_alu *r600_bytecode_alu(void)
{
	struct r600_bytecode_alu *alu = CALLOC_STRUCT(r600_bytecode_alu);

	if (alu == NULL)
		return NULL;
	LIST_INITHEAD(&alu->list);
	return alu;
}

static struct r600_bytecode_vtx *r600_bytecode_vtx(void)
{
	struct r600_bytecode_vtx *vtx = CALLOC_STRUCT(r600_bytecode_vtx);

	if (vtx == NULL)
		return NULL;
	LIST_INITHEAD(&vtx->list);
	return vtx;
}

static struct r600_bytecode_tex *r600_bytecode_tex(void)
{
	struct r600_bytecode_tex *tex = CALLOC_STRUCT(r600_bytecode_tex);

	if (tex == NULL)
		return NULL;
	LIST_INITHEAD(&tex->list);
	return tex;
}

static unsigned stack_entry_size(enum radeon_family chip) {
	/* Wavefront size:
	 *   64: R600/RV670/RV770/Cypress/R740/Barts/Turks/Caicos/
	 *       Aruba/Sumo/Sumo2/redwood/juniper
	 *   32: R630/R730/R710/Palm/Cedar
	 *   16: R610/Rs780
	 *
	 * Stack row size:
	 * 	Wavefront Size                        16  32  48  64
	 * 	Columns per Row (R6xx/R7xx/R8xx only)  8   8   4   4
	 * 	Columns per Row (R9xx+)                8   4   4   4 */

	switch (chip) {
	/* FIXME: are some chips missing here? */
	/* wavefront size 16 */
	case CHIP_RV610:
	case CHIP_RS780:
	case CHIP_RV620:
	case CHIP_RS880:
	/* wavefront size 32 */
	case CHIP_RV630:
	case CHIP_RV635:
	case CHIP_RV730:
	case CHIP_RV710:
	case CHIP_PALM:
	case CHIP_CEDAR:
		return 8;

	/* wavefront size 64 */
	default:
		return 4;
	}
}

void r600_bytecode_init(struct r600_bytecode *bc,
			enum chip_class chip_class,
			enum radeon_family family,
			bool has_compressed_msaa_texturing)
{
	static unsigned next_shader_id = 0;

	bc->debug_id = ++next_shader_id;

	if ((chip_class == R600) &&
	    (family != CHIP_RV670 && family != CHIP_RS780 && family != CHIP_RS880)) {
		bc->ar_handling = AR_HANDLE_RV6XX;
		bc->r6xx_nop_after_rel_dst = 1;
	} else {
		bc->ar_handling = AR_HANDLE_NORMAL;
		bc->r6xx_nop_after_rel_dst = 0;
	}

	LIST_INITHEAD(&bc->cf);
	bc->chip_class = chip_class;
	bc->has_compressed_msaa_texturing = has_compressed_msaa_texturing;
	bc->stack.entry_size = stack_entry_size(family);
}

int r600_bytecode_add_cf(struct r600_bytecode *bc)
{
	struct r600_bytecode_cf *cf = r600_bytecode_cf();

	if (cf == NULL)
		return -ENOMEM;
	LIST_ADDTAIL(&cf->list, &bc->cf);
	if (bc->cf_last) {
		cf->id = bc->cf_last->id + 2;
		if (bc->cf_last->eg_alu_extended) {
			/* take into account extended alu size */
			cf->id += 2;
			bc->ndw += 2;
		}
	}
	bc->cf_last = cf;
	bc->ncf++;
	bc->ndw += 2;
	bc->force_add_cf = 0;
	bc->ar_loaded = 0;
	return 0;
}

int r600_bytecode_add_output(struct r600_bytecode *bc,
		const struct r600_bytecode_output *output)
{
	int r;

	if (output->gpr >= bc->ngpr)
		bc->ngpr = output->gpr + 1;

	if (bc->cf_last && (bc->cf_last->op == output->op ||
		(bc->cf_last->op == CF_OP_EXPORT &&
		output->op == CF_OP_EXPORT_DONE)) &&
		output->type == bc->cf_last->output.type &&
		output->elem_size == bc->cf_last->output.elem_size &&
		output->swizzle_x == bc->cf_last->output.swizzle_x &&
		output->swizzle_y == bc->cf_last->output.swizzle_y &&
		output->swizzle_z == bc->cf_last->output.swizzle_z &&
		output->swizzle_w == bc->cf_last->output.swizzle_w &&
		output->comp_mask == bc->cf_last->output.comp_mask &&
		(output->burst_count + bc->cf_last->output.burst_count) <= 16) {

		if ((output->gpr + output->burst_count) == bc->cf_last->output.gpr &&
			(output->array_base + output->burst_count) == bc->cf_last->output.array_base) {

			bc->cf_last->op = bc->cf_last->output.op = output->op;
			bc->cf_last->output.gpr = output->gpr;
			bc->cf_last->output.array_base = output->array_base;
			bc->cf_last->output.burst_count += output->burst_count;
			return 0;

		} else if (output->gpr == (bc->cf_last->output.gpr + bc->cf_last->output.burst_count) &&
			output->array_base == (bc->cf_last->output.array_base + bc->cf_last->output.burst_count)) {

			bc->cf_last->op = bc->cf_last->output.op = output->op;
			bc->cf_last->output.burst_count += output->burst_count;
			return 0;
		}
	}

	r = r600_bytecode_add_cf(bc);
	if (r)
		return r;
	bc->cf_last->op = output->op;
	memcpy(&bc->cf_last->output, output, sizeof(struct r600_bytecode_output));
	bc->cf_last->barrier = 1;
	return 0;
}

/* alu instructions that can ony exits once per group */
static int is_alu_once_inst(struct r600_bytecode *bc, struct r600_bytecode_alu *alu)
{
	return r600_isa_alu(alu->op)->flags & (AF_KILL | AF_PRED);
}

static int is_alu_reduction_inst(struct r600_bytecode *bc, struct r600_bytecode_alu *alu)
{
	return (r600_isa_alu(alu->op)->flags & AF_REPL) &&
			(r600_isa_alu_slots(bc->isa->hw_class, alu->op) == AF_4V);
}

static int is_alu_mova_inst(struct r600_bytecode *bc, struct r600_bytecode_alu *alu)
{
	return r600_isa_alu(alu->op)->flags & AF_MOVA;
}

static int alu_uses_rel(struct r600_bytecode *bc, struct r600_bytecode_alu *alu)
{
	unsigned num_src = r600_bytecode_get_num_operands(bc, alu);
	unsigned src;

	if (alu->dst.rel) {
		return 1;
	}

	for (src = 0; src < num_src; ++src) {
		if (alu->src[src].rel) {
			return 1;
		}
	}
	return 0;
}

static int is_alu_vec_unit_inst(struct r600_bytecode *bc, struct r600_bytecode_alu *alu)
{
	unsigned slots = r600_isa_alu_slots(bc->isa->hw_class, alu->op);
	return !(slots & AF_S);
}

static int is_alu_trans_unit_inst(struct r600_bytecode *bc, struct r600_bytecode_alu *alu)
{
	unsigned slots = r600_isa_alu_slots(bc->isa->hw_class, alu->op);
	return !(slots & AF_V);
}

/* alu instructions that can execute on any unit */
static int is_alu_any_unit_inst(struct r600_bytecode *bc, struct r600_bytecode_alu *alu)
{
	unsigned slots = r600_isa_alu_slots(bc->isa->hw_class, alu->op);
	return slots == AF_VS;
}

static int is_nop_inst(struct r600_bytecode *bc, struct r600_bytecode_alu *alu)
{
	return alu->op == ALU_OP0_NOP;
}		

static int assign_alu_units(struct r600_bytecode *bc, struct r600_bytecode_alu *alu_first,
			    struct r600_bytecode_alu *assignment[5])
{
	struct r600_bytecode_alu *alu;
	unsigned i, chan, trans;
	int max_slots = bc->chip_class == CAYMAN ? 4 : 5;

	for (i = 0; i < max_slots; i++)
		assignment[i] = NULL;

	for (alu = alu_first; alu; alu = LIST_ENTRY(struct r600_bytecode_alu, alu->list.next, list)) {
		chan = alu->dst.chan;
		if (max_slots == 4)
			trans = 0;
		else if (is_alu_trans_unit_inst(bc, alu))
			trans = 1;
		else if (is_alu_vec_unit_inst(bc, alu))
			trans = 0;
		else if (assignment[chan])
			trans = 1; /* Assume ALU_INST_PREFER_VECTOR. */
		else
			trans = 0;

		if (trans) {
			if (assignment[4]) {
				assert(0); /* ALU.Trans has already been allocated. */
				return -1;
			}
			assignment[4] = alu;
		} else {
			if (assignment[chan]) {
				assert(0); /* ALU.chan has already been allocated. */
				return -1;
			}
			assignment[chan] = alu;
		}

		if (alu->last)
			break;
	}
	return 0;
}

struct alu_bank_swizzle {
	int	hw_gpr[NUM_OF_CYCLES][NUM_OF_COMPONENTS];
	int	hw_cfile_addr[4];
	int	hw_cfile_elem[4];
};

static const unsigned cycle_for_bank_swizzle_vec[][3] = {
	[SQ_ALU_VEC_012] = { 0, 1, 2 },
	[SQ_ALU_VEC_021] = { 0, 2, 1 },
	[SQ_ALU_VEC_120] = { 1, 2, 0 },
	[SQ_ALU_VEC_102] = { 1, 0, 2 },
	[SQ_ALU_VEC_201] = { 2, 0, 1 },
	[SQ_ALU_VEC_210] = { 2, 1, 0 }
};

static const unsigned cycle_for_bank_swizzle_scl[][3] = {
	[SQ_ALU_SCL_210] = { 2, 1, 0 },
	[SQ_ALU_SCL_122] = { 1, 2, 2 },
	[SQ_ALU_SCL_212] = { 2, 1, 2 },
	[SQ_ALU_SCL_221] = { 2, 2, 1 }
};

static void init_bank_swizzle(struct alu_bank_swizzle *bs)
{
	int i, cycle, component;
	/* set up gpr use */
	for (cycle = 0; cycle < NUM_OF_CYCLES; cycle++)
		for (component = 0; component < NUM_OF_COMPONENTS; component++)
			 bs->hw_gpr[cycle][component] = -1;
	for (i = 0; i < 4; i++)
		bs->hw_cfile_addr[i] = -1;
	for (i = 0; i < 4; i++)
		bs->hw_cfile_elem[i] = -1;
}

static int reserve_gpr(struct alu_bank_swizzle *bs, unsigned sel, unsigned chan, unsigned cycle)
{
	if (bs->hw_gpr[cycle][chan] == -1)
		bs->hw_gpr[cycle][chan] = sel;
	else if (bs->hw_gpr[cycle][chan] != (int)sel) {
		/* Another scalar operation has already used the GPR read port for the channel. */
		return -1;
	}
	return 0;
}

static int reserve_cfile(struct r600_bytecode *bc, struct alu_bank_swizzle *bs, unsigned sel, unsigned chan)
{
	int res, num_res = 4;
	if (bc->chip_class >= R700) {
		num_res = 2;
		chan /= 2;
	}
	for (res = 0; res < num_res; ++res) {
		if (bs->hw_cfile_addr[res] == -1) {
			bs->hw_cfile_addr[res] = sel;
			bs->hw_cfile_elem[res] = chan;
			return 0;
		} else if (bs->hw_cfile_addr[res] == sel &&
			bs->hw_cfile_elem[res] == chan)
			return 0; /* Read for this scalar element already reserved, nothing to do here. */
	}
	/* All cfile read ports are used, cannot reference vector element. */
	return -1;
}

static int is_gpr(unsigned sel)
{
	return (sel <= 127);
}

/* CB constants start at 512, and get translated to a kcache index when ALU
 * clauses are constructed. Note that we handle kcache constants the same way
 * as (the now gone) cfile constants, is that really required? */
static int is_cfile(unsigned sel)
{
	return (sel > 255 && sel < 512) ||
		(sel > 511 && sel < 4607) || /* Kcache before translation. */
		(sel > 127 && sel < 192); /* Kcache after translation. */
}

static int is_const(int sel)
{
	return is_cfile(sel) ||
		(sel >= V_SQ_ALU_SRC_0 &&
		sel <= V_SQ_ALU_SRC_LITERAL);
}

static int check_vector(struct r600_bytecode *bc, struct r600_bytecode_alu *alu,
			struct alu_bank_swizzle *bs, int bank_swizzle)
{
	int r, src, num_src, sel, elem, cycle;

	num_src = r600_bytecode_get_num_operands(bc, alu);
	for (src = 0; src < num_src; src++) {
		sel = alu->src[src].sel;
		elem = alu->src[src].chan;
		if (is_gpr(sel)) {
			cycle = cycle_for_bank_swizzle_vec[bank_swizzle][src];
			if (src == 1 && sel == alu->src[0].sel && elem == alu->src[0].chan)
				/* Nothing to do; special-case optimization,
				 * second source uses first sourceâ€™s reservation. */
				continue;
			else {
				r = reserve_gpr(bs, sel, elem, cycle);
				if (r)
					return r;
			}
		} else if (is_cfile(sel)) {
			r = reserve_cfile(bc, bs, (alu->src[src].kc_bank<<16) + sel, elem);
			if (r)
				return r;
		}
		/* No restrictions on PV, PS, literal or special constants. */
	}
	return 0;
}

static int check_scalar(struct r600_bytecode *bc, struct r600_bytecode_alu *alu,
			struct alu_bank_swizzle *bs, int bank_swizzle)
{
	int r, src, num_src, const_count, sel, elem, cycle;

	num_src = r600_bytecode_get_num_operands(bc, alu);
	for (const_count = 0, src = 0; src < num_src; ++src) {
		sel = alu->src[src].sel;
		elem = alu->src[src].chan;
		if (is_const(sel)) { /* Any constant, including literal and inline constants. */
			if (const_count >= 2)
				/* More than two references to a constant in
				 * transcendental operation. */
				return -1;
			else
				const_count++;
		}
		if (is_cfile(sel)) {
			r = reserve_cfile(bc, bs, (alu->src[src].kc_bank<<16) + sel, elem);
			if (r)
				return r;
		}
	}
	for (src = 0; src < num_src; ++src) {
		sel = alu->src[src].sel;
		elem = alu->src[src].chan;
		if (is_gpr(sel)) {
			cycle = cycle_for_bank_swizzle_scl[bank_swizzle][src];
			if (cycle < const_count)
				/* Cycle for GPR load conflicts with
				 * constant load in transcendental operation. */
				return -1;
			r = reserve_gpr(bs, sel, elem, cycle);
			if (r)
				return r;
		}
		/* PV PS restrictions */
		if (const_count && (sel == 254 || sel == 255)) {
			cycle = cycle_for_bank_swizzle_scl[bank_swizzle][src];
			if (cycle < const_count)
				return -1;
		}
	}
	return 0;
}

static int check_and_set_bank_swizzle(struct r600_bytecode *bc,
				      struct r600_bytecode_alu *slots[5])
{
	struct alu_bank_swizzle bs;
	int bank_swizzle[5];
	int i, r = 0, forced = 1;
	boolean scalar_only = bc->chip_class == CAYMAN ? false : true;
	int max_slots = bc->chip_class == CAYMAN ? 4 : 5;

	for (i = 0; i < max_slots; i++) {
		if (slots[i]) {
			if (slots[i]->bank_swizzle_force) {
				slots[i]->bank_swizzle = slots[i]->bank_swizzle_force;
			} else {
				forced = 0;
			}
		}

		if (i < 4 && slots[i])
			scalar_only = false;
	}
	if (forced)
		return 0;

	/* Just check every possible combination of bank swizzle.
	 * Not very efficent, but works on the first try in most of the cases. */
	for (i = 0; i < 4; i++)
		if (!slots[i] || !slots[i]->bank_swizzle_force)
			bank_swizzle[i] = SQ_ALU_VEC_012;
		else
			bank_swizzle[i] = slots[i]->bank_swizzle;

	bank_swizzle[4] = SQ_ALU_SCL_210;
	while(bank_swizzle[4] <= SQ_ALU_SCL_221) {

		init_bank_swizzle(&bs);
		if (scalar_only == false) {
			for (i = 0; i < 4; i++) {
				if (slots[i]) {
					r = check_vector(bc, slots[i], &bs, bank_swizzle[i]);
					if (r)
						break;
				}
			}
		} else
			r = 0;

		if (!r && max_slots == 5 && slots[4]) {
			r = check_scalar(bc, slots[4], &bs, bank_swizzle[4]);
		}
		if (!r) {
			for (i = 0; i < max_slots; i++) {
				if (slots[i])
					slots[i]->bank_swizzle = bank_swizzle[i];
			}
			return 0;
		}

		if (scalar_only) {
			bank_swizzle[4]++;
		} else {
			for (i = 0; i < max_slots; i++) {
				if (!slots[i] || !slots[i]->bank_swizzle_force) {
					bank_swizzle[i]++;
					if (bank_swizzle[i] <= SQ_ALU_VEC_210)
						break;
					else if (i < max_slots - 1)
						bank_swizzle[i] = SQ_ALU_VEC_012;
					else
						return -1;
				}
			}
		}
	}

	/* Couldn't find a working swizzle. */
	return -1;
}

static int replace_gpr_with_pv_ps(struct r600_bytecode *bc,
				  struct r600_bytecode_alu *slots[5], struct r600_bytecode_alu *alu_prev)
{
	struct r600_bytecode_alu *prev[5];
	int gpr[5], chan[5];
	int i, j, r, src, num_src;
	int max_slots = bc->chip_class == CAYMAN ? 4 : 5;

	r = assign_alu_units(bc, alu_prev, prev);
	if (r)
		return r;

	for (i = 0; i < max_slots; ++i) {
		if (prev[i] && (prev[i]->dst.write || prev[i]->is_op3) && !prev[i]->dst.rel) {
			gpr[i] = prev[i]->dst.sel;
			/* cube writes more than PV.X */
			if (is_alu_reduction_inst(bc, prev[i]))
				chan[i] = 0;
			else
				chan[i] = prev[i]->dst.chan;
		} else
			gpr[i] = -1;
	}

	for (i = 0; i < max_slots; ++i) {
		struct r600_bytecode_alu *alu = slots[i];
		if(!alu)
			continue;

		num_src = r600_bytecode_get_num_operands(bc, alu);
		for (src = 0; src < num_src; ++src) {
			if (!is_gpr(alu->src[src].sel) || alu->src[src].rel)
				continue;

			if (bc->chip_class < CAYMAN) {
				if (alu->src[src].sel == gpr[4] &&
				    alu->src[src].chan == chan[4] &&
				    alu_prev->pred_sel == alu->pred_sel) {
					alu->src[src].sel = V_SQ_ALU_SRC_PS;
					alu->src[src].chan = 0;
					continue;
				}
			}

			for (j = 0; j < 4; ++j) {
				if (alu->src[src].sel == gpr[j] &&
					alu->src[src].chan == j &&
				      alu_prev->pred_sel == alu->pred_sel) {
					alu->src[src].sel = V_SQ_ALU_SRC_PV;
					alu->src[src].chan = chan[j];
					break;
				}
			}
		}
	}

	return 0;
}

void r600_bytecode_special_constants(uint32_t value, unsigned *sel, unsigned *neg)
{
	switch(value) {
	case 0:
		*sel = V_SQ_ALU_SRC_0;
		break;
	case 1:
		*sel = V_SQ_ALU_SRC_1_INT;
		break;
	case -1:
		*sel = V_SQ_ALU_SRC_M_1_INT;
		break;
	case 0x3F800000: /* 1.0f */
		*sel = V_SQ_ALU_SRC_1;
		break;
	case 0x3F000000: /* 0.5f */
		*sel = V_SQ_ALU_SRC_0_5;
		break;
	case 0xBF800000: /* -1.0f */
		*sel = V_SQ_ALU_SRC_1;
		*neg ^= 1;
		break;
	case 0xBF000000: /* -0.5f */
		*sel = V_SQ_ALU_SRC_0_5;
		*neg ^= 1;
		break;
	default:
		*sel = V_SQ_ALU_SRC_LITERAL;
		break;
	}
}

/* compute how many literal are needed */
static int r600_bytecode_alu_nliterals(struct r600_bytecode *bc, struct r600_bytecode_alu *alu,
				 uint32_t literal[4], unsigned *nliteral)
{
	unsigned num_src = r600_bytecode_get_num_operands(bc, alu);
	unsigned i, j;

	for (i = 0; i < num_src; ++i) {
		if (alu->src[i].sel == V_SQ_ALU_SRC_LITERAL) {
			uint32_t value = alu->src[i].value;
			unsigned found = 0;
			for (j = 0; j < *nliteral; ++j) {
				if (literal[j] == value) {
					found = 1;
					break;
				}
			}
			if (!found) {
				if (*nliteral >= 4)
					return -EINVAL;
				literal[(*nliteral)++] = value;
			}
		}
	}
	return 0;
}

static void r600_bytecode_alu_adjust_literals(struct r600_bytecode *bc,
					struct r600_bytecode_alu *alu,
					uint32_t literal[4], unsigned nliteral)
{
	unsigned num_src = r600_bytecode_get_num_operands(bc, alu);
	unsigned i, j;

	for (i = 0; i < num_src; ++i) {
		if (alu->src[i].sel == V_SQ_ALU_SRC_LITERAL) {
			uint32_t value = alu->src[i].value;
			for (j = 0; j < nliteral; ++j) {
				if (literal[j] == value) {
					alu->src[i].chan = j;
					break;
				}
			}
		}
	}
}

static int merge_inst_groups(struct r600_bytecode *bc, struct r600_bytecode_alu *slots[5],
			     struct r600_bytecode_alu *alu_prev)
{
	struct r600_bytecode_alu *prev[5];
	struct r600_bytecode_alu *result[5] = { NULL };

	uint32_t literal[4], prev_literal[4];
	unsigned nliteral = 0, prev_nliteral = 0;

	int i, j, r, src, num_src;
	int num_once_inst = 0;
	int have_mova = 0, have_rel = 0;
	int max_slots = bc->chip_class == CAYMAN ? 4 : 5;

	r = assign_alu_units(bc, alu_prev, prev);
	if (r)
		return r;

	for (i = 0; i < max_slots; ++i) {
		if (prev[i]) {
		      if (prev[i]->pred_sel)
			      return 0;
		      if (is_alu_once_inst(bc, prev[i]))
			      return 0;
		}
		if (slots[i]) {
			if (slots[i]->pred_sel)
				return 0;
			if (is_alu_once_inst(bc, slots[i]))
				return 0;
		}
	}

	for (i = 0; i < max_slots; ++i) {
		struct r600_bytecode_alu *alu;

		if (num_once_inst > 0)
		   return 0;

		/* check number of literals */
		if (prev[i]) {
			if (r600_bytecode_alu_nliterals(bc, prev[i], literal, &nliteral))
				return 0;
			if (r600_bytecode_alu_nliterals(bc, prev[i], prev_literal, &prev_nliteral))
				return 0;
			if (is_alu_mova_inst(bc, prev[i])) {
				if (have_rel)
					return 0;
				have_mova = 1;
			}

			if (alu_uses_rel(bc, prev[i])) {
				if (have_mova) {
					return 0;
				}
				have_rel = 1;
			}

			num_once_inst += is_alu_once_inst(bc, prev[i]);
		}
		if (slots[i] && r600_bytecode_alu_nliterals(bc, slots[i], literal, &nliteral))
			return 0;

		/* Let's check used slots. */
		if (prev[i] && !slots[i]) {
			result[i] = prev[i];
			continue;
		} else if (prev[i] && slots[i]) {
			if (max_slots == 5 && result[4] == NULL && prev[4] == NULL && slots[4] == NULL) {
				/* Trans unit is still free try to use it. */
				if (is_alu_any_unit_inst(bc, slots[i])) {
					result[i] = prev[i];
					result[4] = slots[i];
				} else if (is_alu_any_unit_inst(bc, prev[i])) {
					if (slots[i]->dst.sel == prev[i]->dst.sel &&
						(slots[i]->dst.write == 1 || slots[i]->is_op3) &&
						(prev[i]->dst.write == 1 || prev[i]->is_op3))
						return 0;

					result[i] = slots[i];
					result[4] = prev[i];
				} else
					return 0;
			} else
				return 0;
		} else if(!slots[i]) {
			continue;
		} else {
			if (max_slots == 5 && slots[i] && prev[4] &&
					slots[i]->dst.sel == prev[4]->dst.sel &&
					slots[i]->dst.chan == prev[4]->dst.chan &&
					(slots[i]->dst.write == 1 || slots[i]->is_op3) &&
					(prev[4]->dst.write == 1 || prev[4]->is_op3))
				return 0;

			result[i] = slots[i];
		}

		alu = slots[i];
		num_once_inst += is_alu_once_inst(bc, alu);

		/* don't reschedule NOPs */
		if (is_nop_inst(bc, alu))
			return 0;

		if (is_alu_mova_inst(bc, alu)) {
			if (have_rel) {
				return 0;
			}
			have_mova = 1;
		}

		if (alu_uses_rel(bc, alu)) {
			if (have_mova) {
				return 0;
			}
			have_rel = 1;
		}

		/* Let's check source gprs */
		num_src = r600_bytecode_get_num_operands(bc, alu);
		for (src = 0; src < num_src; ++src) {

			/* Constants don't matter. */
			if (!is_gpr(alu->src[src].sel))
				continue;

			for (j = 0; j < max_slots; ++j) {
				if (!prev[j] || !(prev[j]->dst.write || prev[j]->is_op3))
					continue;

				/* If it's relative then we can't determin which gpr is really used. */
				if (prev[j]->dst.chan == alu->src[src].chan &&
					(prev[j]->dst.sel == alu->src[src].sel ||
					prev[j]->dst.rel || alu->src[src].rel))
					return 0;
			}
		}
	}

	/* more than one PRED_ or KILL_ ? */
	if (num_once_inst > 1)
		return 0;

	/* check if the result can still be swizzlet */
	r = check_and_set_bank_swizzle(bc, result);
	if (r)
		return 0;

	/* looks like everything worked out right, apply the changes */

	/* undo adding previus literals */
	bc->cf_last->ndw -= align(prev_nliteral, 2);

	/* sort instructions */
	for (i = 0; i < max_slots; ++i) {
		slots[i] = result[i];
		if (result[i]) {
			LIST_DEL(&result[i]->list);
			result[i]->last = 0;
			LIST_ADDTAIL(&result[i]->list, &bc->cf_last->alu);
		}
	}

	/* determine new last instruction */
	LIST_ENTRY(struct r600_bytecode_alu, bc->cf_last->alu.prev, list)->last = 1;

	/* determine new first instruction */
	for (i = 0; i < max_slots; ++i) {
		if (result[i]) {
			bc->cf_last->curr_bs_head = result[i];
			break;
		}
	}

	bc->cf_last->prev_bs_head = bc->cf_last->prev2_bs_head;
	bc->cf_last->prev2_bs_head = NULL;

	return 0;
}

/* we'll keep kcache sets sorted by bank & addr */
static int r600_bytecode_alloc_kcache_line(struct r600_bytecode *bc,
		struct r600_bytecode_kcache *kcache,
		unsigned bank, unsigned line)
{
	int i, kcache_banks = bc->chip_class >= EVERGREEN ? 4 : 2;

	for (i = 0; i < kcache_banks; i++) {
		if (kcache[i].mode) {
			int d;

			if (kcache[i].bank < bank)
				continue;

			if ((kcache[i].bank == bank && kcache[i].addr > line+1) ||
					kcache[i].bank > bank) {
				/* try to insert new line */
				if (kcache[kcache_banks-1].mode) {
					/* all sets are in use */
					return -ENOMEM;
				}

				memmove(&kcache[i+1],&kcache[i], (kcache_banks-i-1)*sizeof(struct r600_bytecode_kcache));
				kcache[i].mode = V_SQ_CF_KCACHE_LOCK_1;
				kcache[i].bank = bank;
				kcache[i].addr = line;
				return 0;
			}

			d = line - kcache[i].addr;

			if (d == -1) {
				kcache[i].addr--;
				if (kcache[i].mode == V_SQ_CF_KCACHE_LOCK_2) {
					/* we are prepending the line to the current set,
					 * discarding the existing second line,
					 * so we'll have to insert line+2 after it */
					line += 2;
					continue;
				} else if (kcache[i].mode == V_SQ_CF_KCACHE_LOCK_1) {
					kcache[i].mode = V_SQ_CF_KCACHE_LOCK_2;
					return 0;
				} else {
					/* V_SQ_CF_KCACHE_LOCK_LOOP_INDEX is not supported */
					return -ENOMEM;
				}
			} else if (d == 1) {
				kcache[i].mode = V_SQ_CF_KCACHE_LOCK_2;
				return 0;
			} else if (d == 0)
				return 0;
		} else { /* free kcache set - use it */
			kcache[i].mode = V_SQ_CF_KCACHE_LOCK_1;
			kcache[i].bank = bank;
			kcache[i].addr = line;
			return 0;
		}
	}
	return -ENOMEM;
}

static int r600_bytecode_alloc_inst_kcache_lines(struct r600_bytecode *bc,
		struct r600_bytecode_kcache *kcache,
		struct r600_bytecode_alu *alu)
{
	int i, r;

	for (i = 0; i < 3; i++) {
		unsigned bank, line, sel = alu->src[i].sel;

		if (sel < 512)
			continue;

		bank = alu->src[i].kc_bank;
		line = (sel-512)>>4;

		if ((r = r600_bytecode_alloc_kcache_line(bc, kcache, bank, line)))
			return r;
	}
	return 0;
}

static int r600_bytecode_assign_kcache_banks(struct r600_bytecode *bc,
		struct r600_bytecode_alu *alu,
		struct r600_bytecode_kcache * kcache)
{
	int i, j;

	/* Alter the src operands to refer to the kcache. */
	for (i = 0; i < 3; ++i) {
		static const unsigned int base[] = {128, 160, 256, 288};
		unsigned int line, sel = alu->src[i].sel, found = 0;

		if (sel < 512)
			continue;

		sel -= 512;
		line = sel>>4;

		for (j = 0; j < 4 && !found; ++j) {
			switch (kcache[j].mode) {
			case V_SQ_CF_KCACHE_NOP:
			case V_SQ_CF_KCACHE_LOCK_LOOP_INDEX:
				R600_ERR("unexpected kcache line mode\n");
				return -ENOMEM;
			default:
				if (kcache[j].bank == alu->src[i].kc_bank &&
						kcache[j].addr <= line &&
						line < kcache[j].addr + kcache[j].mode) {
					alu->src[i].sel = sel - (kcache[j].addr<<4);
					alu->src[i].sel += base[j];
					found=1;
			    }
			}
		}
	}
	return 0;
}

static int r600_bytecode_alloc_kcache_lines(struct r600_bytecode *bc,
		struct r600_bytecode_alu *alu,
		unsigned type)
{
	struct r600_bytecode_kcache kcache_sets[4];
	struct r600_bytecode_kcache *kcache = kcache_sets;
	int r;

	memcpy(kcache, bc->cf_last->kcache, 4 * sizeof(struct r600_bytecode_kcache));

	if ((r = r600_bytecode_alloc_inst_kcache_lines(bc, kcache, alu))) {
		/* can't alloc, need to start new clause */
		if ((r = r600_bytecode_add_cf(bc))) {
			return r;
		}
		bc->cf_last->op = type;

		/* retry with the new clause */
		kcache = bc->cf_last->kcache;
		if ((r = r600_bytecode_alloc_inst_kcache_lines(bc, kcache, alu))) {
			/* can't alloc again- should never happen */
			return r;
		}
	} else {
		/* update kcache sets */
		memcpy(bc->cf_last->kcache, kcache, 4 * sizeof(struct r600_bytecode_kcache));
	}

	/* if we actually used more than 2 kcache sets - use ALU_EXTENDED on eg+ */
	if (kcache[2].mode != V_SQ_CF_KCACHE_NOP) {
		if (bc->chip_class < EVERGREEN)
			return -ENOMEM;
		bc->cf_last->eg_alu_extended = 1;
	}

	return 0;
}

static int insert_nop_r6xx(struct r600_bytecode *bc)
{
	struct r600_bytecode_alu alu;
	int r, i;

	for (i = 0; i < 4; i++) {
		memset(&alu, 0, sizeof(alu));
		alu.op = ALU_OP0_NOP;
		alu.src[0].chan = i;
		alu.dst.chan = i;
		alu.last = (i == 3);
		r = r600_bytecode_add_alu(bc, &alu);
		if (r)
			return r;
	}
	return 0;
}

/* load AR register from gpr (bc->ar_reg) with MOVA_INT */
static int load_ar_r6xx(struct r600_bytecode *bc)
{
	struct r600_bytecode_alu alu;
	int r;

	if (bc->ar_loaded)
		return 0;

	/* hack to avoid making MOVA the last instruction in the clause */
	if ((bc->cf_last->ndw>>1) >= 110)
		bc->force_add_cf = 1;

	memset(&alu, 0, sizeof(alu));
	alu.op = ALU_OP1_MOVA_GPR_INT;
	alu.src[0].sel = bc->ar_reg;
	alu.src[0].chan = bc->ar_chan;
	alu.last = 1;
	alu.index_mode = INDEX_MODE_LOOP;
	r = r600_bytecode_add_alu(bc, &alu);
	if (r)
		return r;

	/* no requirement to set uses waterfall on MOVA_GPR_INT */
	bc->ar_loaded = 1;
	return 0;
}

/* load AR register from gpr (bc->ar_reg) with MOVA_INT */
static int load_ar(struct r600_bytecode *bc)
{
	struct r600_bytecode_alu alu;
	int r;

	if (bc->ar_handling)
		return load_ar_r6xx(bc);

	if (bc->ar_loaded)
		return 0;

	/* hack to avoid making MOVA the last instruction in the clause */
	if ((bc->cf_last->ndw>>1) >= 110)
		bc->force_add_cf = 1;

	memset(&alu, 0, sizeof(alu));
	alu.op = ALU_OP1_MOVA_INT;
	alu.src[0].sel = bc->ar_reg;
	alu.src[0].chan = bc->ar_chan;
	alu.last = 1;
	r = r600_bytecode_add_alu(bc, &alu);
	if (r)
		return r;

	bc->cf_last->r6xx_uses_waterfall = 1;
	bc->ar_loaded = 1;
	return 0;
}

int r600_bytecode_add_alu_type(struct r600_bytecode *bc,
		const struct r600_bytecode_alu *alu, unsigned type)
{
	struct r600_bytecode_alu *nalu = r600_bytecode_alu();
	struct r600_bytecode_alu *lalu;
	int i, r;

	if (nalu == NULL)
		return -ENOMEM;
	memcpy(nalu, alu, sizeof(struct r600_bytecode_alu));

	if (bc->cf_last != NULL && bc->cf_last->op != type) {
		/* check if we could add it anyway */
		if (bc->cf_last->op == CF_OP_ALU &&
			type == CF_OP_ALU_PUSH_BEFORE) {
			LIST_FOR_EACH_ENTRY(lalu, &bc->cf_last->alu, list) {
				if (lalu->execute_mask) {
					bc->force_add_cf = 1;
					break;
				}
			}
		} else
			bc->force_add_cf = 1;
	}

	/* cf can contains only alu or only vtx or only tex */
	if (bc->cf_last == NULL || bc->force_add_cf) {
		r = r600_bytecode_add_cf(bc);
		if (r) {
			free(nalu);
			return r;
		}
	}
	bc->cf_last->op = type;

	/* Check AR usage and load it if required */
	for (i = 0; i < 3; i++)
		if (nalu->src[i].rel && !bc->ar_loaded)
			load_ar(bc);

	if (nalu->dst.rel && !bc->ar_loaded)
		load_ar(bc);

	/* Setup the kcache for this ALU instruction. This will start a new
	 * ALU clause if needed. */
	if ((r = r600_bytecode_alloc_kcache_lines(bc, nalu, type))) {
		free(nalu);
		return r;
	}

	if (!bc->cf_last->curr_bs_head) {
		bc->cf_last->curr_bs_head = nalu;
	}
	/* number of gpr == the last gpr used in any alu */
	for (i = 0; i < 3; i++) {
		if (nalu->src[i].sel >= bc->ngpr && nalu->src[i].sel < 128) {
			bc->ngpr = nalu->src[i].sel + 1;
		}
		if (nalu->src[i].sel == V_SQ_ALU_SRC_LITERAL)
			r600_bytecode_special_constants(nalu->src[i].value,
				&nalu->src[i].sel, &nalu->src[i].neg);
	}
	if (nalu->dst.sel >= bc->ngpr) {
		bc->ngpr = nalu->dst.sel + 1;
	}
	LIST_ADDTAIL(&nalu->list, &bc->cf_last->alu);
	/* each alu use 2 dwords */
	bc->cf_last->ndw += 2;
	bc->ndw += 2;

	/* process cur ALU instructions for bank swizzle */
	if (nalu->last) {
		uint32_t literal[4];
		unsigned nliteral;
		struct r600_bytecode_alu *slots[5];
		int max_slots = bc->chip_class == CAYMAN ? 4 : 5;
		r = assign_alu_units(bc, bc->cf_last->curr_bs_head, slots);
		if (r)
			return r;

		if (bc->cf_last->prev_bs_head) {
			r = merge_inst_groups(bc, slots, bc->cf_last->prev_bs_head);
			if (r)
				return r;
		}

		if (bc->cf_last->prev_bs_head) {
			r = replace_gpr_with_pv_ps(bc, slots, bc->cf_last->prev_bs_head);
			if (r)
				return r;
		}

		r = check_and_set_bank_swizzle(bc, slots);
		if (r)
			return r;

		for (i = 0, nliteral = 0; i < max_slots; i++) {
			if (slots[i]) {
				r = r600_bytecode_alu_nliterals(bc, slots[i], literal, &nliteral);
				if (r)
					return r;
			}
		}
		bc->cf_last->ndw += align(nliteral, 2);

		/* at most 128 slots, one add alu can add 5 slots + 4 constants(2 slots)
		 * worst case */
		if ((bc->cf_last->ndw >> 1) >= 120) {
			bc->force_add_cf = 1;
		}

		bc->cf_last->prev2_bs_head = bc->cf_last->prev_bs_head;
		bc->cf_last->prev_bs_head = bc->cf_last->curr_bs_head;
		bc->cf_last->curr_bs_head = NULL;
	}

	if (nalu->dst.rel && bc->r6xx_nop_after_rel_dst)
		insert_nop_r6xx(bc);

	return 0;
}

int r600_bytecode_add_alu(struct r600_bytecode *bc, const struct r600_bytecode_alu *alu)
{
	return r600_bytecode_add_alu_type(bc, alu, CF_OP_ALU);
}

static unsigned r600_bytecode_num_tex_and_vtx_instructions(const struct r600_bytecode *bc)
{
	switch (bc->chip_class) {
	case R600:
		return 8;

	case R700:
	case EVERGREEN:
	case CAYMAN:
		return 16;

	default:
		R600_ERR("Unknown chip class %d.\n", bc->chip_class);
		return 8;
	}
}

static inline boolean last_inst_was_not_vtx_fetch(struct r600_bytecode *bc)
{
	return !((r600_isa_cf(bc->cf_last->op)->flags & CF_FETCH) &&
			(bc->chip_class == CAYMAN ||
			bc->cf_last->op != CF_OP_TEX));
}

int r600_bytecode_add_vtx(struct r600_bytecode *bc, const struct r600_bytecode_vtx *vtx)
{
	struct r600_bytecode_vtx *nvtx = r600_bytecode_vtx();
	int r;

	if (nvtx == NULL)
		return -ENOMEM;
	memcpy(nvtx, vtx, sizeof(struct r600_bytecode_vtx));

	/* cf can contains only alu or only vtx or only tex */
	if (bc->cf_last == NULL ||
	    last_inst_was_not_vtx_fetch(bc) ||
	    bc->force_add_cf) {
		r = r600_bytecode_add_cf(bc);
		if (r) {
			free(nvtx);
			return r;
		}
		switch (bc->chip_class) {
		case R600:
		case R700:
		case EVERGREEN:
			bc->cf_last->op = CF_OP_VTX;
			break;
		case CAYMAN:
			bc->cf_last->op = CF_OP_TEX;
			break;
		default:
			R600_ERR("Unknown chip class %d.\n", bc->chip_class);
			free(nvtx);
			return -EINVAL;
		}
	}
	LIST_ADDTAIL(&nvtx->list, &bc->cf_last->vtx);
	/* each fetch use 4 dwords */
	bc->cf_last->ndw += 4;
	bc->ndw += 4;
	if ((bc->cf_last->ndw / 4) >= r600_bytecode_num_tex_and_vtx_instructions(bc))
		bc->force_add_cf = 1;

	bc->ngpr = MAX2(bc->ngpr, vtx->src_gpr + 1);
	bc->ngpr = MAX2(bc->ngpr, vtx->dst_gpr + 1);

	return 0;
}

int r600_bytecode_add_tex(struct r600_bytecode *bc, const struct r600_bytecode_tex *tex)
{
	struct r600_bytecode_tex *ntex = r600_bytecode_tex();
	int r;

	if (ntex == NULL)
		return -ENOMEM;
	memcpy(ntex, tex, sizeof(struct r600_bytecode_tex));

	/* we can't fetch data und use it as texture lookup address in the same TEX clause */
	if (bc->cf_last != NULL &&
		bc->cf_last->op == CF_OP_TEX) {
		struct r600_bytecode_tex *ttex;
		LIST_FOR_EACH_ENTRY(ttex, &bc->cf_last->tex, list) {
			if (ttex->dst_gpr == ntex->src_gpr) {
				bc->force_add_cf = 1;
				break;
			}
		}
		/* slight hack to make gradients always go into same cf */
		if (ntex->op == FETCH_OP_SET_GRADIENTS_H)
			bc->force_add_cf = 1;
	}

	/* cf can contains only alu or only vtx or only tex */
	if (bc->cf_last == NULL ||
		bc->cf_last->op != CF_OP_TEX ||
	        bc->force_add_cf) {
		r = r600_bytecode_add_cf(bc);
		if (r) {
			free(ntex);
			return r;
		}
		bc->cf_last->op = CF_OP_TEX;
	}
	if (ntex->src_gpr >= bc->ngpr) {
		bc->ngpr = ntex->src_gpr + 1;
	}
	if (ntex->dst_gpr >= bc->ngpr) {
		bc->ngpr = ntex->dst_gpr + 1;
	}
	LIST_ADDTAIL(&ntex->list, &bc->cf_last->tex);
	/* each texture fetch use 4 dwords */
	bc->cf_last->ndw += 4;
	bc->ndw += 4;
	if ((bc->cf_last->ndw / 4) >= r600_bytecode_num_tex_and_vtx_instructions(bc))
		bc->force_add_cf = 1;
	return 0;
}

int r600_bytecode_add_cfinst(struct r600_bytecode *bc, unsigned op)
{
	int r;
	r = r600_bytecode_add_cf(bc);
	if (r)
		return r;

	bc->cf_last->cond = V_SQ_CF_COND_ACTIVE;
	bc->cf_last->op = op;
	return 0;
}

int cm_bytecode_add_cf_end(struct r600_bytecode *bc)
{
	return r600_bytecode_add_cfinst(bc, CF_OP_CF_END);
}

/* common to all 3 families */
static int r600_bytecode_vtx_build(struct r600_bytecode *bc, struct r600_bytecode_vtx *vtx, unsigned id)
{
	bc->bytecode[id] = S_SQ_VTX_WORD0_BUFFER_ID(vtx->buffer_id) |
			S_SQ_VTX_WORD0_FETCH_TYPE(vtx->fetch_type) |
			S_SQ_VTX_WORD0_SRC_GPR(vtx->src_gpr) |
			S_SQ_VTX_WORD0_SRC_SEL_X(vtx->src_sel_x);
	if (bc->chip_class < CAYMAN)
		bc->bytecode[id] |= S_SQ_VTX_WORD0_MEGA_FETCH_COUNT(vtx->mega_fetch_count);
	id++;
	bc->bytecode[id++] = S_SQ_VTX_WORD1_DST_SEL_X(vtx->dst_sel_x) |
				S_SQ_VTX_WORD1_DST_SEL_Y(vtx->dst_sel_y) |
				S_SQ_VTX_WORD1_DST_SEL_Z(vtx->dst_sel_z) |
				S_SQ_VTX_WORD1_DST_SEL_W(vtx->dst_sel_w) |
				S_SQ_VTX_WORD1_USE_CONST_FIELDS(vtx->use_const_fields) |
				S_SQ_VTX_WORD1_DATA_FORMAT(vtx->data_format) |
				S_SQ_VTX_WORD1_NUM_FORMAT_ALL(vtx->num_format_all) |
				S_SQ_VTX_WORD1_FORMAT_COMP_ALL(vtx->format_comp_all) |
				S_SQ_VTX_WORD1_SRF_MODE_ALL(vtx->srf_mode_all) |
				S_SQ_VTX_WORD1_GPR_DST_GPR(vtx->dst_gpr);
	bc->bytecode[id] = S_SQ_VTX_WORD2_OFFSET(vtx->offset)|
				S_SQ_VTX_WORD2_ENDIAN_SWAP(vtx->endian);
	if (bc->chip_class < CAYMAN)
		bc->bytecode[id] |= S_SQ_VTX_WORD2_MEGA_FETCH(1);
	id++;
	bc->bytecode[id++] = 0;
	return 0;
}

/* common to all 3 families */
static int r600_bytecode_tex_build(struct r600_bytecode *bc, struct r600_bytecode_tex *tex, unsigned id)
{
	bc->bytecode[id++] = S_SQ_TEX_WORD0_TEX_INST(
					r600_isa_fetch_opcode(bc->isa->hw_class, tex->op)) |
			    EG_S_SQ_TEX_WORD0_INST_MOD(tex->inst_mod) |
				S_SQ_TEX_WORD0_RESOURCE_ID(tex->resource_id) |
				S_SQ_TEX_WORD0_SRC_GPR(tex->src_gpr) |
				S_SQ_TEX_WORD0_SRC_REL(tex->src_rel);
	bc->bytecode[id++] = S_SQ_TEX_WORD1_DST_GPR(tex->dst_gpr) |
				S_SQ_TEX_WORD1_DST_REL(tex->dst_rel) |
				S_SQ_TEX_WORD1_DST_SEL_X(tex->dst_sel_x) |
				S_SQ_TEX_WORD1_DST_SEL_Y(tex->dst_sel_y) |
				S_SQ_TEX_WORD1_DST_SEL_Z(tex->dst_sel_z) |
				S_SQ_TEX_WORD1_DST_SEL_W(tex->dst_sel_w) |
				S_SQ_TEX_WORD1_LOD_BIAS(tex->lod_bias) |
				S_SQ_TEX_WORD1_COORD_TYPE_X(tex->coord_type_x) |
				S_SQ_TEX_WORD1_COORD_TYPE_Y(tex->coord_type_y) |
				S_SQ_TEX_WORD1_COORD_TYPE_Z(tex->coord_type_z) |
				S_SQ_TEX_WORD1_COORD_TYPE_W(tex->coord_type_w);
	bc->bytecode[id++] = S_SQ_TEX_WORD2_OFFSET_X(tex->offset_x) |
				S_SQ_TEX_WORD2_OFFSET_Y(tex->offset_y) |
				S_SQ_TEX_WORD2_OFFSET_Z(tex->offset_z) |
				S_SQ_TEX_WORD2_SAMPLER_ID(tex->sampler_id) |
				S_SQ_TEX_WORD2_SRC_SEL_X(tex->src_sel_x) |
				S_SQ_TEX_WORD2_SRC_SEL_Y(tex->src_sel_y) |
				S_SQ_TEX_WORD2_SRC_SEL_Z(tex->src_sel_z) |
				S_SQ_TEX_WORD2_SRC_SEL_W(tex->src_sel_w);
	bc->bytecode[id++] = 0;
	return 0;
}

/* r600 only, r700/eg bits in r700_asm.c */
static int r600_bytecode_alu_build(struct r600_bytecode *bc, struct r600_bytecode_alu *alu, unsigned id)
{
	unsigned opcode = r600_isa_alu_opcode(bc->isa->hw_class, alu->op);

	/* don't replace gpr by pv or ps for destination register */
	bc->bytecode[id++] = S_SQ_ALU_WORD0_SRC0_SEL(alu->src[0].sel) |
				S_SQ_ALU_WORD0_SRC0_REL(alu->src[0].rel) |
				S_SQ_ALU_WORD0_SRC0_CHAN(alu->src[0].chan) |
				S_SQ_ALU_WORD0_SRC0_NEG(alu->src[0].neg) |
				S_SQ_ALU_WORD0_SRC1_SEL(alu->src[1].sel) |
				S_SQ_ALU_WORD0_SRC1_REL(alu->src[1].rel) |
				S_SQ_ALU_WORD0_SRC1_CHAN(alu->src[1].chan) |
				S_SQ_ALU_WORD0_SRC1_NEG(alu->src[1].neg) |
				S_SQ_ALU_WORD0_INDEX_MODE(alu->index_mode) |
				S_SQ_ALU_WORD0_PRED_SEL(alu->pred_sel) |
				S_SQ_ALU_WORD0_LAST(alu->last);

	if (alu->is_op3) {
		bc->bytecode[id++] = S_SQ_ALU_WORD1_DST_GPR(alu->dst.sel) |
					S_SQ_ALU_WORD1_DST_CHAN(alu->dst.chan) |
					S_SQ_ALU_WORD1_DST_REL(alu->dst.rel) |
					S_SQ_ALU_WORD1_CLAMP(alu->dst.clamp) |
					S_SQ_ALU_WORD1_OP3_SRC2_SEL(alu->src[2].sel) |
					S_SQ_ALU_WORD1_OP3_SRC2_REL(alu->src[2].rel) |
					S_SQ_ALU_WORD1_OP3_SRC2_CHAN(alu->src[2].chan) |
					S_SQ_ALU_WORD1_OP3_SRC2_NEG(alu->src[2].neg) |
					S_SQ_ALU_WORD1_OP3_ALU_INST(opcode) |
					S_SQ_ALU_WORD1_BANK_SWIZZLE(alu->bank_swizzle);
	} else {
		bc->bytecode[id++] = S_SQ_ALU_WORD1_DST_GPR(alu->dst.sel) |
					S_SQ_ALU_WORD1_DST_CHAN(alu->dst.chan) |
					S_SQ_ALU_WORD1_DST_REL(alu->dst.rel) |
					S_SQ_ALU_WORD1_CLAMP(alu->dst.clamp) |
					S_SQ_ALU_WORD1_OP2_SRC0_ABS(alu->src[0].abs) |
					S_SQ_ALU_WORD1_OP2_SRC1_ABS(alu->src[1].abs) |
					S_SQ_ALU_WORD1_OP2_WRITE_MASK(alu->dst.write) |
					S_SQ_ALU_WORD1_OP2_OMOD(alu->omod) |
					S_SQ_ALU_WORD1_OP2_ALU_INST(opcode) |
					S_SQ_ALU_WORD1_BANK_SWIZZLE(alu->bank_swizzle) |
					S_SQ_ALU_WORD1_OP2_UPDATE_EXECUTE_MASK(alu->execute_mask) |
					S_SQ_ALU_WORD1_OP2_UPDATE_PRED(alu->update_pred);
	}
	return 0;
}

static void r600_bytecode_cf_vtx_build(uint32_t *bytecode, const struct r600_bytecode_cf *cf)
{
	*bytecode++ = S_SQ_CF_WORD0_ADDR(cf->addr >> 1);
	*bytecode++ = S_SQ_CF_WORD1_CF_INST(r600_isa_cf_opcode(ISA_CC_R600, cf->op)) |
			S_SQ_CF_WORD1_BARRIER(1) |
			S_SQ_CF_WORD1_COUNT((cf->ndw / 4) - 1);
}

/* common for r600/r700 - eg in eg_asm.c */
static int r600_bytecode_cf_build(struct r600_bytecode *bc, struct r600_bytecode_cf *cf)
{
	unsigned id = cf->id;
	const struct cf_op_info *cfop = r600_isa_cf(cf->op);
	unsigned opcode = r600_isa_cf_opcode(bc->isa->hw_class, cf->op);


	if (cf->op == CF_NATIVE) {
		bc->bytecode[id++] = cf->isa[0];
		bc->bytecode[id++] = cf->isa[1];
	} else if (cfop->flags & CF_ALU) {
		bc->bytecode[id++] = S_SQ_CF_ALU_WORD0_ADDR(cf->addr >> 1) |
			S_SQ_CF_ALU_WORD0_KCACHE_MODE0(cf->kcache[0].mode) |
			S_SQ_CF_ALU_WORD0_KCACHE_BANK0(cf->kcache[0].bank) |
			S_SQ_CF_ALU_WORD0_KCACHE_BANK1(cf->kcache[1].bank);

		bc->bytecode[id++] = S_SQ_CF_ALU_WORD1_CF_INST(opcode) |
			S_SQ_CF_ALU_WORD1_KCACHE_MODE1(cf->kcache[1].mode) |
			S_SQ_CF_ALU_WORD1_KCACHE_ADDR0(cf->kcache[0].addr) |
			S_SQ_CF_ALU_WORD1_KCACHE_ADDR1(cf->kcache[1].addr) |
					S_SQ_CF_ALU_WORD1_BARRIER(1) |
					S_SQ_CF_ALU_WORD1_USES_WATERFALL(bc->chip_class == R600 ? cf->r6xx_uses_waterfall : 0) |
					S_SQ_CF_ALU_WORD1_COUNT((cf->ndw / 2) - 1);
	} else if (cfop->flags & CF_FETCH) {
		if (bc->chip_class == R700)
			r700_bytecode_cf_vtx_build(&bc->bytecode[id], cf);
		else
			r600_bytecode_cf_vtx_build(&bc->bytecode[id], cf);
	} else if (cfop->flags & CF_EXP) {
		bc->bytecode[id++] = S_SQ_CF_ALLOC_EXPORT_WORD0_RW_GPR(cf->output.gpr) |
			S_SQ_CF_ALLOC_EXPORT_WORD0_ELEM_SIZE(cf->output.elem_size) |
			S_SQ_CF_ALLOC_EXPORT_WORD0_ARRAY_BASE(cf->output.array_base) |
			S_SQ_CF_ALLOC_EXPORT_WORD0_TYPE(cf->output.type) |
			S_SQ_CF_ALLOC_EXPORT_WORD0_INDEX_GPR(cf->output.index_gpr);
		bc->bytecode[id++] = S_SQ_CF_ALLOC_EXPORT_WORD1_BURST_COUNT(cf->output.burst_count - 1) |
			S_SQ_CF_ALLOC_EXPORT_WORD1_SWIZ_SEL_X(cf->output.swizzle_x) |
			S_SQ_CF_ALLOC_EXPORT_WORD1_SWIZ_SEL_Y(cf->output.swizzle_y) |
			S_SQ_CF_ALLOC_EXPORT_WORD1_SWIZ_SEL_Z(cf->output.swizzle_z) |
			S_SQ_CF_ALLOC_EXPORT_WORD1_SWIZ_SEL_W(cf->output.swizzle_w) |
			S_SQ_CF_ALLOC_EXPORT_WORD1_BARRIER(cf->barrier) |
			S_SQ_CF_ALLOC_EXPORT_WORD1_CF_INST(opcode) |
			S_SQ_CF_ALLOC_EXPORT_WORD1_END_OF_PROGRAM(cf->end_of_program);
	} else if (cfop->flags & CF_MEM) {
		bc->bytecode[id++] = S_SQ_CF_ALLOC_EXPORT_WORD0_RW_GPR(cf->output.gpr) |
			S_SQ_CF_ALLOC_EXPORT_WORD0_ELEM_SIZE(cf->output.elem_size) |
			S_SQ_CF_ALLOC_EXPORT_WORD0_ARRAY_BASE(cf->output.array_base) |
			S_SQ_CF_ALLOC_EXPORT_WORD0_TYPE(cf->output.type) |
			S_SQ_CF_ALLOC_EXPORT_WORD0_INDEX_GPR(cf->output.index_gpr);
		bc->bytecode[id++] = S_SQ_CF_ALLOC_EXPORT_WORD1_BURST_COUNT(cf->output.burst_count - 1) |
			S_SQ_CF_ALLOC_EXPORT_WORD1_BARRIER(cf->barrier) |
			S_SQ_CF_ALLOC_EXPORT_WORD1_CF_INST(opcode) |
			S_SQ_CF_ALLOC_EXPORT_WORD1_END_OF_PROGRAM(cf->end_of_program) |
			S_SQ_CF_ALLOC_EXPORT_WORD1_BUF_ARRAY_SIZE(cf->output.array_size) |
			S_SQ_CF_ALLOC_EXPORT_WORD1_BUF_COMP_MASK(cf->output.comp_mask);
	} else {
		bc->bytecode[id++] = S_SQ_CF_WORD0_ADDR(cf->cf_addr >> 1);
		bc->bytecode[id++] = S_SQ_CF_WORD1_CF_INST(opcode) |
					S_SQ_CF_WORD1_BARRIER(1) |
			                S_SQ_CF_WORD1_COND(cf->cond) |
			                S_SQ_CF_WORD1_POP_COUNT(cf->pop_count) |
					S_SQ_CF_WORD1_END_OF_PROGRAM(cf->end_of_program);
	}
	return 0;
}

int r600_bytecode_build(struct r600_bytecode *bc)
{
	struct r600_bytecode_cf *cf;
	struct r600_bytecode_alu *alu;
	struct r600_bytecode_vtx *vtx;
	struct r600_bytecode_tex *tex;
	uint32_t literal[4];
	unsigned nliteral;
	unsigned addr;
	int i, r;

	if (!bc->nstack) // If not 0, Stack_size already provided by llvm
		bc->nstack = bc->stack.max_entries;

	if (bc->type == TGSI_PROCESSOR_VERTEX && !bc->nstack) {
		bc->nstack = 1;
	}

	/* first path compute addr of each CF block */
	/* addr start after all the CF instructions */
	addr = bc->cf_last->id + 2;
	LIST_FOR_EACH_ENTRY(cf, &bc->cf, list) {
		if (r600_isa_cf(cf->op)->flags & CF_FETCH) {
			addr += 3;
			addr &= 0xFFFFFFFCUL;
		}
		cf->addr = addr;
		addr += cf->ndw;
		bc->ndw = cf->addr + cf->ndw;
	}
	free(bc->bytecode);
	bc->bytecode = calloc(1, bc->ndw * 4);
	if (bc->bytecode == NULL)
		return -ENOMEM;
	LIST_FOR_EACH_ENTRY(cf, &bc->cf, list) {
		const struct cf_op_info *cfop = r600_isa_cf(cf->op);
		addr = cf->addr;
		if (bc->chip_class >= EVERGREEN)
			r = eg_bytecode_cf_build(bc, cf);
		else
			r = r600_bytecode_cf_build(bc, cf);
		if (r)
			return r;
		if (cfop->flags & CF_ALU) {
			nliteral = 0;
			memset(literal, 0, sizeof(literal));
			LIST_FOR_EACH_ENTRY(alu, &cf->alu, list) {
				r = r600_bytecode_alu_nliterals(bc, alu, literal, &nliteral);
				if (r)
					return r;
				r600_bytecode_alu_adjust_literals(bc, alu, literal, nliteral);
				r600_bytecode_assign_kcache_banks(bc, alu, cf->kcache);

				switch(bc->chip_class) {
				case R600:
					r = r600_bytecode_alu_build(bc, alu, addr);
					break;
				case R700:
				case EVERGREEN: /* eg alu is same encoding as r700 */
				case CAYMAN:
					r = r700_bytecode_alu_build(bc, alu, addr);
					break;
				default:
					R600_ERR("unknown chip class %d.\n", bc->chip_class);
					return -EINVAL;
				}
				if (r)
					return r;
				addr += 2;
				if (alu->last) {
					for (i = 0; i < align(nliteral, 2); ++i) {
						bc->bytecode[addr++] = literal[i];
					}
					nliteral = 0;
					memset(literal, 0, sizeof(literal));
				}
			}
		} else if (cf->op == CF_OP_VTX) {
			LIST_FOR_EACH_ENTRY(vtx, &cf->vtx, list) {
				r = r600_bytecode_vtx_build(bc, vtx, addr);
				if (r)
					return r;
				addr += 4;
			}
		} else if (cf->op == CF_OP_TEX) {
			LIST_FOR_EACH_ENTRY(vtx, &cf->vtx, list) {
				assert(bc->chip_class >= EVERGREEN);
				r = r600_bytecode_vtx_build(bc, vtx, addr);
				if (r)
					return r;
				addr += 4;
			}
			LIST_FOR_EACH_ENTRY(tex, &cf->tex, list) {
				r = r600_bytecode_tex_build(bc, tex, addr);
				if (r)
					return r;
				addr += 4;
			}
		}
	}
	return 0;
}

void r600_bytecode_clear(struct r600_bytecode *bc)
{
	struct r600_bytecode_cf *cf = NULL, *next_cf;

	free(bc->bytecode);
	bc->bytecode = NULL;

	LIST_FOR_EACH_ENTRY_SAFE(cf, next_cf, &bc->cf, list) {
		struct r600_bytecode_alu *alu = NULL, *next_alu;
		struct r600_bytecode_tex *tex = NULL, *next_tex;
		struct r600_bytecode_tex *vtx = NULL, *next_vtx;

		LIST_FOR_EACH_ENTRY_SAFE(alu, next_alu, &cf->alu, list) {
			free(alu);
		}

		LIST_INITHEAD(&cf->alu);

		LIST_FOR_EACH_ENTRY_SAFE(tex, next_tex, &cf->tex, list) {
			free(tex);
		}

		LIST_INITHEAD(&cf->tex);

		LIST_FOR_EACH_ENTRY_SAFE(vtx, next_vtx, &cf->vtx, list) {
			free(vtx);
		}

		LIST_INITHEAD(&cf->vtx);

		free(cf);
	}

	LIST_INITHEAD(&cf->list);
}

static int print_swizzle(unsigned swz)
{
	const char * swzchars = "xyzw01?_";
	assert(swz<8 && swz != 6);
	return fprintf(stderr, "%c", swzchars[swz]);
}

static int print_sel(unsigned sel, unsigned rel, unsigned index_mode,
		unsigned need_brackets)
{
	int o = 0;
	if (rel && index_mode >= 5 && sel < 128)
		o += fprintf(stderr, "G");
	if (rel || need_brackets) {
		o += fprintf(stderr, "[");
	}
	o += fprintf(stderr, "%d", sel);
	if (rel) {
		if (index_mode == 0 || index_mode == 6)
			o += fprintf(stderr, "+AR");
		else if (index_mode == 4)
			o += fprintf(stderr, "+AL");
	}
	if (rel || need_brackets) {
		o += fprintf(stderr, "]");
	}
	return o;
}

static int print_dst(struct r600_bytecode_alu *alu)
{
	int o = 0;
	unsigned sel = alu->dst.sel;
	char reg_char = 'R';
	if (sel > 128 - 4) { /* clause temporary gpr */
		sel -= 128 - 4;
		reg_char = 'T';
	}

	if (alu->dst.write || alu->is_op3) {
		o += fprintf(stderr, "%c", reg_char);
		o += print_sel(alu->dst.sel, alu->dst.rel, alu->index_mode, 0);
	} else {
		o += fprintf(stderr, "__");
	}
	o += fprintf(stderr, ".");
	o += print_swizzle(alu->dst.chan);
	return o;
}

static int print_src(struct r600_bytecode_alu *alu, unsigned idx)
{
	int o = 0;
	struct r600_bytecode_alu_src *src = &alu->src[idx];
	unsigned sel = src->sel, need_sel = 1, need_chan = 1, need_brackets = 0;

	if (src->neg)
		o += fprintf(stderr,"-");
	if (src->abs)
		o += fprintf(stderr,"|");

	if (sel < 128 - 4) {
		o += fprintf(stderr, "R");
	} else if (sel < 128) {
		o += fprintf(stderr, "T");
		sel -= 128 - 4;
	} else if (sel < 160) {
		o += fprintf(stderr, "KC0");
		need_brackets = 1;
		sel -= 128;
	} else if (sel < 192) {
		o += fprintf(stderr, "KC1");
		need_brackets = 1;
		sel -= 160;
	} else if (sel >= 512) {
		o += fprintf(stderr, "C%d", src->kc_bank);
		need_brackets = 1;
		sel -= 512;
	} else if (sel >= 448) {
		o += fprintf(stderr, "Param");
		sel -= 448;
		need_chan = 0;
	} else if (sel >= 288) {
		o += fprintf(stderr, "KC3");
		need_brackets = 1;
		sel -= 288;
	} else if (sel >= 256) {
		o += fprintf(stderr, "KC2");
		need_brackets = 1;
		sel -= 256;
	} else {
		need_sel = 0;
		need_chan = 0;
		switch (sel) {
		case V_SQ_ALU_SRC_PS:
			o += fprintf(stderr, "PS");
			break;
		case V_SQ_ALU_SRC_PV:
			o += fprintf(stderr, "PV");
			need_chan = 1;
			break;
		case V_SQ_ALU_SRC_LITERAL:
			o += fprintf(stderr, "[0x%08X %f]", src->value, *(float*)&src->value);
			break;
		case V_SQ_ALU_SRC_0_5:
			o += fprintf(stderr, "0.5");
			break;
		case V_SQ_ALU_SRC_M_1_INT:
			o += fprintf(stderr, "-1");
			break;
		case V_SQ_ALU_SRC_1_INT:
			o += fprintf(stderr, "1");
			break;
		case V_SQ_ALU_SRC_1:
			o += fprintf(stderr, "1.0");
			break;
		case V_SQ_ALU_SRC_0:
			o += fprintf(stderr, "0");
			break;
		default:
			o += fprintf(stderr, "??IMM_%d", sel);
			break;
		}
	}

	if (need_sel)
		o += print_sel(sel, src->rel, alu->index_mode, need_brackets);

	if (need_chan) {
		o += fprintf(stderr, ".");
		o += print_swizzle(src->chan);
	}

	if (src->abs)
		o += fprintf(stderr,"|");

	return o;
}

static int print_indent(int p, int c)
{
	int o = 0;
	while (p++ < c)
		o += fprintf(stderr, " ");
	return o;
}

void r600_bytecode_disasm(struct r600_bytecode *bc)
{
	static int index = 0;
	struct r600_bytecode_cf *cf = NULL;
	struct r600_bytecode_alu *alu = NULL;
	struct r600_bytecode_vtx *vtx = NULL;
	struct r600_bytecode_tex *tex = NULL;

	unsigned i, id, ngr = 0, last;
	uint32_t literal[4];
	unsigned nliteral;
	char chip = '6';

	switch (bc->chip_class) {
	case R700:
		chip = '7';
		break;
	case EVERGREEN:
		chip = 'E';
		break;
	case CAYMAN:
		chip = 'C';
		break;
	case R600:
	default:
		chip = '6';
		break;
	}
	fprintf(stderr, "bytecode %d dw -- %d gprs -- %d nstack -------------\n",
	        bc->ndw, bc->ngpr, bc->nstack);
	fprintf(stderr, "shader %d -- %c\n", index++, chip);

	LIST_FOR_EACH_ENTRY(cf, &bc->cf, list) {
		id = cf->id;
		if (cf->op == CF_NATIVE) {
			fprintf(stderr, "%04d %08X %08X CF_NATIVE\n", id, bc->bytecode[id],
					bc->bytecode[id + 1]);
		} else {
			const struct cf_op_info *cfop = r600_isa_cf(cf->op);
			if (cfop->flags & CF_ALU) {
				if (cf->eg_alu_extended) {
					fprintf(stderr, "%04d %08X %08X  %s\n", id, bc->bytecode[id],
							bc->bytecode[id + 1], "ALU_EXT");
					id += 2;
				}
				fprintf(stderr, "%04d %08X %08X  %s ", id, bc->bytecode[id],
						bc->bytecode[id + 1], cfop->name);
				fprintf(stderr, "%d @@%d ", cf->ndw / 2, cf->addr);
				for (i = 0; i < 4; ++i) {
					if (cf->kcache[i].mode) {
						int c_start = (cf->kcache[i].addr << 4);
						int c_end = c_start + (cf->kcache[i].mode << 4);
						fprintf(stderr, "KC%d[CB%d:%d-%d] ",
						        i, cf->kcache[i].bank, c_start, c_end);
					}
				}
				fprintf(stderr, "\n");
			} else if (cfop->flags & CF_FETCH) {
				fprintf(stderr, "%04d %08X %08X  %s ", id, bc->bytecode[id],
						bc->bytecode[id + 1], cfop->name);
				fprintf(stderr, "%d @@%d ", cf->ndw / 4, cf->addr);
				fprintf(stderr, "\n");
			} else if (cfop->flags & CF_EXP) {
				int o = 0;
				const char *exp_type[] = {"PIXEL", "POS  ", "PARAM"};
				o += fprintf(stderr, "%04d %08X %08X  %s ", id, bc->bytecode[id],
						bc->bytecode[id + 1], cfop->name);
				o += print_indent(o, 43);
				o += fprintf(stderr, "%s ", exp_type[cf->output.type]);
				if (cf->output.burst_count > 1) {
					o += fprintf(stderr, "%d-%d ", cf->output.array_base,
							cf->output.array_base + cf->output.burst_count - 1);

					o += print_indent(o, 55);
					o += fprintf(stderr, "R%d-%d.", cf->output.gpr,
							cf->output.gpr + cf->output.burst_count - 1);
				} else {
					o += fprintf(stderr, "%d ", cf->output.array_base);
					o += print_indent(o, 55);
					o += fprintf(stderr, "R%d.", cf->output.gpr);
				}

				o += print_swizzle(cf->output.swizzle_x);
				o += print_swizzle(cf->output.swizzle_y);
				o += print_swizzle(cf->output.swizzle_z);
				o += print_swizzle(cf->output.swizzle_w);

				print_indent(o, 67);

				fprintf(stderr, " ES:%X ", cf->output.elem_size);
				if (!cf->barrier)
					fprintf(stderr, "NO_BARRIER ");
				if (cf->end_of_program)
					fprintf(stderr, "EOP ");
				fprintf(stderr, "\n");
			} else if (r600_isa_cf(cf->op)->flags & CF_MEM) {
				int o = 0;
				const char *exp_type[] = {"WRITE", "WRITE_IND", "WRITE_ACK",
						"WRITE_IND_ACK"};
				o += fprintf(stderr, "%04d %08X %08X  %s ", id,
						bc->bytecode[id], bc->bytecode[id + 1], cfop->name);
				o += print_indent(o, 43);
				o += fprintf(stderr, "%s ", exp_type[cf->output.type]);
				if (cf->output.burst_count > 1) {
					o += fprintf(stderr, "%d-%d ", cf->output.array_base,
							cf->output.array_base + cf->output.burst_count - 1);
					o += print_indent(o, 55);
					o += fprintf(stderr, "R%d-%d.", cf->output.gpr,
							cf->output.gpr + cf->output.burst_count - 1);
				} else {
					o += fprintf(stderr, "%d ", cf->output.array_base);
					o += print_indent(o, 55);
					o += fprintf(stderr, "R%d.", cf->output.gpr);
				}
				for (i = 0; i < 4; ++i) {
					if (cf->output.comp_mask & (1 << i))
						o += print_swizzle(i);
					else
						o += print_swizzle(7);
				}

				if (cf->output.type == V_SQ_CF_ALLOC_EXPORT_WORD0_SQ_EXPORT_WRITE_IND)
					o += fprintf(stderr, " R%d", cf->output.index_gpr);

				o += print_indent(o, 67);

				fprintf(stderr, " ES:%i ", cf->output.elem_size);
				if (cf->output.array_size != 0xFFF)
					fprintf(stderr, "AS:%i ", cf->output.array_size);
				if (!cf->barrier)
					fprintf(stderr, "NO_BARRIER ");
				if (cf->end_of_program)
					fprintf(stderr, "EOP ");
				fprintf(stderr, "\n");
			} else {
				fprintf(stderr, "%04d %08X %08X  %s ", id, bc->bytecode[id],
						bc->bytecode[id + 1], cfop->name);
				fprintf(stderr, "@@%d ", cf->cf_addr);
				if (cf->cond)
					fprintf(stderr, "CND:%X ", cf->cond);
				if (cf->pop_count)
					fprintf(stderr, "POP:%X ", cf->pop_count);
				fprintf(stderr, "\n");
			}
		}

		id = cf->addr;
		nliteral = 0;
		last = 1;
		LIST_FOR_EACH_ENTRY(alu, &cf->alu, list) {
			const char *omod_str[] = {"","*2","*4","/2"};
			const struct alu_op_info *aop = r600_isa_alu(alu->op);
			int o = 0;

			r600_bytecode_alu_nliterals(bc, alu, literal, &nliteral);
			o += fprintf(stderr, " %04d %08X %08X  ", id, bc->bytecode[id], bc->bytecode[id+1]);
			if (last)
				o += fprintf(stderr, "%4d ", ++ngr);
			else
				o += fprintf(stderr, "     ");
			o += fprintf(stderr, "%c%c %c ", alu->execute_mask ? 'M':' ',
					alu->update_pred ? 'P':' ',
					alu->pred_sel ? alu->pred_sel==2 ? '0':'1':' ');

			o += fprintf(stderr, "%s%s%s ", aop->name,
					omod_str[alu->omod], alu->dst.clamp ? "_sat":"");

			o += print_indent(o,60);
			o += print_dst(alu);
			for (i = 0; i < aop->src_count; ++i) {
				o += fprintf(stderr, i == 0 ? ",  ": ", ");
				o += print_src(alu, i);
			}

			if (alu->bank_swizzle) {
				o += print_indent(o,75);
				o += fprintf(stderr, "  BS:%d", alu->bank_swizzle);
			}

			fprintf(stderr, "\n");
			id += 2;

			if (alu->last) {
				for (i = 0; i < nliteral; i++, id++) {
					float *f = (float*)(bc->bytecode + id);
					o = fprintf(stderr, " %04d %08X", id, bc->bytecode[id]);
					print_indent(o, 60);
					fprintf(stderr, " %f (%d)\n", *f, *(bc->bytecode + id));
				}
				id += nliteral & 1;
				nliteral = 0;
			}
			last = alu->last;
		}

		LIST_FOR_EACH_ENTRY(tex, &cf->tex, list) {
			int o = 0;
			o += fprintf(stderr, " %04d %08X %08X %08X   ", id, bc->bytecode[id],
					bc->bytecode[id + 1], bc->bytecode[id + 2]);

			o += fprintf(stderr, "%s ", r600_isa_fetch(tex->op)->name);

			o += print_indent(o, 50);

			o += fprintf(stderr, "R%d.", tex->dst_gpr);
			o += print_swizzle(tex->dst_sel_x);
			o += print_swizzle(tex->dst_sel_y);
			o += print_swizzle(tex->dst_sel_z);
			o += print_swizzle(tex->dst_sel_w);

			o += fprintf(stderr, ", R%d.", tex->src_gpr);
			o += print_swizzle(tex->src_sel_x);
			o += print_swizzle(tex->src_sel_y);
			o += print_swizzle(tex->src_sel_z);
			o += print_swizzle(tex->src_sel_w);

			o += fprintf(stderr, ",  RID:%d", tex->resource_id);
			o += fprintf(stderr, ", SID:%d  ", tex->sampler_id);

			if (tex->lod_bias)
				fprintf(stderr, "LB:%d ", tex->lod_bias);

			fprintf(stderr, "CT:%c%c%c%c ",
					tex->coord_type_x ? 'N' : 'U',
					tex->coord_type_y ? 'N' : 'U',
					tex->coord_type_z ? 'N' : 'U',
					tex->coord_type_w ? 'N' : 'U');

			if (tex->offset_x)
				fprintf(stderr, "OX:%d ", tex->offset_x);
			if (tex->offset_y)
				fprintf(stderr, "OY:%d ", tex->offset_y);
			if (tex->offset_z)
				fprintf(stderr, "OZ:%d ", tex->offset_z);

			id += 4;
			fprintf(stderr, "\n");
		}

		LIST_FOR_EACH_ENTRY(vtx, &cf->vtx, list) {
			int o = 0;
			const char * fetch_type[] = {"VERTEX", "INSTANCE", ""};
			o += fprintf(stderr, " %04d %08X %08X %08X   ", id, bc->bytecode[id],
					bc->bytecode[id + 1], bc->bytecode[id + 2]);

			o += fprintf(stderr, "%s ", r600_isa_fetch(vtx->op)->name);

			o += print_indent(o, 50);

			o += fprintf(stderr, "R%d.", vtx->dst_gpr);
			o += print_swizzle(vtx->dst_sel_x);
			o += print_swizzle(vtx->dst_sel_y);
			o += print_swizzle(vtx->dst_sel_z);
			o += print_swizzle(vtx->dst_sel_w);

			o += fprintf(stderr, ", R%d.", vtx->src_gpr);
			o += print_swizzle(vtx->src_sel_x);

			if (vtx->offset)
				fprintf(stderr, " +%db", vtx->offset);

			o += print_indent(o, 55);

			fprintf(stderr, ",  RID:%d ", vtx->buffer_id);

			fprintf(stderr, "%s ", fetch_type[vtx->fetch_type]);

			if (bc->chip_class < CAYMAN && vtx->mega_fetch_count)
				fprintf(stderr, "MFC:%d ", vtx->mega_fetch_count);

			fprintf(stderr, "UCF:%d ", vtx->use_const_fields);
			fprintf(stderr, "FMT(DTA:%d ", vtx->data_format);
			fprintf(stderr, "NUM:%d ", vtx->num_format_all);
			fprintf(stderr, "COMP:%d ", vtx->format_comp_all);
			fprintf(stderr, "MODE:%d)\n", vtx->srf_mode_all);

			id += 4;
		}
	}

	fprintf(stderr, "--------------------------------------\n");
}

void r600_vertex_data_type(enum pipe_format pformat,
				  unsigned *format,
				  unsigned *num_format, unsigned *format_comp, unsigned *endian)
{
	const struct util_format_description *desc;
	unsigned i;

	*format = 0;
	*num_format = 0;
	*format_comp = 0;
	*endian = ENDIAN_NONE;

	if (pformat == PIPE_FORMAT_R11G11B10_FLOAT) {
		*format = FMT_10_11_11_FLOAT;
		*endian = r600_endian_swap(32);
		return;
	}

	desc = util_format_description(pformat);
	if (desc->layout != UTIL_FORMAT_LAYOUT_PLAIN) {
		goto out_unknown;
	}

	/* Find the first non-VOID channel. */
	for (i = 0; i < 4; i++) {
		if (desc->channel[i].type != UTIL_FORMAT_TYPE_VOID) {
			break;
		}
	}

	*endian = r600_endian_swap(desc->channel[i].size);

	switch (desc->channel[i].type) {
	/* Half-floats, floats, ints */
	case UTIL_FORMAT_TYPE_FLOAT:
		switch (desc->channel[i].size) {
		case 16:
			switch (desc->nr_channels) {
			case 1:
				*format = FMT_16_FLOAT;
				break;
			case 2:
				*format = FMT_16_16_FLOAT;
				break;
			case 3:
			case 4:
				*format = FMT_16_16_16_16_FLOAT;
				break;
			}
			break;
		case 32:
			switch (desc->nr_channels) {
			case 1:
				*format = FMT_32_FLOAT;
				break;
			case 2:
				*format = FMT_32_32_FLOAT;
				break;
			case 3:
				*format = FMT_32_32_32_FLOAT;
				break;
			case 4:
				*format = FMT_32_32_32_32_FLOAT;
				break;
			}
			break;
		default:
			goto out_unknown;
		}
		break;
		/* Unsigned ints */
	case UTIL_FORMAT_TYPE_UNSIGNED:
		/* Signed ints */
	case UTIL_FORMAT_TYPE_SIGNED:
		switch (desc->channel[i].size) {
		case 8:
			switch (desc->nr_channels) {
			case 1:
				*format = FMT_8;
				break;
			case 2:
				*format = FMT_8_8;
				break;
			case 3:
			case 4:
				*format = FMT_8_8_8_8;
				break;
			}
			break;
		case 10:
			if (desc->nr_channels != 4)
				goto out_unknown;

			*format = FMT_2_10_10_10;
			break;
		case 16:
			switch (desc->nr_channels) {
			case 1:
				*format = FMT_16;
				break;
			case 2:
				*format = FMT_16_16;
				break;
			case 3:
			case 4:
				*format = FMT_16_16_16_16;
				break;
			}
			break;
		case 32:
			switch (desc->nr_channels) {
			case 1:
				*format = FMT_32;
				break;
			case 2:
				*format = FMT_32_32;
				break;
			case 3:
				*format = FMT_32_32_32;
				break;
			case 4:
				*format = FMT_32_32_32_32;
				break;
			}
			break;
		default:
			goto out_unknown;
		}
		break;
	default:
		goto out_unknown;
	}

	if (desc->channel[i].type == UTIL_FORMAT_TYPE_SIGNED) {
		*format_comp = 1;
	}

	*num_format = 0;
	if (desc->channel[i].type == UTIL_FORMAT_TYPE_UNSIGNED ||
	    desc->channel[i].type == UTIL_FORMAT_TYPE_SIGNED) {
		if (!desc->channel[i].normalized) {
			if (desc->channel[i].pure_integer)
				*num_format = 1;
			else
				*num_format = 2;
		}
	}
	return;
out_unknown:
	R600_ERR("unsupported vertex format %s\n", util_format_name(pformat));
}

void *r600_create_vertex_fetch_shader(struct pipe_context *ctx,
				      unsigned count,
				      const struct pipe_vertex_element *elements)
{
	struct r600_context *rctx = (struct r600_context *)ctx;
	struct r600_bytecode bc;
	struct r600_bytecode_vtx vtx;
	const struct util_format_description *desc;
	unsigned fetch_resource_start = rctx->b.chip_class >= EVERGREEN ? 0 : 160;
	unsigned format, num_format, format_comp, endian;
	uint32_t *bytecode;
	int i, j, r, fs_size;
	struct r600_fetch_shader *shader;
	unsigned no_sb = rctx->screen->b.debug_flags & DBG_NO_SB;
	unsigned sb_disasm = !no_sb || (rctx->screen->b.debug_flags & DBG_SB_DISASM);

	assert(count < 32);

	memset(&bc, 0, sizeof(bc));
	r600_bytecode_init(&bc, rctx->b.chip_class, rctx->b.family,
			   rctx->screen->has_compressed_msaa_texturing);

	bc.isa = rctx->isa;

	for (i = 0; i < count; i++) {
		if (elements[i].instance_divisor > 1) {
			if (rctx->b.chip_class == CAYMAN) {
				for (j = 0; j < 4; j++) {
					struct r600_bytecode_alu alu;
					memset(&alu, 0, sizeof(alu));
					alu.op = ALU_OP2_MULHI_UINT;
					alu.src[0].sel = 0;
					alu.src[0].chan = 3;
					alu.src[1].sel = V_SQ_ALU_SRC_LITERAL;
					alu.src[1].value = (1ll << 32) / elements[i].instance_divisor + 1;
					alu.dst.sel = i + 1;
					alu.dst.chan = j;
					alu.dst.write = j == 3;
					alu.last = j == 3;
					if ((r = r600_bytecode_add_alu(&bc, &alu))) {
						r600_bytecode_clear(&bc);
						return NULL;
					}
				}
			} else {
				struct r600_bytecode_alu alu;
				memset(&alu, 0, sizeof(alu));
				alu.op = ALU_OP2_MULHI_UINT;
				alu.src[0].sel = 0;
				alu.src[0].chan = 3;
				alu.src[1].sel = V_SQ_ALU_SRC_LITERAL;
				alu.src[1].value = (1ll << 32) / elements[i].instance_divisor + 1;
				alu.dst.sel = i + 1;
				alu.dst.chan = 3;
				alu.dst.write = 1;
				alu.last = 1;
				if ((r = r600_bytecode_add_alu(&bc, &alu))) {
					r600_bytecode_clear(&bc);
					return NULL;
				}
			}
		}
	}

	for (i = 0; i < count; i++) {
		r600_vertex_data_type(elements[i].src_format,
				      &format, &num_format, &format_comp, &endian);

		desc = util_format_description(elements[i].src_format);
		if (desc == NULL) {
			r600_bytecode_clear(&bc);
			R600_ERR("unknown format %d\n", elements[i].src_format);
			return NULL;
		}

		if (elements[i].src_offset > 65535) {
			r600_bytecode_clear(&bc);
			R600_ERR("too big src_offset: %u\n", elements[i].src_offset);
			return NULL;
		}

		memset(&vtx, 0, sizeof(vtx));
		vtx.buffer_id = elements[i].vertex_buffer_index + fetch_resource_start;
		vtx.fetch_type = elements[i].instance_divisor ? 1 : 0;
		vtx.src_gpr = elements[i].instance_divisor > 1 ? i + 1 : 0;
		vtx.src_sel_x = elements[i].instance_divisor ? 3 : 0;
		vtx.mega_fetch_count = 0x1F;
		vtx.dst_gpr = i + 1;
		vtx.dst_sel_x = desc->swizzle[0];
		vtx.dst_sel_y = desc->swizzle[1];
		vtx.dst_sel_z = desc->swizzle[2];
		vtx.dst_sel_w = desc->swizzle[3];
		vtx.data_format = format;
		vtx.num_format_all = num_format;
		vtx.format_comp_all = format_comp;
		vtx.offset = elements[i].src_offset;
		vtx.endian = endian;

		if ((r = r600_bytecode_add_vtx(&bc, &vtx))) {
			r600_bytecode_clear(&bc);
			return NULL;
		}
	}

	r600_bytecode_add_cfinst(&bc, CF_OP_RET);

	if ((r = r600_bytecode_build(&bc))) {
		r600_bytecode_clear(&bc);
		return NULL;
	}

	if (rctx->screen->b.debug_flags & DBG_FS) {
		fprintf(stderr, "--------------------------------------------------------------\n");
		fprintf(stderr, "Vertex elements state:\n");
		for (i = 0; i < count; i++) {
			fprintf(stderr, "   ");
			util_dump_vertex_element(stderr, elements+i);
			fprintf(stderr, "\n");
		}

		if (!sb_disasm) {
			r600_bytecode_disasm(&bc);

			fprintf(stderr, "______________________________________________________________\n");
		} else {
			r600_sb_bytecode_process(rctx, &bc, NULL, 1 /*dump*/, 0 /*optimize*/);
		}
	}

	fs_size = bc.ndw*4;

	/* Allocate the CSO. */
	shader = CALLOC_STRUCT(r600_fetch_shader);
	if (!shader) {
		r600_bytecode_clear(&bc);
		return NULL;
	}

	u_suballocator_alloc(rctx->allocator_fetch_shader, fs_size, &shader->offset,
			     (struct pipe_resource**)&shader->buffer);
	if (!shader->buffer) {
		r600_bytecode_clear(&bc);
		FREE(shader);
		return NULL;
	}

	bytecode = r600_buffer_map_sync_with_rings(&rctx->b, shader->buffer, PIPE_TRANSFER_WRITE | PIPE_TRANSFER_UNSYNCHRONIZED);
	bytecode += shader->offset / 4;

	if (R600_BIG_ENDIAN) {
		for (i = 0; i < fs_size / 4; ++i) {
			bytecode[i] = util_cpu_to_le32(bc.bytecode[i]);
		}
	} else {
		memcpy(bytecode, bc.bytecode, fs_size);
	}
	rctx->b.ws->buffer_unmap(shader->buffer->cs_buf);

	r600_bytecode_clear(&bc);
	return shader;
}

void r600_bytecode_alu_read(struct r600_bytecode *bc,
		struct r600_bytecode_alu *alu, uint32_t word0, uint32_t word1)
{
	/* WORD0 */
	alu->src[0].sel = G_SQ_ALU_WORD0_SRC0_SEL(word0);
	alu->src[0].rel = G_SQ_ALU_WORD0_SRC0_REL(word0);
	alu->src[0].chan = G_SQ_ALU_WORD0_SRC0_CHAN(word0);
	alu->src[0].neg = G_SQ_ALU_WORD0_SRC0_NEG(word0);
	alu->src[1].sel = G_SQ_ALU_WORD0_SRC1_SEL(word0);
	alu->src[1].rel = G_SQ_ALU_WORD0_SRC1_REL(word0);
	alu->src[1].chan = G_SQ_ALU_WORD0_SRC1_CHAN(word0);
	alu->src[1].neg = G_SQ_ALU_WORD0_SRC1_NEG(word0);
	alu->index_mode = G_SQ_ALU_WORD0_INDEX_MODE(word0);
	alu->pred_sel = G_SQ_ALU_WORD0_PRED_SEL(word0);
	alu->last = G_SQ_ALU_WORD0_LAST(word0);

	/* WORD1 */
	alu->bank_swizzle = G_SQ_ALU_WORD1_BANK_SWIZZLE(word1);
	if (alu->bank_swizzle)
		alu->bank_swizzle_force = alu->bank_swizzle;
	alu->dst.sel = G_SQ_ALU_WORD1_DST_GPR(word1);
	alu->dst.rel = G_SQ_ALU_WORD1_DST_REL(word1);
	alu->dst.chan = G_SQ_ALU_WORD1_DST_CHAN(word1);
	alu->dst.clamp = G_SQ_ALU_WORD1_CLAMP(word1);
	if (G_SQ_ALU_WORD1_ENCODING(word1)) /*ALU_DWORD1_OP3*/
	{
		alu->is_op3 = 1;
		alu->src[2].sel = G_SQ_ALU_WORD1_OP3_SRC2_SEL(word1);
		alu->src[2].rel = G_SQ_ALU_WORD1_OP3_SRC2_REL(word1);
		alu->src[2].chan = G_SQ_ALU_WORD1_OP3_SRC2_CHAN(word1);
		alu->src[2].neg = G_SQ_ALU_WORD1_OP3_SRC2_NEG(word1);
		alu->op = r600_isa_alu_by_opcode(bc->isa,
				G_SQ_ALU_WORD1_OP3_ALU_INST(word1), /* is_op3 = */ 1);

	}
	else /*ALU_DWORD1_OP2*/
	{
		alu->src[0].abs = G_SQ_ALU_WORD1_OP2_SRC0_ABS(word1);
		alu->src[1].abs = G_SQ_ALU_WORD1_OP2_SRC1_ABS(word1);
		alu->op = r600_isa_alu_by_opcode(bc->isa,
				G_SQ_ALU_WORD1_OP2_ALU_INST(word1), /* is_op3 = */ 0);
		alu->omod = G_SQ_ALU_WORD1_OP2_OMOD(word1);
		alu->dst.write = G_SQ_ALU_WORD1_OP2_WRITE_MASK(word1);
		alu->update_pred = G_SQ_ALU_WORD1_OP2_UPDATE_PRED(word1);
		alu->execute_mask =
			G_SQ_ALU_WORD1_OP2_UPDATE_EXECUTE_MASK(word1);
	}
}

#if 0
void r600_bytecode_export_read(struct r600_bytecode *bc,
		struct r600_bytecode_output *output, uint32_t word0, uint32_t word1)
{
	output->array_base = G_SQ_CF_ALLOC_EXPORT_WORD0_ARRAY_BASE(word0);
	output->type = G_SQ_CF_ALLOC_EXPORT_WORD0_TYPE(word0);
	output->gpr = G_SQ_CF_ALLOC_EXPORT_WORD0_RW_GPR(word0);
	output->elem_size = G_SQ_CF_ALLOC_EXPORT_WORD0_ELEM_SIZE(word0);

	output->swizzle_x = G_SQ_CF_ALLOC_EXPORT_WORD1_SWIZ_SEL_X(word1);
	output->swizzle_y = G_SQ_CF_ALLOC_EXPORT_WORD1_SWIZ_SEL_Y(word1);
	output->swizzle_z = G_SQ_CF_ALLOC_EXPORT_WORD1_SWIZ_SEL_Z(word1);
	output->swizzle_w = G_SQ_CF_ALLOC_EXPORT_WORD1_SWIZ_SEL_W(word1);
	output->burst_count = G_SQ_CF_ALLOC_EXPORT_WORD1_BURST_COUNT(word1);
	output->end_of_program = G_SQ_CF_ALLOC_EXPORT_WORD1_END_OF_PROGRAM(word1);
    output->op = r600_isa_cf_by_opcode(bc->isa,
			G_SQ_CF_ALLOC_EXPORT_WORD1_CF_INST(word1), 0);
	output->barrier = G_SQ_CF_ALLOC_EXPORT_WORD1_BARRIER(word1);
	output->array_size = G_SQ_CF_ALLOC_EXPORT_WORD1_BUF_ARRAY_SIZE(word1);
	output->comp_mask = G_SQ_CF_ALLOC_EXPORT_WORD1_BUF_COMP_MASK(word1);
}
#endif
@


1.8
log
@Merge Mesa 10.2.9
@
text
@@


1.7
log
@Merge Mesa 10.4.3
Tested by matthieu@@ mpi@@ and myself.  landry@@ ran a ports bulk build.
kettenis@@ tracked down the cause of an alignment fault on archs
that require strict eight byte pointer alignment.
@
text
@a145 1
	bc->family = family;
a820 4
		if (alu->op == ALU_OP0_SET_CF_IDX0 ||
			alu->op == ALU_OP0_SET_CF_IDX1)
			return 0; /* data hazard with MOVA */

d886 1
a886 1
		unsigned bank, unsigned line, unsigned index_mode)
a908 1
				kcache[i].index_mode = index_mode;
a937 1
			kcache[i].index_mode = index_mode;
d951 1
a951 1
		unsigned bank, line, sel = alu->src[i].sel, index_mode;
a957 1
		index_mode = alu->src[i].kc_rel ? 1 : 0; // V_SQ_CF_INDEX_0 / V_SQ_CF_INDEX_NONE
d959 1
a959 1
		if ((r = r600_bytecode_alloc_kcache_line(bc, kcache, bank, line, index_mode)))
d1030 2
a1031 3
	/* if we actually used more than 2 kcache sets, or have relative indexing - use ALU_EXTENDED on eg+ */
	if (kcache[2].mode != V_SQ_CF_KCACHE_NOP ||
		kcache[0].index_mode || kcache[1].index_mode || kcache[2].index_mode || kcache[3].index_mode) {
a1150 7
	/* Load index register if required */
	if (bc->chip_class >= EVERGREEN) {
		for (i = 0; i < 3; i++)
			if (nalu->src[i].kc_bank && nalu->src[i].kc_rel)
				egcm_load_index_reg(bc, 0, true);
	}

a1275 6
	/* Load index register if required */
	if (bc->chip_class >= EVERGREEN) {
		if (vtx->buffer_index_mode)
			egcm_load_index_reg(bc, 0, false);
	}

a1321 6
	/* Load index register if required */
	if (bc->chip_class >= EVERGREEN) {
		if (tex->sampler_index_mode || tex->resource_index_mode)
			egcm_load_index_reg(bc, 1, false);
	}

a1401 2
	if (bc->chip_class >= EVERGREEN)
		bc->bytecode[id] |= ((vtx->buffer_index_mode & 0x3) << 21); // S_SQ_VTX_WORD2_BIM(vtx->buffer_index_mode);
d1412 1
a1412 1
	bc->bytecode[id] = S_SQ_TEX_WORD0_TEX_INST(
a1417 4
	if (bc->chip_class >= EVERGREEN)
		bc->bytecode[id] |= ((tex->sampler_index_mode & 0x3) << 27) | // S_SQ_TEX_WORD0_SIM(tex->sampler_index_mode);
				((tex->resource_index_mode & 0x3) << 25); // S_SQ_TEX_WORD0_RIM(tex->resource_index_mode)
	id++;
d1592 1
a1592 1
	bc->bytecode = calloc(4, bc->ndw);
a1848 1
	const char *index_mode[] = {"CF_INDEX_NONE", "CF_INDEX_0", "CF_INDEX_1"};
d1899 2
a1900 4
						fprintf(stderr, "KC%d[CB%d:%d-%d%s%s] ",
						        i, cf->kcache[i].bank, c_start, c_end,
						        cf->kcache[i].index_mode ? " " : "",
						        cf->kcache[i].index_mode ? index_mode[cf->kcache[i].index_mode] : "");
a2065 3
			if (tex->sampler_index_mode)
				fprintf(stderr, "SQ_%s ", index_mode[tex->sampler_index_mode]);

a2115 3

			if (bc->chip_class >= EVERGREEN && vtx->buffer_index_mode)
				fprintf(stderr, "SQ_%s ", index_mode[vtx->buffer_index_mode]);
@


1.6
log
@Merge Mesa 10.2.7
@
text
@d146 1
d822 4
d891 1
a891 1
		unsigned bank, unsigned line)
d914 1
d944 1
d958 1
a958 1
		unsigned bank, line, sel = alu->src[i].sel;
d965 1
d967 1
a967 1
		if ((r = r600_bytecode_alloc_kcache_line(bc, kcache, bank, line)))
d1038 3
a1040 2
	/* if we actually used more than 2 kcache sets - use ALU_EXTENDED on eg+ */
	if (kcache[2].mode != V_SQ_CF_KCACHE_NOP) {
d1160 7
d1292 6
d1344 6
d1430 2
d1442 1
a1442 1
	bc->bytecode[id++] = S_SQ_TEX_WORD0_TEX_INST(
d1448 4
d1626 1
a1626 1
	bc->bytecode = calloc(1, bc->ndw * 4);
d1883 1
d1934 4
a1937 2
						fprintf(stderr, "KC%d[CB%d:%d-%d] ",
						        i, cf->kcache[i].bank, c_start, c_end);
d2103 3
d2156 3
@


1.5
log
@Merge Mesa 10.2.3
tested by matthieu@@ kettenis@@ mpi@@ brett@@ and myself across a
diverse range of hardware
@
text
@a2376 1
		vtx.srf_mode_all = 1;
@


1.4
log
@Merge Mesa 9.2.0
@
text
@a195 1
			bc->cf_last->output.end_of_program |= output->end_of_program;
a204 1
			bc->cf_last->output.end_of_program |= output->end_of_program;
d216 1
d389 1
a389 1
	return (sel >= 0 && sel <= 127);
d1528 2
a1529 1
			S_SQ_CF_ALLOC_EXPORT_WORD0_TYPE(cf->output.type);
d1535 1
a1535 1
			S_SQ_CF_ALLOC_EXPORT_WORD1_BARRIER(cf->output.barrier) |
d1537 2
a1538 2
			S_SQ_CF_ALLOC_EXPORT_WORD1_END_OF_PROGRAM(cf->output.end_of_program);
	} else if (cfop->flags & CF_STRM) {
d1542 2
a1543 1
			S_SQ_CF_ALLOC_EXPORT_WORD0_TYPE(cf->output.type);
d1545 1
a1545 1
			S_SQ_CF_ALLOC_EXPORT_WORD1_BARRIER(cf->output.barrier) |
d1547 1
a1547 1
			S_SQ_CF_ALLOC_EXPORT_WORD1_END_OF_PROGRAM(cf->output.end_of_program) |
d1555 2
a1556 1
			                S_SQ_CF_WORD1_POP_COUNT(cf->pop_count);
d1937 1
a1937 1
				if (!cf->output.barrier)
d1939 1
a1939 1
				if (cf->output.end_of_program)
d1942 1
a1942 1
			} else if (r600_isa_cf(cf->op)->flags & CF_STRM) {
d1968 3
d1976 1
a1976 1
				if (!cf->output.barrier)
d1978 1
a1978 1
				if (cf->output.end_of_program)
d2142 6
d2290 1
a2290 1
	unsigned fetch_resource_start = rctx->chip_class >= EVERGREEN ? 0 : 160;
d2295 2
a2296 1
	unsigned sb_disasm = rctx->screen->debug_flags & (DBG_SB_DISASM | DBG_SB);
d2301 1
a2301 1
	r600_bytecode_init(&bc, rctx->chip_class, rctx->family,
d2308 1
a2308 1
			if (rctx->chip_class == CAYMAN) {
d2394 1
a2394 1
	if (rctx->screen->debug_flags & DBG_FS) {
d2429 1
a2429 1
	bytecode = r600_buffer_mmap_sync_with_rings(rctx, shader->buffer, PIPE_TRANSFER_WRITE | PIPE_TRANSFER_UNSYNCHRONIZED);
d2434 1
a2434 1
			bytecode[i] = util_bswap32(bc.bytecode[i]);
d2439 1
a2439 1
	rctx->ws->buffer_unmap(shader->buffer->cs_buf);
d2494 1
d2515 1
@


1.3
log
@byteswap.h and bswap_32 aren't portable, replace them with calls to
gallium's util_bswap32 as suggested by kettenis.

already merged upstream
ok kettenis@@
@
text
@d23 6
a28 1
#include <stdio.h>
d30 1
a30 1
#include "util/u_format.h"
d34 2
a35 6
#include "r600_pipe.h"
#include "r600_sq.h"
#include "r600_opcodes.h"
#include "r600_asm.h"
#include "r600_formats.h"
#include "r600d.h"
d40 2
a41 1
static inline unsigned int r600_bc_get_num_operands(struct r600_bc *bc, struct r600_bc_alu *alu)
d43 1
a43 110
	if(alu->is_op3)
		return 3;

	switch (bc->chiprev) {
	case CHIPREV_R600:
	case CHIPREV_R700:
		switch (alu->inst) {
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_NOP:
			return 0;
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_ADD:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_ADD_INT:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLE:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLGT:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLGE:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLNE:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MUL:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MULHI_UINT:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MAX:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MIN:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_SETE:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_SETNE:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_SETGT:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_SETGE:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETE:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGT:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGE:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETNE:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_DOT4:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_DOT4_IEEE:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_CUBE:
			return 2;

		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MOV:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MOVA:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MOVA_FLOOR:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MOVA_INT:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_FRACT:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_FLOOR:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_TRUNC:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_EXP_IEEE:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_LOG_CLAMPED:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_LOG_IEEE:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIP_CLAMPED:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIP_IEEE:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIPSQRT_CLAMPED:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIPSQRT_IEEE:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_FLT_TO_INT:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_INT_TO_FLT:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_SIN:
		case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_COS:
			return 1;
		default: R600_ERR(
			"Need instruction operand number for 0x%x.\n", alu->inst);
		}
		break;
	case CHIPREV_EVERGREEN:
	case CHIPREV_CAYMAN:
		switch (alu->inst) {
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_NOP:
			return 0;
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_ADD:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_ADD_INT:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLE:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLGT:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLGE:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLNE:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MUL:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MULHI_UINT:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MAX:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MIN:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_SETE:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_SETNE:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_SETGT:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_SETGE:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETE:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGT:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGE:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETNE:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_DOT4:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_DOT4_IEEE:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_CUBE:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INTERP_XY:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INTERP_ZW:
			return 2;

		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MOV:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MOVA_INT:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_FRACT:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_FLOOR:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_TRUNC:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_EXP_IEEE:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_LOG_CLAMPED:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_LOG_IEEE:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIP_CLAMPED:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIP_IEEE:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIPSQRT_CLAMPED:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIPSQRT_IEEE:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_FLT_TO_INT:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_FLT_TO_INT_FLOOR:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_INT_TO_FLT:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_SIN:
		case EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_COS:
			return 1;
		default: R600_ERR(
			"Need instruction operand number for 0x%x.\n", alu->inst);
		}
		break;
	}

	return 3;
d46 2
a47 1
int r700_bc_alu_build(struct r600_bc *bc, struct r600_bc_alu *alu, unsigned id);
d49 1
a49 1
static struct r600_bc_cf *r600_bc_cf(void)
d51 1
a51 1
	struct r600_bc_cf *cf = CALLOC_STRUCT(r600_bc_cf);
d62 1
a62 1
static struct r600_bc_alu *r600_bc_alu(void)
d64 1
a64 1
	struct r600_bc_alu *alu = CALLOC_STRUCT(r600_bc_alu);
d72 1
a72 1
static struct r600_bc_vtx *r600_bc_vtx(void)
d74 1
a74 1
	struct r600_bc_vtx *vtx = CALLOC_STRUCT(r600_bc_vtx);
d82 1
a82 1
static struct r600_bc_tex *r600_bc_tex(void)
d84 1
a84 1
	struct r600_bc_tex *tex = CALLOC_STRUCT(r600_bc_tex);
d92 15
a106 6
int r600_bc_init(struct r600_bc *bc, enum radeon_family family)
{
	LIST_INITHEAD(&bc->cf);
	bc->family = family;
	switch (bc->family) {
	case CHIP_R600:
d108 4
a112 2
	case CHIP_RV670:
	case CHIP_RV620:
a113 5
	case CHIP_RS780:
	case CHIP_RS880:
		bc->chiprev = CHIPREV_R600;
		break;
	case CHIP_RV770:
d116 1
a116 3
	case CHIP_RV740:
		bc->chiprev = CHIPREV_R700;
		break;
d118 3
a120 15
	case CHIP_REDWOOD:
	case CHIP_JUNIPER:
	case CHIP_CYPRESS:
	case CHIP_HEMLOCK:
	case CHIP_PALM:
	case CHIP_SUMO:
	case CHIP_SUMO2:
	case CHIP_BARTS:
	case CHIP_TURKS:
	case CHIP_CAICOS:
		bc->chiprev = CHIPREV_EVERGREEN;
		break;
	case CHIP_CAYMAN:
		bc->chiprev = CHIPREV_CAYMAN;
		break;
d122 1
a122 2
		R600_ERR("unknown family %d\n", bc->family);
		return -EINVAL;
a123 1
	return 0;
d126 25
a150 1
static int r600_bc_add_cf(struct r600_bc *bc)
d152 1
a152 1
	struct r600_bc_cf *cf = r600_bc_cf();
d157 1
a157 1
	if (bc->cf_last)
d159 6
d169 1
d173 2
a174 1
int r600_bc_add_output(struct r600_bc *bc, const struct r600_bc_output *output)
d178 6
a183 3
	if (bc->cf_last && (bc->cf_last->inst == output->inst ||
		(bc->cf_last->inst == BC_INST(bc, V_SQ_CF_ALLOC_EXPORT_WORD1_SQ_CF_INST_EXPORT) &&
		output->inst == BC_INST(bc, V_SQ_CF_ALLOC_EXPORT_WORD1_SQ_CF_INST_EXPORT_DONE))) &&
d190 1
d197 1
a197 1
			bc->cf_last->output.inst = output->inst;
d207 1
a207 1
			bc->cf_last->output.inst = output->inst;
d213 1
a213 1
	r = r600_bc_add_cf(bc);
d216 2
a217 2
	bc->cf_last->inst = output->inst;
	memcpy(&bc->cf_last->output, output, sizeof(struct r600_bc_output));
d222 6
a227 1
static int is_alu_once_inst(struct r600_bc *bc, struct r600_bc_alu *alu)
d229 7
a235 77
	switch (bc->chiprev) {
	case CHIPREV_R600:
	case CHIPREV_R700:
		return !alu->is_op3 && (
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLE ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLGT ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLGE ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLNE ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLGT_UINT ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLGE_UINT ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLE_INT ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLGT_INT ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLGE_INT ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLNE_INT ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGT_UINT ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGE_UINT ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETE ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGT ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGE ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETNE ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SET_INV ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SET_POP ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SET_CLR ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SET_RESTORE ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETE_PUSH ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGT_PUSH ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGE_PUSH ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETNE_PUSH ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETE_INT ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGT_INT ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGE_INT ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETNE_INT ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETE_PUSH_INT ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGT_PUSH_INT ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGE_PUSH_INT ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETNE_PUSH_INT ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETLT_PUSH_INT ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETLE_PUSH_INT);
	case CHIPREV_EVERGREEN:
	case CHIPREV_CAYMAN:
	default:
		return !alu->is_op3 && (
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLE ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLGT ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLGE ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLNE ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLGT_UINT ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLGE_UINT ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLE_INT ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLGT_INT ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLGE_INT ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLNE_INT ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGT_UINT ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGE_UINT ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETE ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGT ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGE ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETNE ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SET_INV ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SET_POP ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SET_CLR ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SET_RESTORE ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETE_PUSH ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGT_PUSH ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGE_PUSH ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETNE_PUSH ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETE_INT ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGT_INT ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGE_INT ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETNE_INT ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETE_PUSH_INT ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGT_PUSH_INT ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGE_PUSH_INT ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETNE_PUSH_INT ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETLT_PUSH_INT ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETLE_PUSH_INT);
	}
d238 7
a244 18
static int is_alu_reduction_inst(struct r600_bc *bc, struct r600_bc_alu *alu)
{
	switch (bc->chiprev) {
	case CHIPREV_R600:
	case CHIPREV_R700:
		return !alu->is_op3 && (
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_CUBE ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_DOT4 ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_DOT4_IEEE ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MAX4);
	case CHIPREV_EVERGREEN:
	case CHIPREV_CAYMAN:
	default:
		return !alu->is_op3 && (
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_CUBE ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_DOT4 ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_DOT4_IEEE ||
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MAX4);
a245 1
}
d247 4
a250 12
static int is_alu_cube_inst(struct r600_bc *bc, struct r600_bc_alu *alu)
{
	switch (bc->chiprev) {
	case CHIPREV_R600:
	case CHIPREV_R700:
		return !alu->is_op3 &&
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_CUBE;
	case CHIPREV_EVERGREEN:
	case CHIPREV_CAYMAN:
	default:
		return !alu->is_op3 &&
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_CUBE;
d252 1
d255 1
a255 1
static int is_alu_mova_inst(struct r600_bc *bc, struct r600_bc_alu *alu)
d257 2
a258 13
	switch (bc->chiprev) {
	case CHIPREV_R600:
	case CHIPREV_R700:
		return !alu->is_op3 && (
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MOVA ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MOVA_FLOOR ||
			alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MOVA_INT);
	case CHIPREV_EVERGREEN:
	case CHIPREV_CAYMAN:
	default:
		return !alu->is_op3 && (
			alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MOVA_INT);
	}
d261 1
a261 2
/* alu instructions that can only execute on the vector unit */
static int is_alu_vec_unit_inst(struct r600_bc *bc, struct r600_bc_alu *alu)
d263 2
a264 75
	return is_alu_reduction_inst(bc, alu) ||
		is_alu_mova_inst(bc, alu) ||
		(bc->chiprev == CHIPREV_EVERGREEN &&
		alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_FLT_TO_INT_FLOOR);
}

/* alu instructions that can only execute on the trans unit */
static int is_alu_trans_unit_inst(struct r600_bc *bc, struct r600_bc_alu *alu)
{
	switch (bc->chiprev) {
	case CHIPREV_R600:
	case CHIPREV_R700:
		if (!alu->is_op3)
			return alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_ASHR_INT ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_FLT_TO_INT ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_INT_TO_FLT ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_LSHL_INT ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_LSHR_INT ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MULHI_INT ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MULHI_UINT ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MULLO_INT ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MULLO_UINT ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIP_INT ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIP_UINT ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_UINT_TO_FLT ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_COS ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_EXP_IEEE ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_LOG_CLAMPED ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_LOG_IEEE ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIP_CLAMPED ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIP_FF ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIP_IEEE ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIPSQRT_CLAMPED ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIPSQRT_FF ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIPSQRT_IEEE ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_SIN ||
				alu->inst == V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_SQRT_IEEE;
		else
			return alu->inst == V_SQ_ALU_WORD1_OP3_SQ_OP3_INST_MUL_LIT ||
				alu->inst == V_SQ_ALU_WORD1_OP3_SQ_OP3_INST_MUL_LIT_D2 ||
				alu->inst == V_SQ_ALU_WORD1_OP3_SQ_OP3_INST_MUL_LIT_M2 ||
				alu->inst == V_SQ_ALU_WORD1_OP3_SQ_OP3_INST_MUL_LIT_M4;
	case CHIPREV_EVERGREEN:
	case CHIPREV_CAYMAN:
	default:
		if (!alu->is_op3)
			/* Note that FLT_TO_INT_* instructions are vector-only instructions
			 * on Evergreen, despite what the documentation says. FLT_TO_INT
			 * can do both vector and scalar. */
			return alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_ASHR_INT ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_INT_TO_FLT ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_LSHL_INT ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_LSHR_INT ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MULHI_INT ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MULHI_UINT ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MULLO_INT ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MULLO_UINT ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIP_INT ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIP_UINT ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_UINT_TO_FLT ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_COS ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_EXP_IEEE ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_LOG_CLAMPED ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_LOG_IEEE ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIP_CLAMPED ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIP_FF ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIP_IEEE ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIPSQRT_CLAMPED ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIPSQRT_FF ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIPSQRT_IEEE ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_SIN ||
				alu->inst == EG_V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_SQRT_IEEE;
		else
			return alu->inst == EG_V_SQ_ALU_WORD1_OP3_SQ_OP3_INST_MUL_LIT;
	}
d268 1
a268 1
static int is_alu_any_unit_inst(struct r600_bc *bc, struct r600_bc_alu *alu)
d270 2
a271 2
	return !is_alu_vec_unit_inst(bc, alu) &&
		!is_alu_trans_unit_inst(bc, alu);
d274 7
a280 2
static int assign_alu_units(struct r600_bc *bc, struct r600_bc_alu *alu_first,
			    struct r600_bc_alu *assignment[5])
d282 1
a282 1
	struct r600_bc_alu *alu;
d284 1
a284 1
	int max_slots = bc->chiprev == CHIPREV_CAYMAN ? 4 : 5;
d289 1
a289 1
	for (alu = alu_first; alu; alu = LIST_ENTRY(struct r600_bc_alu, alu->list.next, list)) {
d368 1
a368 1
static int reserve_cfile(struct r600_bc *bc, struct alu_bank_swizzle *bs, unsigned sel, unsigned chan)
d371 1
a371 1
	if (bc->chiprev >= CHIPREV_R700) {
d410 1
a410 1
static int check_vector(struct r600_bc *bc, struct r600_bc_alu *alu,
d415 1
a415 1
	num_src = r600_bc_get_num_operands(bc, alu);
d431 1
a431 1
			r = reserve_cfile(bc, bs, sel, elem);
d440 1
a440 1
static int check_scalar(struct r600_bc *bc, struct r600_bc_alu *alu,
d445 1
a445 1
	num_src = r600_bc_get_num_operands(bc, alu);
d458 1
a458 1
			r = reserve_cfile(bc, bs, sel, elem);
d486 2
a487 2
static int check_and_set_bank_swizzle(struct r600_bc *bc,
				      struct r600_bc_alu *slots[5])
d492 2
a493 2
	boolean scalar_only = bc->chiprev == CHIPREV_CAYMAN ? false : true;
	int max_slots = bc->chiprev == CHIPREV_CAYMAN ? 4 : 5;
a520 6
		if (max_slots == 4) {
			for (i = 0; i < max_slots; i++) {
				if (bank_swizzle[i] == SQ_ALU_VEC_210)
				  return -1;
			}
		}
d533 1
a533 1
		if (!r && slots[4] && max_slots == 5) {
d552 2
d555 1
a555 1
						bank_swizzle[i] = SQ_ALU_VEC_012;
d565 2
a566 2
static int replace_gpr_with_pv_ps(struct r600_bc *bc,
				  struct r600_bc_alu *slots[5], struct r600_bc_alu *alu_prev)
d568 1
a568 1
	struct r600_bc_alu *prev[5];
d571 1
a571 1
	int max_slots = bc->chiprev == CHIPREV_CAYMAN ? 4 : 5;
d581 1
a581 1
			if (!is_alu_cube_inst(bc, prev[i]) && is_alu_reduction_inst(bc, prev[i]))
d590 1
a590 1
		struct r600_bc_alu *alu = slots[i];
d594 1
a594 1
		num_src = r600_bc_get_num_operands(bc, alu);
d599 1
a599 1
			if (bc->chiprev < CHIPREV_CAYMAN) {
d601 2
a602 1
				    alu->src[src].chan == chan[4]) {
d611 2
a612 1
					alu->src[src].chan == j) {
d624 1
a624 1
void r600_bc_special_constants(u32 value, unsigned *sel, unsigned *neg)
d657 1
a657 1
static int r600_bc_alu_nliterals(struct r600_bc *bc, struct r600_bc_alu *alu,
d660 1
a660 1
	unsigned num_src = r600_bc_get_num_operands(bc, alu);
d683 2
a684 2
static void r600_bc_alu_adjust_literals(struct r600_bc *bc,
					struct r600_bc_alu *alu,
d687 1
a687 1
	unsigned num_src = r600_bc_get_num_operands(bc, alu);
d703 2
a704 2
static int merge_inst_groups(struct r600_bc *bc, struct r600_bc_alu *slots[5],
			     struct r600_bc_alu *alu_prev)
d706 2
a707 2
	struct r600_bc_alu *prev[5];
	struct r600_bc_alu *result[5] = { NULL };
d715 1
a715 1
	int max_slots = bc->chiprev == CHIPREV_CAYMAN ? 4 : 5;
d722 19
a740 1
		struct r600_bc_alu *alu;
d744 1
a744 1
			if (r600_bc_alu_nliterals(bc, prev[i], literal, &nliteral))
d746 1
a746 1
			if (r600_bc_alu_nliterals(bc, prev[i], prev_literal, &prev_nliteral))
d753 8
d763 1
a763 1
		if (slots[i] && r600_bc_alu_nliterals(bc, slots[i], literal, &nliteral))
d777 5
d790 8
a797 1
		} else
d799 1
d804 13
a816 3
		/* Let's check dst gpr. */
		if (alu->dst.rel) {
			if (have_mova)
d818 1
d823 1
a823 1
		num_src = r600_bc_get_num_operands(bc, alu);
a824 5
			if (alu->src[src].rel) {
				if (have_mova)
					return 0;
				have_rel = 1;
			}
d831 1
a831 1
				if (!prev[j] || !prev[j]->dst.write)
d868 1
a868 1
	LIST_ENTRY(struct r600_bc_alu, bc->cf_last->alu.prev, list)->last = 1;
d884 13
a896 13
/* This code handles kcache lines as single blocks of 32 constants. We could
 * probably do slightly better by recognizing that we actually have two
 * consecutive lines of 16 constants, but the resulting code would also be
 * somewhat more complicated. */
static int r600_bc_alloc_kcache_lines(struct r600_bc *bc, struct r600_bc_alu *alu, int type)
{
	struct r600_bc_kcache *kcache = bc->cf_last->kcache;
	unsigned int required_lines;
	unsigned int free_lines = 0;
	unsigned int cache_line[3];
	unsigned int count = 0;
	unsigned int i, j;
	int r;
d898 7
a904 4
	/* Collect required cache lines. */
	for (i = 0; i < 3; ++i) {
		boolean found = false;
		unsigned int line;
d906 6
a911 2
		if (alu->src[i].sel < 512)
			continue;
d913 1
a913 1
		line = ((alu->src[i].sel - 512) / 32) * 2;
d915 25
a939 5
		for (j = 0; j < count; ++j) {
			if (cache_line[j] == line) {
				found = true;
				break;
			}
d941 3
d945 17
a961 2
		if (!found)
			cache_line[count++] = line;
d963 2
d966 13
a978 2
	/* This should never actually happen. */
	if (count >= 3) return -ENOMEM;
d980 2
a981 5
	for (i = 0; i < 2; ++i) {
		if (kcache[i].mode == V_SQ_CF_KCACHE_NOP) {
			++free_lines;
		}
	}
d983 14
a996 9
	/* Filter lines pulled in by previous intructions. Note that this is
	 * only for the required_lines count, we can't remove these from the
	 * cache_line array since we may have to start a new ALU clause. */
	for (i = 0, required_lines = count; i < count; ++i) {
		for (j = 0; j < 2; ++j) {
			if (kcache[j].mode == V_SQ_CF_KCACHE_LOCK_2 &&
			    kcache[j].addr == cache_line[i]) {
				--required_lines;
				break;
d1000 2
d1003 13
a1015 3
	/* Start a new ALU clause if needed. */
	if (required_lines > free_lines) {
		if ((r = r600_bc_add_cf(bc))) {
d1018 3
a1020 1
		bc->cf_last->inst = (type << 3);
d1022 7
d1031 9
a1039 11
	/* Setup the kcache lines. */
	for (i = 0; i < count; ++i) {
		boolean found = false;

		for (j = 0; j < 2; ++j) {
			if (kcache[j].mode == V_SQ_CF_KCACHE_LOCK_2 &&
			    kcache[j].addr == cache_line[i]) {
				found = true;
				break;
			}
		}
d1041 4
a1044 1
		if (found) continue;
d1046 9
a1054 8
		for (j = 0; j < 2; ++j) {
			if (kcache[j].mode == V_SQ_CF_KCACHE_NOP) {
				kcache[j].bank = 0;
				kcache[j].addr = cache_line[i];
				kcache[j].mode = V_SQ_CF_KCACHE_LOCK_2;
				break;
			}
		}
d1056 25
d1082 13
a1094 4
	/* Alter the src operands to refer to the kcache. */
	for (i = 0; i < 3; ++i) {
		static const unsigned int base[] = {128, 160, 256, 288};
		unsigned int line;
d1096 2
a1097 2
		if (alu->src[i].sel < 512)
			continue;
d1099 3
a1101 2
		alu->src[i].sel -= 512;
		line = (alu->src[i].sel / 32) * 2;
d1103 8
a1110 9
		for (j = 0; j < 2; ++j) {
			if (kcache[j].mode == V_SQ_CF_KCACHE_LOCK_2 &&
			    kcache[j].addr == line) {
				alu->src[i].sel &= 0x1f;
				alu->src[i].sel += base[j];
				break;
			}
		}
	}
d1112 2
d1117 2
a1118 1
int r600_bc_add_alu_type(struct r600_bc *bc, const struct r600_bc_alu *alu, int type)
d1120 2
a1121 2
	struct r600_bc_alu *nalu = r600_bc_alu();
	struct r600_bc_alu *lalu;
d1126 1
a1126 1
	memcpy(nalu, alu, sizeof(struct r600_bc_alu));
d1128 1
a1128 1
	if (bc->cf_last != NULL && bc->cf_last->inst != (type << 3)) {
d1130 2
a1131 2
		if (bc->cf_last->inst == (V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU << 3) &&
			type == V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU_PUSH_BEFORE) {
d1133 1
a1133 1
				if (lalu->predicate) {
d1144 1
a1144 1
		r = r600_bc_add_cf(bc);
d1150 9
a1158 1
	bc->cf_last->inst = (type << 3);
d1162 1
a1162 1
	if ((r = r600_bc_alloc_kcache_lines(bc, nalu, type))) {
d1176 1
a1176 1
			r600_bc_special_constants(nalu->src[i].value,
d1191 2
a1192 2
		struct r600_bc_alu *slots[5];
		int max_slots = bc->chiprev == CHIPREV_CAYMAN ? 4 : 5;
d1215 1
a1215 1
				r = r600_bc_alu_nliterals(bc, slots[i], literal, &nliteral);
d1232 4
d1239 1
a1239 1
int r600_bc_add_alu(struct r600_bc *bc, const struct r600_bc_alu *alu)
d1241 1
a1241 1
	return r600_bc_add_alu_type(bc, alu, BC_INST(bc, V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU));
d1244 1
a1244 1
static unsigned r600_bc_num_tex_and_vtx_instructions(const struct r600_bc *bc)
d1246 2
a1247 2
	switch (bc->chiprev) {
	case CHIPREV_R600:
d1250 3
a1252 1
	case CHIPREV_R700:
a1254 4
	case CHIPREV_EVERGREEN:
	case CHIPREV_CAYMAN:
		return 64;

d1256 1
a1256 1
		R600_ERR("Unknown chiprev %d.\n", bc->chiprev);
d1261 1
a1261 1
static inline boolean last_inst_was_vtx_fetch(struct r600_bc *bc)
d1263 3
a1265 9
	if (bc->chiprev == CHIPREV_CAYMAN) {
		if (bc->cf_last->inst != CM_V_SQ_CF_WORD1_SQ_CF_INST_TC)
			return TRUE;
	} else {
		if (bc->cf_last->inst != V_SQ_CF_WORD1_SQ_CF_INST_VTX &&
		    bc->cf_last->inst != V_SQ_CF_WORD1_SQ_CF_INST_VTX_TC)
			return TRUE;
	}
	return FALSE;
d1268 1
a1268 1
int r600_bc_add_vtx(struct r600_bc *bc, const struct r600_bc_vtx *vtx)
d1270 1
a1270 1
	struct r600_bc_vtx *nvtx = r600_bc_vtx();
d1275 1
a1275 1
	memcpy(nvtx, vtx, sizeof(struct r600_bc_vtx));
d1279 1
a1279 1
	    last_inst_was_vtx_fetch(bc) ||
d1281 1
a1281 1
		r = r600_bc_add_cf(bc);
d1286 14
a1299 4
		if (bc->chiprev == CHIPREV_CAYMAN)
			bc->cf_last->inst = CM_V_SQ_CF_WORD1_SQ_CF_INST_TC;
		else
			bc->cf_last->inst = V_SQ_CF_WORD1_SQ_CF_INST_VTX;
d1305 1
a1305 1
	if ((bc->cf_last->ndw / 4) >= r600_bc_num_tex_and_vtx_instructions(bc))
d1307 4
d1314 1
a1314 1
int r600_bc_add_tex(struct r600_bc *bc, const struct r600_bc_tex *tex)
d1316 1
a1316 1
	struct r600_bc_tex *ntex = r600_bc_tex();
d1321 1
a1321 1
	memcpy(ntex, tex, sizeof(struct r600_bc_tex));
d1325 2
a1326 2
		bc->cf_last->inst == V_SQ_CF_WORD1_SQ_CF_INST_TEX) {
		struct r600_bc_tex *ttex;
d1334 1
a1334 1
		if (ntex->inst == SQ_TEX_INST_SET_GRADIENTS_H)
d1340 1
a1340 1
		bc->cf_last->inst != V_SQ_CF_WORD1_SQ_CF_INST_TEX ||
d1342 1
a1342 1
		r = r600_bc_add_cf(bc);
d1347 1
a1347 1
		bc->cf_last->inst = V_SQ_CF_WORD1_SQ_CF_INST_TEX;
d1359 1
a1359 1
	if ((bc->cf_last->ndw / 4) >= r600_bc_num_tex_and_vtx_instructions(bc))
d1364 1
a1364 1
int r600_bc_add_cfinst(struct r600_bc *bc, int inst)
d1367 1
a1367 1
	r = r600_bc_add_cf(bc);
d1372 1
a1372 1
	bc->cf_last->inst = inst;
d1376 1
a1376 1
int cm_bc_add_cf_end(struct r600_bc *bc)
d1378 1
a1378 1
	return r600_bc_add_cfinst(bc, CM_V_SQ_CF_WORD1_SQ_CF_INST_END);
d1382 1
a1382 1
static int r600_bc_vtx_build(struct r600_bc *bc, struct r600_bc_vtx *vtx, unsigned id)
d1388 1
a1388 1
	if (bc->chiprev < CHIPREV_CAYMAN)
d1403 1
a1403 1
	if (bc->chiprev < CHIPREV_CAYMAN)
d1411 1
a1411 1
static int r600_bc_tex_build(struct r600_bc *bc, struct r600_bc_tex *tex, unsigned id)
d1413 3
a1415 1
	bc->bytecode[id++] = S_SQ_TEX_WORD0_TEX_INST(tex->inst) |
d1443 1
a1443 1
static int r600_bc_alu_build(struct r600_bc *bc, struct r600_bc_alu *alu, unsigned id)
d1445 2
d1456 2
d1469 1
a1469 1
					S_SQ_ALU_WORD1_OP3_ALU_INST(alu->inst) |
d1480 1
a1480 1
					S_SQ_ALU_WORD1_OP2_ALU_INST(alu->inst) |
d1482 2
a1483 2
					S_SQ_ALU_WORD1_OP2_UPDATE_EXECUTE_MASK(alu->predicate) |
					S_SQ_ALU_WORD1_OP2_UPDATE_PRED(alu->predicate);
d1488 1
a1488 1
static void r600_bc_cf_vtx_build(uint32_t *bytecode, const struct r600_bc_cf *cf)
d1491 1
a1491 1
	*bytecode++ = S_SQ_CF_WORD1_CF_INST(cf->inst) |
d1497 1
a1497 1
static int r600_bc_cf_build(struct r600_bc *bc, struct r600_bc_cf *cf)
d1500 3
d1504 4
a1507 5
	switch (cf->inst) {
	case (V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU << 3):
	case (V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU_PUSH_BEFORE << 3):
	case (V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU_POP_AFTER << 3):
	case (V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU_POP2_AFTER << 3):
d1513 1
a1513 1
		bc->bytecode[id++] = S_SQ_CF_ALU_WORD1_CF_INST(cf->inst >> 3) |
d1518 1
a1518 1
					S_SQ_CF_ALU_WORD1_USES_WATERFALL(bc->chiprev == CHIPREV_R600 ? cf->r6xx_uses_waterfall : 0) |
d1520 3
a1522 6
		break;
	case V_SQ_CF_WORD1_SQ_CF_INST_TEX:
	case V_SQ_CF_WORD1_SQ_CF_INST_VTX:
	case V_SQ_CF_WORD1_SQ_CF_INST_VTX_TC:
		if (bc->chiprev == CHIPREV_R700)
			r700_bc_cf_vtx_build(&bc->bytecode[id], cf);
d1524 2
a1525 4
			r600_bc_cf_vtx_build(&bc->bytecode[id], cf);
		break;
	case V_SQ_CF_ALLOC_EXPORT_WORD1_SQ_CF_INST_EXPORT:
	case V_SQ_CF_ALLOC_EXPORT_WORD1_SQ_CF_INST_EXPORT_DONE:
d1536 1
a1536 1
			S_SQ_CF_ALLOC_EXPORT_WORD1_CF_INST(cf->output.inst) |
d1538 12
a1549 10
		break;
	case V_SQ_CF_WORD1_SQ_CF_INST_JUMP:
	case V_SQ_CF_WORD1_SQ_CF_INST_ELSE:
	case V_SQ_CF_WORD1_SQ_CF_INST_POP:
	case V_SQ_CF_WORD1_SQ_CF_INST_LOOP_START_NO_AL:
	case V_SQ_CF_WORD1_SQ_CF_INST_LOOP_END:
	case V_SQ_CF_WORD1_SQ_CF_INST_LOOP_CONTINUE:
	case V_SQ_CF_WORD1_SQ_CF_INST_LOOP_BREAK:
	case V_SQ_CF_WORD1_SQ_CF_INST_CALL_FS:
	case V_SQ_CF_WORD1_SQ_CF_INST_RETURN:
d1551 1
a1551 1
		bc->bytecode[id++] = S_SQ_CF_WORD1_CF_INST(cf->inst) |
a1554 5

		break;
	default:
		R600_ERR("unsupported CF instruction (0x%X)\n", cf->inst);
		return -EINVAL;
d1559 1
a1559 1
int r600_bc_build(struct r600_bc *bc)
d1561 4
a1564 4
	struct r600_bc_cf *cf;
	struct r600_bc_alu *alu;
	struct r600_bc_vtx *vtx;
	struct r600_bc_tex *tex;
d1570 3
a1572 2
	if (bc->callstack[0].max > 0)
		bc->nstack = ((bc->callstack[0].max + 3) >> 2) + 2;
d1581 1
a1581 10
		switch (cf->inst) {
		case (V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU << 3):
		case (V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU_POP_AFTER << 3):
		case (V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU_POP2_AFTER << 3):
		case (V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU_PUSH_BEFORE << 3):
			break;
		case V_SQ_CF_WORD1_SQ_CF_INST_TEX:
		case V_SQ_CF_WORD1_SQ_CF_INST_VTX:
		case V_SQ_CF_WORD1_SQ_CF_INST_VTX_TC:
			/* fetch node need to be 16 bytes aligned*/
a1583 20
			break;
		case V_SQ_CF_ALLOC_EXPORT_WORD1_SQ_CF_INST_EXPORT:
		case V_SQ_CF_ALLOC_EXPORT_WORD1_SQ_CF_INST_EXPORT_DONE:
		case EG_V_SQ_CF_ALLOC_EXPORT_WORD1_SQ_CF_INST_EXPORT:
		case EG_V_SQ_CF_ALLOC_EXPORT_WORD1_SQ_CF_INST_EXPORT_DONE:
			break;
		case V_SQ_CF_WORD1_SQ_CF_INST_JUMP:
		case V_SQ_CF_WORD1_SQ_CF_INST_ELSE:
		case V_SQ_CF_WORD1_SQ_CF_INST_POP:
		case V_SQ_CF_WORD1_SQ_CF_INST_LOOP_START_NO_AL:
		case V_SQ_CF_WORD1_SQ_CF_INST_LOOP_END:
		case V_SQ_CF_WORD1_SQ_CF_INST_LOOP_CONTINUE:
		case V_SQ_CF_WORD1_SQ_CF_INST_LOOP_BREAK:
		case V_SQ_CF_WORD1_SQ_CF_INST_CALL_FS:
		case V_SQ_CF_WORD1_SQ_CF_INST_RETURN:
		case CM_V_SQ_CF_WORD1_SQ_CF_INST_END:
			break;
		default:
			R600_ERR("unsupported CF instruction (0x%X)\n", cf->inst);
			return -EINVAL;
d1594 1
d1596 2
a1597 2
		if (bc->chiprev >= CHIPREV_EVERGREEN)
			r = eg_bc_cf_build(bc, cf);
d1599 1
a1599 1
			r = r600_bc_cf_build(bc, cf);
d1602 1
a1602 5
		switch (cf->inst) {
		case (V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU << 3):
		case (V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU_POP_AFTER << 3):
		case (V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU_POP2_AFTER << 3):
		case (V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU_PUSH_BEFORE << 3):
d1606 1
a1606 1
				r = r600_bc_alu_nliterals(bc, alu, literal, &nliteral);
d1609 6
a1614 4
				r600_bc_alu_adjust_literals(bc, alu, literal, nliteral);
				switch(bc->chiprev) {
				case CHIPREV_R600:
					r = r600_bc_alu_build(bc, alu, addr);
d1616 4
a1619 4
				case CHIPREV_R700:
				case CHIPREV_EVERGREEN: /* eg alu is same encoding as r700 */
				case CHIPREV_CAYMAN: /* eg alu is same encoding as r700 */
					r = r700_bc_alu_build(bc, alu, addr);
d1622 1
a1622 1
					R600_ERR("unknown family %d\n", bc->family);
d1636 1
a1636 3
			break;
		case V_SQ_CF_WORD1_SQ_CF_INST_VTX:
		case V_SQ_CF_WORD1_SQ_CF_INST_VTX_TC:
d1638 1
a1638 1
				r = r600_bc_vtx_build(bc, vtx, addr);
d1643 7
a1649 9
			break;
		case V_SQ_CF_WORD1_SQ_CF_INST_TEX:
			if (bc->chiprev == CHIPREV_CAYMAN) {
				LIST_FOR_EACH_ENTRY(vtx, &cf->vtx, list) {
					r = r600_bc_vtx_build(bc, vtx, addr);
					if (r)
						return r;
					addr += 4;
				}
d1652 1
a1652 1
				r = r600_bc_tex_build(bc, tex, addr);
a1656 19
			break;
		case V_SQ_CF_ALLOC_EXPORT_WORD1_SQ_CF_INST_EXPORT:
		case V_SQ_CF_ALLOC_EXPORT_WORD1_SQ_CF_INST_EXPORT_DONE:
		case EG_V_SQ_CF_ALLOC_EXPORT_WORD1_SQ_CF_INST_EXPORT:
		case EG_V_SQ_CF_ALLOC_EXPORT_WORD1_SQ_CF_INST_EXPORT_DONE:
		case V_SQ_CF_WORD1_SQ_CF_INST_LOOP_START_NO_AL:
		case V_SQ_CF_WORD1_SQ_CF_INST_LOOP_END:
		case V_SQ_CF_WORD1_SQ_CF_INST_LOOP_CONTINUE:
		case V_SQ_CF_WORD1_SQ_CF_INST_LOOP_BREAK:
		case V_SQ_CF_WORD1_SQ_CF_INST_JUMP:
		case V_SQ_CF_WORD1_SQ_CF_INST_ELSE:
		case V_SQ_CF_WORD1_SQ_CF_INST_POP:
		case V_SQ_CF_WORD1_SQ_CF_INST_CALL_FS:
		case V_SQ_CF_WORD1_SQ_CF_INST_RETURN:
		case CM_V_SQ_CF_WORD1_SQ_CF_INST_END:
			break;
		default:
			R600_ERR("unsupported CF instruction (0x%X)\n", cf->inst);
			return -EINVAL;
d1662 1
a1662 1
void r600_bc_clear(struct r600_bc *bc)
d1664 1
a1664 1
	struct r600_bc_cf *cf = NULL, *next_cf;
d1670 3
a1672 3
		struct r600_bc_alu *alu = NULL, *next_alu;
		struct r600_bc_tex *tex = NULL, *next_tex;
		struct r600_bc_tex *vtx = NULL, *next_vtx;
d1698 148
a1845 1
void r600_bc_dump(struct r600_bc *bc)
d1847 5
a1851 4
	struct r600_bc_cf *cf = NULL;
	struct r600_bc_alu *alu = NULL;
	struct r600_bc_vtx *vtx = NULL;
	struct r600_bc_tex *tex = NULL;
d1853 1
a1853 1
	unsigned i, id;
d1858 2
a1859 2
	switch (bc->chiprev) {
	case 1:
d1862 1
a1862 1
	case 2:
d1865 1
a1865 1
	case 3:
d1868 1
a1868 1
	case 0:
d1873 3
a1875 2
	fprintf(stderr, "bytecode %d dw -- %d gprs ---------------------\n", bc->ndw, bc->ngpr);
	fprintf(stderr, "     %c\n", chip);
d1879 86
d1966 20
a1985 66
		switch (cf->inst) {
		case (V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU << 3):
		case (V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU_POP_AFTER << 3):
		case (V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU_POP2_AFTER << 3):
		case (V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU_PUSH_BEFORE << 3):
			fprintf(stderr, "%04d %08X ALU ", id, bc->bytecode[id]);
			fprintf(stderr, "ADDR:%d ", cf->addr);
			fprintf(stderr, "KCACHE_MODE0:%X ", cf->kcache[0].mode);
			fprintf(stderr, "KCACHE_BANK0:%X ", cf->kcache[0].bank);
			fprintf(stderr, "KCACHE_BANK1:%X\n", cf->kcache[1].bank);
			id++;
			fprintf(stderr, "%04d %08X ALU ", id, bc->bytecode[id]);
			fprintf(stderr, "INST:%d ", cf->inst);
			fprintf(stderr, "KCACHE_MODE1:%X ", cf->kcache[1].mode);
			fprintf(stderr, "KCACHE_ADDR0:%X ", cf->kcache[0].addr);
			fprintf(stderr, "KCACHE_ADDR1:%X ", cf->kcache[1].addr);
			fprintf(stderr, "COUNT:%d\n", cf->ndw / 2);
			break;
		case V_SQ_CF_WORD1_SQ_CF_INST_TEX:
		case V_SQ_CF_WORD1_SQ_CF_INST_VTX:
		case V_SQ_CF_WORD1_SQ_CF_INST_VTX_TC:
			fprintf(stderr, "%04d %08X TEX/VTX ", id, bc->bytecode[id]);
			fprintf(stderr, "ADDR:%d\n", cf->addr);
			id++;
			fprintf(stderr, "%04d %08X TEX/VTX ", id, bc->bytecode[id]);
			fprintf(stderr, "INST:%d ", cf->inst);
			fprintf(stderr, "COUNT:%d\n", cf->ndw / 4);
			break;
		case V_SQ_CF_ALLOC_EXPORT_WORD1_SQ_CF_INST_EXPORT:
		case V_SQ_CF_ALLOC_EXPORT_WORD1_SQ_CF_INST_EXPORT_DONE:
		case EG_V_SQ_CF_ALLOC_EXPORT_WORD1_SQ_CF_INST_EXPORT:
		case EG_V_SQ_CF_ALLOC_EXPORT_WORD1_SQ_CF_INST_EXPORT_DONE:
			fprintf(stderr, "%04d %08X EXPORT ", id, bc->bytecode[id]);
			fprintf(stderr, "GPR:%X ", cf->output.gpr);
			fprintf(stderr, "ELEM_SIZE:%X ", cf->output.elem_size);
			fprintf(stderr, "ARRAY_BASE:%X ", cf->output.array_base);
			fprintf(stderr, "TYPE:%X\n", cf->output.type);
			id++;
			fprintf(stderr, "%04d %08X EXPORT ", id, bc->bytecode[id]);
			fprintf(stderr, "SWIZ_X:%X ", cf->output.swizzle_x);
			fprintf(stderr, "SWIZ_Y:%X ", cf->output.swizzle_y);
			fprintf(stderr, "SWIZ_Z:%X ", cf->output.swizzle_z);
			fprintf(stderr, "SWIZ_W:%X ", cf->output.swizzle_w);
			fprintf(stderr, "BARRIER:%X ", cf->output.barrier);
			fprintf(stderr, "INST:%d ", cf->output.inst);
			fprintf(stderr, "BURST_COUNT:%d ", cf->output.burst_count);
			fprintf(stderr, "EOP:%X\n", cf->output.end_of_program);
			break;
		case V_SQ_CF_WORD1_SQ_CF_INST_JUMP:
		case V_SQ_CF_WORD1_SQ_CF_INST_ELSE:
		case V_SQ_CF_WORD1_SQ_CF_INST_POP:
		case V_SQ_CF_WORD1_SQ_CF_INST_LOOP_START_NO_AL:
		case V_SQ_CF_WORD1_SQ_CF_INST_LOOP_END:
		case V_SQ_CF_WORD1_SQ_CF_INST_LOOP_CONTINUE:
		case V_SQ_CF_WORD1_SQ_CF_INST_LOOP_BREAK:
		case V_SQ_CF_WORD1_SQ_CF_INST_CALL_FS:
		case V_SQ_CF_WORD1_SQ_CF_INST_RETURN:
		case CM_V_SQ_CF_WORD1_SQ_CF_INST_END:
			fprintf(stderr, "%04d %08X CF ", id, bc->bytecode[id]);
			fprintf(stderr, "ADDR:%d\n", cf->cf_addr);
			id++;
			fprintf(stderr, "%04d %08X CF ", id, bc->bytecode[id]);
			fprintf(stderr, "INST:%d ", cf->inst);
			fprintf(stderr, "COND:%X ", cf->cond);
			fprintf(stderr, "POP_COUNT:%X\n", cf->pop_count);
			break;
d1990 1
d1992 16
a2007 1
			r600_bc_alu_nliterals(bc, alu, literal, &nliteral);
d2009 10
a2018 30
			fprintf(stderr, "%04d %08X   ", id, bc->bytecode[id]);
			fprintf(stderr, "SRC0(SEL:%d ", alu->src[0].sel);
			fprintf(stderr, "REL:%d ", alu->src[0].rel);
			fprintf(stderr, "CHAN:%d ", alu->src[0].chan);
			fprintf(stderr, "NEG:%d) ", alu->src[0].neg);
			fprintf(stderr, "SRC1(SEL:%d ", alu->src[1].sel);
			fprintf(stderr, "REL:%d ", alu->src[1].rel);
			fprintf(stderr, "CHAN:%d ", alu->src[1].chan);
			fprintf(stderr, "NEG:%d) ", alu->src[1].neg);
			fprintf(stderr, "LAST:%d)\n", alu->last);
			id++;
			fprintf(stderr, "%04d %08X %c ", id, bc->bytecode[id], alu->last ? '*' : ' ');
			fprintf(stderr, "INST:%d ", alu->inst);
			fprintf(stderr, "DST(SEL:%d ", alu->dst.sel);
			fprintf(stderr, "CHAN:%d ", alu->dst.chan);
			fprintf(stderr, "REL:%d ", alu->dst.rel);
			fprintf(stderr, "CLAMP:%d) ", alu->dst.clamp);
			fprintf(stderr, "BANK_SWIZZLE:%d ", alu->bank_swizzle);
			if (alu->is_op3) {
				fprintf(stderr, "SRC2(SEL:%d ", alu->src[2].sel);
				fprintf(stderr, "REL:%d ", alu->src[2].rel);
				fprintf(stderr, "CHAN:%d ", alu->src[2].chan);
				fprintf(stderr, "NEG:%d)\n", alu->src[2].neg);
			} else {
				fprintf(stderr, "SRC0_ABS:%d ", alu->src[0].abs);
				fprintf(stderr, "SRC1_ABS:%d ", alu->src[1].abs);
				fprintf(stderr, "WRITE_MASK:%d ", alu->dst.write);
				fprintf(stderr, "OMOD:%d ", alu->omod);
				fprintf(stderr, "EXECUTE_MASK:%d ", alu->predicate);
				fprintf(stderr, "UPDATE_PRED:%d\n", alu->predicate);
d2021 3
a2023 1
			id++;
d2027 3
a2029 1
					fprintf(stderr, "%04d %08X\t%f\n", id, bc->bytecode[id], *f);
d2034 1
d2038 41
a2078 31
			fprintf(stderr, "%04d %08X   ", id, bc->bytecode[id]);
			fprintf(stderr, "INST:%d ", tex->inst);
			fprintf(stderr, "RESOURCE_ID:%d ", tex->resource_id);
			fprintf(stderr, "SRC(GPR:%d ", tex->src_gpr);
			fprintf(stderr, "REL:%d)\n", tex->src_rel);
			id++;
			fprintf(stderr, "%04d %08X   ", id, bc->bytecode[id]);
			fprintf(stderr, "DST(GPR:%d ", tex->dst_gpr);
			fprintf(stderr, "REL:%d ", tex->dst_rel);
			fprintf(stderr, "SEL_X:%d ", tex->dst_sel_x);
			fprintf(stderr, "SEL_Y:%d ", tex->dst_sel_y);
			fprintf(stderr, "SEL_Z:%d ", tex->dst_sel_z);
			fprintf(stderr, "SEL_W:%d) ", tex->dst_sel_w);
			fprintf(stderr, "LOD_BIAS:%d ", tex->lod_bias);
			fprintf(stderr, "COORD_TYPE_X:%d ", tex->coord_type_x);
			fprintf(stderr, "COORD_TYPE_Y:%d ", tex->coord_type_y);
			fprintf(stderr, "COORD_TYPE_Z:%d ", tex->coord_type_z);
			fprintf(stderr, "COORD_TYPE_W:%d\n", tex->coord_type_w);
			id++;
			fprintf(stderr, "%04d %08X   ", id, bc->bytecode[id]);
			fprintf(stderr, "OFFSET_X:%d ", tex->offset_x);
			fprintf(stderr, "OFFSET_Y:%d ", tex->offset_y);
			fprintf(stderr, "OFFSET_Z:%d ", tex->offset_z);
			fprintf(stderr, "SAMPLER_ID:%d ", tex->sampler_id);
			fprintf(stderr, "SRC(SEL_X:%d ", tex->src_sel_x);
			fprintf(stderr, "SEL_Y:%d ", tex->src_sel_y);
			fprintf(stderr, "SEL_Z:%d ", tex->src_sel_z);
			fprintf(stderr, "SEL_W:%d)\n", tex->src_sel_w);
			id++;
			fprintf(stderr, "%04d %08X   \n", id, bc->bytecode[id]);
			id++;
d2082 32
a2113 20
			fprintf(stderr, "%04d %08X   ", id, bc->bytecode[id]);
			fprintf(stderr, "INST:%d ", vtx->inst);
			fprintf(stderr, "FETCH_TYPE:%d ", vtx->fetch_type);
			fprintf(stderr, "BUFFER_ID:%d\n", vtx->buffer_id);
			id++;
			/* This assumes that no semantic fetches exist */
			fprintf(stderr, "%04d %08X   ", id, bc->bytecode[id]);
			fprintf(stderr, "SRC(GPR:%d ", vtx->src_gpr);
			fprintf(stderr, "SEL_X:%d) ", vtx->src_sel_x);
			if (bc->chiprev < CHIPREV_CAYMAN)
				fprintf(stderr, "MEGA_FETCH_COUNT:%d ", vtx->mega_fetch_count);
			else
				fprintf(stderr, "SEL_Y:%d) ", 0);
			fprintf(stderr, "DST(GPR:%d ", vtx->dst_gpr);
			fprintf(stderr, "SEL_X:%d ", vtx->dst_sel_x);
			fprintf(stderr, "SEL_Y:%d ", vtx->dst_sel_y);
			fprintf(stderr, "SEL_Z:%d ", vtx->dst_sel_z);
			fprintf(stderr, "SEL_W:%d) ", vtx->dst_sel_w);
			fprintf(stderr, "USE_CONST_FIELDS:%d ", vtx->use_const_fields);
			fprintf(stderr, "FORMAT(DATA:%d ", vtx->data_format);
d2117 2
a2118 8
			id++;
			fprintf(stderr, "%04d %08X   ", id, bc->bytecode[id]);
			fprintf(stderr, "ENDIAN:%d ", vtx->endian);
			fprintf(stderr, "OFFSET:%d\n", vtx->offset);
			/* TODO */
			id++;
			fprintf(stderr, "%04d %08X   \n", id, bc->bytecode[id]);
			id++;
d2125 3
a2127 2
static void r600_vertex_data_type(enum pipe_format pformat, unsigned *format,
				unsigned *num_format, unsigned *format_comp, unsigned *endian)
d2208 6
d2255 10
a2264 4
	if (desc->channel[i].normalized) {
		*num_format = 0;
	} else {
		*num_format = 2;
d2271 7
a2277 7
int r600_vertex_elements_build_fetch_shader(struct r600_pipe_context *rctx, struct r600_vertex_element *ve)
{
	static int dump_shaders = -1;

	struct r600_bc bc;
	struct r600_bc_vtx vtx;
	struct pipe_vertex_element *elements = ve->elements;
d2279 1
a2279 1
	unsigned fetch_resource_start = rctx->family >= CHIP_CEDAR ? 0 : 160;
d2281 4
a2284 2
	u32 *bytecode;
	int i, r;
d2286 1
a2286 11
	/* Vertex element offsets need special handling. If the offset is
	 * bigger than what we can put in the fetch instruction we need to
	 * alter the vertex resource offset. In order to simplify code we
	 * will bind one resource per element in such cases. It's a worst
	 * case scenario. */
	for (i = 0; i < ve->count; i++) {
		ve->vbuffer_offset[i] = C_SQ_VTX_WORD2_OFFSET & elements[i].src_offset;
		if (ve->vbuffer_offset[i]) {
			ve->vbuffer_need_offset = 1;
		}
	}
d2289 4
a2292 3
	r = r600_bc_init(&bc, r600_get_family(rctx->radeon));
	if (r)
		return r;
d2294 1
a2294 1
	for (i = 0; i < ve->count; i++) {
d2296 34
a2329 18
			struct r600_bc_alu alu;

			memset(&alu, 0, sizeof(alu));
			alu.inst = BC_INST(&bc, V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MULHI_UINT);
			alu.src[0].sel = 0;
			alu.src[0].chan = 3;

			alu.src[1].sel = V_SQ_ALU_SRC_LITERAL;
			alu.src[1].value = (1ll << 32) / elements[i].instance_divisor + 1;

			alu.dst.sel = i + 1;
			alu.dst.chan = 3;
			alu.dst.write = 1;
			alu.last = 1;

			if ((r = r600_bc_add_alu(&bc, &alu))) {
				r600_bc_clear(&bc);
				return r;
d2334 5
a2338 4
	for (i = 0; i < ve->count; i++) {
		unsigned vbuffer_index;
		r600_vertex_data_type(ve->elements[i].src_format, &format, &num_format, &format_comp, &endian);
		desc = util_format_description(ve->elements[i].src_format);
d2340 9
a2348 3
			r600_bc_clear(&bc);
			R600_ERR("unknown format %d\n", ve->elements[i].src_format);
			return -EINVAL;
a2350 2
		/* see above for vbuffer_need_offset explanation */
		vbuffer_index = elements[i].vertex_buffer_index;
d2352 1
a2352 1
		vtx.buffer_id = (ve->vbuffer_need_offset ? i : vbuffer_index) + fetch_resource_start;
d2369 3
a2371 3
		if ((r = r600_bc_add_vtx(&bc, &vtx))) {
			r600_bc_clear(&bc);
			return r;
d2375 1
a2375 1
	r600_bc_add_cfinst(&bc, BC_INST(&bc, V_SQ_CF_WORD1_SQ_CF_INST_RETURN));
d2377 3
a2379 3
	if ((r = r600_bc_build(&bc))) {
		r600_bc_clear(&bc);
		return r;
d2382 11
a2392 2
	if (dump_shaders == -1)
		dump_shaders = debug_get_bool_option("R600_DUMP_SHADERS", FALSE);
d2394 4
a2397 4
	if (dump_shaders) {
		fprintf(stderr, "--------------------------------------------------------------\n");
		r600_bc_dump(&bc);
		fprintf(stderr, "______________________________________________________________\n");
d2400 1
a2400 1
	ve->fs_size = bc.ndw*4;
d2402 5
a2406 5
	/* use PIPE_BIND_VERTEX_BUFFER so we use the cache buffer manager */
	ve->fetch_shader = r600_bo(rctx->radeon, ve->fs_size, 256, PIPE_BIND_VERTEX_BUFFER, PIPE_USAGE_IMMUTABLE);
	if (ve->fetch_shader == NULL) {
		r600_bc_clear(&bc);
		return -ENOMEM;
d2409 6
a2414 5
	bytecode = r600_bo_map(rctx->radeon, ve->fetch_shader, 0, NULL);
	if (bytecode == NULL) {
		r600_bc_clear(&bc);
		r600_bo_reference(rctx->radeon, &ve->fetch_shader, NULL);
		return -ENOMEM;
d2417 3
d2421 1
a2421 1
		for (i = 0; i < ve->fs_size / 4; ++i) {
d2425 1
a2425 1
		memcpy(bytecode, bc.bytecode, ve->fs_size);
d2427 1
d2429 3
a2431 2
	r600_bo_unmap(rctx->radeon, ve->fetch_shader);
	r600_bc_clear(&bc);
d2433 68
a2500 6
	if (rctx->family >= CHIP_CEDAR)
		evergreen_fetch_shader(&rctx->context, ve);
	else
		r600_fetch_shader(&rctx->context, ve);

	return 0;
@


1.2
log
@Upate to libGL 7.11.2

Tested by jsg@@, matthieu@@ and ajacoutot@@, ok mattieu@@
@
text
@a24 1
#include <byteswap.h>
d27 1
d2291 1
a2291 1
			bytecode[i] = bswap_32(bc.bytecode[i]);
@


1.1
log
@Initial revision
@
text
@d25 1
d36 4
a39 1
static inline unsigned int r600_bc_get_num_operands(struct r600_bc_alu *alu)
d44 105
a148 41
	switch (alu->inst) {
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_NOP:
		return 0;
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_ADD:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLE:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLGT:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLGE:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_KILLNE:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MUL: 
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MAX:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MIN:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_SETE: 
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_SETNE:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_SETGT:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_SETGE:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETE:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGT:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETGE:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_PRED_SETNE:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_DOT4:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_DOT4_IEEE:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_CUBE:
		return 2;

	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MOV: 
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_MOVA_FLOOR:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_FRACT:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_FLOOR:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_TRUNC:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_EXP_IEEE:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_LOG_CLAMPED:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_LOG_IEEE:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIP_IEEE:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_RECIPSQRT_IEEE:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_FLT_TO_INT:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_SIN:
	case V_SQ_ALU_WORD1_OP2_SQ_OP2_INST_COS:
		return 1;
	default: R600_ERR(
		"Need instruction operand number for 0x%x.\n", alu->inst); 
	};
a174 1
	LIST_INITHEAD(&alu->bs_list);
d225 2
d232 3
d262 31
d301 81
a381 3
const unsigned bank_swizzle_vec[8] = {SQ_ALU_VEC_210,  //000
				      SQ_ALU_VEC_120,  //001
				      SQ_ALU_VEC_102,  //010
d383 20
a402 3
				      SQ_ALU_VEC_201,  //011
				      SQ_ALU_VEC_012,  //100
				      SQ_ALU_VEC_021,  //101
d404 141
a544 2
				      SQ_ALU_VEC_012,  //110
				      SQ_ALU_VEC_012}; //111
d546 13
a558 3
const unsigned bank_swizzle_scl[8] = {SQ_ALU_SCL_210,  //000
				      SQ_ALU_SCL_122,  //001
				      SQ_ALU_SCL_122,  //010
d560 5
a564 3
				      SQ_ALU_SCL_221,  //011
				      SQ_ALU_SCL_212,  //100
				      SQ_ALU_SCL_122,  //101
d566 21
a586 2
				      SQ_ALU_SCL_122,  //110
				      SQ_ALU_SCL_122}; //111
d588 1
a588 1
static int init_gpr(struct r600_bc_alu *alu)
d590 1
a590 1
	int cycle, component;
d594 5
a598 2
			 alu->hw_gpr[cycle][component] = -1;
	return 0;
d601 6
a606 7
#if 0
static int reserve_gpr(struct r600_bc_alu *alu, unsigned sel, unsigned chan, unsigned cycle)
{
	if (alu->hw_gpr[cycle][chan] < 0)
		alu->hw_gpr[cycle][chan] = sel;
	else if (alu->hw_gpr[cycle][chan] != (int)sel) {
		R600_ERR("Another scalar operation has already used GPR read port for channel\n");
d612 1
a612 1
static int cycle_for_scalar_bank_swizzle(const int swiz, const int sel, unsigned *p_cycle)
d614 13
a626 24
	int table[3];
	int ret = 0;
	switch (swiz) {
	case SQ_ALU_SCL_210:
		table[0] = 2; table[1] = 1; table[2] = 0;
                *p_cycle = table[sel];
                break;
	case SQ_ALU_SCL_122:
		table[0] = 1; table[1] = 2; table[2] = 2;
                *p_cycle = table[sel];
                break;
	case SQ_ALU_SCL_212:
		table[0] = 2; table[1] = 1; table[2] = 2;
                *p_cycle = table[sel];
                break;
	case SQ_ALU_SCL_221:
		table[0] = 2; table[1] = 2; table[2] = 1;
		*p_cycle = table[sel];
                break;
		break;
	default:
		R600_ERR("bad scalar bank swizzle value\n");
		ret = -1;
		break;
d628 2
a629 1
	return ret;
d632 1
a632 1
static int cycle_for_vector_bank_swizzle(const int swiz, const int sel, unsigned *p_cycle)
d634 46
a679 32
	int table[3];
	int ret;

	switch (swiz) {
	case SQ_ALU_VEC_012:
		table[0] = 0; table[1] = 1; table[2] = 2;
                *p_cycle = table[sel];
                break;
	case SQ_ALU_VEC_021:
		table[0] = 0; table[1] = 2; table[2] = 1;
                *p_cycle = table[sel];
                break;
	case SQ_ALU_VEC_120:
		table[0] = 1; table[1] = 2; table[2] = 0;
                *p_cycle = table[sel];
                break;
	case SQ_ALU_VEC_102:
		table[0] = 1; table[1] = 0; table[2] = 2;
                *p_cycle = table[sel];
                break;
	case SQ_ALU_VEC_201:
		table[0] = 2; table[1] = 0; table[2] = 1;
                *p_cycle = table[sel];
                break;
	case SQ_ALU_VEC_210:
		table[0] = 2; table[1] = 1; table[2] = 0;
                *p_cycle = table[sel];
                break;
	default:
		R600_ERR("bad vector bank swizzle value\n");
		ret = -1;
		break;
d681 1
a681 1
	return ret;
d684 4
d689 40
d730 2
a731 1
static void update_chan_counter(struct r600_bc_alu *alu, int *chan_counter)
d733 28
a760 3
	int num_src;
	int i;
	int channel_swizzle;
d762 2
a763 1
	num_src = r600_bc_get_num_operands(alu);
d765 42
a806 4
	for (i = 0; i < num_src; i++) {
		channel_swizzle = alu->src[i].chan;
		if ((alu->src[i].sel > 0 && alu->src[i].sel < 128) && channel_swizzle <= 3)
			chan_counter[channel_swizzle]++;
d808 3
d813 2
a814 2
/* we need something like this I think - but this is bogus */
int check_read_slots(struct r600_bc *bc, struct r600_bc_alu *alu_first)
d816 8
a823 2
	struct r600_bc_alu *alu;
	int chan_counter[4]  = { 0 };
d825 30
a854 1
	update_chan_counter(alu_first, chan_counter);
d856 9
a864 2
	LIST_FOR_EACH_ENTRY(alu, &alu_first->bs_list, bs_list) {
		update_chan_counter(alu, chan_counter);
a866 8
	if (chan_counter[0] > 3 ||
	    chan_counter[1] > 3 ||
	    chan_counter[2] > 3 ||
	    chan_counter[3] > 3) {
		R600_ERR("needed to split instruction for input ran out of banks %x %d %d %d %d\n",
			 alu_first->inst, chan_counter[0], chan_counter[1], chan_counter[2], chan_counter[3]);
		return -1;
	}
a868 1
#endif
d870 1
a870 1
static int is_const(int sel)
d872 54
a925 4
	if (sel > 255 && sel < 512)
		return 1;
	if (sel >= V_SQ_ALU_SRC_0 && sel <= V_SQ_ALU_SRC_LITERAL)
		return 1;
d929 22
a950 1
static int check_scalar(struct r600_bc *bc, struct r600_bc_alu *alu)
d952 74
a1025 1
	unsigned swizzle_key;
d1027 24
a1050 2
	if (alu->bank_swizzle_force) {
		alu->bank_swizzle = alu->bank_swizzle_force;
d1052 14
a1066 3
	swizzle_key = (is_const(alu->src[0].sel) ? 4 : 0 ) + 
		(is_const(alu->src[1].sel) ? 2 : 0 ) + 
		(is_const(alu->src[2].sel) ? 1 : 0 );
d1068 14
a1081 1
	alu->bank_swizzle = bank_swizzle_scl[swizzle_key];
d1085 56
a1140 3
static int check_vector(struct r600_bc *bc, struct r600_bc_alu *alu)
{
	unsigned swizzle_key;
d1142 7
a1148 3
	if (alu->bank_swizzle_force) {
		alu->bank_swizzle = alu->bank_swizzle_force;
		return 0;
a1149 3
	swizzle_key = (is_const(alu->src[0].sel) ? 4 : 0 ) + 
		(is_const(alu->src[1].sel) ? 2 : 0 ) + 
		(is_const(alu->src[2].sel) ? 1 : 0 );
d1151 3
a1153 3
	alu->bank_swizzle = bank_swizzle_vec[swizzle_key];
	return 0;
}
d1155 7
a1161 4
static int check_and_set_bank_swizzle(struct r600_bc *bc, struct r600_bc_alu *alu_first)
{
	struct r600_bc_alu *alu = NULL;
	int num_instr = 1;
d1163 1
a1163 1
	init_gpr(alu_first);
d1165 8
a1172 2
	LIST_FOR_EACH_ENTRY(alu, &alu_first->bs_list, bs_list) {
		num_instr++;
d1175 18
a1192 8
	if (num_instr == 1) {
		check_scalar(bc, alu_first);
		
	} else {
/*		check_read_slots(bc, bc->cf_last->curr_bs_head);*/
		check_vector(bc, alu_first);
		LIST_FOR_EACH_ENTRY(alu, &alu_first->bs_list, bs_list) {
			check_vector(bc, alu);
d1195 1
d1208 14
a1221 1
	nalu->nliteral = 0;
d1224 1
a1224 2
	if (bc->cf_last == NULL || bc->cf_last->inst != (type << 3) ||
		bc->force_add_cf) {
a1229 1
		bc->cf_last->inst = (type << 3);
d1231 9
a1241 8
		LIST_INITHEAD(&nalu->bs_list);
	} else {
		LIST_ADDTAIL(&nalu->bs_list, &bc->cf_last->curr_bs_head->bs_list);
	}
	/* at most 128 slots, one add alu can add 4 slots + 4 constants(2 slots)
	 * worst case */
	if (alu->last && (bc->cf_last->ndw >> 1) >= 120) {
		bc->force_add_cf = 1;
d1245 2
a1246 10
		if (alu->src[i].sel >= bc->ngpr && alu->src[i].sel < 128) {
			bc->ngpr = alu->src[i].sel + 1;
		}
		/* compute how many literal are needed
		 * either 2 or 4 literals
		 */
		if (alu->src[i].sel == 253) {
			if (((alu->src[i].chan + 2) & 0x6) > nalu->nliteral) {
				nalu->nliteral = (alu->src[i].chan + 2) & 0x6;
			}
d1248 3
d1252 2
a1253 8
	if (!LIST_IS_EMPTY(&bc->cf_last->alu)) {
		lalu = LIST_ENTRY(struct r600_bc_alu, bc->cf_last->alu.prev, list);
		if (!lalu->last && lalu->nliteral > nalu->nliteral) {
			nalu->nliteral = lalu->nliteral;
		}
	}
	if (alu->dst.sel >= bc->ngpr) {
		bc->ngpr = alu->dst.sel + 1;
d1260 15
a1274 16
	/* The following configuration provides 64 128-bit constants.
	 * Each cacheline holds 16 128-bit constants and each
	 * kcache can lock 2 cachelines and there are 2 kcaches per
	 * ALU clause for a max of 64 constants.
	 * For supporting more than 64 constants, the code needs
	 * to be broken down into multiple ALU clauses.
	 */
	/* select the constant buffer (0-15) for each kcache */
	bc->cf_last->kcache0_bank = 0;
	bc->cf_last->kcache1_bank = 0;
	/* lock 2 cachelines per kcache; 4 total */
	bc->cf_last->kcache0_mode = V_SQ_CF_KCACHE_LOCK_2;
	bc->cf_last->kcache1_mode = V_SQ_CF_KCACHE_LOCK_2;
	/* set the cacheline offsets for each kcache */
	bc->cf_last->kcache0_addr = 0;
	bc->cf_last->kcache1_addr = 2;
d1276 27
a1302 3
	/* process cur ALU instructions for bank swizzle */
	if (alu->last) {
		check_and_set_bank_swizzle(bc, bc->cf_last->curr_bs_head);
d1313 1
a1313 1
int r600_bc_add_literal(struct r600_bc *bc, const u32 *value)
d1315 10
a1324 1
	struct r600_bc_alu *alu;
d1326 3
a1328 2
	if (bc->cf_last == NULL) {
		return 0;
d1330 11
a1340 12
	if (bc->cf_last->inst == V_SQ_CF_WORD1_SQ_CF_INST_TEX) {
		return 0;
	}
	/* all same on EG */
	if (bc->cf_last->inst == V_SQ_CF_WORD1_SQ_CF_INST_JUMP ||
	    bc->cf_last->inst == V_SQ_CF_WORD1_SQ_CF_INST_ELSE ||
	    bc->cf_last->inst == V_SQ_CF_WORD1_SQ_CF_INST_LOOP_START_NO_AL ||
	    bc->cf_last->inst == V_SQ_CF_WORD1_SQ_CF_INST_LOOP_BREAK ||
	    bc->cf_last->inst == V_SQ_CF_WORD1_SQ_CF_INST_LOOP_CONTINUE ||
	    bc->cf_last->inst == V_SQ_CF_WORD1_SQ_CF_INST_LOOP_END ||
	    bc->cf_last->inst == V_SQ_CF_WORD1_SQ_CF_INST_POP) {
		return 0;
d1342 1
a1342 16
	/* same on EG */
	if (((bc->cf_last->inst != (V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU << 3)) &&
	     (bc->cf_last->inst != (V_SQ_CF_ALU_WORD1_SQ_CF_INST_ALU_PUSH_BEFORE << 3))) ||
		LIST_IS_EMPTY(&bc->cf_last->alu)) {
		R600_ERR("last CF is not ALU (%p)\n", bc->cf_last);
		return -EINVAL;
	}
	alu = LIST_ENTRY(struct r600_bc_alu, bc->cf_last->alu.prev, list);
	if (!alu->last || !alu->nliteral || alu->literal_added) {
		return 0;
	}
	memcpy(alu->value, value, 4 * 4);
	bc->cf_last->ndw += alu->nliteral;
	bc->ndw += alu->nliteral;
	alu->literal_added = 1;
	return 0;
d1356 2
a1357 3
		(bc->cf_last->inst != V_SQ_CF_WORD1_SQ_CF_INST_VTX &&
		 bc->cf_last->inst != V_SQ_CF_WORD1_SQ_CF_INST_VTX_TC) ||
	         bc->force_add_cf) {
d1363 4
a1366 1
		bc->cf_last->inst = V_SQ_CF_WORD1_SQ_CF_INST_VTX;
d1372 1
a1372 1
	if ((bc->ndw / 4) > 7)
d1386 15
d1412 6
d1422 1
a1422 1
	if ((bc->ndw / 4) > 7)
d1439 5
d1447 2
a1448 25
	unsigned fetch_resource_start = 0;

	/* check if we are fetch shader */
			/* fetch shader can also access vertex resource,
			 * first fetch shader resource is at 160
			 */
	if (bc->type == -1) {
		switch (bc->chiprev) {
		/* r600 */
		case CHIPREV_R600:
		/* r700 */
		case CHIPREV_R700:
			fetch_resource_start = 160;
			break;
		/* evergreen */
		case CHIPREV_EVERGREEN:
			fetch_resource_start = 0;
			break;
		default:
			fprintf(stderr,  "%s:%s:%d unknown chiprev %d\n",
				__FILE__, __func__, __LINE__, bc->chiprev);
			break;
		}
	}
	bc->bytecode[id++] = S_SQ_VTX_WORD0_BUFFER_ID(vtx->buffer_id + fetch_resource_start) |
d1450 4
a1453 2
			S_SQ_VTX_WORD0_SRC_SEL_X(vtx->src_sel_x) |
			S_SQ_VTX_WORD0_MEGA_FETCH_COUNT(vtx->mega_fetch_count);
d1464 5
a1468 1
	bc->bytecode[id++] = S_SQ_VTX_WORD2_MEGA_FETCH(1);
a1505 2
	unsigned i;

d1536 1
a1541 8
	if (alu->last) {
		if (alu->nliteral && !alu->literal_added) {
			R600_ERR("Bug in ALU processing for instruction 0x%08x, literal not added correctly\n", alu->inst);
		}
		for (i = 0; i < alu->nliteral; i++) {
			bc->bytecode[id++] = alu->value[i];
		}
	}
d1545 8
d1561 2
d1564 3
a1566 3
			S_SQ_CF_ALU_WORD0_KCACHE_MODE0(cf->kcache0_mode) |
			S_SQ_CF_ALU_WORD0_KCACHE_BANK0(cf->kcache0_bank) |
			S_SQ_CF_ALU_WORD0_KCACHE_BANK1(cf->kcache1_bank);
d1569 3
a1571 3
			S_SQ_CF_ALU_WORD1_KCACHE_MODE1(cf->kcache1_mode) |
			S_SQ_CF_ALU_WORD1_KCACHE_ADDR0(cf->kcache0_addr) |
			S_SQ_CF_ALU_WORD1_KCACHE_ADDR1(cf->kcache1_addr) |
d1579 4
a1582 4
		bc->bytecode[id++] = S_SQ_CF_WORD0_ADDR(cf->addr >> 1);
		bc->bytecode[id++] = S_SQ_CF_WORD1_CF_INST(cf->inst) |
					S_SQ_CF_WORD1_BARRIER(1) |
					S_SQ_CF_WORD1_COUNT((cf->ndw / 4) - 1);
d1590 2
a1591 1
		bc->bytecode[id++] = S_SQ_CF_ALLOC_EXPORT_WORD1_SWIZ_SEL_X(cf->output.swizzle_x) |
d1628 2
d1631 1
a1631 1
	int r;
d1645 2
d1670 1
d1686 1
a1686 1
		if (bc->chiprev == CHIPREV_EVERGREEN)
d1694 2
d1697 2
d1700 4
d1710 1
d1721 5
a1725 1
					addr += alu->nliteral;
d1739 8
d1767 1
d1815 8
a1822 1
	unsigned i;
d1832 3
d1840 1
a1840 1
	fprintf(stderr, "bytecode %d dw -----------------------\n", bc->ndw);
d1842 187
a2028 2
	for (i = 0; i < bc->ndw; i++) {
		fprintf(stderr, "0x%08X\n", bc->bytecode[i]);
d2030 1
a2033 72
void r600_cf_vtx(struct r600_vertex_element *ve, u32 *bytecode, unsigned count)
{
	struct r600_pipe_state *rstate;
	unsigned i = 0;

	if (count > 8) {
		bytecode[i++] = S_SQ_CF_WORD0_ADDR(8 >> 1);
		bytecode[i++] = S_SQ_CF_WORD1_CF_INST(V_SQ_CF_WORD1_SQ_CF_INST_VTX) |
						S_SQ_CF_WORD1_BARRIER(1) |
						S_SQ_CF_WORD1_COUNT(8 - 1);
		bytecode[i++] = S_SQ_CF_WORD0_ADDR(40 >> 1);
		bytecode[i++] = S_SQ_CF_WORD1_CF_INST(V_SQ_CF_WORD1_SQ_CF_INST_VTX) |
						S_SQ_CF_WORD1_BARRIER(1) |
						S_SQ_CF_WORD1_COUNT(count - 8 - 1);
	} else {
		bytecode[i++] = S_SQ_CF_WORD0_ADDR(8 >> 1);
		bytecode[i++] = S_SQ_CF_WORD1_CF_INST(V_SQ_CF_WORD1_SQ_CF_INST_VTX) |
						S_SQ_CF_WORD1_BARRIER(1) |
						S_SQ_CF_WORD1_COUNT(count - 1);
	}
	bytecode[i++] = S_SQ_CF_WORD0_ADDR(0);
	bytecode[i++] = S_SQ_CF_WORD1_CF_INST(V_SQ_CF_WORD1_SQ_CF_INST_RETURN) |
			S_SQ_CF_WORD1_BARRIER(1);

	rstate = &ve->rstate;
	rstate->id = R600_PIPE_STATE_FETCH_SHADER;
	rstate->nregs = 0;
	r600_pipe_state_add_reg(rstate, R_0288A4_SQ_PGM_RESOURCES_FS,
				0x00000000, 0xFFFFFFFF, NULL);
	r600_pipe_state_add_reg(rstate, R_0288DC_SQ_PGM_CF_OFFSET_FS,
				0x00000000, 0xFFFFFFFF, NULL);
	r600_pipe_state_add_reg(rstate, R_028894_SQ_PGM_START_FS,
				r600_bo_offset(ve->fetch_shader) >> 8,
				0xFFFFFFFF, ve->fetch_shader);
}

void r600_cf_vtx_tc(struct r600_vertex_element *ve, u32 *bytecode, unsigned count)
{
	struct r600_pipe_state *rstate;
	unsigned i = 0;

	if (count > 8) {
		bytecode[i++] = S_SQ_CF_WORD0_ADDR(8 >> 1);
		bytecode[i++] = S_SQ_CF_WORD1_CF_INST(V_SQ_CF_WORD1_SQ_CF_INST_VTX_TC) |
						S_SQ_CF_WORD1_BARRIER(1) |
						S_SQ_CF_WORD1_COUNT(8 - 1);
		bytecode[i++] = S_SQ_CF_WORD0_ADDR(40 >> 1);
		bytecode[i++] = S_SQ_CF_WORD1_CF_INST(V_SQ_CF_WORD1_SQ_CF_INST_VTX_TC) |
						S_SQ_CF_WORD1_BARRIER(1) |
						S_SQ_CF_WORD1_COUNT((count - 8) - 1);
	} else {
		bytecode[i++] = S_SQ_CF_WORD0_ADDR(8 >> 1);
		bytecode[i++] = S_SQ_CF_WORD1_CF_INST(V_SQ_CF_WORD1_SQ_CF_INST_VTX_TC) |
						S_SQ_CF_WORD1_BARRIER(1) |
						S_SQ_CF_WORD1_COUNT(count - 1);
	}
	bytecode[i++] = S_SQ_CF_WORD0_ADDR(0);
	bytecode[i++] = S_SQ_CF_WORD1_CF_INST(V_SQ_CF_WORD1_SQ_CF_INST_RETURN) |
			S_SQ_CF_WORD1_BARRIER(1);

	rstate = &ve->rstate;
	rstate->id = R600_PIPE_STATE_FETCH_SHADER;
	rstate->nregs = 0;
	r600_pipe_state_add_reg(rstate, R_0288A4_SQ_PGM_RESOURCES_FS,
				0x00000000, 0xFFFFFFFF, NULL);
	r600_pipe_state_add_reg(rstate, R_0288DC_SQ_PGM_CF_OFFSET_FS,
				0x00000000, 0xFFFFFFFF, NULL);
	r600_pipe_state_add_reg(rstate, R_028894_SQ_PGM_START_FS,
				r600_bo_offset(ve->fetch_shader) >> 8,
				0xFFFFFFFF, ve->fetch_shader);
}

d2035 1
a2035 1
				unsigned *num_format, unsigned *format_comp)
d2043 1
d2057 2
d2060 1
a2060 1
		/* Half-floats, floats, doubles */
a2071 2
				*format = FMT_16_16_16_FLOAT;
				break;
a2110 2
			//	*format = FMT_8_8_8; /* fails piglit draw-vertices test */
			//	break;
a2124 2
			//	*format = FMT_16_16_16; /* fails piglit draw-vertices test */
			//	break;
d2167 1
a2167 1
static void r600_bc(unsigned ndw, unsigned chiprev, u32 *bytecode)
d2169 81
a2249 2
	unsigned i;
	char chip = '6';
d2251 4
a2254 11
	switch (chiprev) {
	case 1:
		chip = '7';
		break;
	case 2:
		chip = 'E';
		break;
	case 0:
	default:
		chip = '6';
		break;
d2256 6
a2261 4
	fprintf(stderr, "bytecode %d dw -----------------------\n", ndw);
	fprintf(stderr, "    %c\n", chip);
	for (i = 0; i < ndw; i++) {
		fprintf(stderr, "0x%08X\n", bytecode[i]);
a2262 2
	fprintf(stderr, "--------------------------------------\n");
}
d2264 8
a2271 7
int r600_vertex_elements_build_fetch_shader(struct r600_pipe_context *rctx, struct r600_vertex_element *ve)
{
	unsigned ndw, i;
	u32 *bytecode;
	unsigned fetch_resource_start = 0, format, num_format, format_comp;
	struct pipe_vertex_element *elements = ve->elements;
	const struct util_format_description *desc;
d2273 1
a2273 3
	/* 2 dwords for cf aligned to 4 + 4 dwords per input */
	ndw = 8 + ve->count * 4;
	ve->fs_size = ndw * 4;
d2276 1
a2276 1
	ve->fetch_shader = r600_bo(rctx->radeon, ndw*4, 256, PIPE_BIND_VERTEX_BUFFER, 0);
d2278 1
d2284 1
d2289 4
a2292 2
	if (rctx->family >= CHIP_CEDAR) {
		eg_cf_vtx(ve, &bytecode[0], (ndw - 8) / 4);
d2294 1
a2294 2
		r600_cf_vtx(ve, &bytecode[0], (ndw - 8) / 4);
		fetch_resource_start = 160;
d2297 2
a2298 11
	/* vertex elements offset need special handling, if offset is bigger
	 * than what we can put in fetch instruction then we need to alterate
	 * the vertex resource offset. In such case in order to simplify code
	 * we will bound one resource per elements. It's a worst case scenario.
	 */
	for (i = 0; i < ve->count; i++) {
		ve->vbuffer_offset[i] = C_SQ_VTX_WORD2_OFFSET & elements[i].src_offset;
		if (ve->vbuffer_offset[i]) {
			ve->vbuffer_need_offset = 1;
		}
	}
d2300 4
a2303 9
	for (i = 0; i < ve->count; i++) {
		unsigned vbuffer_index;
		r600_vertex_data_type(ve->hw_format[i], &format, &num_format, &format_comp);
		desc = util_format_description(ve->hw_format[i]);
		if (desc == NULL) {
			R600_ERR("unknown format %d\n", ve->hw_format[i]);
			r600_bo_reference(rctx->radeon, &ve->fetch_shader, NULL);
			return -EINVAL;
		}
a2304 25
		/* see above for vbuffer_need_offset explanation */
		vbuffer_index = elements[i].vertex_buffer_index;
		if (ve->vbuffer_need_offset) {
			bytecode[8 + i * 4 + 0] = S_SQ_VTX_WORD0_BUFFER_ID(i + fetch_resource_start);
		} else {
			bytecode[8 + i * 4 + 0] = S_SQ_VTX_WORD0_BUFFER_ID(vbuffer_index + fetch_resource_start);
		}
		bytecode[8 + i * 4 + 0] |= S_SQ_VTX_WORD0_SRC_GPR(0) |
					S_SQ_VTX_WORD0_SRC_SEL_X(0) |
					S_SQ_VTX_WORD0_MEGA_FETCH_COUNT(0x1F);
		bytecode[8 + i * 4 + 1] = S_SQ_VTX_WORD1_DST_SEL_X(desc->swizzle[0]) |
					S_SQ_VTX_WORD1_DST_SEL_Y(desc->swizzle[1]) |
					S_SQ_VTX_WORD1_DST_SEL_Z(desc->swizzle[2]) |
					S_SQ_VTX_WORD1_DST_SEL_W(desc->swizzle[3]) |
					S_SQ_VTX_WORD1_USE_CONST_FIELDS(0) |
					S_SQ_VTX_WORD1_DATA_FORMAT(format) |
					S_SQ_VTX_WORD1_NUM_FORMAT_ALL(num_format) |
					S_SQ_VTX_WORD1_FORMAT_COMP_ALL(format_comp) |
					S_SQ_VTX_WORD1_SRF_MODE_ALL(1) |
					S_SQ_VTX_WORD1_GPR_DST_GPR(i + 1);
		bytecode[8 + i * 4 + 2] = S_SQ_VTX_WORD2_OFFSET(elements[i].src_offset) |
					S_SQ_VTX_WORD2_MEGA_FETCH(1);
		bytecode[8 + i * 4 + 3] = 0;
	}
	r600_bo_unmap(rctx->radeon, ve->fetch_shader);
@


1.1.1.1
log
@Import Mesa 7.10.3
@
text
@@


1.1.1.2
log
@Import Mesa 9.2.0
@
text
@d23 6
d31 1
a32 1
#include "r600_shader.h"
d35 4
a38 5
#include <errno.h>
#include "util/u_dump.h"
#include "util/u_memory.h"
#include "util/u_math.h"
#include "pipe/p_shader_tokens.h"
d40 41
a80 4
#include "sb/sb_public.h"

#define NUM_OF_CYCLES 3
#define NUM_OF_COMPONENTS 4
d82 1
a82 4
static inline unsigned int r600_bytecode_get_num_operands(
		struct r600_bytecode *bc, struct r600_bytecode_alu *alu)
{
	return r600_isa_alu(alu->op)->src_count;
d85 1
a85 2
int r700_bytecode_alu_build(struct r600_bytecode *bc,
		struct r600_bytecode_alu *alu, unsigned id);
d87 1
a87 1
static struct r600_bytecode_cf *r600_bytecode_cf(void)
d89 1
a89 1
	struct r600_bytecode_cf *cf = CALLOC_STRUCT(r600_bytecode_cf);
d100 1
a100 1
static struct r600_bytecode_alu *r600_bytecode_alu(void)
d102 1
a102 1
	struct r600_bytecode_alu *alu = CALLOC_STRUCT(r600_bytecode_alu);
d107 1
d111 1
a111 1
static struct r600_bytecode_vtx *r600_bytecode_vtx(void)
d113 1
a113 1
	struct r600_bytecode_vtx *vtx = CALLOC_STRUCT(r600_bytecode_vtx);
d121 1
a121 1
static struct r600_bytecode_tex *r600_bytecode_tex(void)
d123 1
a123 1
	struct r600_bytecode_tex *tex = CALLOC_STRUCT(r600_bytecode_tex);
d131 6
a136 15
static unsigned stack_entry_size(enum radeon_family chip) {
	/* Wavefront size:
	 *   64: R600/RV670/RV770/Cypress/R740/Barts/Turks/Caicos/
	 *       Aruba/Sumo/Sumo2/redwood/juniper
	 *   32: R630/R730/R710/Palm/Cedar
	 *   16: R610/Rs780
	 *
	 * Stack row size:
	 * 	Wavefront Size                        16  32  48  64
	 * 	Columns per Row (R6xx/R7xx/R8xx only)  8   8   4   4
	 * 	Columns per Row (R9xx+)                8   4   4   4 */

	switch (chip) {
	/* FIXME: are some chips missing here? */
	/* wavefront size 16 */
d138 4
a142 1
	case CHIP_RV620:
d144 3
a146 3
	/* wavefront size 32 */
	case CHIP_RV630:
	case CHIP_RV635:
d149 8
d158 5
a162 4
	case CHIP_CEDAR:
		return 8;

	/* wavefront size 64 */
d164 2
a165 1
		return 4;
d167 1
d170 1
a170 25
void r600_bytecode_init(struct r600_bytecode *bc,
			enum chip_class chip_class,
			enum radeon_family family,
			bool has_compressed_msaa_texturing)
{
	static unsigned next_shader_id = 0;

	bc->debug_id = ++next_shader_id;

	if ((chip_class == R600) &&
	    (family != CHIP_RV670 && family != CHIP_RS780 && family != CHIP_RS880)) {
		bc->ar_handling = AR_HANDLE_RV6XX;
		bc->r6xx_nop_after_rel_dst = 1;
	} else {
		bc->ar_handling = AR_HANDLE_NORMAL;
		bc->r6xx_nop_after_rel_dst = 0;
	}

	LIST_INITHEAD(&bc->cf);
	bc->chip_class = chip_class;
	bc->has_compressed_msaa_texturing = has_compressed_msaa_texturing;
	bc->stack.entry_size = stack_entry_size(family);
}

int r600_bytecode_add_cf(struct r600_bytecode *bc)
d172 1
a172 1
	struct r600_bytecode_cf *cf = r600_bytecode_cf();
d177 1
a177 1
	if (bc->cf_last) {
a178 6
		if (bc->cf_last->eg_alu_extended) {
			/* take into account extended alu size */
			cf->id += 2;
			bc->ndw += 2;
		}
	}
a182 1
	bc->ar_loaded = 0;
d186 1
a186 2
int r600_bytecode_add_output(struct r600_bytecode *bc,
		const struct r600_bytecode_output *output)
d190 1
a190 36
	if (output->gpr >= bc->ngpr)
		bc->ngpr = output->gpr + 1;

	if (bc->cf_last && (bc->cf_last->op == output->op ||
		(bc->cf_last->op == CF_OP_EXPORT &&
		output->op == CF_OP_EXPORT_DONE)) &&
		output->type == bc->cf_last->output.type &&
		output->elem_size == bc->cf_last->output.elem_size &&
		output->swizzle_x == bc->cf_last->output.swizzle_x &&
		output->swizzle_y == bc->cf_last->output.swizzle_y &&
		output->swizzle_z == bc->cf_last->output.swizzle_z &&
		output->swizzle_w == bc->cf_last->output.swizzle_w &&
		output->comp_mask == bc->cf_last->output.comp_mask &&
		(output->burst_count + bc->cf_last->output.burst_count) <= 16) {

		if ((output->gpr + output->burst_count) == bc->cf_last->output.gpr &&
			(output->array_base + output->burst_count) == bc->cf_last->output.array_base) {

			bc->cf_last->output.end_of_program |= output->end_of_program;
			bc->cf_last->op = bc->cf_last->output.op = output->op;
			bc->cf_last->output.gpr = output->gpr;
			bc->cf_last->output.array_base = output->array_base;
			bc->cf_last->output.burst_count += output->burst_count;
			return 0;

		} else if (output->gpr == (bc->cf_last->output.gpr + bc->cf_last->output.burst_count) &&
			output->array_base == (bc->cf_last->output.array_base + bc->cf_last->output.burst_count)) {

			bc->cf_last->output.end_of_program |= output->end_of_program;
			bc->cf_last->op = bc->cf_last->output.op = output->op;
			bc->cf_last->output.burst_count += output->burst_count;
			return 0;
		}
	}

	r = r600_bytecode_add_cf(bc);
d193 2
a194 2
	bc->cf_last->op = output->op;
	memcpy(&bc->cf_last->output, output, sizeof(struct r600_bytecode_output));
d198 3
a200 5
/* alu instructions that can ony exits once per group */
static int is_alu_once_inst(struct r600_bytecode *bc, struct r600_bytecode_alu *alu)
{
	return r600_isa_alu(alu->op)->flags & (AF_KILL | AF_PRED);
}
d202 3
a204 5
static int is_alu_reduction_inst(struct r600_bytecode *bc, struct r600_bytecode_alu *alu)
{
	return (r600_isa_alu(alu->op)->flags & AF_REPL) &&
			(r600_isa_alu_slots(bc->isa->hw_class, alu->op) == AF_4V);
}
d206 2
a207 4
static int is_alu_mova_inst(struct r600_bytecode *bc, struct r600_bytecode_alu *alu)
{
	return r600_isa_alu(alu->op)->flags & AF_MOVA;
}
d209 3
a211 77
static int alu_uses_rel(struct r600_bytecode *bc, struct r600_bytecode_alu *alu)
{
	unsigned num_src = r600_bytecode_get_num_operands(bc, alu);
	unsigned src;

	if (alu->dst.rel) {
		return 1;
	}

	for (src = 0; src < num_src; ++src) {
		if (alu->src[src].rel) {
			return 1;
		}
	}
	return 0;
}

static int is_alu_vec_unit_inst(struct r600_bytecode *bc, struct r600_bytecode_alu *alu)
{
	unsigned slots = r600_isa_alu_slots(bc->isa->hw_class, alu->op);
	return !(slots & AF_S);
}

static int is_alu_trans_unit_inst(struct r600_bytecode *bc, struct r600_bytecode_alu *alu)
{
	unsigned slots = r600_isa_alu_slots(bc->isa->hw_class, alu->op);
	return !(slots & AF_V);
}

/* alu instructions that can execute on any unit */
static int is_alu_any_unit_inst(struct r600_bytecode *bc, struct r600_bytecode_alu *alu)
{
	unsigned slots = r600_isa_alu_slots(bc->isa->hw_class, alu->op);
	return slots == AF_VS;
}

static int is_nop_inst(struct r600_bytecode *bc, struct r600_bytecode_alu *alu)
{
	return alu->op == ALU_OP0_NOP;
}		

static int assign_alu_units(struct r600_bytecode *bc, struct r600_bytecode_alu *alu_first,
			    struct r600_bytecode_alu *assignment[5])
{
	struct r600_bytecode_alu *alu;
	unsigned i, chan, trans;
	int max_slots = bc->chip_class == CAYMAN ? 4 : 5;

	for (i = 0; i < max_slots; i++)
		assignment[i] = NULL;

	for (alu = alu_first; alu; alu = LIST_ENTRY(struct r600_bytecode_alu, alu->list.next, list)) {
		chan = alu->dst.chan;
		if (max_slots == 4)
			trans = 0;
		else if (is_alu_trans_unit_inst(bc, alu))
			trans = 1;
		else if (is_alu_vec_unit_inst(bc, alu))
			trans = 0;
		else if (assignment[chan])
			trans = 1; /* Assume ALU_INST_PREFER_VECTOR. */
		else
			trans = 0;

		if (trans) {
			if (assignment[4]) {
				assert(0); /* ALU.Trans has already been allocated. */
				return -1;
			}
			assignment[4] = alu;
		} else {
			if (assignment[chan]) {
				assert(0); /* ALU.chan has already been allocated. */
				return -1;
			}
			assignment[chan] = alu;
		}
d213 3
a215 5
		if (alu->last)
			break;
	}
	return 0;
}
d217 2
a218 21
struct alu_bank_swizzle {
	int	hw_gpr[NUM_OF_CYCLES][NUM_OF_COMPONENTS];
	int	hw_cfile_addr[4];
	int	hw_cfile_elem[4];
};

static const unsigned cycle_for_bank_swizzle_vec[][3] = {
	[SQ_ALU_VEC_012] = { 0, 1, 2 },
	[SQ_ALU_VEC_021] = { 0, 2, 1 },
	[SQ_ALU_VEC_120] = { 1, 2, 0 },
	[SQ_ALU_VEC_102] = { 1, 0, 2 },
	[SQ_ALU_VEC_201] = { 2, 0, 1 },
	[SQ_ALU_VEC_210] = { 2, 1, 0 }
};

static const unsigned cycle_for_bank_swizzle_scl[][3] = {
	[SQ_ALU_SCL_210] = { 2, 1, 0 },
	[SQ_ALU_SCL_122] = { 1, 2, 2 },
	[SQ_ALU_SCL_212] = { 2, 1, 2 },
	[SQ_ALU_SCL_221] = { 2, 2, 1 }
};
d220 1
a220 1
static void init_bank_swizzle(struct alu_bank_swizzle *bs)
d222 1
a222 1
	int i, cycle, component;
d226 2
a227 5
			 bs->hw_gpr[cycle][component] = -1;
	for (i = 0; i < 4; i++)
		bs->hw_cfile_addr[i] = -1;
	for (i = 0; i < 4; i++)
		bs->hw_cfile_elem[i] = -1;
d230 7
a236 6
static int reserve_gpr(struct alu_bank_swizzle *bs, unsigned sel, unsigned chan, unsigned cycle)
{
	if (bs->hw_gpr[cycle][chan] == -1)
		bs->hw_gpr[cycle][chan] = sel;
	else if (bs->hw_gpr[cycle][chan] != (int)sel) {
		/* Another scalar operation has already used the GPR read port for the channel. */
d242 1
a242 1
static int reserve_cfile(struct r600_bytecode *bc, struct alu_bank_swizzle *bs, unsigned sel, unsigned chan)
d244 24
a267 13
	int res, num_res = 4;
	if (bc->chip_class >= R700) {
		num_res = 2;
		chan /= 2;
	}
	for (res = 0; res < num_res; ++res) {
		if (bs->hw_cfile_addr[res] == -1) {
			bs->hw_cfile_addr[res] = sel;
			bs->hw_cfile_elem[res] = chan;
			return 0;
		} else if (bs->hw_cfile_addr[res] == sel &&
			bs->hw_cfile_elem[res] == chan)
			return 0; /* Read for this scalar element already reserved, nothing to do here. */
d269 1
a269 2
	/* All cfile read ports are used, cannot reference vector element. */
	return -1;
d272 1
a272 1
static int is_gpr(unsigned sel)
d274 2
a275 2
	return (sel >= 0 && sel <= 127);
}
d277 29
a305 43
/* CB constants start at 512, and get translated to a kcache index when ALU
 * clauses are constructed. Note that we handle kcache constants the same way
 * as (the now gone) cfile constants, is that really required? */
static int is_cfile(unsigned sel)
{
	return (sel > 255 && sel < 512) ||
		(sel > 511 && sel < 4607) || /* Kcache before translation. */
		(sel > 127 && sel < 192); /* Kcache after translation. */
}

static int is_const(int sel)
{
	return is_cfile(sel) ||
		(sel >= V_SQ_ALU_SRC_0 &&
		sel <= V_SQ_ALU_SRC_LITERAL);
}

static int check_vector(struct r600_bytecode *bc, struct r600_bytecode_alu *alu,
			struct alu_bank_swizzle *bs, int bank_swizzle)
{
	int r, src, num_src, sel, elem, cycle;

	num_src = r600_bytecode_get_num_operands(bc, alu);
	for (src = 0; src < num_src; src++) {
		sel = alu->src[src].sel;
		elem = alu->src[src].chan;
		if (is_gpr(sel)) {
			cycle = cycle_for_bank_swizzle_vec[bank_swizzle][src];
			if (src == 1 && sel == alu->src[0].sel && elem == alu->src[0].chan)
				/* Nothing to do; special-case optimization,
				 * second source uses first sourceâ€™s reservation. */
				continue;
			else {
				r = reserve_gpr(bs, sel, elem, cycle);
				if (r)
					return r;
			}
		} else if (is_cfile(sel)) {
			r = reserve_cfile(bc, bs, (alu->src[src].kc_bank<<16) + sel, elem);
			if (r)
				return r;
		}
		/* No restrictions on PV, PS, literal or special constants. */
d307 1
a307 1
	return 0;
a309 4
static int check_scalar(struct r600_bytecode *bc, struct r600_bytecode_alu *alu,
			struct alu_bank_swizzle *bs, int bank_swizzle)
{
	int r, src, num_src, const_count, sel, elem, cycle;
a310 40
	num_src = r600_bytecode_get_num_operands(bc, alu);
	for (const_count = 0, src = 0; src < num_src; ++src) {
		sel = alu->src[src].sel;
		elem = alu->src[src].chan;
		if (is_const(sel)) { /* Any constant, including literal and inline constants. */
			if (const_count >= 2)
				/* More than two references to a constant in
				 * transcendental operation. */
				return -1;
			else
				const_count++;
		}
		if (is_cfile(sel)) {
			r = reserve_cfile(bc, bs, (alu->src[src].kc_bank<<16) + sel, elem);
			if (r)
				return r;
		}
	}
	for (src = 0; src < num_src; ++src) {
		sel = alu->src[src].sel;
		elem = alu->src[src].chan;
		if (is_gpr(sel)) {
			cycle = cycle_for_bank_swizzle_scl[bank_swizzle][src];
			if (cycle < const_count)
				/* Cycle for GPR load conflicts with
				 * constant load in transcendental operation. */
				return -1;
			r = reserve_gpr(bs, sel, elem, cycle);
			if (r)
				return r;
		}
		/* PV PS restrictions */
		if (const_count && (sel == 254 || sel == 255)) {
			cycle = cycle_for_bank_swizzle_scl[bank_swizzle][src];
			if (cycle < const_count)
				return -1;
		}
	}
	return 0;
}
d312 1
a312 2
static int check_and_set_bank_swizzle(struct r600_bytecode *bc,
				      struct r600_bytecode_alu *slots[5])
d314 3
a316 28
	struct alu_bank_swizzle bs;
	int bank_swizzle[5];
	int i, r = 0, forced = 1;
	boolean scalar_only = bc->chip_class == CAYMAN ? false : true;
	int max_slots = bc->chip_class == CAYMAN ? 4 : 5;

	for (i = 0; i < max_slots; i++) {
		if (slots[i]) {
			if (slots[i]->bank_swizzle_force) {
				slots[i]->bank_swizzle = slots[i]->bank_swizzle_force;
			} else {
				forced = 0;
			}
		}

		if (i < 4 && slots[i])
			scalar_only = false;
	}
	if (forced)
		return 0;

	/* Just check every possible combination of bank swizzle.
	 * Not very efficent, but works on the first try in most of the cases. */
	for (i = 0; i < 4; i++)
		if (!slots[i] || !slots[i]->bank_swizzle_force)
			bank_swizzle[i] = SQ_ALU_VEC_012;
		else
			bank_swizzle[i] = slots[i]->bank_swizzle;
d318 1
a318 2
	bank_swizzle[4] = SQ_ALU_SCL_210;
	while(bank_swizzle[4] <= SQ_ALU_SCL_221) {
d320 4
a323 38
		init_bank_swizzle(&bs);
		if (scalar_only == false) {
			for (i = 0; i < 4; i++) {
				if (slots[i]) {
					r = check_vector(bc, slots[i], &bs, bank_swizzle[i]);
					if (r)
						break;
				}
			}
		} else
			r = 0;

		if (!r && max_slots == 5 && slots[4]) {
			r = check_scalar(bc, slots[4], &bs, bank_swizzle[4]);
		}
		if (!r) {
			for (i = 0; i < max_slots; i++) {
				if (slots[i])
					slots[i]->bank_swizzle = bank_swizzle[i];
			}
			return 0;
		}

		if (scalar_only) {
			bank_swizzle[4]++;
		} else {
			for (i = 0; i < max_slots; i++) {
				if (!slots[i] || !slots[i]->bank_swizzle_force) {
					bank_swizzle[i]++;
					if (bank_swizzle[i] <= SQ_ALU_VEC_210)
						break;
					else if (i < max_slots - 1)
						bank_swizzle[i] = SQ_ALU_VEC_012;
					else
						return -1;
				}
			}
		}
a324 3

	/* Couldn't find a working swizzle. */
	return -1;
d327 2
a328 2
static int replace_gpr_with_pv_ps(struct r600_bytecode *bc,
				  struct r600_bytecode_alu *slots[5], struct r600_bytecode_alu *alu_prev)
d330 2
a331 4
	struct r600_bytecode_alu *prev[5];
	int gpr[5], chan[5];
	int i, j, r, src, num_src;
	int max_slots = bc->chip_class == CAYMAN ? 4 : 5;
d333 1
a333 3
	r = assign_alu_units(bc, alu_prev, prev);
	if (r)
		return r;
d335 3
a337 31
	for (i = 0; i < max_slots; ++i) {
		if (prev[i] && (prev[i]->dst.write || prev[i]->is_op3) && !prev[i]->dst.rel) {
			gpr[i] = prev[i]->dst.sel;
			/* cube writes more than PV.X */
			if (is_alu_reduction_inst(bc, prev[i]))
				chan[i] = 0;
			else
				chan[i] = prev[i]->dst.chan;
		} else
			gpr[i] = -1;
	}

	for (i = 0; i < max_slots; ++i) {
		struct r600_bytecode_alu *alu = slots[i];
		if(!alu)
			continue;

		num_src = r600_bytecode_get_num_operands(bc, alu);
		for (src = 0; src < num_src; ++src) {
			if (!is_gpr(alu->src[src].sel) || alu->src[src].rel)
				continue;

			if (bc->chip_class < CAYMAN) {
				if (alu->src[src].sel == gpr[4] &&
				    alu->src[src].chan == chan[4] &&
				    alu_prev->pred_sel == alu->pred_sel) {
					alu->src[src].sel = V_SQ_ALU_SRC_PS;
					alu->src[src].chan = 0;
					continue;
				}
			}
d339 7
a345 10
			for (j = 0; j < 4; ++j) {
				if (alu->src[src].sel == gpr[j] &&
					alu->src[src].chan == j &&
				      alu_prev->pred_sel == alu->pred_sel) {
					alu->src[src].sel = V_SQ_ALU_SRC_PV;
					alu->src[src].chan = chan[j];
					break;
				}
			}
		}
a346 1

d349 1
d351 1
a351 1
void r600_bytecode_special_constants(uint32_t value, unsigned *sel, unsigned *neg)
d353 4
a356 54
	switch(value) {
	case 0:
		*sel = V_SQ_ALU_SRC_0;
		break;
	case 1:
		*sel = V_SQ_ALU_SRC_1_INT;
		break;
	case -1:
		*sel = V_SQ_ALU_SRC_M_1_INT;
		break;
	case 0x3F800000: /* 1.0f */
		*sel = V_SQ_ALU_SRC_1;
		break;
	case 0x3F000000: /* 0.5f */
		*sel = V_SQ_ALU_SRC_0_5;
		break;
	case 0xBF800000: /* -1.0f */
		*sel = V_SQ_ALU_SRC_1;
		*neg ^= 1;
		break;
	case 0xBF000000: /* -0.5f */
		*sel = V_SQ_ALU_SRC_0_5;
		*neg ^= 1;
		break;
	default:
		*sel = V_SQ_ALU_SRC_LITERAL;
		break;
	}
}

/* compute how many literal are needed */
static int r600_bytecode_alu_nliterals(struct r600_bytecode *bc, struct r600_bytecode_alu *alu,
				 uint32_t literal[4], unsigned *nliteral)
{
	unsigned num_src = r600_bytecode_get_num_operands(bc, alu);
	unsigned i, j;

	for (i = 0; i < num_src; ++i) {
		if (alu->src[i].sel == V_SQ_ALU_SRC_LITERAL) {
			uint32_t value = alu->src[i].value;
			unsigned found = 0;
			for (j = 0; j < *nliteral; ++j) {
				if (literal[j] == value) {
					found = 1;
					break;
				}
			}
			if (!found) {
				if (*nliteral >= 4)
					return -EINVAL;
				literal[(*nliteral)++] = value;
			}
		}
	}
d360 1
a360 22
static void r600_bytecode_alu_adjust_literals(struct r600_bytecode *bc,
					struct r600_bytecode_alu *alu,
					uint32_t literal[4], unsigned nliteral)
{
	unsigned num_src = r600_bytecode_get_num_operands(bc, alu);
	unsigned i, j;

	for (i = 0; i < num_src; ++i) {
		if (alu->src[i].sel == V_SQ_ALU_SRC_LITERAL) {
			uint32_t value = alu->src[i].value;
			for (j = 0; j < nliteral; ++j) {
				if (literal[j] == value) {
					alu->src[i].chan = j;
					break;
				}
			}
		}
	}
}

static int merge_inst_groups(struct r600_bytecode *bc, struct r600_bytecode_alu *slots[5],
			     struct r600_bytecode_alu *alu_prev)
d362 1
a362 108
	struct r600_bytecode_alu *prev[5];
	struct r600_bytecode_alu *result[5] = { NULL };

	uint32_t literal[4], prev_literal[4];
	unsigned nliteral = 0, prev_nliteral = 0;

	int i, j, r, src, num_src;
	int num_once_inst = 0;
	int have_mova = 0, have_rel = 0;
	int max_slots = bc->chip_class == CAYMAN ? 4 : 5;

	r = assign_alu_units(bc, alu_prev, prev);
	if (r)
		return r;

	for (i = 0; i < max_slots; ++i) {
		if (prev[i]) {
		      if (prev[i]->pred_sel)
			      return 0;
		      if (is_alu_once_inst(bc, prev[i]))
			      return 0;
		}
		if (slots[i]) {
			if (slots[i]->pred_sel)
				return 0;
			if (is_alu_once_inst(bc, slots[i]))
				return 0;
		}
	}

	for (i = 0; i < max_slots; ++i) {
		struct r600_bytecode_alu *alu;

		if (num_once_inst > 0)
		   return 0;

		/* check number of literals */
		if (prev[i]) {
			if (r600_bytecode_alu_nliterals(bc, prev[i], literal, &nliteral))
				return 0;
			if (r600_bytecode_alu_nliterals(bc, prev[i], prev_literal, &prev_nliteral))
				return 0;
			if (is_alu_mova_inst(bc, prev[i])) {
				if (have_rel)
					return 0;
				have_mova = 1;
			}

			if (alu_uses_rel(bc, prev[i])) {
				if (have_mova) {
					return 0;
				}
				have_rel = 1;
			}

			num_once_inst += is_alu_once_inst(bc, prev[i]);
		}
		if (slots[i] && r600_bytecode_alu_nliterals(bc, slots[i], literal, &nliteral))
			return 0;

		/* Let's check used slots. */
		if (prev[i] && !slots[i]) {
			result[i] = prev[i];
			continue;
		} else if (prev[i] && slots[i]) {
			if (max_slots == 5 && result[4] == NULL && prev[4] == NULL && slots[4] == NULL) {
				/* Trans unit is still free try to use it. */
				if (is_alu_any_unit_inst(bc, slots[i])) {
					result[i] = prev[i];
					result[4] = slots[i];
				} else if (is_alu_any_unit_inst(bc, prev[i])) {
					if (slots[i]->dst.sel == prev[i]->dst.sel &&
						(slots[i]->dst.write == 1 || slots[i]->is_op3) &&
						(prev[i]->dst.write == 1 || prev[i]->is_op3))
						return 0;

					result[i] = slots[i];
					result[4] = prev[i];
				} else
					return 0;
			} else
				return 0;
		} else if(!slots[i]) {
			continue;
		} else {
			if (max_slots == 5 && slots[i] && prev[4] &&
					slots[i]->dst.sel == prev[4]->dst.sel &&
					slots[i]->dst.chan == prev[4]->dst.chan &&
					(slots[i]->dst.write == 1 || slots[i]->is_op3) &&
					(prev[4]->dst.write == 1 || prev[4]->is_op3))
				return 0;

			result[i] = slots[i];
		}

		alu = slots[i];
		num_once_inst += is_alu_once_inst(bc, alu);

		/* don't reschedule NOPs */
		if (is_nop_inst(bc, alu))
			return 0;

		if (is_alu_mova_inst(bc, alu)) {
			if (have_rel) {
				return 0;
			}
			have_mova = 1;
		}
d364 2
a365 35
		if (alu_uses_rel(bc, alu)) {
			if (have_mova) {
				return 0;
			}
			have_rel = 1;
		}

		/* Let's check source gprs */
		num_src = r600_bytecode_get_num_operands(bc, alu);
		for (src = 0; src < num_src; ++src) {

			/* Constants don't matter. */
			if (!is_gpr(alu->src[src].sel))
				continue;

			for (j = 0; j < max_slots; ++j) {
				if (!prev[j] || !(prev[j]->dst.write || prev[j]->is_op3))
					continue;

				/* If it's relative then we can't determin which gpr is really used. */
				if (prev[j]->dst.chan == alu->src[src].chan &&
					(prev[j]->dst.sel == alu->src[src].sel ||
					prev[j]->dst.rel || alu->src[src].rel))
					return 0;
			}
		}
	}

	/* more than one PRED_ or KILL_ ? */
	if (num_once_inst > 1)
		return 0;

	/* check if the result can still be swizzlet */
	r = check_and_set_bank_swizzle(bc, result);
	if (r)
a366 14

	/* looks like everything worked out right, apply the changes */

	/* undo adding previus literals */
	bc->cf_last->ndw -= align(prev_nliteral, 2);

	/* sort instructions */
	for (i = 0; i < max_slots; ++i) {
		slots[i] = result[i];
		if (result[i]) {
			LIST_DEL(&result[i]->list);
			result[i]->last = 0;
			LIST_ADDTAIL(&result[i]->list, &bc->cf_last->alu);
		}
d368 3
d372 1
a372 14
	/* determine new last instruction */
	LIST_ENTRY(struct r600_bytecode_alu, bc->cf_last->alu.prev, list)->last = 1;

	/* determine new first instruction */
	for (i = 0; i < max_slots; ++i) {
		if (result[i]) {
			bc->cf_last->curr_bs_head = result[i];
			break;
		}
	}

	bc->cf_last->prev_bs_head = bc->cf_last->prev2_bs_head;
	bc->cf_last->prev2_bs_head = NULL;

d376 1
a376 4
/* we'll keep kcache sets sorted by bank & addr */
static int r600_bytecode_alloc_kcache_line(struct r600_bytecode *bc,
		struct r600_bytecode_kcache *kcache,
		unsigned bank, unsigned line)
d378 1
a378 1
	int i, kcache_banks = bc->chip_class >= EVERGREEN ? 4 : 2;
d380 3
a382 71
	for (i = 0; i < kcache_banks; i++) {
		if (kcache[i].mode) {
			int d;

			if (kcache[i].bank < bank)
				continue;

			if ((kcache[i].bank == bank && kcache[i].addr > line+1) ||
					kcache[i].bank > bank) {
				/* try to insert new line */
				if (kcache[kcache_banks-1].mode) {
					/* all sets are in use */
					return -ENOMEM;
				}

				memmove(&kcache[i+1],&kcache[i], (kcache_banks-i-1)*sizeof(struct r600_bytecode_kcache));
				kcache[i].mode = V_SQ_CF_KCACHE_LOCK_1;
				kcache[i].bank = bank;
				kcache[i].addr = line;
				return 0;
			}

			d = line - kcache[i].addr;

			if (d == -1) {
				kcache[i].addr--;
				if (kcache[i].mode == V_SQ_CF_KCACHE_LOCK_2) {
					/* we are prepending the line to the current set,
					 * discarding the existing second line,
					 * so we'll have to insert line+2 after it */
					line += 2;
					continue;
				} else if (kcache[i].mode == V_SQ_CF_KCACHE_LOCK_1) {
					kcache[i].mode = V_SQ_CF_KCACHE_LOCK_2;
					return 0;
				} else {
					/* V_SQ_CF_KCACHE_LOCK_LOOP_INDEX is not supported */
					return -ENOMEM;
				}
			} else if (d == 1) {
				kcache[i].mode = V_SQ_CF_KCACHE_LOCK_2;
				return 0;
			} else if (d == 0)
				return 0;
		} else { /* free kcache set - use it */
			kcache[i].mode = V_SQ_CF_KCACHE_LOCK_1;
			kcache[i].bank = bank;
			kcache[i].addr = line;
			return 0;
		}
	}
	return -ENOMEM;
}

static int r600_bytecode_alloc_inst_kcache_lines(struct r600_bytecode *bc,
		struct r600_bytecode_kcache *kcache,
		struct r600_bytecode_alu *alu)
{
	int i, r;

	for (i = 0; i < 3; i++) {
		unsigned bank, line, sel = alu->src[i].sel;

		if (sel < 512)
			continue;

		bank = alu->src[i].kc_bank;
		line = (sel-512)>>4;

		if ((r = r600_bytecode_alloc_kcache_line(bc, kcache, bank, line)))
			return r;
d384 3
a386 2
	return 0;
}
d388 1
a388 34
static int r600_bytecode_assign_kcache_banks(struct r600_bytecode *bc,
		struct r600_bytecode_alu *alu,
		struct r600_bytecode_kcache * kcache)
{
	int i, j;

	/* Alter the src operands to refer to the kcache. */
	for (i = 0; i < 3; ++i) {
		static const unsigned int base[] = {128, 160, 256, 288};
		unsigned int line, sel = alu->src[i].sel, found = 0;

		if (sel < 512)
			continue;

		sel -= 512;
		line = sel>>4;

		for (j = 0; j < 4 && !found; ++j) {
			switch (kcache[j].mode) {
			case V_SQ_CF_KCACHE_NOP:
			case V_SQ_CF_KCACHE_LOCK_LOOP_INDEX:
				R600_ERR("unexpected kcache line mode\n");
				return -ENOMEM;
			default:
				if (kcache[j].bank == alu->src[i].kc_bank &&
						kcache[j].addr <= line &&
						line < kcache[j].addr + kcache[j].mode) {
					alu->src[i].sel = sel - (kcache[j].addr<<4);
					alu->src[i].sel += base[j];
					found=1;
			    }
			}
		}
	}
d392 1
a392 3
static int r600_bytecode_alloc_kcache_lines(struct r600_bytecode *bc,
		struct r600_bytecode_alu *alu,
		unsigned type)
d394 2
a395 3
	struct r600_bytecode_kcache kcache_sets[4];
	struct r600_bytecode_kcache *kcache = kcache_sets;
	int r;
d397 1
a397 1
	memcpy(kcache, bc->cf_last->kcache, 4 * sizeof(struct r600_bytecode_kcache));
d399 3
a401 6
	if ((r = r600_bytecode_alloc_inst_kcache_lines(bc, kcache, alu))) {
		/* can't alloc, need to start new clause */
		if ((r = r600_bytecode_add_cf(bc))) {
			return r;
		}
		bc->cf_last->op = type;
d403 8
a410 5
		/* retry with the new clause */
		kcache = bc->cf_last->kcache;
		if ((r = r600_bytecode_alloc_inst_kcache_lines(bc, kcache, alu))) {
			/* can't alloc again- should never happen */
			return r;
a411 29
	} else {
		/* update kcache sets */
		memcpy(bc->cf_last->kcache, kcache, 4 * sizeof(struct r600_bytecode_kcache));
	}

	/* if we actually used more than 2 kcache sets - use ALU_EXTENDED on eg+ */
	if (kcache[2].mode != V_SQ_CF_KCACHE_NOP) {
		if (bc->chip_class < EVERGREEN)
			return -ENOMEM;
		bc->cf_last->eg_alu_extended = 1;
	}

	return 0;
}

static int insert_nop_r6xx(struct r600_bytecode *bc)
{
	struct r600_bytecode_alu alu;
	int r, i;

	for (i = 0; i < 4; i++) {
		memset(&alu, 0, sizeof(alu));
		alu.op = ALU_OP0_NOP;
		alu.src[0].chan = i;
		alu.dst.chan = i;
		alu.last = (i == 3);
		r = r600_bytecode_add_alu(bc, &alu);
		if (r)
			return r;
d416 1
a416 2
/* load AR register from gpr (bc->ar_reg) with MOVA_INT */
static int load_ar_r6xx(struct r600_bytecode *bc)
d418 2
a419 60
	struct r600_bytecode_alu alu;
	int r;

	if (bc->ar_loaded)
		return 0;

	/* hack to avoid making MOVA the last instruction in the clause */
	if ((bc->cf_last->ndw>>1) >= 110)
		bc->force_add_cf = 1;

	memset(&alu, 0, sizeof(alu));
	alu.op = ALU_OP1_MOVA_GPR_INT;
	alu.src[0].sel = bc->ar_reg;
	alu.src[0].chan = bc->ar_chan;
	alu.last = 1;
	alu.index_mode = INDEX_MODE_LOOP;
	r = r600_bytecode_add_alu(bc, &alu);
	if (r)
		return r;

	/* no requirement to set uses waterfall on MOVA_GPR_INT */
	bc->ar_loaded = 1;
	return 0;
}

/* load AR register from gpr (bc->ar_reg) with MOVA_INT */
static int load_ar(struct r600_bytecode *bc)
{
	struct r600_bytecode_alu alu;
	int r;

	if (bc->ar_handling)
		return load_ar_r6xx(bc);

	if (bc->ar_loaded)
		return 0;

	/* hack to avoid making MOVA the last instruction in the clause */
	if ((bc->cf_last->ndw>>1) >= 110)
		bc->force_add_cf = 1;

	memset(&alu, 0, sizeof(alu));
	alu.op = ALU_OP1_MOVA_INT;
	alu.src[0].sel = bc->ar_reg;
	alu.src[0].chan = bc->ar_chan;
	alu.last = 1;
	r = r600_bytecode_add_alu(bc, &alu);
	if (r)
		return r;

	bc->cf_last->r6xx_uses_waterfall = 1;
	bc->ar_loaded = 1;
	return 0;
}

int r600_bytecode_add_alu_type(struct r600_bytecode *bc,
		const struct r600_bytecode_alu *alu, unsigned type)
{
	struct r600_bytecode_alu *nalu = r600_bytecode_alu();
	struct r600_bytecode_alu *lalu;
d424 2
a425 15
	memcpy(nalu, alu, sizeof(struct r600_bytecode_alu));

	if (bc->cf_last != NULL && bc->cf_last->op != type) {
		/* check if we could add it anyway */
		if (bc->cf_last->op == CF_OP_ALU &&
			type == CF_OP_ALU_PUSH_BEFORE) {
			LIST_FOR_EACH_ENTRY(lalu, &bc->cf_last->alu, list) {
				if (lalu->execute_mask) {
					bc->force_add_cf = 1;
					break;
				}
			}
		} else
			bc->force_add_cf = 1;
	}
d428 3
a430 2
	if (bc->cf_last == NULL || bc->force_add_cf) {
		r = r600_bytecode_add_cf(bc);
d435 1
a436 17
	bc->cf_last->op = type;

	/* Check AR usage and load it if required */
	for (i = 0; i < 3; i++)
		if (nalu->src[i].rel && !bc->ar_loaded)
			load_ar(bc);

	if (nalu->dst.rel && !bc->ar_loaded)
		load_ar(bc);

	/* Setup the kcache for this ALU instruction. This will start a new
	 * ALU clause if needed. */
	if ((r = r600_bytecode_alloc_kcache_lines(bc, nalu, type))) {
		free(nalu);
		return r;
	}

d439 8
d449 17
a465 3
	for (i = 0; i < 3; i++) {
		if (nalu->src[i].sel >= bc->ngpr && nalu->src[i].sel < 128) {
			bc->ngpr = nalu->src[i].sel + 1;
a466 3
		if (nalu->src[i].sel == V_SQ_ALU_SRC_LITERAL)
			r600_bytecode_special_constants(nalu->src[i].value,
				&nalu->src[i].sel, &nalu->src[i].neg);
d468 2
a469 2
	if (nalu->dst.sel >= bc->ngpr) {
		bc->ngpr = nalu->dst.sel + 1;
d476 17
d494 2
a495 42
	if (nalu->last) {
		uint32_t literal[4];
		unsigned nliteral;
		struct r600_bytecode_alu *slots[5];
		int max_slots = bc->chip_class == CAYMAN ? 4 : 5;
		r = assign_alu_units(bc, bc->cf_last->curr_bs_head, slots);
		if (r)
			return r;

		if (bc->cf_last->prev_bs_head) {
			r = merge_inst_groups(bc, slots, bc->cf_last->prev_bs_head);
			if (r)
				return r;
		}

		if (bc->cf_last->prev_bs_head) {
			r = replace_gpr_with_pv_ps(bc, slots, bc->cf_last->prev_bs_head);
			if (r)
				return r;
		}

		r = check_and_set_bank_swizzle(bc, slots);
		if (r)
			return r;

		for (i = 0, nliteral = 0; i < max_slots; i++) {
			if (slots[i]) {
				r = r600_bytecode_alu_nliterals(bc, slots[i], literal, &nliteral);
				if (r)
					return r;
			}
		}
		bc->cf_last->ndw += align(nliteral, 2);

		/* at most 128 slots, one add alu can add 5 slots + 4 constants(2 slots)
		 * worst case */
		if ((bc->cf_last->ndw >> 1) >= 120) {
			bc->force_add_cf = 1;
		}

		bc->cf_last->prev2_bs_head = bc->cf_last->prev_bs_head;
		bc->cf_last->prev_bs_head = bc->cf_last->curr_bs_head;
a497 4

	if (nalu->dst.rel && bc->r6xx_nop_after_rel_dst)
		insert_nop_r6xx(bc);

d501 1
a501 1
int r600_bytecode_add_alu(struct r600_bytecode *bc, const struct r600_bytecode_alu *alu)
d503 1
a503 1
	return r600_bytecode_add_alu_type(bc, alu, CF_OP_ALU);
d506 1
a506 1
static unsigned r600_bytecode_num_tex_and_vtx_instructions(const struct r600_bytecode *bc)
d508 1
a508 3
	switch (bc->chip_class) {
	case R600:
		return 8;
d510 26
a535 8
	case R700:
	case EVERGREEN:
	case CAYMAN:
		return 16;

	default:
		R600_ERR("Unknown chip class %d.\n", bc->chip_class);
		return 8;
d537 5
d544 1
a544 1
static inline boolean last_inst_was_not_vtx_fetch(struct r600_bytecode *bc)
d546 1
a546 8
	return !((r600_isa_cf(bc->cf_last->op)->flags & CF_FETCH) &&
			(bc->chip_class == CAYMAN ||
			bc->cf_last->op != CF_OP_TEX));
}

int r600_bytecode_add_vtx(struct r600_bytecode *bc, const struct r600_bytecode_vtx *vtx)
{
	struct r600_bytecode_vtx *nvtx = r600_bytecode_vtx();
d551 1
a551 1
	memcpy(nvtx, vtx, sizeof(struct r600_bytecode_vtx));
d555 4
a558 3
	    last_inst_was_not_vtx_fetch(bc) ||
	    bc->force_add_cf) {
		r = r600_bytecode_add_cf(bc);
d563 1
a563 14
		switch (bc->chip_class) {
		case R600:
		case R700:
		case EVERGREEN:
			bc->cf_last->op = CF_OP_VTX;
			break;
		case CAYMAN:
			bc->cf_last->op = CF_OP_TEX;
			break;
		default:
			R600_ERR("Unknown chip class %d.\n", bc->chip_class);
			free(nvtx);
			return -EINVAL;
		}
d569 1
a569 1
	if ((bc->cf_last->ndw / 4) >= r600_bytecode_num_tex_and_vtx_instructions(bc))
a570 4

	bc->ngpr = MAX2(bc->ngpr, vtx->src_gpr + 1);
	bc->ngpr = MAX2(bc->ngpr, vtx->dst_gpr + 1);

d574 1
a574 1
int r600_bytecode_add_tex(struct r600_bytecode *bc, const struct r600_bytecode_tex *tex)
d576 1
a576 1
	struct r600_bytecode_tex *ntex = r600_bytecode_tex();
d581 1
a581 16
	memcpy(ntex, tex, sizeof(struct r600_bytecode_tex));

	/* we can't fetch data und use it as texture lookup address in the same TEX clause */
	if (bc->cf_last != NULL &&
		bc->cf_last->op == CF_OP_TEX) {
		struct r600_bytecode_tex *ttex;
		LIST_FOR_EACH_ENTRY(ttex, &bc->cf_last->tex, list) {
			if (ttex->dst_gpr == ntex->src_gpr) {
				bc->force_add_cf = 1;
				break;
			}
		}
		/* slight hack to make gradients always go into same cf */
		if (ntex->op == FETCH_OP_SET_GRADIENTS_H)
			bc->force_add_cf = 1;
	}
d585 1
a585 1
		bc->cf_last->op != CF_OP_TEX ||
d587 1
a587 1
		r = r600_bytecode_add_cf(bc);
d592 1
a592 7
		bc->cf_last->op = CF_OP_TEX;
	}
	if (ntex->src_gpr >= bc->ngpr) {
		bc->ngpr = ntex->src_gpr + 1;
	}
	if (ntex->dst_gpr >= bc->ngpr) {
		bc->ngpr = ntex->dst_gpr + 1;
d598 1
a598 1
	if ((bc->cf_last->ndw / 4) >= r600_bytecode_num_tex_and_vtx_instructions(bc))
d603 1
a603 1
int r600_bytecode_add_cfinst(struct r600_bytecode *bc, unsigned op)
d606 1
a606 1
	r = r600_bytecode_add_cf(bc);
d611 1
a611 1
	bc->cf_last->op = op;
d615 2
a616 1
int cm_bytecode_add_cf_end(struct r600_bytecode *bc)
d618 1
a618 2
	return r600_bytecode_add_cfinst(bc, CF_OP_CF_END);
}
d620 23
a642 5
/* common to all 3 families */
static int r600_bytecode_vtx_build(struct r600_bytecode *bc, struct r600_bytecode_vtx *vtx, unsigned id)
{
	bc->bytecode[id] = S_SQ_VTX_WORD0_BUFFER_ID(vtx->buffer_id) |
			S_SQ_VTX_WORD0_FETCH_TYPE(vtx->fetch_type) |
d644 2
a645 4
			S_SQ_VTX_WORD0_SRC_SEL_X(vtx->src_sel_x);
	if (bc->chip_class < CAYMAN)
		bc->bytecode[id] |= S_SQ_VTX_WORD0_MEGA_FETCH_COUNT(vtx->mega_fetch_count);
	id++;
d656 1
a656 5
	bc->bytecode[id] = S_SQ_VTX_WORD2_OFFSET(vtx->offset)|
				S_SQ_VTX_WORD2_ENDIAN_SWAP(vtx->endian);
	if (bc->chip_class < CAYMAN)
		bc->bytecode[id] |= S_SQ_VTX_WORD2_MEGA_FETCH(1);
	id++;
d662 1
a662 1
static int r600_bytecode_tex_build(struct r600_bytecode *bc, struct r600_bytecode_tex *tex, unsigned id)
d664 1
a664 3
	bc->bytecode[id++] = S_SQ_TEX_WORD0_TEX_INST(
					r600_isa_fetch_opcode(bc->isa->hw_class, tex->op)) |
			    EG_S_SQ_TEX_WORD0_INST_MOD(tex->inst_mod) |
d692 1
a692 1
static int r600_bytecode_alu_build(struct r600_bytecode *bc, struct r600_bytecode_alu *alu, unsigned id)
d694 1
a694 1
	unsigned opcode = r600_isa_alu_opcode(bc->isa->hw_class, alu->op);
a704 2
				S_SQ_ALU_WORD0_INDEX_MODE(alu->index_mode) |
				S_SQ_ALU_WORD0_PRED_SEL(alu->pred_sel) |
d716 1
a716 1
					S_SQ_ALU_WORD1_OP3_ALU_INST(opcode) |
d726 1
a726 2
					S_SQ_ALU_WORD1_OP2_OMOD(alu->omod) |
					S_SQ_ALU_WORD1_OP2_ALU_INST(opcode) |
d728 10
a737 2
					S_SQ_ALU_WORD1_OP2_UPDATE_EXECUTE_MASK(alu->execute_mask) |
					S_SQ_ALU_WORD1_OP2_UPDATE_PRED(alu->update_pred);
a741 8
static void r600_bytecode_cf_vtx_build(uint32_t *bytecode, const struct r600_bytecode_cf *cf)
{
	*bytecode++ = S_SQ_CF_WORD0_ADDR(cf->addr >> 1);
	*bytecode++ = S_SQ_CF_WORD1_CF_INST(r600_isa_cf_opcode(ISA_CC_R600, cf->op)) |
			S_SQ_CF_WORD1_BARRIER(1) |
			S_SQ_CF_WORD1_COUNT((cf->ndw / 4) - 1);
}

d743 1
a743 1
static int r600_bytecode_cf_build(struct r600_bytecode *bc, struct r600_bytecode_cf *cf)
a745 3
	const struct cf_op_info *cfop = r600_isa_cf(cf->op);
	unsigned opcode = r600_isa_cf_opcode(bc->isa->hw_class, cf->op);

d747 3
a749 4
	if (cf->op == CF_NATIVE) {
		bc->bytecode[id++] = cf->isa[0];
		bc->bytecode[id++] = cf->isa[1];
	} else if (cfop->flags & CF_ALU) {
d751 8
a758 8
			S_SQ_CF_ALU_WORD0_KCACHE_MODE0(cf->kcache[0].mode) |
			S_SQ_CF_ALU_WORD0_KCACHE_BANK0(cf->kcache[0].bank) |
			S_SQ_CF_ALU_WORD0_KCACHE_BANK1(cf->kcache[1].bank);

		bc->bytecode[id++] = S_SQ_CF_ALU_WORD1_CF_INST(opcode) |
			S_SQ_CF_ALU_WORD1_KCACHE_MODE1(cf->kcache[1].mode) |
			S_SQ_CF_ALU_WORD1_KCACHE_ADDR0(cf->kcache[0].addr) |
			S_SQ_CF_ALU_WORD1_KCACHE_ADDR1(cf->kcache[1].addr) |
d760 1
a760 1
					S_SQ_CF_ALU_WORD1_USES_WATERFALL(bc->chip_class == R600 ? cf->r6xx_uses_waterfall : 0) |
d762 11
a772 6
	} else if (cfop->flags & CF_FETCH) {
		if (bc->chip_class == R700)
			r700_bytecode_cf_vtx_build(&bc->bytecode[id], cf);
		else
			r600_bytecode_cf_vtx_build(&bc->bytecode[id], cf);
	} else if (cfop->flags & CF_EXP) {
d777 1
a777 2
		bc->bytecode[id++] = S_SQ_CF_ALLOC_EXPORT_WORD1_BURST_COUNT(cf->output.burst_count - 1) |
			S_SQ_CF_ALLOC_EXPORT_WORD1_SWIZ_SEL_X(cf->output.swizzle_x) |
d782 1
a782 1
			S_SQ_CF_ALLOC_EXPORT_WORD1_CF_INST(opcode) |
d784 10
a793 12
	} else if (cfop->flags & CF_STRM) {
		bc->bytecode[id++] = S_SQ_CF_ALLOC_EXPORT_WORD0_RW_GPR(cf->output.gpr) |
			S_SQ_CF_ALLOC_EXPORT_WORD0_ELEM_SIZE(cf->output.elem_size) |
			S_SQ_CF_ALLOC_EXPORT_WORD0_ARRAY_BASE(cf->output.array_base) |
			S_SQ_CF_ALLOC_EXPORT_WORD0_TYPE(cf->output.type);
		bc->bytecode[id++] = S_SQ_CF_ALLOC_EXPORT_WORD1_BURST_COUNT(cf->output.burst_count - 1) |
			S_SQ_CF_ALLOC_EXPORT_WORD1_BARRIER(cf->output.barrier) |
			S_SQ_CF_ALLOC_EXPORT_WORD1_CF_INST(opcode) |
			S_SQ_CF_ALLOC_EXPORT_WORD1_END_OF_PROGRAM(cf->output.end_of_program) |
			S_SQ_CF_ALLOC_EXPORT_WORD1_BUF_ARRAY_SIZE(cf->output.array_size) |
			S_SQ_CF_ALLOC_EXPORT_WORD1_BUF_COMP_MASK(cf->output.comp_mask);
	} else {
d795 1
a795 1
		bc->bytecode[id++] = S_SQ_CF_WORD1_CF_INST(opcode) |
d799 5
d808 1
a808 1
int r600_bytecode_build(struct r600_bytecode *bc)
d810 4
a813 6
	struct r600_bytecode_cf *cf;
	struct r600_bytecode_alu *alu;
	struct r600_bytecode_vtx *vtx;
	struct r600_bytecode_tex *tex;
	uint32_t literal[4];
	unsigned nliteral;
d815 1
a815 4
	int i, r;

	if (!bc->nstack) // If not 0, Stack_size already provided by llvm
		bc->nstack = bc->stack.max_entries;
d817 2
d827 8
a834 1
		if (r600_isa_cf(cf->op)->flags & CF_FETCH) {
d837 19
a865 1
		const struct cf_op_info *cfop = r600_isa_cf(cf->op);
d867 2
a868 2
		if (bc->chip_class >= EVERGREEN)
			r = eg_bytecode_cf_build(bc, cf);
d870 1
a870 1
			r = r600_bytecode_cf_build(bc, cf);
d873 3
a875 3
		if (cfop->flags & CF_ALU) {
			nliteral = 0;
			memset(literal, 0, sizeof(literal));
d877 3
a879 9
				r = r600_bytecode_alu_nliterals(bc, alu, literal, &nliteral);
				if (r)
					return r;
				r600_bytecode_alu_adjust_literals(bc, alu, literal, nliteral);
				r600_bytecode_assign_kcache_banks(bc, alu, cf->kcache);

				switch(bc->chip_class) {
				case R600:
					r = r600_bytecode_alu_build(bc, alu, addr);
d881 3
a883 4
				case R700:
				case EVERGREEN: /* eg alu is same encoding as r700 */
				case CAYMAN:
					r = r700_bytecode_alu_build(bc, alu, addr);
d886 1
a886 1
					R600_ERR("unknown chip class %d.\n", bc->chip_class);
d893 1
a893 5
					for (i = 0; i < align(nliteral, 2); ++i) {
						bc->bytecode[addr++] = literal[i];
					}
					nliteral = 0;
					memset(literal, 0, sizeof(literal));
d896 3
a898 1
		} else if (cf->op == CF_OP_VTX) {
d900 1
a900 9
				r = r600_bytecode_vtx_build(bc, vtx, addr);
				if (r)
					return r;
				addr += 4;
			}
		} else if (cf->op == CF_OP_TEX) {
			LIST_FOR_EACH_ENTRY(vtx, &cf->vtx, list) {
				assert(bc->chip_class >= EVERGREEN);
				r = r600_bytecode_vtx_build(bc, vtx, addr);
d905 2
d908 1
a908 1
				r = r600_bytecode_tex_build(bc, tex, addr);
d913 18
d936 1
a936 1
void r600_bytecode_clear(struct r600_bytecode *bc)
d938 1
a938 1
	struct r600_bytecode_cf *cf = NULL, *next_cf;
d944 3
a946 3
		struct r600_bytecode_alu *alu = NULL, *next_alu;
		struct r600_bytecode_tex *tex = NULL, *next_tex;
		struct r600_bytecode_tex *vtx = NULL, *next_vtx;
d972 1
a972 1
static int print_swizzle(unsigned swz)
d974 1
a974 156
	const char * swzchars = "xyzw01?_";
	assert(swz<8 && swz != 6);
	return fprintf(stderr, "%c", swzchars[swz]);
}

static int print_sel(unsigned sel, unsigned rel, unsigned index_mode,
		unsigned need_brackets)
{
	int o = 0;
	if (rel && index_mode >= 5 && sel < 128)
		o += fprintf(stderr, "G");
	if (rel || need_brackets) {
		o += fprintf(stderr, "[");
	}
	o += fprintf(stderr, "%d", sel);
	if (rel) {
		if (index_mode == 0 || index_mode == 6)
			o += fprintf(stderr, "+AR");
		else if (index_mode == 4)
			o += fprintf(stderr, "+AL");
	}
	if (rel || need_brackets) {
		o += fprintf(stderr, "]");
	}
	return o;
}

static int print_dst(struct r600_bytecode_alu *alu)
{
	int o = 0;
	unsigned sel = alu->dst.sel;
	char reg_char = 'R';
	if (sel > 128 - 4) { /* clause temporary gpr */
		sel -= 128 - 4;
		reg_char = 'T';
	}

	if (alu->dst.write || alu->is_op3) {
		o += fprintf(stderr, "%c", reg_char);
		o += print_sel(alu->dst.sel, alu->dst.rel, alu->index_mode, 0);
	} else {
		o += fprintf(stderr, "__");
	}
	o += fprintf(stderr, ".");
	o += print_swizzle(alu->dst.chan);
	return o;
}

static int print_src(struct r600_bytecode_alu *alu, unsigned idx)
{
	int o = 0;
	struct r600_bytecode_alu_src *src = &alu->src[idx];
	unsigned sel = src->sel, need_sel = 1, need_chan = 1, need_brackets = 0;

	if (src->neg)
		o += fprintf(stderr,"-");
	if (src->abs)
		o += fprintf(stderr,"|");

	if (sel < 128 - 4) {
		o += fprintf(stderr, "R");
	} else if (sel < 128) {
		o += fprintf(stderr, "T");
		sel -= 128 - 4;
	} else if (sel < 160) {
		o += fprintf(stderr, "KC0");
		need_brackets = 1;
		sel -= 128;
	} else if (sel < 192) {
		o += fprintf(stderr, "KC1");
		need_brackets = 1;
		sel -= 160;
	} else if (sel >= 512) {
		o += fprintf(stderr, "C%d", src->kc_bank);
		need_brackets = 1;
		sel -= 512;
	} else if (sel >= 448) {
		o += fprintf(stderr, "Param");
		sel -= 448;
		need_chan = 0;
	} else if (sel >= 288) {
		o += fprintf(stderr, "KC3");
		need_brackets = 1;
		sel -= 288;
	} else if (sel >= 256) {
		o += fprintf(stderr, "KC2");
		need_brackets = 1;
		sel -= 256;
	} else {
		need_sel = 0;
		need_chan = 0;
		switch (sel) {
		case V_SQ_ALU_SRC_PS:
			o += fprintf(stderr, "PS");
			break;
		case V_SQ_ALU_SRC_PV:
			o += fprintf(stderr, "PV");
			need_chan = 1;
			break;
		case V_SQ_ALU_SRC_LITERAL:
			o += fprintf(stderr, "[0x%08X %f]", src->value, *(float*)&src->value);
			break;
		case V_SQ_ALU_SRC_0_5:
			o += fprintf(stderr, "0.5");
			break;
		case V_SQ_ALU_SRC_M_1_INT:
			o += fprintf(stderr, "-1");
			break;
		case V_SQ_ALU_SRC_1_INT:
			o += fprintf(stderr, "1");
			break;
		case V_SQ_ALU_SRC_1:
			o += fprintf(stderr, "1.0");
			break;
		case V_SQ_ALU_SRC_0:
			o += fprintf(stderr, "0");
			break;
		default:
			o += fprintf(stderr, "??IMM_%d", sel);
			break;
		}
	}

	if (need_sel)
		o += print_sel(sel, src->rel, alu->index_mode, need_brackets);

	if (need_chan) {
		o += fprintf(stderr, ".");
		o += print_swizzle(src->chan);
	}

	if (src->abs)
		o += fprintf(stderr,"|");

	return o;
}

static int print_indent(int p, int c)
{
	int o = 0;
	while (p++ < c)
		o += fprintf(stderr, " ");
	return o;
}

void r600_bytecode_disasm(struct r600_bytecode *bc)
{
	static int index = 0;
	struct r600_bytecode_cf *cf = NULL;
	struct r600_bytecode_alu *alu = NULL;
	struct r600_bytecode_vtx *vtx = NULL;
	struct r600_bytecode_tex *tex = NULL;

	unsigned i, id, ngr = 0, last;
	uint32_t literal[4];
	unsigned nliteral;
d977 2
a978 2
	switch (bc->chip_class) {
	case R700:
d981 1
a981 1
	case EVERGREEN:
d984 1
a984 4
	case CAYMAN:
		chip = 'C';
		break;
	case R600:
d989 7
a995 3
	fprintf(stderr, "bytecode %d dw -- %d gprs -- %d nstack -------------\n",
	        bc->ndw, bc->ngpr, bc->nstack);
	fprintf(stderr, "shader %d -- %c\n", index++, chip);
d997 4
a1000 49
	LIST_FOR_EACH_ENTRY(cf, &bc->cf, list) {
		id = cf->id;
		if (cf->op == CF_NATIVE) {
			fprintf(stderr, "%04d %08X %08X CF_NATIVE\n", id, bc->bytecode[id],
					bc->bytecode[id + 1]);
		} else {
			const struct cf_op_info *cfop = r600_isa_cf(cf->op);
			if (cfop->flags & CF_ALU) {
				if (cf->eg_alu_extended) {
					fprintf(stderr, "%04d %08X %08X  %s\n", id, bc->bytecode[id],
							bc->bytecode[id + 1], "ALU_EXT");
					id += 2;
				}
				fprintf(stderr, "%04d %08X %08X  %s ", id, bc->bytecode[id],
						bc->bytecode[id + 1], cfop->name);
				fprintf(stderr, "%d @@%d ", cf->ndw / 2, cf->addr);
				for (i = 0; i < 4; ++i) {
					if (cf->kcache[i].mode) {
						int c_start = (cf->kcache[i].addr << 4);
						int c_end = c_start + (cf->kcache[i].mode << 4);
						fprintf(stderr, "KC%d[CB%d:%d-%d] ",
						        i, cf->kcache[i].bank, c_start, c_end);
					}
				}
				fprintf(stderr, "\n");
			} else if (cfop->flags & CF_FETCH) {
				fprintf(stderr, "%04d %08X %08X  %s ", id, bc->bytecode[id],
						bc->bytecode[id + 1], cfop->name);
				fprintf(stderr, "%d @@%d ", cf->ndw / 4, cf->addr);
				fprintf(stderr, "\n");
			} else if (cfop->flags & CF_EXP) {
				int o = 0;
				const char *exp_type[] = {"PIXEL", "POS  ", "PARAM"};
				o += fprintf(stderr, "%04d %08X %08X  %s ", id, bc->bytecode[id],
						bc->bytecode[id + 1], cfop->name);
				o += print_indent(o, 43);
				o += fprintf(stderr, "%s ", exp_type[cf->output.type]);
				if (cf->output.burst_count > 1) {
					o += fprintf(stderr, "%d-%d ", cf->output.array_base,
							cf->output.array_base + cf->output.burst_count - 1);

					o += print_indent(o, 55);
					o += fprintf(stderr, "R%d-%d.", cf->output.gpr,
							cf->output.gpr + cf->output.burst_count - 1);
				} else {
					o += fprintf(stderr, "%d ", cf->output.array_base);
					o += print_indent(o, 55);
					o += fprintf(stderr, "R%d.", cf->output.gpr);
				}
d1002 65
a1066 196
				o += print_swizzle(cf->output.swizzle_x);
				o += print_swizzle(cf->output.swizzle_y);
				o += print_swizzle(cf->output.swizzle_z);
				o += print_swizzle(cf->output.swizzle_w);

				print_indent(o, 67);

				fprintf(stderr, " ES:%X ", cf->output.elem_size);
				if (!cf->output.barrier)
					fprintf(stderr, "NO_BARRIER ");
				if (cf->output.end_of_program)
					fprintf(stderr, "EOP ");
				fprintf(stderr, "\n");
			} else if (r600_isa_cf(cf->op)->flags & CF_STRM) {
				int o = 0;
				const char *exp_type[] = {"WRITE", "WRITE_IND", "WRITE_ACK",
						"WRITE_IND_ACK"};
				o += fprintf(stderr, "%04d %08X %08X  %s ", id,
						bc->bytecode[id], bc->bytecode[id + 1], cfop->name);
				o += print_indent(o, 43);
				o += fprintf(stderr, "%s ", exp_type[cf->output.type]);
				if (cf->output.burst_count > 1) {
					o += fprintf(stderr, "%d-%d ", cf->output.array_base,
							cf->output.array_base + cf->output.burst_count - 1);
					o += print_indent(o, 55);
					o += fprintf(stderr, "R%d-%d.", cf->output.gpr,
							cf->output.gpr + cf->output.burst_count - 1);
				} else {
					o += fprintf(stderr, "%d ", cf->output.array_base);
					o += print_indent(o, 55);
					o += fprintf(stderr, "R%d.", cf->output.gpr);
				}
				for (i = 0; i < 4; ++i) {
					if (cf->output.comp_mask & (1 << i))
						o += print_swizzle(i);
					else
						o += print_swizzle(7);
				}

				o += print_indent(o, 67);

				fprintf(stderr, " ES:%i ", cf->output.elem_size);
				if (cf->output.array_size != 0xFFF)
					fprintf(stderr, "AS:%i ", cf->output.array_size);
				if (!cf->output.barrier)
					fprintf(stderr, "NO_BARRIER ");
				if (cf->output.end_of_program)
					fprintf(stderr, "EOP ");
				fprintf(stderr, "\n");
			} else {
				fprintf(stderr, "%04d %08X %08X  %s ", id, bc->bytecode[id],
						bc->bytecode[id + 1], cfop->name);
				fprintf(stderr, "@@%d ", cf->cf_addr);
				if (cf->cond)
					fprintf(stderr, "CND:%X ", cf->cond);
				if (cf->pop_count)
					fprintf(stderr, "POP:%X ", cf->pop_count);
				fprintf(stderr, "\n");
			}
		}

		id = cf->addr;
		nliteral = 0;
		last = 1;
		LIST_FOR_EACH_ENTRY(alu, &cf->alu, list) {
			const char *omod_str[] = {"","*2","*4","/2"};
			const struct alu_op_info *aop = r600_isa_alu(alu->op);
			int o = 0;

			r600_bytecode_alu_nliterals(bc, alu, literal, &nliteral);
			o += fprintf(stderr, " %04d %08X %08X  ", id, bc->bytecode[id], bc->bytecode[id+1]);
			if (last)
				o += fprintf(stderr, "%4d ", ++ngr);
			else
				o += fprintf(stderr, "     ");
			o += fprintf(stderr, "%c%c %c ", alu->execute_mask ? 'M':' ',
					alu->update_pred ? 'P':' ',
					alu->pred_sel ? alu->pred_sel==2 ? '0':'1':' ');

			o += fprintf(stderr, "%s%s%s ", aop->name,
					omod_str[alu->omod], alu->dst.clamp ? "_sat":"");

			o += print_indent(o,60);
			o += print_dst(alu);
			for (i = 0; i < aop->src_count; ++i) {
				o += fprintf(stderr, i == 0 ? ",  ": ", ");
				o += print_src(alu, i);
			}

			if (alu->bank_swizzle) {
				o += print_indent(o,75);
				o += fprintf(stderr, "  BS:%d", alu->bank_swizzle);
			}

			fprintf(stderr, "\n");
			id += 2;

			if (alu->last) {
				for (i = 0; i < nliteral; i++, id++) {
					float *f = (float*)(bc->bytecode + id);
					o = fprintf(stderr, " %04d %08X", id, bc->bytecode[id]);
					print_indent(o, 60);
					fprintf(stderr, " %f (%d)\n", *f, *(bc->bytecode + id));
				}
				id += nliteral & 1;
				nliteral = 0;
			}
			last = alu->last;
		}

		LIST_FOR_EACH_ENTRY(tex, &cf->tex, list) {
			int o = 0;
			o += fprintf(stderr, " %04d %08X %08X %08X   ", id, bc->bytecode[id],
					bc->bytecode[id + 1], bc->bytecode[id + 2]);

			o += fprintf(stderr, "%s ", r600_isa_fetch(tex->op)->name);

			o += print_indent(o, 50);

			o += fprintf(stderr, "R%d.", tex->dst_gpr);
			o += print_swizzle(tex->dst_sel_x);
			o += print_swizzle(tex->dst_sel_y);
			o += print_swizzle(tex->dst_sel_z);
			o += print_swizzle(tex->dst_sel_w);

			o += fprintf(stderr, ", R%d.", tex->src_gpr);
			o += print_swizzle(tex->src_sel_x);
			o += print_swizzle(tex->src_sel_y);
			o += print_swizzle(tex->src_sel_z);
			o += print_swizzle(tex->src_sel_w);

			o += fprintf(stderr, ",  RID:%d", tex->resource_id);
			o += fprintf(stderr, ", SID:%d  ", tex->sampler_id);

			if (tex->lod_bias)
				fprintf(stderr, "LB:%d ", tex->lod_bias);

			fprintf(stderr, "CT:%c%c%c%c ",
					tex->coord_type_x ? 'N' : 'U',
					tex->coord_type_y ? 'N' : 'U',
					tex->coord_type_z ? 'N' : 'U',
					tex->coord_type_w ? 'N' : 'U');

			if (tex->offset_x)
				fprintf(stderr, "OX:%d ", tex->offset_x);
			if (tex->offset_y)
				fprintf(stderr, "OY:%d ", tex->offset_y);
			if (tex->offset_z)
				fprintf(stderr, "OZ:%d ", tex->offset_z);

			id += 4;
			fprintf(stderr, "\n");
		}

		LIST_FOR_EACH_ENTRY(vtx, &cf->vtx, list) {
			int o = 0;
			const char * fetch_type[] = {"VERTEX", "INSTANCE", ""};
			o += fprintf(stderr, " %04d %08X %08X %08X   ", id, bc->bytecode[id],
					bc->bytecode[id + 1], bc->bytecode[id + 2]);

			o += fprintf(stderr, "%s ", r600_isa_fetch(vtx->op)->name);

			o += print_indent(o, 50);

			o += fprintf(stderr, "R%d.", vtx->dst_gpr);
			o += print_swizzle(vtx->dst_sel_x);
			o += print_swizzle(vtx->dst_sel_y);
			o += print_swizzle(vtx->dst_sel_z);
			o += print_swizzle(vtx->dst_sel_w);

			o += fprintf(stderr, ", R%d.", vtx->src_gpr);
			o += print_swizzle(vtx->src_sel_x);

			if (vtx->offset)
				fprintf(stderr, " +%db", vtx->offset);

			o += print_indent(o, 55);

			fprintf(stderr, ",  RID:%d ", vtx->buffer_id);

			fprintf(stderr, "%s ", fetch_type[vtx->fetch_type]);

			if (bc->chip_class < CAYMAN && vtx->mega_fetch_count)
				fprintf(stderr, "MFC:%d ", vtx->mega_fetch_count);

			fprintf(stderr, "UCF:%d ", vtx->use_const_fields);
			fprintf(stderr, "FMT(DTA:%d ", vtx->data_format);
			fprintf(stderr, "NUM:%d ", vtx->num_format_all);
			fprintf(stderr, "COMP:%d ", vtx->format_comp_all);
			fprintf(stderr, "MODE:%d)\n", vtx->srf_mode_all);

			id += 4;
		}
	}

	fprintf(stderr, "--------------------------------------\n");
d1069 2
a1070 3
void r600_vertex_data_type(enum pipe_format pformat,
				  unsigned *format,
				  unsigned *num_format, unsigned *format_comp, unsigned *endian)
a1077 1
	*endian = ENDIAN_NONE;
a1090 2
	*endian = r600_endian_swap(desc->channel[i].size);

d1092 1
a1092 1
	/* Half-floats, floats, ints */
d1104 2
d1145 2
a1151 6
		case 10:
			if (desc->nr_channels != 4)
				goto out_unknown;

			*format = FMT_2_10_10_10;
			break;
d1161 2
d1195 4
a1198 10

	*num_format = 0;
	if (desc->channel[i].type == UTIL_FORMAT_TYPE_UNSIGNED ||
	    desc->channel[i].type == UTIL_FORMAT_TYPE_SIGNED) {
		if (!desc->channel[i].normalized) {
			if (desc->channel[i].pure_integer)
				*num_format = 1;
			else
				*num_format = 2;
		}
d1205 16
a1220 61
void *r600_create_vertex_fetch_shader(struct pipe_context *ctx,
				      unsigned count,
				      const struct pipe_vertex_element *elements)
{
	struct r600_context *rctx = (struct r600_context *)ctx;
	struct r600_bytecode bc;
	struct r600_bytecode_vtx vtx;
	const struct util_format_description *desc;
	unsigned fetch_resource_start = rctx->chip_class >= EVERGREEN ? 0 : 160;
	unsigned format, num_format, format_comp, endian;
	uint32_t *bytecode;
	int i, j, r, fs_size;
	struct r600_fetch_shader *shader;
	unsigned sb_disasm = rctx->screen->debug_flags & (DBG_SB_DISASM | DBG_SB);

	assert(count < 32);

	memset(&bc, 0, sizeof(bc));
	r600_bytecode_init(&bc, rctx->chip_class, rctx->family,
			   rctx->screen->has_compressed_msaa_texturing);

	bc.isa = rctx->isa;

	for (i = 0; i < count; i++) {
		if (elements[i].instance_divisor > 1) {
			if (rctx->chip_class == CAYMAN) {
				for (j = 0; j < 4; j++) {
					struct r600_bytecode_alu alu;
					memset(&alu, 0, sizeof(alu));
					alu.op = ALU_OP2_MULHI_UINT;
					alu.src[0].sel = 0;
					alu.src[0].chan = 3;
					alu.src[1].sel = V_SQ_ALU_SRC_LITERAL;
					alu.src[1].value = (1ll << 32) / elements[i].instance_divisor + 1;
					alu.dst.sel = i + 1;
					alu.dst.chan = j;
					alu.dst.write = j == 3;
					alu.last = j == 3;
					if ((r = r600_bytecode_add_alu(&bc, &alu))) {
						r600_bytecode_clear(&bc);
						return NULL;
					}
				}
			} else {
				struct r600_bytecode_alu alu;
				memset(&alu, 0, sizeof(alu));
				alu.op = ALU_OP2_MULHI_UINT;
				alu.src[0].sel = 0;
				alu.src[0].chan = 3;
				alu.src[1].sel = V_SQ_ALU_SRC_LITERAL;
				alu.src[1].value = (1ll << 32) / elements[i].instance_divisor + 1;
				alu.dst.sel = i + 1;
				alu.dst.chan = 3;
				alu.dst.write = 1;
				alu.last = 1;
				if ((r = r600_bytecode_add_alu(&bc, &alu))) {
					r600_bytecode_clear(&bc);
					return NULL;
				}
			}
		}
d1222 4
a1225 40

	for (i = 0; i < count; i++) {
		r600_vertex_data_type(elements[i].src_format,
				      &format, &num_format, &format_comp, &endian);

		desc = util_format_description(elements[i].src_format);
		if (desc == NULL) {
			r600_bytecode_clear(&bc);
			R600_ERR("unknown format %d\n", elements[i].src_format);
			return NULL;
		}

		if (elements[i].src_offset > 65535) {
			r600_bytecode_clear(&bc);
			R600_ERR("too big src_offset: %u\n", elements[i].src_offset);
			return NULL;
		}

		memset(&vtx, 0, sizeof(vtx));
		vtx.buffer_id = elements[i].vertex_buffer_index + fetch_resource_start;
		vtx.fetch_type = elements[i].instance_divisor ? 1 : 0;
		vtx.src_gpr = elements[i].instance_divisor > 1 ? i + 1 : 0;
		vtx.src_sel_x = elements[i].instance_divisor ? 3 : 0;
		vtx.mega_fetch_count = 0x1F;
		vtx.dst_gpr = i + 1;
		vtx.dst_sel_x = desc->swizzle[0];
		vtx.dst_sel_y = desc->swizzle[1];
		vtx.dst_sel_z = desc->swizzle[2];
		vtx.dst_sel_w = desc->swizzle[3];
		vtx.data_format = format;
		vtx.num_format_all = num_format;
		vtx.format_comp_all = format_comp;
		vtx.srf_mode_all = 1;
		vtx.offset = elements[i].src_offset;
		vtx.endian = endian;

		if ((r = r600_bytecode_add_vtx(&bc, &vtx))) {
			r600_bytecode_clear(&bc);
			return NULL;
		}
d1227 2
d1230 7
a1236 1
	r600_bytecode_add_cfinst(&bc, CF_OP_RET);
d1238 8
a1245 3
	if ((r = r600_bytecode_build(&bc))) {
		r600_bytecode_clear(&bc);
		return NULL;
d1248 4
a1251 16
	if (rctx->screen->debug_flags & DBG_FS) {
		fprintf(stderr, "--------------------------------------------------------------\n");
		fprintf(stderr, "Vertex elements state:\n");
		for (i = 0; i < count; i++) {
			fprintf(stderr, "   ");
			util_dump_vertex_element(stderr, elements+i);
			fprintf(stderr, "\n");
		}

		if (!sb_disasm) {
			r600_bytecode_disasm(&bc);

			fprintf(stderr, "______________________________________________________________\n");
		} else {
			r600_sb_bytecode_process(rctx, &bc, NULL, 1 /*dump*/, 0 /*optimize*/);
		}
d1254 5
a1258 7
	fs_size = bc.ndw*4;

	/* Allocate the CSO. */
	shader = CALLOC_STRUCT(r600_fetch_shader);
	if (!shader) {
		r600_bytecode_clear(&bc);
		return NULL;
d1261 10
a1270 6
	u_suballocator_alloc(rctx->allocator_fetch_shader, fs_size, &shader->offset,
			     (struct pipe_resource**)&shader->buffer);
	if (!shader->buffer) {
		r600_bytecode_clear(&bc);
		FREE(shader);
		return NULL;
d1273 9
a1281 2
	bytecode = r600_buffer_mmap_sync_with_rings(rctx, shader->buffer, PIPE_TRANSFER_WRITE | PIPE_TRANSFER_UNSYNCHRONIZED);
	bytecode += shader->offset / 4;
d1283 6
a1288 3
	if (R600_BIG_ENDIAN) {
		for (i = 0; i < fs_size / 4; ++i) {
			bytecode[i] = util_bswap32(bc.bytecode[i]);
d1290 16
a1305 2
	} else {
		memcpy(bytecode, bc.bytecode, fs_size);
d1307 2
a1308 74
	rctx->ws->buffer_unmap(shader->buffer->cs_buf);

	r600_bytecode_clear(&bc);
	return shader;
}

void r600_bytecode_alu_read(struct r600_bytecode *bc,
		struct r600_bytecode_alu *alu, uint32_t word0, uint32_t word1)
{
	/* WORD0 */
	alu->src[0].sel = G_SQ_ALU_WORD0_SRC0_SEL(word0);
	alu->src[0].rel = G_SQ_ALU_WORD0_SRC0_REL(word0);
	alu->src[0].chan = G_SQ_ALU_WORD0_SRC0_CHAN(word0);
	alu->src[0].neg = G_SQ_ALU_WORD0_SRC0_NEG(word0);
	alu->src[1].sel = G_SQ_ALU_WORD0_SRC1_SEL(word0);
	alu->src[1].rel = G_SQ_ALU_WORD0_SRC1_REL(word0);
	alu->src[1].chan = G_SQ_ALU_WORD0_SRC1_CHAN(word0);
	alu->src[1].neg = G_SQ_ALU_WORD0_SRC1_NEG(word0);
	alu->index_mode = G_SQ_ALU_WORD0_INDEX_MODE(word0);
	alu->pred_sel = G_SQ_ALU_WORD0_PRED_SEL(word0);
	alu->last = G_SQ_ALU_WORD0_LAST(word0);

	/* WORD1 */
	alu->bank_swizzle = G_SQ_ALU_WORD1_BANK_SWIZZLE(word1);
	if (alu->bank_swizzle)
		alu->bank_swizzle_force = alu->bank_swizzle;
	alu->dst.sel = G_SQ_ALU_WORD1_DST_GPR(word1);
	alu->dst.rel = G_SQ_ALU_WORD1_DST_REL(word1);
	alu->dst.chan = G_SQ_ALU_WORD1_DST_CHAN(word1);
	alu->dst.clamp = G_SQ_ALU_WORD1_CLAMP(word1);
	if (G_SQ_ALU_WORD1_ENCODING(word1)) /*ALU_DWORD1_OP3*/
	{
		alu->is_op3 = 1;
		alu->src[2].sel = G_SQ_ALU_WORD1_OP3_SRC2_SEL(word1);
		alu->src[2].rel = G_SQ_ALU_WORD1_OP3_SRC2_REL(word1);
		alu->src[2].chan = G_SQ_ALU_WORD1_OP3_SRC2_CHAN(word1);
		alu->src[2].neg = G_SQ_ALU_WORD1_OP3_SRC2_NEG(word1);
		alu->op = r600_isa_alu_by_opcode(bc->isa,
				G_SQ_ALU_WORD1_OP3_ALU_INST(word1), /* is_op3 = */ 1);

	}
	else /*ALU_DWORD1_OP2*/
	{
		alu->src[0].abs = G_SQ_ALU_WORD1_OP2_SRC0_ABS(word1);
		alu->src[1].abs = G_SQ_ALU_WORD1_OP2_SRC1_ABS(word1);
		alu->op = r600_isa_alu_by_opcode(bc->isa,
				G_SQ_ALU_WORD1_OP2_ALU_INST(word1), /* is_op3 = */ 0);
		alu->omod = G_SQ_ALU_WORD1_OP2_OMOD(word1);
		alu->dst.write = G_SQ_ALU_WORD1_OP2_WRITE_MASK(word1);
		alu->update_pred = G_SQ_ALU_WORD1_OP2_UPDATE_PRED(word1);
		alu->execute_mask =
			G_SQ_ALU_WORD1_OP2_UPDATE_EXECUTE_MASK(word1);
	}
}

void r600_bytecode_export_read(struct r600_bytecode *bc,
		struct r600_bytecode_output *output, uint32_t word0, uint32_t word1)
{
	output->array_base = G_SQ_CF_ALLOC_EXPORT_WORD0_ARRAY_BASE(word0);
	output->type = G_SQ_CF_ALLOC_EXPORT_WORD0_TYPE(word0);
	output->gpr = G_SQ_CF_ALLOC_EXPORT_WORD0_RW_GPR(word0);
	output->elem_size = G_SQ_CF_ALLOC_EXPORT_WORD0_ELEM_SIZE(word0);

	output->swizzle_x = G_SQ_CF_ALLOC_EXPORT_WORD1_SWIZ_SEL_X(word1);
	output->swizzle_y = G_SQ_CF_ALLOC_EXPORT_WORD1_SWIZ_SEL_Y(word1);
	output->swizzle_z = G_SQ_CF_ALLOC_EXPORT_WORD1_SWIZ_SEL_Z(word1);
	output->swizzle_w = G_SQ_CF_ALLOC_EXPORT_WORD1_SWIZ_SEL_W(word1);
	output->burst_count = G_SQ_CF_ALLOC_EXPORT_WORD1_BURST_COUNT(word1);
	output->end_of_program = G_SQ_CF_ALLOC_EXPORT_WORD1_END_OF_PROGRAM(word1);
    output->op = r600_isa_cf_by_opcode(bc->isa,
			G_SQ_CF_ALLOC_EXPORT_WORD1_CF_INST(word1), 0);
	output->barrier = G_SQ_CF_ALLOC_EXPORT_WORD1_BARRIER(word1);
	output->array_size = G_SQ_CF_ALLOC_EXPORT_WORD1_BUF_ARRAY_SIZE(word1);
	output->comp_mask = G_SQ_CF_ALLOC_EXPORT_WORD1_BUF_COMP_MASK(word1);
@


1.1.1.3
log
@Import Mesa 10.2.3
@
text
@d196 1
d206 1
a217 1
	bc->cf_last->barrier = 1;
d390 1
a390 1
	return (sel <= 127);
d1529 1
a1529 2
			S_SQ_CF_ALLOC_EXPORT_WORD0_TYPE(cf->output.type) |
			S_SQ_CF_ALLOC_EXPORT_WORD0_INDEX_GPR(cf->output.index_gpr);
d1535 1
a1535 1
			S_SQ_CF_ALLOC_EXPORT_WORD1_BARRIER(cf->barrier) |
d1537 2
a1538 2
			S_SQ_CF_ALLOC_EXPORT_WORD1_END_OF_PROGRAM(cf->end_of_program);
	} else if (cfop->flags & CF_MEM) {
d1542 1
a1542 2
			S_SQ_CF_ALLOC_EXPORT_WORD0_TYPE(cf->output.type) |
			S_SQ_CF_ALLOC_EXPORT_WORD0_INDEX_GPR(cf->output.index_gpr);
d1544 1
a1544 1
			S_SQ_CF_ALLOC_EXPORT_WORD1_BARRIER(cf->barrier) |
d1546 1
a1546 1
			S_SQ_CF_ALLOC_EXPORT_WORD1_END_OF_PROGRAM(cf->end_of_program) |
d1554 1
a1554 2
			                S_SQ_CF_WORD1_POP_COUNT(cf->pop_count) |
					S_SQ_CF_WORD1_END_OF_PROGRAM(cf->end_of_program);
d1935 1
a1935 1
				if (!cf->barrier)
d1937 1
a1937 1
				if (cf->end_of_program)
d1940 1
a1940 1
			} else if (r600_isa_cf(cf->op)->flags & CF_MEM) {
a1965 3
				if (cf->output.type == V_SQ_CF_ALLOC_EXPORT_WORD0_SQ_EXPORT_WRITE_IND)
					o += fprintf(stderr, " R%d", cf->output.index_gpr);

d1971 1
a1971 1
				if (!cf->barrier)
d1973 1
a1973 1
				if (cf->end_of_program)
a2136 6
	if (pformat == PIPE_FORMAT_R11G11B10_FLOAT) {
		*format = FMT_10_11_11_FLOAT;
		*endian = r600_endian_swap(32);
		return;
	}

d2279 1
a2279 1
	unsigned fetch_resource_start = rctx->b.chip_class >= EVERGREEN ? 0 : 160;
d2284 1
a2284 2
	unsigned no_sb = rctx->screen->b.debug_flags & DBG_NO_SB;
	unsigned sb_disasm = !no_sb || (rctx->screen->b.debug_flags & DBG_SB_DISASM);
d2289 1
a2289 1
	r600_bytecode_init(&bc, rctx->b.chip_class, rctx->b.family,
d2296 1
a2296 1
			if (rctx->b.chip_class == CAYMAN) {
d2382 1
a2382 1
	if (rctx->screen->b.debug_flags & DBG_FS) {
d2417 1
a2417 1
	bytecode = r600_buffer_map_sync_with_rings(&rctx->b, shader->buffer, PIPE_TRANSFER_WRITE | PIPE_TRANSFER_UNSYNCHRONIZED);
d2422 1
a2422 1
			bytecode[i] = util_cpu_to_le32(bc.bytecode[i]);
d2427 1
a2427 1
	rctx->b.ws->buffer_unmap(shader->buffer->cs_buf);
a2481 1
#if 0
a2501 1
#endif
@


1.1.1.4
log
@Import Mesa 10.2.7
@
text
@d2377 1
@


1.1.1.5
log
@Import Mesa 10.4.3
@
text
@a145 1
	bc->family = family;
a820 4
		if (alu->op == ALU_OP0_SET_CF_IDX0 ||
			alu->op == ALU_OP0_SET_CF_IDX1)
			return 0; /* data hazard with MOVA */

d886 1
a886 1
		unsigned bank, unsigned line, unsigned index_mode)
a908 1
				kcache[i].index_mode = index_mode;
a937 1
			kcache[i].index_mode = index_mode;
d951 1
a951 1
		unsigned bank, line, sel = alu->src[i].sel, index_mode;
a957 1
		index_mode = alu->src[i].kc_rel ? 1 : 0; // V_SQ_CF_INDEX_0 / V_SQ_CF_INDEX_NONE
d959 1
a959 1
		if ((r = r600_bytecode_alloc_kcache_line(bc, kcache, bank, line, index_mode)))
d1030 2
a1031 3
	/* if we actually used more than 2 kcache sets, or have relative indexing - use ALU_EXTENDED on eg+ */
	if (kcache[2].mode != V_SQ_CF_KCACHE_NOP ||
		kcache[0].index_mode || kcache[1].index_mode || kcache[2].index_mode || kcache[3].index_mode) {
a1150 7
	/* Load index register if required */
	if (bc->chip_class >= EVERGREEN) {
		for (i = 0; i < 3; i++)
			if (nalu->src[i].kc_bank && nalu->src[i].kc_rel)
				egcm_load_index_reg(bc, 0, true);
	}

a1275 6
	/* Load index register if required */
	if (bc->chip_class >= EVERGREEN) {
		if (vtx->buffer_index_mode)
			egcm_load_index_reg(bc, 0, false);
	}

a1321 6
	/* Load index register if required */
	if (bc->chip_class >= EVERGREEN) {
		if (tex->sampler_index_mode || tex->resource_index_mode)
			egcm_load_index_reg(bc, 1, false);
	}

a1401 2
	if (bc->chip_class >= EVERGREEN)
		bc->bytecode[id] |= ((vtx->buffer_index_mode & 0x3) << 21); // S_SQ_VTX_WORD2_BIM(vtx->buffer_index_mode);
d1412 1
a1412 1
	bc->bytecode[id] = S_SQ_TEX_WORD0_TEX_INST(
a1417 4
	if (bc->chip_class >= EVERGREEN)
		bc->bytecode[id] |= ((tex->sampler_index_mode & 0x3) << 27) | // S_SQ_TEX_WORD0_SIM(tex->sampler_index_mode);
				((tex->resource_index_mode & 0x3) << 25); // S_SQ_TEX_WORD0_RIM(tex->resource_index_mode)
	id++;
d1592 1
a1592 1
	bc->bytecode = calloc(4, bc->ndw);
a1848 1
	const char *index_mode[] = {"CF_INDEX_NONE", "CF_INDEX_0", "CF_INDEX_1"};
d1899 2
a1900 4
						fprintf(stderr, "KC%d[CB%d:%d-%d%s%s] ",
						        i, cf->kcache[i].bank, c_start, c_end,
						        cf->kcache[i].index_mode ? " " : "",
						        cf->kcache[i].index_mode ? index_mode[cf->kcache[i].index_mode] : "");
a2065 3
			if (tex->sampler_index_mode)
				fprintf(stderr, "SQ_%s ", index_mode[tex->sampler_index_mode]);

a2115 3

			if (bc->chip_class >= EVERGREEN && vtx->buffer_index_mode)
				fprintf(stderr, "SQ_%s ", index_mode[vtx->buffer_index_mode]);
@


1.1.1.6
log
@Import Mesa 10.2.9
@
text
@d146 1
d822 4
d891 1
a891 1
		unsigned bank, unsigned line)
d914 1
d944 1
d958 1
a958 1
		unsigned bank, line, sel = alu->src[i].sel;
d965 1
d967 1
a967 1
		if ((r = r600_bytecode_alloc_kcache_line(bc, kcache, bank, line)))
d1038 3
a1040 2
	/* if we actually used more than 2 kcache sets - use ALU_EXTENDED on eg+ */
	if (kcache[2].mode != V_SQ_CF_KCACHE_NOP) {
d1160 7
d1292 6
d1344 6
d1430 2
d1442 1
a1442 1
	bc->bytecode[id++] = S_SQ_TEX_WORD0_TEX_INST(
d1448 4
d1626 1
a1626 1
	bc->bytecode = calloc(1, bc->ndw * 4);
d1883 1
d1934 4
a1937 2
						fprintf(stderr, "KC%d[CB%d:%d-%d] ",
						        i, cf->kcache[i].bank, c_start, c_end);
d2103 3
d2156 3
@


